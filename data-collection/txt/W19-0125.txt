








































A logical and computational methodology for exploring systems of
phonotactic constraints

Dakotah Lambert
Earlham College

Richmond, Indiana, USA
djlambe11@earlham.edu

James Rogers
Earlham College

Richmond, Indiana, USA
jrogers@cs.earlham.edu

Abstract

We introduce a methodology built around a
logical analysis component based on a hi-
erarchy of classes of Subregular constraints
characterized by the kinds of features of a
string a mechanism must be sensitive to in or-
der to determine whether it satisfies the con-
straint, and a computational component built
around a publicly-available interactive work-
bench that implements, based on the equiv-
alence between logical formulae and finite-
state automata, a theorem prover for these
logics (even algorithmically extracting certain
classes of constraints), wherein the alternation
between these logical and computational anal-
yses can provide useful insight more easily
than using either in isolation.

We demonstrate this methodology by explor-
ing a series of examples drawn from the
StressTyp2 database (Goedemans et al., 2015)
of patterns of lexical (suprasegmental) stress.
Along the way we provide justification for the
underlying model-theoretic approach to for-
malizing phonotactic patterns and demonstrate
the ways in which this dual methodology can
be applied to a range of phonological issues.

1 Introduction

In this paper, we introduce a set of logical (model-
theoretic) and computational (automata-theoretic)
tools along with a methodology for exploring sys-
tems of constraints on strings that combines them.
We have incorporated these into a computational
workbench, which we use to demonstrate the ap-
plication of this methodology to the study of lexi-
cal (suprasegmental) stress patterns obtained from
StressTyp2 (Goedemans et al., 2015).

Although the formal tools we employ here are
tailored to phonotactics, the methodology we are
using — alternating between the logical and com-
putational tools in exploring the data — is appli-
cable, with suitably modified tools, to other as-

pects of phonology, syntax and semantics, as well
as many non-linguistic applications.

In our specific application, the phenomena we
must account for are phonotactic stress patterns
of human languages. Our facts are descriptions
of these patterns drawn from the literature, and
our methods are intended to support identification
and generalization of regularities and variations
both within and across languages. When we say
“constraints,” we are referring to these observed
facts.1 Often there will be constraints that are true
of some words in a language but not others. This
variation will be listed among the observed facts.
There may also be constraints true of all or most
languages. The expected universality of these con-
straints will also be among the observed facts.

With this notion of constraints, we identify the
following desiderata for systems of phonotactic
constraints:

1. The constraints should distinguish possible
unmarked words from those that are not pos-
sible. They must be complete, licensing all
and only the unmarked words, and consistent
in the logical sense.

2. The constraints should provide a useful foun-
dation for generalizing across languages. A
system should provide a means to compare
phonotactic constraints across languages and,
in particular, a means to identify potential
universals. At the same time the system must
provide a means of identifying unnecessary
constraints. Consequently, a system must
provide a means of determining if a set of

1Our use of the term ”constraint” here should not be con-
fused with the formalized notion of constraint in Optimality
Theoretic accounts of phonology, in which the violability of
constraints is fundamental to the formal framework. In the
sense we mean here, the constraints are the regularities of the
surface structure of language that an OT account is intended
to account for.

247
Proceedings of the Society for Computation in Linguistics (SCiL) 2019, pages 247-256.

New York City, New York, January 3-6, 2019



constraints implicitly satisfies constraints that
are not explicitly stated. Finally, the system
should, in principle, be capable of fully de-
scribing the entire range of attested human
languages in a uniform way.

3. The phenomena the constraints describe are
a consequence of actual human behavior.
Thus, there actually exists some physical
mechanism that can, in principle, determine
whether a given set of constraints are satisfied
by a given word. Further, these mechanisms
do this quickly. Hence the constraints must
be feasible in the sense that they lie at a rela-
tively low level of complexity with respect to
some computational model (but not necessar-
ily all such models). Finally, the constraints
are learnable. There are physical mecha-
nisms that in principle, given some (possibly
empty) set of universal constraints and suffi-
ciently many (possibly positive or negative)
examples, can generalize to an equivalent set
of constraints.

In the next section we sketch the model-
theoretic foundations of our methodology. We
then proceed, in Sections 3 and 4 to introduce the
analytic component of the methodology by apply-
ing it to examples drawn from StressTyp2.

In Section 5 we begin to explore the computa-
tional component by looking at the computational
and cognitive complexity of simple propositional
systems of constraints based on adjacency. We fol-
low that, in Section 6, with a similar exploration
of simple constraints based solely on precedence
(“long distance” constraints).

In Section 7 we describe the algorithmic mech-
anisms underlying the computational component
of the methodology. We then turn, in Section 8, to
sketch the space of classes of stringsets definable
with more powerful logical mechanisms beyond
the propositional logic characterizing these simple
classes.

In Sections 9 and 10 we lay out the full method-
ology and sketch the results of its application to
Yidin. Finally, we conclude by revisiting the
desiderata we list in the introduction. We then
summarize some of the results that have been ob-
tained using this methodology and close by noting
some of the ways the model-theoretic approach
has been generalized beyond phonotactics, all of
which are candidates for potential extensions of
our computational tools.

2 Logical Foundations

We interpret the descriptions of phonotactic stress
patterns collected in the StressTyp2 database as
sets of strings over an alphabet, Σ, of symbols,
each of which denotes a particular syllable type. In
this paper, we take Σ to represent syllable weight:
light (L) or heavy (H);2 along with diacritics de-
noting stress level: none (no mark), secondary
stress ( ` ), or primary stress ( ´ ). For our log-
ical formulae we include symbols denoting arbi-
trary weight (σ) and stress marks denoting arbi-
trary stress ( ∗ ), some stress (i.e., not unstressed)
( + ) and non-primary stress (i.e., either secondary

or unstressed) ( ). So σ
+
HLσ̀ would denote a

word consisting of an arbitrary unstressed syllable,
followed by a heavy syllable with either primary
or secondary stress, followed by a light syllable
with either secondary or no stress and followed by
any syllable with secondary stress.

The semantics of our logic is built on two re-
lations between strings. The first, based on ad-
jacency, is the substring relation. A string, v, is
a substring of another, w, if and only if (iff) the
symbols of v occur in order as a contiguous block
in w. Formally

v ! w def⇐⇒ w = w1vw2, w1, w2 ∈ Σ∗

The second relation is based on precedence. A
string, v, is a subsequence of another, w, iff the
symbols of v occur in w in order but not necessar-
ily contiguously. Formally

v ⊑ w def⇐⇒ v = v1v2 · · · vn, and
w = w1v1w2v2 · · · vnwn+1,
vi, wi ∈ Σ∗

2.1 Logical formulae
Our focus, in this paper, is on a propositional logic
in which the atoms are either substrings or subse-
quences of a string. The set of substrings occur-
ring in a string is traditionally referred to as its set
of factors. We extend this to subsequences, spec-
ifying substring factor or subsequence factor only
when necessary to avoid confusion.

Substring factors are denoted with just the se-
quence of symbols that comprise the factor. Sub-
sequence factors are distinguished by placing the
connective ‘. .’ between the symbols of the factor.

2The full database includes five levels of weight but we
need only these two here.

248



ϕ W |= ϕ
σ1σ2 · · · σn ∈ {!} · Σ∗ · {"} σ1σ2 · · · σn ! {!} · W · {"}

σ1 . . σ2 . . · · · . . σn, σ1σ2 · · · σn ∈ Σ∗ σ1σ2 · · · σn ⊑ W
¬ϕ W ̸|= ϕ

ϕ1 ∧ ϕ2 W |= ϕ1 and W |= ϕ2

Figure 1: The semantics of our logical formulae

Note that we do not license atoms that mix sub-
string and subsequence, although complex formu-
lae may well include atoms of both types. In ad-
dition, substring factors may include either a left-
end marker (‘!’) or a right-end marker (‘"’) or
both, in which case we say that they are anchored.
In addition to these atoms the language includes
the full set of Boolean connectives with their se-
mantics derived from the semantics of negation
(‘¬’) and conjunction (‘∧’).

The model-theoretic semantics of this logic are
given formally in Figure 1. An atom is true of a
string iff it is a factor of the appropriate kind of that
string. By augmenting the models with endmark-
ers in defining the semantics of substring models,
anchored substring factors are required to occur at
the either the left end or right end of the string
or to span the entire string, as appropriate. The
semantics of subsequence factors is insensitive to
string boundaries. The Boolean operators are de-
fined canonically. We use the notation ‘W |= ϕ’
to denote the satisfaction relation between strings
and formulae; a string W satisfies a formula ϕ iff
ϕ evaluates to TRUE with respect to the string W .

Note that, while our models (i.e., strings) have
internal structure which come into play when we
add quantifiers to the logic, that structure is only
significant here in assigning truth values to the
atoms. Each string is simply a Boolean valuation
of the set of all atoms occurring in a formula; this
is truly a propositional logic.

3 An example: Cambodian

Let us take for example the Cambodian language,
as described in StressTyp2:

(1) a. In words of all sizes, primary stress
falls on the final syllable.

b. In words of all sizes, secondary stress
falls on all heavy syllables.

c. Light syllables occur only immedi-
ately following heavy syllables.

d. Light monosyllables do not occur.

We begin by examining Constraint 1a. Using our
logical notation, we write this constraint as a pos-
itive literal:

(1a) σ́" (Preliminary)

Let us now continue to Constraint 1b. Here, we
may be tempted to say something like this:

(1b)
∗
H → H̀ (Wrong)

However, this would mean “If a heavy syllable
happens, then a heavy syllable with secondary
stress also happens.” What Constraint 1b re-
ally says is “No heavy syllable without secondary
stress occurs,” which in turn implies “No un-
stressed heavy syllable occurs, and no heavy syl-
lable with primary stress occurs.” So we write in-
stead a conjunction of two negative literals:

(1b) ¬H ∧ ¬H́ (Preliminary)
However, this is still not quite the correct con-
straint, as it would prevent primary stress on a
heavy syllable, which Cambodian requires if it is
final. As is not unusual, many of the descriptions
of stress patterns rely on common phonological as-
sumptions and are inconsistent or ambiguous in
their absence. Indeed, the constraint we actually
want is “No unstressed heavy syllables occur.”

(1b) ¬H (Final)
This is a single negative literal. In fact, we can
rewrite Constraint 1a as a negative literal as well:

(1a) ¬σ" (Preliminary)
Note that, since the semantics ‘σ’ is disjunctive,
this expands into a conjunction of four negative
literals:

(1a) ¬L"∧¬L̀"∧¬H"∧¬H̀" (Preliminary)
Next, we look at Constraint 1c. Its implication
is that a light syllable cannot immediately follow
another light syllable. Further, any light syllable
must be preceded by some (heavy) syllable, so
they do not begin a word:

249



(1c) ¬
∗
L

∗
L ∧ ¬!

∗
L (Final)

Finally, we have Constraint 1d, that light mono-
syllables do not occur:

(1d) ¬!
∗
L" (Final)

It is clear at this point that any word satisfying
Constraint 1c also satisfies Constraint 1d, so in-
cluding the latter is logically unnecessary. There-
fore the following conjunction suffices to describe
these constraints:

(1) ¬σ" ∧ ¬H ∧ ¬
∗
L

∗
L ∧ ¬!

∗
L (Preliminary)

This will be refined again at the end of the next
section.

As we will see shortly, this form, a conjunction
of negative literals, is significant from a cognitive
and complexity-theoretic perspective.

4 Phonotactic regularities

Constraint 1d is logically unnecessary in the de-
scription of Cambodian, but it is still interesting
phonologically. For example, the stress pattern of
Alawa, a language with only one syllable weight
and two levels of stress, is given in StressTyp2 as

(2) In words of all sizes, primary stress falls
on the penultimate syllable.

This constraint, of course, cannot apply to mono-
syllables, which have no penultimate syllable.
Again, the description relies on common phono-
logical assumptions; in this case the meaning is
ambiguous. There are four distinct possibilities for
what might happen to monosyllables in Alawa:

1. Monosyllables do not occur (similar to Con-
straint 1d).

2. Monosyllables occur, and are always
stressed.

3. Monosyllables occur, and are never stressed.

4. Monosyllables occur, and may or may not be
stressed.

In the case of Alawa, monosyllables do occur and
are always stressed, so Constraint 1d is not satis-
fied by Alawa, even though the original descrip-
tion suggests it would be.

This leads us naturally to consider what kinds
of constraints do, in fact, occur universally across
languages. One such putative universal is that

all words contain exactly one syllable with pri-
mary stress (which we will call 1-Stress). Hyman
(2009) argues, in the context of unifying the anal-
ysis of stress and tone, that 1-Stress is better an-
alyzed as the conjunction of two constraints, one
of which is that every word contains some sylla-
ble with primary stress (which, following Hyman,
we will refer to as obligatoriness). The other is
that no word contains more than one syllable with
primary stress (culminativity).

Between the description of Alawa and our ob-
servation regarding monosyllables, we see that
Alawa satisfies this constraint. We also see that, in
Cambodian, Constraint 1a logically implies obli-
gatoriness for words of at least one syllable. If
we wanted to be truly accurate, we might rule out
words of less than one syllable:

(0) When a human says something, they actu-
ally say something.

Formally:

(0) ¬!" (Final)
This may be overly pedantic, but it explicitly states
that every word contains at least one syllable.
Such things matter when using logical machinery
to test hypotheses.

Looking at Cambodian’s English description,
culminativity is a (pragmatic) implicature of Con-
straint 1a, but it is neither explicitly stated nor log-
ically implied. If this constraint says that primary
stress falls on the final syllable and we assume cul-
minativity, then primary stress may not occur on
any non-final syllable. We obtain a complete de-
scription by augmenting this constraint to account
for obligatoriness and culminativity.

(1a) ¬σ" ∧ ¬!" ∧ ¬σ́ ∗σ (Final)
(1) ¬σ" ∧ ¬!" ∧ ¬σ́ ∗σ ∧ ¬H ∧ ¬

∗
L

∗
L ∧ ¬!

∗
L

(Final)

5 Local constraints

Conjunctions of negative literals, such as the fi-
nal formula for Cambodian, characterize the low-
est level of a strict hierarchy of logics explored
by Rogers and Pullum (2011) and Rogers et al.
(2012) (also see Section 8 of this paper), which
characterize a range of sub-Regular classes of
stringsets. These classes of stringsets are also
characterized by classes of finite-state automata,
grammars, and, more importantly, abstract proper-
ties of the sets in the class. The constrast between

250



classes corresponds to a ranking of cognitive com-
plexity based on the nature of the information in a
string: each class is characterized by the kinds of
features of strings that a mechanism must be sen-
sitive to in order to determine whether a string is
in a given set.

Because the pattern of phonological stress in
Cambodian is completely described by a conjunc-
tion of finitely many negative atomic formulae,
a mechanism that is able to make judgments as
to whether a word satisfies each constraint only
needs to be sensitive to whether certain substrings
of some fixed length occur in the word.

Specifically, ‘¬H’ requires sensitivity only to
single syllables in isolation while the other con-
straints in Cambodian require a mechanism to be
sensitive to pairs of consecutive syllables. Such a
pattern is called “Strictly 2-Local,” or “SL2”, The
‘2’ in “SL2” is a parameter giving the length of
factors that a mechanism must necessarily be sen-
sitive to in order to be able to make judgments
about well-formedness.

From a procedural perspective, these judgments
can be made by a scanner, a mechanism that sim-
ply scans a window of a fixed size across the in-
put, one symbol at a time, looking at each factor
in sequence. Since SLk stringsets are defined by
conjunctions of negative constraints, it suffices to
look for unlicensed factors, rejecting the string if
any are found.

This generalizes to any pattern completely de-
scribed by a conjunction of finitely many negative
literals: such a pattern is SLk, where k is the length
of the longest factor. For example, Alawa is SL3:

(2) ¬σσ" ∧ ¬σ́ ∗σ ∗σ ∧ ¬∗σσ́" ∧ ¬!σ" ∧ ¬!"
(Final)

Since each k-factor can be extended to an equiv-
alent (k + 1)-factor by extending it with all possi-
ble next syllables, a pattern that is SLk must also
be SLk+1.

If we say ‘SL’ with no explicit factor length,
what we really mean is “SLk for some k.” A con-
straint can be shown to be SL simply by giving a
formula that witnesses this. Of course, this merely
gives an upper bound.

Generally, lower bounds can be found by ap-
pealing to the abstract properties of classes of
stringsets. In this case we can show that Alawa
is not SL2 using the fact that SLk stringsets are
characterized by a suffix substitution closure prop-
erty: if some (k − 1) factor occurs in two strings

that satisfy the constraint then the results of swap-
ping suffixes of the two strings that start with that
factor will also satisfy the constraint. (Intuitively,
recognizing the penult requires noting that it is fol-
lowed by a single syllable and no more: !σσσ́σ"
and !σσ́σσ" share the same 2-factors, so a mech-
anism needs a window of size at least three.)

In SL stringsets, each constraint must be satis-
fied at every position in the word. Since a single
violation suffices to rule out a word, a mechanism
only needs to be sensitive to factors in isolation.
Logical complements of SL constraints (coSL),
which are defined by disjunctions of positive lit-
erals, also only require sensitivity to factors in iso-
lation (accepting if any required factor occurs) but
combinations of positive and negative literal con-
straints are not so simple: in order to verify that
certain factors occur somewhere in the word while
others do not a mechanism must be sensitive to
the entire set of factors in the word. Constraints
requiring sensitivity to this entire set are “Locally
Testable,” or “LT”. Much as factor-width may be
specified in SL stringsets, we may say a pattern or
constraint is LTk, where the salient factors have a
length of at most k. Again like SL patterns, every
LTk pattern is LTk+1.

Since a mechanism capable of making judg-
ments based on the set of factors in a word must
necessarily be able to check these factors individ-
ually, any constraint that is SLk or coSLk must
also be LTk. Further, since the entire set of fac-
tors is available, any Boolean combination of fac-
tors may be used as an LT constraint. Giving a
constraint in this form is sufficient to show that it
is LT, and again we can use abstract properties of
the LT stringsets to show that a constraint is not in
the class.

Obligatoriness by itself is coSL1, hence LT1,
as witnessed by its expression as a single positive
atomic constraint: ‘σ́’. It is not, in itself, SLk for
any k. Obligatoriness can only be satisfied by a
system of SL constraints if they require primary
stress to fall within some fixed distance from either
end of the word.

Similarly, culminativity is not SL. It can
only be satisfied by a system of SL constraints
if they require all syllables with primary stress
to occur within a fixed distance of either end
of the word. Since satisfaction of an LT con-
straint depends only on the set of factors of
a string, LT constraints cannot distinguish be-

251



tween strings that have the same factorization,
thus we can see by example that culminativity
is also not LT3, as ‘LLH́LL’ and ‘LLH́LLH́LL’
contain the same set of substring 3-factors:
{!LL,LLH́,LH́L, H́LL,LL"}. This counter-
example generalizes to any factor-width, so cul-
minativity is not LT (a fortiori also not coSL).

6 Piecewise constraints

All local constraints are given in terms of adja-
cency. If we instead use precedence, then culmi-
nativity is quite a simple constraint:

(3) ¬σ́ ..σ́ (Final)

A constraint described by a negative atomic for-
mula of length k is “Strictly k-Piecewise”, or
“SPk”. A mechanism must be sensitive to sub-
sequences of length k in isolation in order to de-
termine whether a string is in an SPk stringset.

Culminativity in particular is SP2. Another SP
constraint comes from Nubian, this one SP3. It is
also LT2, but not SL:

(4) a. If a word contains a non-final heavy
syllable, then no light syllable with
primary stress occurs in that word.

(4a) ¬(
∗
H

∗
σ ∧ Ĺ) [or:

∗
H

∗
σ → ¬Ĺ] (Adjacency)

(4a) ¬Ĺ..
∗
H..

∗
σ ∧ ¬

∗
H..Ĺ (Precedence)

Although Constraint 4a is both LT and SP, It
is not the case that every LT constraint is SP.
If a string satisfies an SP constraint, then every
string formed by deleting finitely many symbols
from that string also satisfies that same constraint
(Rogers et al., 2010). Knowing that, it is impossi-
ble for obligatoriness to be satisfied by a system of
only SP constraints.

In order to capture obligatoriness using prece-
dence, a mechanism must be sensitive to the set of
all subsequences in a string. These constraints are
“Piecewise Testable”, or “PT”. Just as Boolean
combinations of SL constraints are LT, Boolean
combinations of SP constraints are PT. As with
the local classes, stringsets that are the comple-
ment of SP stringsets (i.e., that are coSP), while
properly PT are effectively no harder to recognize
than SP stringsets. Obligatoriness is coSP as wit-
nessed by ‘σ́’, the same formula that witnesses that
it is coSL; SLk and SPk converge for k = 1.

LH́

Σ − {L} L Σ
H́L

Σ − {L, H́}

!LH́

Σ

H́L

!LH́"
H́L

L . . H́

Σ − {L} Σ − {H́}
Σ

H́L

Figure 2: Automata for substring and subsequence fac-
tors.

7 Computational Foundations

Our computational workbench is a theorem prover
(written in Haskell) based on the equivalence
between logical formulae for finite sequences
(successor models) and finite state automata es-
tablished originally by Medvedev (1964); Büchi
(1960) and Elgot (1961). The underlying idea is
quite simple. One constructs automata for each of
the atomic formulae of the logic which accept ex-
actly those strings which satisfy that atom. Since
our logic (so far) is quantifier free and our models
are simply strings, the automata work directly on
the models.

Examples of automata for anchored and unan-
chored substring formulae and for a subsequence
formula are given in Figure 2. The Boolean
connectives are implemented via the correspond-
ing automaton constructions: conjunction corre-
sponds to intersection, negation to complement.

Using this procedure on a formula for a stress
pattern yields an automaton that recognizes the set
of all strings that satisfy that pattern. The Stress-
Typ2 database includes minimal deterministic fi-
nite state automata for nearly all of the lects3 it
includes and these can be read directly into the
workbench. Hence we can establish the correct-
ness of a formula relative to the automata-theoretic
interpretation given in the database by testing the
equivalence of that automaton and the one con-
structed from our formula. One way of doing this
(although not the most efficient way) is to con-
struct the automaton between the sets recognized
that recognizes the set of strings that the formula
incorrectly excludes (undergenerates), and another
that recognizes the set that the formula incorrectly

3StressTyp2 adopts the convention of using the bare com-
bining form ‘lect’ to denote a distinct pattern and, by exten-
sion, the class of languages that exhibit it.

252



?

Prop

Strict

FO

PTLT

MSOReg

SF

SL+SP

SPSL

SPL

PLT

LT+PT

LTT

coSL coSP
▹ ▹, < <

Figure 3: A cognitive complexity hierarchy.

includes (overgenerates); the formula is correct if
both sets are empty.

The automata from the database are use-
ful in analysis as well. The workbench in-
cludes algorithms that, given a finite state au-
tomaton, can determine whether the stringset it
recognizes is Strictly Local (Caron, 2000) or
if it is Strictly Piecewise (Rogers et al., 2010)
and, if it is, determines the factor width pa-
rameter k. In addition, it includes the algo-
rithms given by Rogers and Lambert (2017) and
Rogers and Lambert (to appear) which can, given
an automaton, extract the set of forbidden sub-
string or subsequence factors which suffice to
characterize the stringset recognized by that au-
tomaton if it is SL or SP (or a conjunction of
SL+SP+coSL +coSP constraints) and can pro-
duce an automaton that recognizes an SL + SP +
coSL + coSP approximation of that stringset if it
is not.

In each case the approximation, if it is not exact,
overgenerates and, so, by taking the difference be-
tween the approximation and the original automa-
ton one gets a stringset that provides guidance in
formulating the non-strict constraints necessary to
completely characterize the original pattern.

8 Higher level constraints

Culminativity is neither SL nor LT. It is possible
to enforce culminativity using only adjacency but
in order to do so a mechanism must distinguish oc-
currences of primary stress by their position in the
string. The logic we are working with here is the
propositional fragment of the hierarchy of logics
explored by Rogers et al. (2012). The higher lev-
els (i.e. regular stringsets that are not LT + PT)
represent strings as the same first-order models,
with binary predicates for adjacency and prece-

dence, but also allow for quantification over po-
sitions (first-order) or sets of positions (monadic
second-order). Recognizing whether a string sat-
isfies a quantified formula requires inferring in-
formation that is not explicit in the string which
changes the nature of the cognitive task, not just
its magnitude.

First-order formulae that employ only adja-
cency characterize the Locally Threshold Testable
(LTTk,t) class. A mechanism recognizing such a
stringset can count occurrences of k-factors, but
only up to a threshold: the second parameter, t. It
cannot distinguish t or more distinct occurrences.

If, on the other hand, these first-order formu-
lae make use of precedence (‘<’), then the result
is something strictly stronger, the Star Free (SF)
stringsets. Such stringsets are defined much like
Regular stringsets, except they are closed under
complement rather than the Kleene star.

Finally, if we allow monadic second-order
quantification we can define all and only the Reg-
ular stringsets. This completes the sub-Regular hi-
erarchy shown in Figure 3; the classes in the mid-
dle of the diagram are the stringsets definable by
combinations of local and piecewise constraints
(conjunctions at the restricted level, any Boolean
combinations at the full propositional level and
atoms that mix adjacency and precedence in the
PL classes).

Some of the constraints listed in StressTyp2 are
most naturally expressed in terms of the quantified
logics but these turn out to never be necessary for
stress patterns.

9 Methodology

We explore patterns by alternating between anal-
ysis based on linguistic and logical knowledge
and computational analysis and synthesis using
the tools of the workbench. In this paper, we began
with an analytic phase, transforming the English
description of a pattern into a logical description.
During this translation process, one can use the ab-
stract characterizations of the complexity classes
as a guide to the form needed to express a given
constraint. Assuming this translation is success-
ful, these constraints provide an upper-bound on
the complexity of the pattern as a whole.

Alternatively, for patterns already described by
automata, one can start with a computational an-
alytic phase, using the workbench to extract sys-
tems of SL, SP, coSL and coSP constraints from

253



those automata (Rogers and Lambert, to appear).
If the pattern is not simply SL+SP+coSL+coSP
the result of these computational methods is an ap-
proximation that is.

Another alternative is to work directly from a
corpus of annotated examples using learning algo-
rithms based on Chandlee et al. (2018), which are
currently being incorporated into the workbench.
Again, the result is a (possibly exact) approxima-
tion that is SL + SP + coSL + coSP.

In all three cases, the workbench implements
a computational synthesis phase which represents
these systems of constraints as automata. If an
automaton is provided for the pattern the correct-
ness and completeness of the constraints can be
checked computationally against this automaton
by constructing an automaton that recognizes the
symmetric difference between the two, which can
either be examined directly or used to generate ex-
amples of strings that satisfy the constraints but
should be excluded or those that should not be ex-
cluded but fail to satisfy the constraints. If there
is no existing automaton to work against, one can
generate strings up to a given length-bound and
look for inconsistencies. In any case, if there is
under- or overgeneration the structures of these
residues guide a return to the analytical phase,
adding or modifying constraints in order to ac-
count for the differences.

Once the conjunction of logical constraints cor-
rectly describes the pattern in question, the work-
bench can minimize the description by removing
constraints that are logically implied by others.
Because these subregular classes form a proper hi-
erarchy and are all closed under intersection, the
complexity of the stringset is simply the maximum
of the complexity of the constraints that describe
it.

Our workbench can find all of the minimal in-
dependent subsets of a set of constraints con-
straints that describe the same pattern as the full
set. However, if a constraint of higher complexity
is implied by a set of lower-complexity constraints
a smaller subset in which the higher-complexity
constraint is explicit will be not be an accurate in-
dication of the complexity of the stringset, rather
a larger set of lower-complexity constraints would
be preferred. So the workbench can also check
sets of constraints provided by the user, such as the
constraints identified earlier in the process either
from analysis of other patterns or from theoretical

▹ <
one σ́ LTT1,2 PT2

obligatoriness coSL1 PT1
culminativity LTT1,2 SP2

no H before H́ SF SP2
no

∗
H with Ĺ LT1 SP2

nothing before Ĺ SL2 SP2
alternation SL2 SF
no light monosyllables SL3 PT2

Table 1: Constraints in Yidin expressed locally and
piecewise.

analysis of the linguistic phenomena under study,
against the rest of the set and find independent
subsets that are minimally complex. It should be
noted that minimal descriptions from a linguistic
perspective may well not be the same as the mini-
mal descriptions from a complexity-theoretic per-
spective. But as long as they are logically equiva-
lent, the complexity result is still valid.

One can use this same mechanism to determine
whether a pattern satisfies a putative universal con-
straint by merely checking whether this constraint
is implied by those that describe the pattern in
question. When the corpus of patterns of Stress-
Typ2 was tested for both obligatoriness and cul-
minativity, it was discovered that while every lect
satisfies culminativity, there are two that do not
satisfy obligatoriness, namely Seneca and Cayuga.
These are languages that Hyman identifies as not
satisfying “the more accent-like properties of obli-
gatoriness and culminativity” (Hyman, 2009).

When working with a set of lects, one will col-
lect a library of non-strict constraints. The work-
bench can use this to automatically determine if a
new pattern can be completely described by a con-
junction of strict constraints and some subset of
this library. When the StressTyp2 corpus was ana-
lyzed, only five non-strict constraints were needed
to describe the entire set of patterns.

10 Yidin: An example

Yidin is described as:

(5) a. In words of all sizes, primary stress
falls on the left-most heavy syllable,
else on the initial syllable.

b. In words of all sizes, secondary stress
falls iteratively on every second sylla-
ble in both directions from the main

254



stress.
c. Light monosyllables do not occur.

Table 1 shows the constraints we derived from this
description. The left column is an English gloss of
the constraint, while the remaining two columns
note the complexity class in which the constraint
falls on both the local and piecewise branches of
the hierarchy. Alternation, SF on the piecewise
side, is only SL2 on the local side. Similarly, “no
H before H́” is SF on the local side, but only SP2
on the piecewise side. Thus, considering either
branch of the hierarchy in isolation brings the con-
clusion that the pattern is SF, but using a mix of
constraints from both sides shows that the pattern
is SL3 + coSL1 + SP2.

11 Conclusion

We have introduced an approach to formaliz-
ing linguistic patterns that is based on a model-
theoretic analysis of strings. We work primarily
with propositional formulae for which satisfaction
depends the substrings or subsequences that occur
in a string. Definability of sets of strings in these
logics characterizes the lowest classes of the local
and piecewise subregular hierarchies.

This foundation fulfills all of the desiderata for
systems of phonotactic constraints that we iden-
tify in the introduction. The logical constraints
are unambiguous and fully explicit. As we have
seen, the process of translating constraints stated
in English to an equivalent logical form can illumi-
nate inconsistencies and ambiguities that are usu-
ally resolved by pragmatic linguistic assumptions.

By comparing systems of logical constraints
along with the sets of their models one can gen-
eralize across languages, identifying constraints
that are common to classes of languages and
testing putative universals against those classes.
Again, using standard model-theoretic tools, one
can identify minimal independent sets of con-
straints, eliminating those that are logically im-
plied by the others.

We have demonstrated the breadth of cover-
age of this approach with respect to one range
of phonotactic phenomena by using it to fully
characterize the phonological stress patterns gath-
ered in the StressTyp2 database. In Heinz (2018),
Heinz argues that essentially all of phonotactics
falls within the the classes of this subregular hi-
erarchy. Moreover there is a growing body of
work (Chandlee and Heinz, 2018; Chandlee et al.,

2015, 2014; Chandlee, 2014; Jardine, 2017,
2016a,b) that suggests that many phonological
processes can be captured by functions based on
these same sorts of logics.

Most importantly, all of these model-theoretic
tools are effective in the sense of being com-
putable. Moreover, the classes of the hierarchy
correspond directly to the nature of the informa-
tion about a string that any mechanism must be
sensitive to in order to determine if it satisfies a
constraint. Consequently, the hierarchy provides a
measure of the relative complexity of constraints.
They are also all learnable in the limit from posi-
tive data by algorithms of low computational com-
plexity.

Our analysis of StressTyp2 demonstrates that
phonological stress is extremely simple. Our focus
is the methodology itself, not the phonological re-
sults that have been obtained using it. But we note
that, as reported elsewhere, when this methodol-
ogy was applied to a corpus of the 106 lects in
StressTyp2 that have both English language and
automata descriptions, it was found that all but
eight (92.5%) were SL + SP + coSL, six more
needed some subset of a library of LT constraints
consisting of obligatoriness and three other con-
straints, and the remaining two were properly Reg-
ular, sharing a constraint based on hidden stress
alternation. If secondary stress were to surface in
these latter two then they would simply be SL.
This means that, aside from the two patterns in-
volving the properly Regular constraint, no pattern
in the corpus requires a mechanism to infer addi-
tional information beyond that which is present in
the surface string. Moreover, the only piecewise
constraints are SP, forbidding the coöccurrence
of certain syllables as in the case of culmanitivity,
confirming Heinz (2014).

It has been verified that all patterns in this cor-
pus satisfy culminativity, and the two patterns
that do not satisfy obligatoriness, as expected by
Hyman (2009), have been identified.

The logical and computational methods we use
have applications beyond phonotactics. Sim-
ilar techniques have proven useful in phonol-
ogy in general. In particular, for explor-
ing phonological functions (Chandlee and Heinz,
2018; Chandlee et al., 2014; Chandlee, 2014),
morphology (Chandlee, 2017), and tone (Jardine,
2017, 2016a,b). These have also been used to an-
alyze syntax (Graf, 2014; Rogers, 1998).

255



References
J. R. Büchi. 1960. Weak second-order arithmetic and

finite automata. Zeitschrift für mathematische Logik
und Grundlagen der Mathematik 6:66–92.

Pascal Caron. 2000. Families of locally testable lan-
guages. Theoretical Computer Science 242:361–
376.

Jane Chandlee. 2014. Strictly Local Phonological Pro-
cesses. Ph.D. thesis, The University of Delaware.

Jane Chandlee. 2017. Computational locality in mor-
phological maps. Morphology 27:599–641.

Jane Chandlee, Rémi Eryraud, Jeffery Heinz, Adam
Jardine, and Jonathan Rawski. 2018. Learning with
partially ordered representations. Submitted to ALT
2019.

Jane Chandlee, Rémi Eyraud, and Jeffrey Heinz.
2014. Learning strictly local subsequential func-
tions. Transactions of the Association for Compu-
tational Linguistics 2:491–503.

Jane Chandlee, Rémi Eyraud, and Jeffrey Heinz. 2015.
Output strictly local functions. In Marco Kuhlmann,
Makoto Kanazawa, and Gregory M. Kobele, editors,
Proceedings of the 14th Meeting on the Mathemat-
ics of Language (MoL 2015). Chicago, USA, pages
112–125.

Jane Chandlee and Jeffrey Heinz. 2018. Strictly lo-
cality and phonological maps. Linguistic Inquiry
49(1):23–60.

Calvin C. Elgot. 1961. Decision problems of finite au-
tomata design and related arithmetics. Transactions
of the American Mathematical Society 98:21–51.

R. W. Goedemans, Jeffrey Heinz,
and Harry van der Hulst. 2015.
http://st2.ullet.net/files/files/
st2-v1-archive-0415.tar.gz. Retrieved
24 Jun 2015.

Thomas Graf. 2014. Beyond the apparent: Cognitive
parallels between syntax and phonology. In Car-
son T. Schütze and Linnaea Stockall, editors, Con-
nectedness: Papers by and for Sarah van Wagenen.
volume 18 of UCLA Working Papers in Linguistics,
pages 161–174.

Jeffrey Heinz. 2014. Culminativity times harmony
equals unbounded stress. In Harry van der Hulst,
editor, Word Stress: Theoretical and Typological Is-
sues, Cambridge University Press, Cambridge, UK,
chapter 8.

Jeffrey Heinz. 2018. The computational nature of
phonological generalizations. In Larry Hyman and
Frank Plank, editors, Phonological Typology, Mou-
ton De Gruyter, volume 23 of Phonetics and Phonol-
ogy, chapter 5, pages 126–195.

Larry M. Hyman. 2009. How (not) to do phonolog-
ical typology: the case of pitch-accent. Language
Sciences 31(2–3):213–238.

Adam Jardine. 2016a. Computationally, tone is differ-
ent. Phonology 32(2):247–283.

Adam Jardine. 2016b. Locality and non-linear repre-
sentations in tonal phonology. Ph.D. thesis, Univer-
sity of Delaware.

Adam Jardine. 2017. The local nature of tone-
association patterns. Phonology 34:385–405.

Yu. T. Medvedev. 1964. On the class of events rep-
resentable in a finite automaton. In Edward F.
Moore, editor, Sequential Machines; Selected Pa-
pers, Addison-Wesley, pages 215–227. Originally
published in Russian in Avtomaty, 1956, 385–401.

James Rogers. 1998. A Descriptive Approach to
Language-Theoretic Complexity. (Monograph.)
Studies in Logic, Language, and Information.
CSLI/FoLLI.

James Rogers, Jeff Heinz, Margaret Fero, Jeremy
Hurst, Dakotah Lambert, and Sean Wibel. 2012.
Cognitive and sub-regular complexity. In Glyn Mor-
rill and Mark-Jan Nederhof, editors, Formal Gram-
mar 2012, Springer, volume 8036 of Lecture Notes
in Computer Science, pages 90–108.

James Rogers, Jeffrey Heinz, Gil Bailey, Matt Edlef-
sen, Molly Visscher, David Wellcome, and Sean
Wibel. 2010. On languages piecewise testable in the
strict sense. In Christian Ebert, Gerhard Jäger, and
Jens Michaelis, editors, The Mathematics of Lan-
guage: 10th and 11th Biennial Conference, MOL 10,
Los Angeles, CA, USA, July 28-30, 2007, and MOL
11, Bielefeld, Germany, August 20-21, 2009, Re-
vised Selected Papers, Springer Berlin Heidelberg,
Berlin, Heidelberg, pages 255–265.

James Rogers and Dakotah Lambert. 2017.
Extracting forbidden factors from regular stringsets.
In Proceedings of the 15th Meeting on the
Mathematics of Language. Association for
Computational Linguistics, pages 36–46.
http://aclweb.org/anthology/W17-3404.

James Rogers and Dakotah Lambert. to appear.
Extracting subregular constraints from regular
stringsets. Under review.

James Rogers and Geoffrey K. Pullum. 2011. Aural
pattern recognition experiments and the subregular
hierarchy. Journal of Logic, Language and Infor-
mation 20(3):329–342.

256


