
























































Weighting Model Based on Group Dynamics to Measure Convergence in Multi-party Dialogue


Proceedings of the SIGDIAL 2018 Conference, pages 385–390,
Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics

385

Weighting Model Based on Group Dynamics to Measure Convergence in
Multi-party Dialogue

Zahra Rahimi
Intelligent Systems Program

University of Pittsburgh
Pittsburgh, PA, 15260
zar10@pitt.edu

Diane Litman
Intelligent Systems Program

University of Pittsburgh
Pittsburgh, PA, 15260

litman@cs.pitt.edu

Abstract

This paper proposes a new weighting
method for extending a dyad-level mea-
sure of convergence to multi-party dia-
logues by considering group dynamics in-
stead of simply averaging. Experiments
indicate the usefulness of the proposed
weighted measure and also show that in
general a proper weighting of the dyad-
level measures performs better than non-
weighted averaging in multiple tasks.

1 Introduction

Entrainment is the tendency of speakers to begin
behaving like one another in conversation. The
development of methods for automatically quanti-
fying entrainment in text and speech data is an ac-
tive research area, as entrainment has been shown
to correlate with outcomes such as success mea-
sures and social variables for a variety of phenom-
ena, e.g., acoustic-prosodic, lexical, and syntactic
(Nenkova et al., 2008; Reitter and Moore, 2007;
Mitchell et al., 2012; Levitan et al., 2012; Lee
et al., 2011; Stoyanchev and Stent, 2009; Lopes
et al., 2013; Lubold and Pon-Barry, 2014; Moon
et al., 2014; Sinha and Cassell, 2015; Lubold et al.,
2015). One of the main measures of entrainment is
convergence which is the main focus of this paper.
Within a conversation, convergence measures the
amount of increase in similarity of speakers over
time in terms of linguistic features (Levitan and
Hirschberg, 2011).

While most research has focused on quantifying
the amount of entrainment between speaker pairs
(i.e., dyads), recent studies have started to develop
measures for quantifying entrainment between
larger groups of speakers (Friedberg et al., 2012;
Danescu-Niculescu-Mizil et al., 2012; Gonzales
et al., 2010; Doyle and Frank, 2016; Litman et al.,

2016; Rahimi et al., 2017a). To date, mainly sim-
ple methods such as unweighted averaging have
been used to move from dyads to groups (Gon-
zales et al., 2010; Danescu-Niculescu-Mizil et al.,
2012; Litman et al., 2016).

However, because multi-party interactions are
more complicated than dyad-level interactions, it
is not clear that the contribution of all group mem-
bers should be weighted equally. For example,
to account for participation differences, Friedberg
et al. proposed a weighting method based on the
number of uttered words of each dyad (Friedberg
et al., 2012), although this did not yield perfor-
mance improvements compared to simple averag-
ing. Rahimi et al. (Rahimi et al., 2017b) pro-
vided examples of group-specific behaviors that
were not properly quantified using simple averag-
ing. While this case study nicely identified poten-
tial problems with prior measures, their observa-
tions were only based on a few example dialogues
and no solutions were proposed.

In this paper, we propose a new weighting
method to normalize the contribution of speak-
ers based on group dynamics. We explore the ef-
fect of our method, participation weighting, and
simple averaging when calculating group conver-
gence from dyads. We conclude that our proposed
weighted convergence measure performs signif-
icantly better on multiple benchmark prediction
and regression tasks that have been used to eval-
uate convergence in prior studies (De Looze et al.,
2014; Lee et al., 2011; Jain et al., 2012; Rahimi
et al., 2017a; Doyle et al., 2016; Lee et al., 2011).

2 Convergence for Multi-Party Dialogue

The convergence measure that we extend in this
paper is adopted from prior work. Originally, con-
vergence between dyads (Levitan and Hirschberg,
2011) was measured by calculating the difference



386

between the dissimilarity of speakers in two non-
overlapping time intervals. If the dissimilarity in
the second interval was less than in the first, the
pair was said to be converging.

Extending this work, multi-party conver-
gence (Litman et al., 2016) was measured using
Non-Weighted (NW) averaging of each pairs’ con-
vergence, as shown in Equations 1 and 2:

GroupDifft =

∑
∀i 6=j∈group(|fi,t − fj,t|)
|group| ∗ (|group| − 1) (1)

ConvNW = GroupDifft1 −GroupDifft2 (2)

GroupDifft corresponds to average group differ-
ences calculated for linguistic feature f in time in-
terval t for all pairs (i,j). The convergence is the
difference between GroupDiffs in two intervals.

In the next subsections, we introduce two
weighted variations of these formulas: a base-
line based on participation ratios (Friedberg et al.,
2012), and a method based on group dynamics.

2.1 Weighting Based on Participation
The idea behind this approach is that the weights
for speakers that may have talked very little should
be reduced. In prior work on multi-party lexi-
cal entrainment (Friedberg et al., 2012), speaker
participation was measured by number of uttered
words; the participation ratios of speaker pairs
were then used as the weights.

Since our work focuses on acoustic-prosodic
entrainment, we measure speaker participation
by amount of speaking time. The Participation
Ratio (PR) of each speaker in a given tempo-
ral interval is their total speech time divided by
the duration of the interval including silences.
Speech and silence periods are automatically an-
notated using Praat (Boersma and Heuven, 2002).
The Participation-based Weighted (PW) average
of convergence for all pairs p in a group is then
computed as follows:

ConvPW =

∑
∀p∈group(Convp ∗ PRp)
Nump

∑
∀p∈group PRp

(3)

Nump indicates number of pairs, and Participa-
tion Ratio for a pair, PRp, for the two intervals
is the sum of PRs for both speakers and in both
intervals. Finally, convergence for pair p = (i, j)
and for two disjoint intervals t1 and t2 is calculated
as in Equation 4:

Convp=(i,j) = (|fi,t1 − fj,t1 | − |fi,t2 − fj,t2 |) (4)

Figure 1: A group in which all speakers except
Speaker2 are converging to each other.

2.2 Weighting Based on Group Dynamics
Although participation-based weighting decreases
the contribution of less active speakers when cal-
culating group convergence, it does not take group
convergence dynamics into account. Rahimi et al.
(Rahimi et al., 2017b) argue that it might instead
be better to decrease the contribution of speak-
ers whose convergence behaviors differ from the
rest of the group (e.g., Speaker2 in Figure 1). To
tackle this issue, we use weighting to decrease the
contribution of outlier speakers. In particular, we
propose that the weight for a speaker should be the
percentage of individuals who have the same con-
vergence behavior as the speaker.

Equation 5 defines our proposed Group
Dynamic-Based Weighted (GDW) convergence
measure:

ConvGDW =
∑
g∈G

|g|
|N | ∗

∑
i∈g

∑
j 6=i∈N Convij

|Numpair|
(5)

G is a set including three categories: G =
{Converging,Diverging,MixedBehavior}, g
is a set of all individuals who belong to a cate-
gory in G, |N | is the number of all speakers in the
group, and |Numpair| is the number of pairs.

Consider the example in Figure 1. There are 12
pairs (6 unique pairs since convergence is a sym-
metric measure). Each speaker is in three unique
pairs with the other three members of the group.

If all conversational pairs that a speaker is in-
volved in have positive convergence values, the
speaker is converging to the group and has the
Converging category. If all involved pairs have
negative value, the speaker is diverging from the
group. Else, the speaker has a mixed-behavior.

The weight for each category is the number of
speakers who have corresponding behavior nor-
malized by the group size. For example, in a group



387

where all members diverge from each other, the
weights will be: converging = 0, diverging =
1, and mixedBehavior = 0. For the group
in Figure 1, weights are: converging = 0,
diverging = 1/4, and mixedBehavior = 3/4.
So, the group convergence for this example is as
follows, where C(i) is shortened for sum of pair
convergences for speaker i:

ConvGDW = 0 ∗ 0 +
1

4
∗ C(2)

+
3

4
∗ [C(1) + C(3) + C(4)] (6)

3 Data

To evaluate the utility of weighting based on group
dynamics, we measure acoustic-prosodic conver-
gence in the Teams Corpus (Litman et al., 2016).
The corpus includes audio files for 62 teams of 3
or 4 individuals playing a cooperative board game
in two sessions. First games (Game1) take signif-
icantly longer than second games (Game2) (27.1
vs. 18.4 minutes, p < .001) and are in chronolog-
ical order. The teams are disjoint in participants.
We break each game into four equal intervals1 (in-
cluding silences) and choose the first and last in-
tervals to compute convergence for eight acoustic-
prosodic features: maximum (max), mean, and
standard deviation (SD) of pitch; max, mean, and
SD of intensity; local jitter2; and local shimmer3.
The features are extracted from each of the first
and last intervals for each speaker in each team.

Individually taken self-reported pre- and post-
game surveys are available for both sessions,
including: (1) favorable social outcome mea-
sures (perceptions of cohesion, satisfaction, po-
tency/efficacy and perceptions of shared cogni-
tion), and (2) conflict measures (task, process, and
relationship conflicts). Since favorable measures
have high correlations, we z-scored each separate
outcome and averaged these scores to make a sin-
gle omnibus favorable group perception scale and
then averaged them for each team to create a team-
level Favorable measure. Since process conflict
was the only conflict measure that could be split at
the median without making arbitrary choices 4, we
z-scored the process conflict and averaged it in the

1Any method of breaking the games to compare two dis-
joint intervals can be used.

2The average absolute difference between the amplitudes
of consecutive periods, divided by the average amplitude.

3The average absolute difference between consecutive pe-
riods, divided by the average amplitude.

4The median split is required for our classification tasks.

groups to construct a team-level Process Conflict
measure. Favorable and Process Conflict will be
used to evaluate the quality of the different conver-
gence measures from Section 2.

4 Experiments and Discussion

Our experimental evaluations use two tasks that
have been used for convergence measure evalua-
tions in previous studies (De Looze et al., 2014;
Lee et al., 2011; Jain et al., 2012; Rahimi et al.,
2017a; Doyle et al., 2016; Lee et al., 2011).

Predicting Social Outcomes: Our first task ex-
amines how the NW, PW, and GDW measures of
acoustic-prosodic convergence (independent vari-
ables) relate to the social outcome measures (de-
pendent variables) from Section 3. This is sim-
ilar to prior studies which have evaluated con-
vergence in terms of predicting outcomes (Doyle
et al., 2016; Lee et al., 2011; Rahimi et al., 2017a).
We hypothesize that the group-dynamic weighted
convergence measure will outperform the non-
weighted and participation-based measures.

First, we train a hierarchical multiple regression
with each of the three groups of convergence mea-
sures, added once in the first level and the other
time in the second, to measure if the second level
predictors significantly improve the explanation of
variance. We only keep predictors with significant
coefficients when presenting the models.5

For Process Conflict, the results show that all
NW, PW, and GDW predictor groups are as good
as each other; no matter which group is entered in
the first level, the predictors in the second level do
not significantly improve model fit.

For Favorable, neither PW nor NW in the
second level significantly improves performance.
However, Table 1 shows that adding the GDW
measures at the second level significantly im-
proves a model with only NW features at the first
level. The amount of variance explained in Model
2 is significantly above and beyond Model 1,
∆R2 = 0.048, ∆F (2, 119) = 3.179, p = 0.045.
The reverse order, GDW at first level and NW at
the second level, shows that the improvement at
the second level is not significant, ∆R2 = 0.031,
∆F (2, 119) = 2.068, p = 0.131. These results
indicate that the proposed weighted (GDW) con-
vergence (for intensity max and SD) are the best

5To control for the effect of first versus second dialogue
(game) for each group, we also included an independent vari-
able for game. However, the coefficient was never significant.



388

Independent Vars M1 (β) M2 (β)
Intensity max (NW) 0.248* -0.164
Intensity SD(NW) -0.055 -0.479+
Intensity max(GDW) 0.430+
Intensity SD(GDW) 0.457+

R2 0.063 0.110
F 4.034* 3.678*

Table 1: Hierarchical regression results with inten-
sity max and SD convergence as independent, and
Favorable as dependent, variables. The NW mea-
sures are added in the first level and GDW mea-
sures in the second level. Significant / trending
results if p-value is < 0.05 (*) or < 0.1 (+).

Favorable Process Conflict
Majority 50 53
NW 50 66.93
PW 53.23 67.74+(GDW)
GDW 62.90** 62.90
GDW+PW 58.87 66.13

Table 2: LOOCV prediction accuracies of bi-
nary favorable social outcome and process conflict
variables. (**) indicates GWD model significantly
outperforms both PW and NW models. (+) indi-
cates PW improvement over GDW is trending.

predictors of the favorable social outcome com-
pared with the other two measures of convergence.

Next, we reduce the task from regression to
a binary classification by splitting the two social
outcome variables at the median. We perform
Leave-One-Out Cross-Validations (LOOCV) us-
ing a logistic regression (L2) algorithm and all
eight acoustic-prosodic features to predict binary
outcomes. The results in Table 2 show that the
GWD model significantly6 outperforms both PW
and NW models to predict the favorable social out-
come. In the prediction of process conflict, the
PW model outperforms both NW and GDW mod-
els and its improvement over GDW is trending.

In sum, the results in both tables support our hy-
pothesis for the favorable social outcome, where
the proposed GDW convergence measure is a bet-
ter predictor of the outcome. For process conflict,
we do not see any significant difference.

Predicting Real Dialogues: The existence of
entrainment should not be incidental. To evaluate
this criteria, we use permuted versus real conver-
sations as in (De Looze et al., 2014; Lee et al.,
2011; Jain et al., 2012). We hypothesize that GDW
will be the best convergence measure for distin-

6Corrected paired t-test was performed to address instance
dependency from both games (Nadeau and Bengio, 2000).

All Game1 Game2
Majority 50 50 50
NW 54.43 60.48 49.19
PW 53.62 58.06 51.61
GDW 54.03 67.74*+ 48.39

Table 3: Accuracies using the linear SVM models
and LOOCV to predict real conversations. (+) in-
dicates GWD outperforms NW with p = 0.06 , (*)
indicates GWD outperforms PW with p = 0.004.

guishing real versus permuted dialogues.
For each of the 124 game sessions, we con-

struct artificially permuted versions of the real dia-
logues as follows. For each speaker, we randomly
permute the silence and speech intervals extracted
by Praat. Next, we measure convergence for all
the groups with permuted audios. We perform a
leave-one-out cross-validation experiment to pre-
dict real conversations using the convergence mea-
sures. We examined several classification algo-
rithms including logistic regression; linear SVM
was the only one that showed significant results.

The “All” results in Table 3 show that none of
the models significantly outperform the majority
baseline. To diagnose the issue, we perform the
prediction on each game separately. The proposed
GDW model significantly outperforms other mod-
els for Game 1. However, for Game 2, none of
the results are significantly different. One reason
might be that convergence occurs quickly during
Game 1, and there is not much convergence occur-
ring at Game 2. Thus, there is no significant dif-
ference between permuted and not permuted con-
vergence for any of the features during Game 2.

5 Conclusion

In this paper, we introduced a new weighted
convergence measure for multi-party entrainment
which utilizes group convergence dynamics to
weight pair convergences. Experimental results
show that the proposed weighted measure is more
predictive for two evaluation tasks used in prior
entrainment studies: predicting favorable social
outcomes and predicting real versus permuted
conversations. In future work we plan to apply the
proposed weighted convergence measure to fea-
tures other than acoustic-prosodic, e.g., lexical.

Acknowledgments

This work is supported by NSF 1420784,1420377.
We thank Susannah Paletz for her feedback.



389

References
Paul Boersma and Vincent van Heuven. 2002. Praat, a

system for doing phonetics by computer. Glot inter-
national, 5(9/10):341–345.

Cristian Danescu-Niculescu-Mizil, Lillian Lee,
Bo Pang, and Jon Kleinberg. 2012. Echoes of
power: Language effects and power differences in
social interaction. In Proceedings of WWW, pages
699–708.

Celine De Looze, Stefan Scherer, Brian Vaughan, and
Nick Cambpell. 2014. Investigating automatic mea-
surements of prosodic accommodation and its dy-
namics in social interaction. Speech Communica-
tion, 58:11–34.

Gabriel Doyle and Michael C Frank. 2016. Investigat-
ing the sources of linguistic alignment in conversa-
tion. In ACL (1).

Gabriel Doyle, Dan Yurovsky, and Michael C Frank.
2016. A robust framework for estimating linguistic
alignment in twitter conversations. In Proceedings
of the 25th international conference on world wide
web, pages 637–648. International World Wide Web
Conferences Steering Committee.

Heather Friedberg, Diane Litman, and Susannah B. F.
Paletz. 2012. Lexical entrainment and success in
student engineering groups. In Proceedings Fourth
IEEE Workshop on Spoken Language Technology
(SLT), Miami, Florida.

Amy L. Gonzales, Jeffrey T. Hancock, and James W.
Pennebaker. 2010. Language style matching as a
predictor of social dynamics in small groups. Com-
munication Research, 37:3–19.

Mahaveer Jain, John W. McDonough, Gahgene
Gweon, Bhiksha Raj, and Carolyn Penstein Ros.
2012. An unsupervised dynamic bayesian network
approach to measuring speech style accommodation.
In EACL, pages 787–797.

Chi-Chun Lee, Athanasios Katsamanis, Matthew P.
Black, Brian R. Baucom, Panayiotis G. Georgiou,
and Shrikanth Narayanan. 2011. An analysis of
pca-based vocal entrainment measures in married
couples’ affective spoken interactions. In INTER-
SPEECH, pages 3101–3104.

Rivka Levitan, Agustı́n Gravano, Laura Willson, Stefan
Benus, Julia Hirschberg, and Ani Nenkova. 2012.
Acoustic-prosodic entrainment and social behavior.
In 2012 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 11–19.

Rivka Levitan and Julia Hirschberg. 2011. Measuring
acoustic-prosodic entrainment with respect to multi-
ple levels and dimensions. In Interspeech.

Diane Litman, Susannah Paletz, Zahra Rahimi, Ste-
fani Allegretti, and Caitlin Rice. 2016. The teams

corpus and entrainment in multi-party spoken dia-
logues. In Proceedings of the 2016 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1421–1431.

José Lopes, Maxine Eskenazi, and Isabel Trancoso.
2013. Automated two-way entrainment to improve
spoken dialog system performance. In ICASSP,
pages 8372–8376.

Nichola Lubold and Heather Pon-Barry. 2014.
Acoustic-prosodic entrainment and rapport in
collaborative learning dialogues. In Proceedings of
the 2014 ACM workshop on Multimodal Learning
Analytics Workshop and Grand Challenge, pages
5–12. ACM.

Nichola Lubold, Heather Pon-Barry, and Erin Walker.
2015. Naturalness and rapport in a pitch adaptive
learning companion. In Automatic Speech Recogni-
tion and Understanding (ASRU), 2015 IEEE Work-
shop on, pages 103–110. IEEE.

Christopher Michael Mitchell, Kristy Elizabeth Boyer,
and James C. Lester. 2012. From strangers to part-
ners: Examining convergence within a longitudinal
study of task-oriented dialogue. In SIGDIAL Con-
ference, pages 94–98.

Seungwhan Moon, Saloni Potdar, and Lara Martin.
2014. Identifying student leaders from mooc dis-
cussion forums through language influence. In Pro-
ceedings of the EMNLP 2014 Workshop on Analysis
of Large Scale Social Interaction in MOOCs, pages
15–20.

Claude Nadeau and Yoshua Bengio. 2000. Inference
for the generalization error. In Advances in neural
information processing systems, pages 307–313.

Ani Nenkova, Agustı́n Gravano, and Julia Hirschberg.
2008. High frequency word entrainment in spoken
dialogue. In Proceedings of the 46th Annual Meet-
ing of the Association for Computational Linguistics
on Human Language Technologies: Short Papers,
HLT-Short ’08, pages 169–172.

Zahra Rahimi, Anish Kumar, Diane Litman, Susan-
nah Paletz, and Mingzhi Yu. 2017a. Entrainment in
multi-party spoken dialogues at multiple linguistic
levels. Proc. Interspeech 2017, pages 1696–1700.

Zahra Rahimi, Diane Litman, and Susannah Paletz.
2017b. Acoustic-prosodic entrainment in multi-
party spoken dialogues: Does simple averaging ex-
tend existing pair measures properly? In Interna-
tional Workshop On Spoken Dialogue Systems Tech-
nology.

David Reitter and Johanna D. Moore. 2007. Predict-
ing success in dialogue. In Proceedings of the 45th
Meeting of the Association of Computational Lin-
guistics, pages 808–815.



390

Tanmay Sinha and Justine Cassell. 2015. Fine-grained
analyses of interpersonal processes and their effect
on learning. In Artificial Intelligence in Education:
17th International Conference, pages 781–785.

Svetlana Stoyanchev and Amanda Stent. 2009. Lexical
and syntactic priming and their impact in deployed
spoken dialog systems. In Proceedings of Human
Language Technologies: The 2009 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, Companion Vol-
ume: Short Papers, NAACL-Short ’09, pages 189–
192, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.


