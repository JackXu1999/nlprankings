



















































Detecting Political Bias in News Articles Using Headline Attention


Proceedings of the Second BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 77–84
Florence, Italy, August 1, 2019. c©2019 Association for Computational Linguistics

77

Detecting Political Bias in News Articles Using Headline Attention

Rama Rohit Reddy
International Institute of
Information Technology,

Hyderabad
ramarohitreddy.g

@research.iiit.ac.in

Suma Reddy Duggenpudi
International Institute of
Information Technology,

Hyderabad
sumareddy.duggenpudi
@research.iiit.ac.in

Radhika Mamidi
International Institute of
Information Technology,

Hyderabad
radhika.mamidi
@iiit.ac.in

Abstract

Language is a powerful tool which can be used
to state the facts as well as express our views
and perceptions. Most of the times, we find
a subtle bias towards or against someone or
something. When it comes to politics, me-
dia houses and journalists are known to cre-
ate bias by shrewd means such as misinterpret-
ing reality and distorting viewpoints towards
some parties. This misinterpretation on a large
scale can lead to the production of biased news
and conspiracy theories. Automating bias de-
tection in newspaper articles could be a good
challenge for research in NLP.

We proposed a headline attention network for
this bias detection. Our model has two distinc-
tive characteristics: (i) it has a structure that
mirrors a person’s way of reading a news arti-
cle (ii) it has attention mechanism applied on
the article based on its headline, enabling it to
attend to more critical content to predict bias.
As the required datasets were not available, we
created a dataset comprising of 1329 news arti-
cles collected from various Telugu newspapers
and marked them for bias towards a particu-
lar political party. The experiments conducted
on it demonstrated that our model outperforms
various baseline methods by a substantial mar-
gin.

1 Introduction

News bias is a ubiquitous phenomenon, poten-
tially present in most of the newspapers. The first
step in challenging biased news is documenting
bias. So detection of the inclination of a news ar-
ticle towards a political party has gained attention
today. Such news articles are mostly selected and
analyzed manually using a process called coding
or theoretical frameworks like discourse analysis
and content analysis. This analysis requires a lot
of effort, concentration, attention to detail and is
also time taking. Thus automating this bias de-

tection in a news article could be very helpful and
necessary for media verification.

Media bias can be observed and defined through
various factors. In political domain, it ranges
from selectively publishing articles to specifically
choosing to highlight some events, parties and
leaders. We also come across articles where bias
can be detected by observing the unclear assump-
tions, loaded language, or lack of proper context.
Especially during the election campaigning due to
several unjust factors, media houses often align
themselves either for or against some specific par-
ties and instead of reporting just the content, they
subtly add their stand towards it. This is usually
reflected in the headline, and making the headline
biased has an effect on the reader who reads the ar-
ticle after registering the headline subconsciously.
As there was no dataset marked for political bias
available in Telugu, we created a dataset compris-
ing of 1329 news articles collected from various
Telugu newspapers and annotated them for bias
towards a political party. The bias is marked as
None if the article is unbiased.

Telugu is an agglutinative Dravidian language
spoken widely in two states of India namely Telan-
gana and Andhra Pradesh. According to Ethno-
logue1 list of most spoken languages worldwide,
Telugu ranks fifteenth in the list, and a total of
85 million Telugu native speakers exist across the
world. There are only 5 major political parties
present in the two Telugu speaking states. We
treat the problem of political bias detection as a
classification problem. The political parties can
be treated as labels and the goal will be to as-
sign labels to each news article. Any news arti-
cle deviating its reader from the original news to-
wards a political party is considered biased. Tra-
ditional approaches of text classification represent

1https://www.ethnologue.com/statistics/size



78

documents with sparse lexical features, such as n-
grams, and then use a linear model or kernel meth-
ods on this representation (Wang and Manning,
2012; Joachims, 1998). More recent approaches
used deep learning, such as convolutional neural
networks (Kalchbrenner et al., 2014) and recurrent
neural networks based on long short-term memory
(LSTM) (Hochreiter and Schmidhuber, 1997) to
learn text representations.

Although neural-network based approaches
have been quite effective, classification based only
on articles or only on headlines may not give bet-
ter results as articles may contain unnecessary ex-
tra information and headlines being short may not
capture required information. So a combination of
article and headline is required for better classifi-
cation. In this paper, we test our hypothesis that
classification can be improved by focusing on es-
sential parts of news articles based on their head-
lines. Since headlines are designed to be short and
catchy, journalists tend to exploit them to express
their ideological view of the news stories and de-
pending on these headlines the interpretation of
the stories can change. So the intuition underly-
ing our model is that bias in an article can be ef-
fectively found by focusing on essential parts of
articles based on their headlines.

Our contributions in this paper are (i) The cre-
ation and annotation of a newspaper dataset for po-
litical bias detection, (ii) The proposal of a neu-
ral network architecture, the Headline Attention
Network that is designed to capture the important
parts of news article causing political bias by pay-
ing headline attention.Generally, readers first read
the headlines and then go through the news article
with those headlines in their mind. Thus attention
is paid on news article with its headline in reader’s
mind. Headline Attention Networks are designed
to do the same thing and find important parts that
reflect bias in news articles. To illustrate, consider
the example in Figure 1. In the figure, importance
of each highlighted word in causing bias is directly
proportional to the intensity of the blue colour in
highlighting2. So focusing more on these words
according to their importance would give better re-
sults rather than focusing on all words.The key dif-
ference to other neural networks is that our system
focuses on the importance of headline for politi-
cal bias detection in an article and discover which

2Translation, explanation and visualizations of Headline
attention are given in Supplement Material

sequence of tokens are relevant rather than sim-
ply filtering out. Our model outperforms various
common classification architectures by a signifi-
cant margin.

Figure 1: News article from the dataset. Bias towards
”TDP”

2 Related Work

Identification and analysis of bias in news articles
has led to extensive research in the fields of an-
thropology, discourse analysis, and media studies.
(Sivandi and Dowlatabadi, 2015) used the head-
lines and leads of newspaper articles to detect bias
in their complete linguistic approach to the prob-
lem.

(Iyyer et al., 2014) used recursive neural net-
works to detect political ideology.

(Rashkin et al., 2017) introduced a propagan-
dists dataset focused propaganda news and pre-
sented a study on the language of news media in
context of political fact checking.

(Recasens et al., 2013) conducted a study re-
lated to bias in the Wikipedia articles using logisitc
regression.

Many industrial organizations are working in
this space worldwide to fight disinformation. First
Draft News is a project ”to fight mis- and dis-
information online” founded by 9 organizations
brought together by the Google News Lab. Full
Fact is a charity based in London to check and
correct facts reported in the news. CrossCheck is
a new initiative from Google Labs and First Draft
to support truth and verification in Media.

In Telugu, a small amount of work is done on
news data. (Mukku et al., 2016) apply ML tech-
niques for Sentiment Analysis of Telugu news ar-
ticles. (Gangula and Mamidi, 2018) performed
multidomain sentiment analysis in Telugu.

3 Dataset

Our aim is to detect the bias of a newspaper ar-
ticle towards a particular political party. An arti-
cle is said to be biased if it is inclined or preju-
diced for or against a political party. We created a

https://firstdraftnews.org
https://firstdraftnews.org
https://fullfact.org
https://fullfact.org


79

dataset3 containing headline of the article, article
and the political party towards which it is biased.
We marked it with label ”None” if it was unbiased.
The statistics of the dataset is shown in Table 1.

Four annotators annotated each article in the
dataset with one of the 5 parties namely BJP, TDP,
Congress, TRS, YCP or as None if the article is
unbiased. The annotators are native Telugu speak-
ers with good proficiency in the language. While
choosing annotators care was taken that they do
not have any bias towards any party and have suf-
ficient political knowledge. The following annota-
tion guidelines were followed: Each article along
with the headline was presented to the annotators.
They were asked to read them just as they read
newspapers. After reading, they were asked to an-
notate whether the article was subjectively biased
towards or against a party or is unbiased. A Kappa
score of 0.9 was achieved through multiple discus-
sions.

Figure 6 presented in supplemental Material
shows some of the examples from our dataset. We
can see in the examples below that there is some
inherent bias towards a party in the way a partic-
ular newspaper has reported. This could be due
to several factors like the ownership of the me-
dia house, the present power of a party (ruling or
opposition), and the ideology of the target group
of readers that particular newspaper is catering to.
Many a times, political parties themselves estab-
lish media houses and newspaper agencies to in-
crease their outreach and glorify their party. This
greatly contributes to bias in the published articles.

Parties Documents Sentences Words avg #w in headline avg #w in article
BJP 182 2244 24863 4.13 132.48

Congress 82 1031 11410 4.06 135.08
TRS 151 1860 21685 4.09 139.52
TDP 361 3484 40495 3.86 108.3
YCP 335 1958 22370 3.79 62.98

Unbiased 218 1546 19245 4.09 65.14
Total 1329 12123 140068 3.95 98.3

Table 1: Data statistics: #w denotes the number of
words per document

4 Headline Attention Networks

The overall architecture of the Headline Attention
Network is shown in Figure 2. It consists of sev-
eral parts: a headline encoder, an article encoder
and a headline attention layer. We describe the de-
tails of these components below.

3Our dataset is freely available at
https://drive.google.com/open?id=
1IyaKYeDkl7ubuabTI65G0nSBfxQNdeTr

Figure 2: Headline Attention Network

4.1 Model

We focus on classifying a given article as biased
towards one of the political parties in this work.
Assume that the article has T words, wi with i ∈
[1, T ] represents the ith word in article and head-
line has H words, qi with i ∈ [1, H] represents
ith word in headline of the article. The proposed
model projects the raw articles into a vector repre-
sentation which can be used for classification. In
the following, we will present this method of pro-
jection.

4.1.1 Headline Encoder
Given the headline of an article with words qi, i
∈ [1, H], we first embed the words into vectors
through an embedding matrix We, xi=Weqi. We
use a bidirectional LSTM to get contextual en-
coding of headline from both the directions. The
bidirectional LSTM contains a forward LSTM

−→
f

which reads headline from q1 to qH and a back-
ward LSTM

←−
f which reads headline from qH to

q1:
xi =Weqi, i ∈ [1, H] (1)

−→
hi =

−−−−→
LSTM(xi)i ∈ [1, H] (2)

←−
hi =

←−−−−
LSTM(xi)i ∈ [H, 1] (3)

We encode the headline of the article by con-
catenating the forward representation

−→
hH and the

backward representation
←−
h1, i.e, Q=[

←−
h1,
−→
hH ] is the

representation of the article headline.

4.1.2 Article Encoder
An article is nothing but a sequence of words. We
embed these words into vectors and use bidirec-
tional LSTM to get annotations of the words by
summarizing information from both direction for
words and therefore incorporating contextual in-
formation in the annotation. We encode article as:

xi =Wewi, i ∈ [1, T ] (4)

https://drive.google.com/open?id=1IyaKYeDkl7ubuabTI65G0nSBfxQNdeTr
https://drive.google.com/open?id=1IyaKYeDkl7ubuabTI65G0nSBfxQNdeTr


80

−→
hi =

−−−−→
LSTM(xi), i ∈ [1, T ] (5)

←−
hi =

←−−−−
LSTM(xi), i ∈ [T, 1] (6)

We concatenate
−→
hi and

←−
hi to get annotation of

word wi i.e hi=[
−→
hi ,
←−
hi ]. hi summarizes the neigh-

boring words around word wi but still focuses on
word wi.

4.1.3 Headline Attention Layer
Headline of a news article is very important to
report news biased towards a political party as a
reader generally reads headline first and then goes
through the article with that headline in his mind
i.e paying attention to article based on the head-
line. We introduce attention mechanism to extract
words that contribute to political bias and form a
vector representation v. Specifically,

ui = tanh(Wwhi + bw) (7)

αi =
exp(uTi .U)∑
i exp(u

T
i .U)

(8)

v =
∑
i

αihi (9)

We measure the importance of the word as the sim-
ilarity of ui with U, the hidden representation of
encoded headline representation Q and get a nor-
malized importance αi through a softmax func-
tion. After that we compute the representation of
the news article as a weighted sum of the word an-
notations based on the weights. All of the above
are learned during the training process.

4.1.4 Bias detection
The vector v is used to detect towards which polit-
ical party the article is biased to as:

p = Softmax(Wcv + bc) (10)

Training loss is the negative log likelihood of the
correct labels:

L = −
∑
d

Log(pdi) (11)

where i is the label of document d.

5 Experiments

All the experiments are carried out in a 5-fold
cross validation scenario. As headlines express
the ideological view of the news stories, in some
cases only the headline would be sufficient to de-
tect bias. So except for Headline Attention Net-
works, for all other baselines we divided dataset
into three parts:

1. Only headline.

2. Only news article.

3. Concatenation of both headline and news ar-
ticle.

We compared how each of them differs in bias de-
tection.

5.1 Baselines
We compare Headline Attention Networks with
several baseline methods, including traditional ap-
proaches such as Naive Bayes, SVMs, CNNs,
Branched CNNs, LSTMs and GRUs. Word em-
beddings are available for Telugu4.

5.1.1 Naive Bayes
Naive Bayes classifier is used to classify docu-
ments using the following features.

TFIDF The TFIDF values of each word is used
as features.

Bag-of-means The average word2vec (Mikolov
et al., 2013) embedding is used as feature set.

5.1.2 SVMs
SVM-based classifier is used including following
different features.

TFIDF+Unigrams The TFIDF values of bag of
Unigrams is used as features.

TFIDF+Bigrams The TFIDF values of bag of
Bigrams is used as features.

AverageSG The average word embeddings of
each document is used as feature set.

5.1.3 Neural Network methods
We experimented with multiple neural network ar-
chitectures like:

CNNs Word based neural network model like in
(Kim, 2014) are used.

Branched CNNs Figure 3 shows the branched
CNN architecture.

Figure 3: Branched CNN architecture

LSTMs and GRU based models like in (Wang
et al., 2018) are used.

4https://bit.ly/2JQNYrw

https://bit.ly/2JQNYrw


81

Methods Only Headline Only article Concatenation of headline and article Maximum
Naive Bayes+TFIDF+Unigrams 39 58 59 59
Naive Bayes+TFIDF+Bigrams 29 32 33 33

Naive Bayes+Bag-of-means 49 63 63 63
SVM+TFIDF+Unigrams 41 69 69 69
SVM+TFIDF+Bigrams 55 76 71 76

SVM+AverageSG 57 69 66 69
CNNs 80 80.5 81.7 81.7

Branched CNNs 83.33 84.52 84.6 84.6
LSTM 84 85.25 85.32 85.32
GRU 81 82.7 82.7 82.7

Headline Attention Network without attention layer - - - 85.25
Headline Attention Network - - - 89.54

Table 2: Bias Detection Accuracy in percentage. Maximum is the best value among the three divisions of our
dataset for baselines.

5.2 Results and analysis

The experimental results are shown in table 2. The
results show that our model gives the best per-
formance. Our model outperforms previous best
baseline methods by 4.22%. From table 2 we
can see that there is a significant improvement in
neural network based methods compared to tradi-
tional methods. But involving the headline atten-
tion can significantly improve over them. As men-
tioned earlier, headlines are designed to be short
and catchy so the journalists tend to exploit them
to influence readers. Therefore, considering only
the headlines also predicts bias with only a small
difference in accuracy when compared to consid-
ering whole article. This can be clearly observed
in table 2 in neural network methods. We can also
observe that simply concatenating headline does
not help much in bias prediction, instead attending
to article with headline representation increases
accuracy by a significant margin. Our Headline
Attention Network outperforms all other models
because it effectively finds out important words
causing bias in a document.

6 Conclusion

In this paper, we proposed a headline attention
mechanism for automatic detection of bias in news
articles along with a manually annotated dataset to
enable further research. Our model builds a vector
for news article by aggregating important words
obtained by paying attention based on headline
representation. The experimental results demon-
strate that our model significantly outperforms all
the previous baseline models. Visualization of at-
tention shows how headline attention effectively
picks out words causing bias.

This model can also be extended to other sen-

timent based classification of texts such as blogs
or online trending articles, which contains a ti-
tle/headline and a body.

Acknowledgments

We would like to thank Lalitha, Vaishnavi and
other annotators for helping us with the dataset
creation.

References
Sreyasee Das Bhattacharjee, Ashit Talukder, and

Bala Venkatram Balantrapu. 2017. Active learning
based news veracity detection with feature weight-
ing and deep-shallow fusion. In 2017 IEEE Inter-
national Conference on Big Data, BigData 2017,
Boston, MA, USA, December 11-14, 2017, pages
556–565.

Ceren Budak, Sharad Goel, and Justin M. Rao. 2016.
Fair and balanced? quantifying media bias through
crowdsourced content analysis. 80:250–271.

Rama Rohit Reddy Gangula and Radhika Mamidi.
2018. Resource creation towards automated senti-
ment analysis in telugu (a low resource language)
and integrating multiple domain sources to enhance
sentiment prediction. In Proceedings of the Eleventh
International Conference on Language Resources
and Evaluation, LREC 2018, Miyazaki, Japan, May
7-12, 2018.

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Un-
supervised coding with LOCOCODE. In Artificial
Neural Networks - ICANN ’97, 7th International
Conference, Lausanne, Switzerland, October 8-10,
1997, Proceedings, pages 655–660.

Nicholas Holtzman, J.P. Schott, Michael N Jones,
David A Balota, and Tal Yarkoni. 2010. Exploring
media bias with semantic analysis tools: Validation
of the contrast analysis of semantic similarity (cass).
43:193–200.

https://doi.org/10.1109/BigData.2017.8257971
https://doi.org/10.1109/BigData.2017.8257971
https://doi.org/10.1109/BigData.2017.8257971
https://doi.org/10.1007/BFb0020229
https://doi.org/10.1007/BFb0020229


82

Mohit Iyyer, Peter Enns, Jordan L. Boyd-Graber, and
Philip Resnik. 2014. Political ideology detection us-
ing recursive neural networks. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics, ACL 2014, June 22-27, 2014,
Baltimore, MD, USA, Volume 1: Long Papers, pages
1113–1122.

Thorsten Joachims. 1998. Text categorization with
support vector machines: Learning with many rel-
evant features. In Machine Learning: ECML-98,
10th European Conference on Machine Learning,
Chemnitz, Germany, April 21-23, 1998, Proceed-
ings, pages 137–142.

Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A convolutional neural network for
modelling sentences. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics, ACL 2014, June 22-27, 2014,
Baltimore, MD, USA, Volume 1: Long Papers, pages
655–665.

Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2014, October 25-29,
2014, Doha, Qatar, A meeting of SIGDAT, a Special
Interest Group of the ACL, pages 1746–1751.

Konstantina Lazaridou. 2016. Identifying political bias
in news articles. TCDL Bulletin, 12(2).

Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S.
Corrado, and Jeffrey Dean. 2013. Distributed rep-
resentations of words and phrases and their com-
positionality. In Advances in Neural Information
Processing Systems 26: 27th Annual Conference on
Neural Information Processing Systems 2013. Pro-
ceedings of a meeting held December 5-8, 2013,
Lake Tahoe, Nevada, United States., pages 3111–
3119.

Sandeep Sricharan Mukku, Nurendra Choudhary, and
Radhika Mamidi. 2016. Enhanced sentiment clas-
sification of telugu text using ML techniques. In
Proceedings of the 4th Workshop on Sentiment Anal-
ysis where AI meets Psychology (SAAIP 2016) co-
located with 25th International Joint Conference on
Artificial Intelligence (IJCAI 2016), New York City,
USA, July 10, 2016., pages 29–34.

Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana
Volkova, and Yejin Choi. 2017. Truth of varying
shades: Analyzing language in fake news and polit-
ical fact-checking. In Proceedings of the 2017 Con-
ference on Empirical Methods in Natural Language
Processing, EMNLP 2017, Copenhagen, Denmark,
September 9-11, 2017, pages 2931–2937.

Marta Recasens, Cristian Danescu-Niculescu-Mizil,
and Dan Jurafsky. 2013. Linguistic models for an-
alyzing and detecting biased language. In Proceed-
ings of the 51st Annual Meeting of the Association

for Computational Linguistics, ACL 2013, 4-9 Au-
gust 2013, Sofia, Bulgaria, Volume 1: Long Papers,
pages 1650–1659.

Filipe Nunes Ribeiro, Lucas Henrique, Fabrı́cio Ben-
evenuto, Abhijnan Chakraborty, Juhi Kulshrestha,
Mahmoudreza Babaei, and Krishna P. Gummadi.
2018. Media bias monitor: Quantifying biases of
social media news outlets at large-scale. In Proceed-
ings of the Twelfth International Conference on Web
and Social Media, ICWSM 2018, Stanford, Califor-
nia, USA, June 25-28, 2018., pages 290–299.

Rosa Sicilia, Stella Lo Giudice, Yulong Pei, Mykola
Pechenizkiy, and Paolo Soda. 2017. Health-
related rumour detection on twitter. In 2017 IEEE
International Conference on Bioinformatics and
Biomedicine, BIBM 2017, Kansas City, MO, USA,
November 13-16, 2017, pages 1599–1606.

Zohre Sivandi and Hamid Dowlatabadi. 2015. A crit-
ical discourse analysis on newspapers: The case
study of nuclear program of iran. 4.

Jenq-Haur Wang, Ting-Wei Liu, Xiong Luo, and Long
Wang. 2018. An LSTM approach to short text sen-
timent classification with word embeddings. In Pro-
ceedings of the 30th Conference on Computational
Linguistics and Speech Processing, ROCLING 2018,
Hsinchu, Taiwan, October 4-5, 2018, pages 214–
223.

Sida I. Wang and Christopher D. Manning. 2012. Base-
lines and bigrams: Simple, good sentiment and topic
classification. In The 50th Annual Meeting of the As-
sociation for Computational Linguistics, Proceed-
ings of the Conference, July 8-14, 2012, Jeju Island,
Korea - Volume 2: Short Papers, pages 90–94.

Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,
Alexander J. Smola, and Eduard H. Hovy. 2016. Hi-
erarchical attention networks for document classifi-
cation. In NAACL HLT 2016, The 2016 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, San Diego California, USA, June 12-
17, 2016, pages 1480–1489.

Daniel Xiaodan Zhou, Paul Resnick, and Qiaozhu Mei.
2011. Classifying the political leaning of news ar-
ticles and users from user votes. In Proceedings of
the Fifth International Conference on Weblogs and
Social Media, Barcelona, Catalonia, Spain, July 17-
21, 2011.

A Supplemental Material

A.1 Visualization of Headline Attention
Figure 4 and 5 show the visualization of our head-
line attention networks. Intensity of blue color de-
notes word weight.

Figures 4 and 5 shows that our model selects
words with strong emphasis on a person or a po-
litical party. The darker the blue colour, it implies

http://aclweb.org/anthology/P/P14/P14-1105.pdf
http://aclweb.org/anthology/P/P14/P14-1105.pdf
https://doi.org/10.1007/BFb0026683
https://doi.org/10.1007/BFb0026683
https://doi.org/10.1007/BFb0026683
http://aclweb.org/anthology/P/P14/P14-1062.pdf
http://aclweb.org/anthology/P/P14/P14-1062.pdf
http://aclweb.org/anthology/D/D14/D14-1181.pdf
http://aclweb.org/anthology/D/D14/D14-1181.pdf
http://www.ieee-tcdl.org/Bulletin/v12n2/papers/lazaridou.pdf
http://www.ieee-tcdl.org/Bulletin/v12n2/papers/lazaridou.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality
http://ceur-ws.org/Vol-1619/paper5.pdf
http://ceur-ws.org/Vol-1619/paper5.pdf
https://aclanthology.info/papers/D17-1317/d17-1317
https://aclanthology.info/papers/D17-1317/d17-1317
https://aclanthology.info/papers/D17-1317/d17-1317
http://aclweb.org/anthology/P/P13/P13-1162.pdf
http://aclweb.org/anthology/P/P13/P13-1162.pdf
https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17878
https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17878
https://doi.org/10.1109/BIBM.2017.8217899
https://doi.org/10.1109/BIBM.2017.8217899
https://aclanthology.info/papers/O18-1021/o18-1021
https://aclanthology.info/papers/O18-1021/o18-1021
http://www.aclweb.org/anthology/P12-2018
http://www.aclweb.org/anthology/P12-2018
http://www.aclweb.org/anthology/P12-2018
http://aclweb.org/anthology/N/N16/N16-1174.pdf
http://aclweb.org/anthology/N/N16/N16-1174.pdf
http://aclweb.org/anthology/N/N16/N16-1174.pdf
http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/view/2782
http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/view/2782


83

higher is its importance in predicting bias towards
a party. Words with the darkest blue highlighting,
such as YSRCP,Chandra Babu, People’s leader are
the most important ones as they refer to who/what
the article is intending to inform about. So they
are given more weight. The English translation
of words in blue are ”Chandra Babu”, ”progress”,
”inspiration”, ”strongest person on earth”, ”spe-
cial”, ”encourage” etc. Our headline attention fo-
cuses most on ”Chandra Babu” who is the chair
person of the TDP political party and the other
words are attended according to the intensity of
praising.

Figure 4: News article from the dataset. Bias towards
”TDP”

Figure 5: News article from the dataset. Bias towards
”YCP”

Approximate translation of Figure 4:
Headline : Path of welfare
Article : On Friday, YSR Congress chief Jagan-

mohan Reddy carried out the fulfillment of peo-
ple’s desires successfully. The main goal of the
walk is the welfare and betterment of the people
of the state and people participated with a lot of
excitement and offered immense support to the
leader. The leader of the masses was given a warm
welcome by the people, who have waited for hours
just to see him. The people were very eager and
enthusiastic to see him, meet him, greet him and
to be addressed by him in the public talk that the
leader addresses. The leader of masses, with a
constant smile on his face, also greeted the people
affectionately, spoke with them to find out about
the current problems that they are facing and gave
offered them to support and ensured that he is al-
ways with the people in any kind of need.

Approximate translation of Figure 5:
Headline : Chandra Babu Naidu praised by New

York Times

Article : The step taken by Chandra Babu is
now an inspiration for all other states. The mea-
sures taken by Chandra Babu regarding organic
farming are exceptionally great and are getting
great applauses from various environmentalists.
New scheme called Zero Budget Natural Farm-
ing introduced by Chandra Babu mainly encour-
ages the farmers to implement organic farming and
techniques and are the main reason for the farmer
to have hope on their life. The same has been
even published in the New York Times. The ef-
fort put by Chandra Babu for encouraging farmers
in chemical-free farming is truly appreciation wor-
thy.



84

Figure 6: Examples of biased articles from our dataset.


