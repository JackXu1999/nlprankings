



















































Proceedings of the...


S Bandyopadhyay, D S Sharma and R Sangal. Proc. of the 14th Intl. Conference on Natural Language Processing, pages 103–111,
Kolkata, India. December 2017. c©2016 NLP Association of India (NLPAI)

Hybrid Approach for Marathi Named Entity Recognition

Nita Patil
SOCS

N. M. U. Jalgaon (MS)
India

nvpatil@nmu.ac.in

Ajay S. Patil
SOCS

N. M. U. Jalgaon (MS)
India

aspatil@nmu.ac.in

B. V. Pawar
SOCS

N. M. U. Jalgaon (MS)
India

bvpawar@nmu.ac.in

Abstract
This paper describes a named entity
recognition system that combines hid-
den markov model, handcrafted rules,
and gazetteers to recognize named en-
tities in Marathi language. The objec-
tive of the system is to recognize twelve
types of NEs from the Marathi text.
Marathi is morphologically rich and in-
flectional language. The inflections in
NEs are handled by using lemmatiza-
tion. The difficulties of zero and poor
probabilities caused due to the sparse
data are handled using pseudo word re-
placement and smoothing techniques.
Viterbi algorithm is used for decoding
and word disambiguation. The perfor-
mance of the system is improved using
gazetteers and grammar rules.

Keywords: Named Entity Recognition,
Marathi, HMM, Gazetteers, Rules

1 Introduction
Named Entity Recognition (NER) is informa-
tion extraction task which can play significant
role in many different natural language pro-
cessing tasks such as information retrieval, ma-
chine translation, question answering systems
etc. Predefined entities in text such as peo-
ple, organizations, locations, events, expres-
sions such as amount, percentage, numbers,
date, time are named entities (NEs). Iden-
tification of NEs from unstructured text and
their classification into suitable NE class is
known as NER. This paper describes a hy-
brid model based on Hidden Markov Model
(HMM), handcrafted rules and gazetteers to
recognize named entities in Marathi. The dif-
ficulties of unseen probabilities are handled

by pseudo word replacement and poor prob-
abilities caused due to sparse data are han-
dled using smoothing techniques. Viterbi alo-
girithm is used for decoding and word disam-
biguation. The performance of the system is
improved using gazetteers. Linguistic rules
are used to generate patterns that can rec-
ognize dates, time and numerical expressions.
Following MUC specifications twelve types of
NE are considered in recognition problem they
are Person, Organization, Location, Miscella-
neous, Amount, Number, Date, Time, Year,
Month, Day and Measure. Patil (2017) re-
ported the NER system based on trigram
HMM model trained using pre-processed data
for the Marathi language. The system uses
Viterbi decoding to generate the optimal tag
sequence for the test data. The system im-
plemented using lemma model with trigram
HMM has performed well in NE recognition,
but it has further scope for improvement. Nu-
merical NEs generally follow some fixed pat-
terns, hence linguistic knowledge based recog-
nition could be the better choice than prob-
ability based recognition. The study aims
to improve NE recognition rate by combining
effectiveness of statistical model with good-
ness of rule and gazetteer based technique
for Marathi NER. The paper is organized in
five main sections. Introduction and litera-
ture survey is discussed in first and second sec-
tion. Supervised learning method for Marathi
NER that uses HMM is described in third sec-
tion. Fourth section briefs about rules and
gazetteer based Marathi named entity recog-
nition and the fifth section of the paper de-
scribes proposed hybrid model for develop-
ment of Marathi NER system.

103



2 Related Work
Research in named entity recognition for In-
dian languages is initiated by (Bandyopad-
hyay (2007), Varma (2008), Murthy (2008),
Nusrat (2008), Bhattacharya (2009)). Many
researchers have proposed rule based NER
systems (Krupka (1998), William (1998),
Awaghad (2009), Kashif (2010), Sasidhar
(2011)) that give accurate results and achieve
high performance. But the downside of this
approach is lack of robustness and portabil-
ity. Also, high maintenance is needed. Re-
cently NER problems are solved by most of
the researchers using statistical machine learn-
ing approach which uses mathematical and
statistical models to train and test the data.
Reasonable performance is reported by us-
ing this approach by the researchers (Daniel
(1999), John (2001), GuoDong (2002), Asif
(2008)). One more thought towards solv-
ing NER problem is combining the good-
ness of both approaches to achieve great per-
formance and minimize the drawback is us-
ing Hybrid approach (Raymond (2006), Bra-
nimir (2008), Alireza (2008), Sitanath (2009),
Xueqing (2009). Hybrid approach combines
hand crafted rules with machine learning tech-
niques. The time-consuming work like cre-
ation of resources can be done using machine
learning and the other important task like pre-
processing and post-processing can be done us-
ing hand crafted rules.

3 Machine Learning for NE
Recognition

3.1 Using Hidden Markov Models
Hidden markov models relies on three param-
eters that are a matrix A of tag transition
probabilities, a matrix B of emission or obser-
vation probabilities and a matrix π in which
probability of the tag to occur in the initial
state are recorded. Trigram HMM is defined
as (K,V, λ), where K = {s1, s2,….., sn} is a fi-
nite set of possible states, V = {x1, x2,….., xn}
is a finite set of possible observations and
λ = (π,A,B), where, π = {πi} : Set of ini-
tial state probabilities and πi : Initial proba-
bility that system starts at state i, A = {aij}
: Set of state transition probabilities and aij :
Probability of going to state j from state i,
B = {bi{xk}}: Set of emission probabilities

and bi{xk}: Probability of generating symbol
xk at state i. Maximum likelihood estimates
are used to estimate parameters of λ model
as, aijk =

C(i, j, k)

C(i, j)
and bi{xk} =

C(i ; xk)

C(i)
.

The start of the sentence is marked by ∗∗ and
end of the sentence is marked by STOP tag.
The probability of state sequence s1, s2…..sn+1
for given x1, x2…..xn observation sequence for
NE tagging can be computed as,

P (x1x2…..xn|s1s2…..sn+1) ∼=
n+1∏

i=1

q(si|si−2, si−1)

×
n∏

i=1

e(xi|si)

Where q and e are parameters for max-
imum likelihood estimates. If we have
n = 6, x1, x2, ...., x6 equal to the sentence
ट यात १० हजार पये अनुदान., and s1, s2, ..., s7
equal to the tag sequence O B-AMT I-AMT
E-AMT O O STOP, then Bigram counts
(MatBC) for probable tag sequence O B-
AMT I-AMT E-AMT O O STOP for the
sentence ट यात १० हजार पये अनुदान. is,

MatBC =




* B-AMT I-AMT E-AMT O STOP

* 26462 44 0 0 19544 0

B-AMT 0 0 937 491 0 0

I-AMT 0 0 768 936 0 0

E-AMT 0 24 0 0 1335 1

O 0 1227 0 0 265391 26305

STOP 0 0 0 0 0 0




Unigram counts (MatUC) for probable
tag sequence O B-AMT I-AMT E-AMT O O
STOP is

MatUC =
( * B-AMT I-AMT E-AMT O STOP
0 1428 1705 1427 323621 0

)

Bigram probabilities (MatBP ) for proba-
ble tag sequence O B-AMT I-AMT E-AMT
O O STOP is,

104



MatBP =




* B-AMT I-AMT E-AMT O STOP

* 0 0 0 0 0 0

B-AMT 0 0 0.656 0.344 0 0

I-AMT 0 0 0.450 0.549 0 0

E-AMT 0 0.017 0 0 0.936 0.001

O 0 0.004 0 0 0.820 0.081

STOP 0 0 0 0 0 0




The q and e parameter estimations for
above sentence are




q(O|*) = C(*,O)C(*) = 0.73857

q(B-AMT|O) = C(O,B-AMT)C(O) = 0.00379

q(I-AMT|B-AMT) = C(B-AMT,I-AMT)C(B-AMT) = 0.656162

q(E-AMT|I-AMT) = C(I-AMT,E-AMT)C(I-AMT) = 0.548974

q(O|E-AMT) = C(E-AMT,O)C(E-AMT) = 0.93553

q(O|O) = C(O,O)C(O) = 0.82007

q(O|STOP) = C(O,STOP)C(O) = 0.08128

e(ट यात|O) = C(O ; ट यात)C(O) = 0.000108

e(१०|B-AMT) = C(B −AMT ; १०)C(B-AMT) = 0.006303

e(हजार|I-AMT) = C(I −AMT ; हजार)C(I-AMT) = 0.226979

e( पये|E-AMT) = C(E −AMT ; पये)C(E-AMT) = 0.280308

e(अनुदान|O) = C(O ; अनुदान)C(O) = 0.000121

e(.|O) = C(O ; .)C(O) = 0.079025




Bigram probability for an optimal tag se-
quence O B-AMT I-AMT E-AMT O O STOP
for the sentence ट यात १० हजार पये अनुदान.

is,

P (x1...x6, s1...s7) =

q(O|∗)
×q(B −AMT |O)
×q(I −AMT |B −AMT )
×q(E −AMT |I −AMT )
×q(O|E −AMT )
×q(O|O)
×q(O|STOP )
×e(ट यात|O)
×e(१०|B −AMT )
×e(हजार|I −AMT )
×e( पये|E −AMT )
×e(अनुदान|O)
×e(.|O)
= 2.59683×10-17

The probability of optimal tag sequence for a
given word sequence is illustrated in above ex-
ample. Similar probabilities are computed for
all possible tag sequences for a given sentence
using MLE estimation. Among all such pos-
sible tag sequences for a given sentence, the
optimal path of tag sequence is to be selected.
The tag sequence with highest probability is
selected. This decoding is done by Viterbi al-
gorithm(section 3.3). The trellis diagram for
Viterbi decoding for a sample sentence ट यात
१० हजार पये अनुदान., is shown in figure 1.
3.1.1 Preprocessing Data
The lemmatization based technique (Patil
(2017) is implemented in which inflected word
forms are replaced by specialized tokens. On-
tologies for number names in words, time,
length, weight, electricity, temperature, area,
volume and units of currency has been devel-
oped. The Marathi text is preprocessed using
lemmatization based technique to deal with
the inflections in named entities.

3.1.2 Minimizing Comparisons
Twelve different types of NEs using 40 tags
need to be recognized by the NE recognizer.
General trigram HMM assigns every tag to
each word, computes bigram, trigram and un-
igram probabilities and assigns most probable105



Figure 1: NE Tag Decoding

tag to the word based on maximum proba-
bility. We have taken two sentences to find
number of trigram and emission probability
computations. If 40 is the number of tags
in tag set, then 40 tags are assigned to first
word in sentence, 1600 bigram combinations
are assigned to first and second word in sen-
tence and 64, 000 trigram combinations are as-
signed to first, second and third word. Thus,
64, 000 trigram combinations are assigned to
remaining words in sentence. Two * symbols
are added to first word in sentence to make tri-
gram. Trigram probability (TP ) is the ratio of
trigram count (TC) to bigram count (BC) i.e.
TP = TC/BC . Combination BC that is not
seen in training becomes zero, zero value at
denominator results in infinite trigram prob-
ability. The difficulty introduced because of
unseen BC is solved by using two solutions.
First solution is return value 1 for unseen BC
which can temporary solve the problem. Sec-
ond solution is find out all the bigram com-
binations which are never seen in training as
well as not expected during testing. All such
combinations are called invalid bigram com-
binations. There are approximately 1089 bi-
gram tag combinations that are never seen in
training and not expected in testing some of
them are shown in table 1. For all combina-
tions, which are invalid computation of TP is
skipped so that load of algorithm execution

can be released to some extent as well wrong
trigram state assignment to observations can
be controlled. Comparison between first and
second solution is shown in table 2.

CurTag NextTag CurTag NextTag
B-LOC B-TIME B-LOC I-DATE
B-LOC B-AMT B-LOC I-MEAS
B-LOC B-DATE B-LOC I-MISC
B-LOC B-LOC B-LOC I-NUM
B-LOC B-MEAS B-LOC I-ORG
B-LOC B-MISC B-LOC I-PER
B-LOC B-NUM B-LOC MONTH
B-LOC B-ORG B-LOC O
B-LOC B-PER B-LOC S-TIME
B-LOC E-TIME B-LOC S-AMT
B-LOC E-AMT B-LOC S-DATE
B-LOC E-DATE B-LOC S-LOC
B-LOC E-MEAS B-LOC S-MEAS
B-LOC E-MISC B-LOC S-MISC
B-LOC E-NUM B-LOC S-NUM
B-LOC E-ORG B-LOC S-ORG
B-LOC E-PER B-LOC S-PER
B-LOC I-TIME B-LOC WEEKDAY
B-LOC I-AMT B-LOC YEAR

Table 1: Part of Unseen Bigram Tag Combi-
nations

TP Computations Solution 1 Solution 2

Trigram comparisons 142596 36581
Non zero TP s 3959 3959
Zero TP s 138637 32622

Table 2: Comparison between Tp Computa-
tions for Two Solutions106



3.2 Viterbi Decoding
Viterbi algorithm is used to predict most
likely tag sequence for an input sequence.
The algorithm finds most probable state se-
quence s1, s2,….., sn for a observation sentence
x1, x2,….., xn. The problem of maximizing
P (s1, s2...sn|x1, x2.....xn) is addressed using
argmaxs1…..snP (s1s2…..sn|∗, x1x2…..xn, STOP ).

3.3 Handling Unseen words
Unseen words are absent in training, therefore
their prediction probability becomes zero. If
frequency of observation in test set is less than
or equal to 5, then that observation is treated
as rare word. Non frequent words in test set
are replaced by < RARE > token. Katz back-
off smoothing is used to estimate the count of
words that are never seen in training.

4 Linguistics for NE Recognition

Linguistic knowledge to recognize Marathi
NEs is represented using indicator word lists,
gazetteers, and grammar rules. This subsec-
tion provides brief information about the lin-
guistic resources developed for detection of
NEs from newspaper articles.

4.1 Indicator Word Lists
The indicators often surrounding the NEs can
act as trigger words in identification of NEs
in their context. Such words play significant
role in designing heuristics to indicate NEs
within the text. Certain words exist in text
that are not indicators but are ambiguous NEs
and must be treated separately. The word lists
for indicators such as title person, awards, de-
gree, person name suffixes, suffixes to person
first name, suffixes to person last name, colli-
sion of proper and common noun, collision of
proper, common noun and verbs, ambiguous
last names, Marathi abbreviations, English in
Devanagari abbreviations, location indicators,
location suffixes etc. were developed to assists
NE recognition by rule based NER algorithm.

4.2 Using Gazetteers
Gazetteer for first names, last names, orga-
nizations names, miscellaneous names, days
of the week, month names (English and
Marathi), single word location, organization
and miscellaneous etc. were created. The

word form(s) which is (are) untagged if found
in some gazette(s), then the appropriate tag(s)
is (are) assigned to the word form(s) based on
the gazette(s) in which it found.

4.3 Using Grammatical Rules
The grammatical rules are a set of grammati-
cal patterns designed to derive NEs based on
lemmatization. Grammatical patterns were
indicated using regular expressions. Several
rules have been developed, which are used
to extract person, location, amount, measure,
date, time, and number entities.

5 Experimental Work
5.1 Dataset Preparation
FIRE-2010 corpus is used to develop NE an-
notated corpus by manually tagging 12 types
of NEs. 27,177 sentences of Marathi text have
been annotated using IOBES scheme. Train-
ing data developed for Marathi NER consists
of 4,01,295 word forms that comprise of 12,303
person names, 7,440 organization, 10,015 loca-
tion, 3,242 miscellaneous, 7,093 number, 1,500
amount, 2,967 measure, 1,549 date, 369 time,
197 month, 456 weekdays, and 395 year named
entities. The rich morphology of the Marathi
language allows adding suffixes and prefixes
to a morpheme to add semantic to a word and
to create meaningful context. It is observed
during corpus annotation that almost all NE
instances are present in inflected form. Al-
though the dataset is large enough, frequency
count of word is found to be lower since inflec-
tions result in same word appearing in differ-
ent forms. This further results in poor prob-
abilities and sparse data problem in MLE es-
timates. Lemmatization based preprocessing
deals with such inflections and is used in the
preprocessing of training and testing datasets.

5.1.1 Held Out Test Dataset
Preparation

Two sets of training and testing datasets is cre-
ated by dividing the NE annotated corpus pre-
processed using lemmatization in 80:20 and
90:10 percent proportions. The actual num-
ber of sentences in the corpus are computed,
20% of the total sentences in the corpus were
randomly selected and removed from the cor-
pus. The set of randomly selected sentences107



NE Class NE Annotated Data Training Dataset1 Held-out Dataset1 Training Dataset2 Held-out Dataset2
Person 12,303 11,998 0305 12,285 018
Organization 07,440 07,236 0204 07,421 019
Location 10,015 09,723 0292 09,983 032
Miscellaneous 03,242 03,170 0072 03,231 011
Number 07,093 06,893 0200 07,081 012
Amount 01,500 01,463 0037 01,494 006
Measure 02,967 02,887 0080 02,958 009
Date 01,549 01,515 0034 01,541 008
Time 00369 00360 0009 00363 006
Month 00197 00193 0004 00190 007
Weekday 00456 00441 0015 00455 001
Year 00395 00384 0011 00389 006
Total NEs 47,526 46,263 1,263 47,391 135
#Sentences 27,177 26,462 0715 27,127 050

Table 3: Held Out Training and Testing Dataset Details

is termed as Held-out dataset1. The remain-
ing sentences (80%) in the corpus (training
dataset1) were used to train the NER sys-
tem. Similarly, 10% of the total sentences in
the corpus were randomly selected, removed
and stored in Held-out dataset2. The remain-
ing sentences (90%) in the corpus (training
dataset2) were used to train the NER system.
The total number of NE instances found in the
training dataset1, training dataset2, held-out
dataset1 and held-out dataset2 are shown in
table 3.

NE Class Train1 Unseen1 Unseen2
Person 11,998 33 08
Organization 07,236 15 16
Location 09,723 17 22
Miscellaneous 03,170 16 02
Number 06,893 10 16
Amount 01,463 05 01
Measure 02,887 02 06
Date 01,515 03 03
Time 00,360 01 01
Month 00,193 02 01
Weekday 00,441 01 01
Year 00,384 04 04
Total NEs 46,263 109 81
Sentences 26,462 33 24

Table 4: Unseen Test Dataset Details

5.1.2 Unseen Test Dataset
Preparation

Unseen dataset1 is a dataset composed of
news items taken from online eSakal newspa-
per in October 2016. Unseen dataset2 is a

dataset composed of news items taken from
online eSakal newspaper in February 2017.
Both the unseen datasets were tokenized and
preprocessed using lemmatization. The total
number of NE instances found in the unseen
dataset1 and unseen dataset2 is shown in ta-
ble 4. The NE annotated corpus pre-processed
using lemmatization consisting of 27,177 sen-
tences mentioned in the dataset preparation
section is used to train the NER system.

5.2 NER System Architecture

The proposed NER system applies statistical
algorithm i.e. trigram HMM using lemmati-
zation algorithm to test data. This algorithm
recognizes Marathi NEs satisfactorily. It also
deals with unknown words and performs word
disambiguation to some extent. There is pos-
sibility that some NEs might be untouched
by the system. Therefore, rule and gazetteer
based NER algorithm is cascaded to the NER
system. The rule based algorithms do not
modify the recognition carried by statistical al-
gorithm, rather it tags only the untagged NEs
in the test data. The NEs which are not con-
tained in any gazetteer are termed as unseen
NEs. The problem of unseen NEs is solved
by statistical algorithm using pseudo word re-
placement. Therefore, continuous expansion
of gazetteers is not required. Expected per-
formance of the Marathi NE recognition is
achieved using combining the statistical algo-
rithm with the rule based algorithm. The ar-
chitecture of NER system for the Marathi lan-
guage that combines statistical named entity
recognition, gazetteers and grammar rules is108



Figure 2: Marathi NER System

shown in figure 2.

5.3 Evaluation of Hybrid NER System
The performance of the Marathi NER based
on hybrid approach is evaluated using four
varying size datasets containing varying num-
ber of NEs. Out of them two datasets were
held out and remaining two datasets were un-
known datasets.
The system is trained on dataset(s) prepro-
cessed using lemmatization. The performance
of the system using held out datasets is shown
in table 5 and 6. The overall NE identification
accuracy reported by the system for held out
dataset1 and 2 is 93.35% and 98.14% respec-
tively. The average NE classification accuracy
reported is 95.24% and 97.79% respectively.

The overall NE identification accuracy re-
ported by the system for unseen dataset1 and
2 is 81.37% and 83.33% respectively which is
relatively satisfactory. The average NE classi-
fication accuracy reported for unseen dataset1
and 2 is 83.09% and 84.23% respectively. The
NE recognition accuracy for organization NE
is relatively less result in unsatisfactory av-
erage NE classification accuracy for unseen
dataset2. Numeric NEs in this dataset were
accurately recognized than the enamex type of
NEs by the system. The performance of the
system using unseen datasets is shown in table
7 and 8 respectively. Overall NE identification
accuracy and average NE classification accu-
racy is shown in graph 3 and 4 respectively.

NE Class Precision Recall F1-Score
NEI 92.79 93.92 93.35
Person 84.05 86.35 85.18
Organization 95.02 98.96 96.95
Location 97.26 97.26 97.26
Miscellaneous 95.83 95.83 95.83
Number 96.43 90.43 93.33
Amount 80.00 100.0 88.89
Measure 100.0 100.0 100.0
Date 93.67 97.37 95.48
Time 81.82 100.0 90.00
Month 100.0 100.0 100.0
Weekday 100.0 100.0 100.0
Year 100.0 100.0 100.0
NEC 93.67 97.18 95.24

Table 5: NER System Performance on Held-
out Dataset1

NE Class Precision Recall F1-Score
NEI 98.51 97.78 98.14
Person 94.74 100.0 97.30
Organization 100.0 100.0 100.0
Location 100.0 96.88 98.41
Miscellaneous 100.0 100.0 100.0
Number 92.31 100.0 96.00
Amount 100.0 100.0 100.0
Measure 100.0 100.0 100.0
Date 100.0 100.0 100.0
Time 100.0 83.33 90.91
Month 100.0 100.0 100.0
Weekday 100.0 100.0 100.0
Year 100.0 83.33 90.91
NEC 98.92 96.96 97.79

Table 6: NER System Performance on Held-
out Dataset2

Figure 3: Overall NE Identification
109



NE Class Precision Recall F1-Score
NEI 86.46 76.85 81.37
Person 78.57 66.67 72.13
Organization 90.91 66.67 76.93
Location 100.0 94.12 96.97
Miscellaneous 100.0 87.50 93.33
Number 69.23 90.00 78.26
Amount 66.67 80.00 72.73
Measure 100.0 50.00 66.67
Date 100.0 100.0 100.0
Time 100.0 100.0 100.0
Month 100.0 100.0 100.0
Weekday 100.0 100.0 100.0
Year 100.0 25.00 40.00
NEC 92.12 80.00 83.09

Table 7: NER System Performance on Unseen
Dataset1

NE Class Precision Recall F1-Score
NEI 92.31 75.95 83.33
Person 83.33 62.50 71.43
Organization 87.50 43.75 58.33
Location 85.00 77.27 80.95
Miscellaneous 100.0 0 0
Number 100.0 100.0 100.0
Amount 100.0 100.0 100.0
Measure 100.0 100.0 100.0
Date 100.0 100.0 100.0
Time 100.0 100.0 100.0
Month 100.0 100.0 100.0
Weekday 100.0 100.0 100.0
Year 100.0 100.0 100.0
NEC 96.32 81.96 84.23

Table 8: NER System Performance on Unseen
Dataset2

Figure 4: Overall NE Classification

The cumulative performance of Marathi
NER system based on Hybrid approach for
held out and unseen test datasets is shown in
table 9. NE identification and classification re-
ported by this system is 90% approximately,
which is satisfactory for Marathi language.

Test Datasets NEI NEC
Held-Out Dataset1 93.35 95.24
Held-Out Dataset2 98.14 97.79
Unseen Dataset1 81.37 83.09
Unseen Dataset2 83.33 84.23
Average 89.05 90.09

Table 9: Average Performance of NER

6 Conclusion

A NER system for Marathi language is de-
scribed that applies hidden markov model,
language specific rules and gazetteers to the
task of named entity recognition (NER) in
Marathi language. Starting with named en-
tity (NE) annotated corpora and lemmatiza-
tion first a baseline NER system was imple-
mented. Then some language specific rules are
added to the system to recognize some specific
NE classes. Also, some gazetteers and context
patterns are added to the system to increase
the performance. After preparing the one-level
NER system, a set of rules are applied to iden-
tify the nested entities. The system can rec-
ognize 12 classes of NEs with 89.05% accuracy
in average NE identification and 90.09% accu-
racy in average NE classification for held out
and unseen test datasets in Marathi.

Acknowledgement

This research work is supported by grants
under Rajiv Gandhi Science and Technology
Commission, Govt. of Maharashtra, India.

References
Asif Ekbal and Sivaji Bandyopadhyay. 2007. A

Hidden Markov Model Based Named Entity
Recognition System: Bengali and Hindi as Case
Studies. Springer International Conference on
Pattern Recognition and Machine Intelligence
(PReMI 2007) Heidelberg, LNCS, 4815:545–552.110



Anup Patel, Ganesh Ramakrishnan and Pushpak
Bhattacharya. 2009 Incorporating Linguistic Ex-
pertise using ILP for Named Entity Recognition
in Data Hungry Indian Languages. In Proceed-
ings of the 19th International Conference on In-
ductive Logic Programming (ILP’09), Leuven,
Belgium,178–185.

Sudha Morwal, and Nusrat Jahan. 2013. Named
entity recognition using hidden markov model
(hmm): An experimental result on Hindi, urdu
and marathi languages. International Journal of
Advanced Research in Computer Science and
Software Engineering (IJARCSSE),3(4):671–
675.

Praneeth Shishtla, Karthik Gali, Prasad Pingali,
and Vasudeva Varma. 2008. Experiments in Tel-
ugu NER: A Conditional Random Field Ap-
proach. In Proceedings of the Workshop on
NER for South and South East Asian languages
(IJCNLP-08), Hyderabad, India,105–110.

P. Srikanth and Kavi Narayana Murthy. 2008.
Named Entity Recognition for Telugu. In Pro-
ceedings of the Workshop on Named Entity
Recognition for South and South East Asian
Languages, Third International Joint Confer-
ence on Natural Langauge Processing (IJCNLP-
08), Hyderabad, India, 41-50.

Krupka, G.R., and Hausman, K. 1998. IsoQuest
Inc: Description of the NetOwl Text Extrac-
tion System as used for MUC-7. In Proceedings
of Seventh Message Understanding Conference
(MUC-7), Fairfax, Virgina.

William J Black, Fabio Rinaldi and David Mowatt.
1998. Facile: Description Of The NE System
Used For Muc-7. In Proceedings of Seventh Mes-
sage Understanding Conference (MUC-7), Fair-
fax, Virgina.

Awaghad Ashish Krishnarao, Himanshu Gahlot,
Amit Srinet and D. S. Kushwaha. 2009. A Com-
parative Study of Named Entity Recognition
for Hindi using Sequential Learning Algorithms.
International Advance Computing Conference
(IACC 2009), Patiala, India:1163-1168.

Kashif Riaz. 2010. Rule-based Named Entity Recog-
nition in Urdu. In Proceedings of the 2010
Named Entities Workshop, ACL 2010, Uppsala,
Sweden:126–135.

B. Sasidhar, P.M. Yohan, A. Vinaya Babu, A. Go-
vardhan. 2011. Named Entity Recognition in Tel-
ugu Language using Language Dependent Fea-
tures and Rule based Approach. International
Journal of Computer Applications, 22(8):30-34.

Daniel M. Bikel, Richard L. Schwartz, and Ralph
M. Weischedel. 1999. An Algorithm that Learns
What’s in a Name. Machine Learning, 34(1):
211-231.

John Lafferty, Andrew McCallum, and Fernando
C.N. Pereira. 2001. Conditional Random Fields:
Probabilistic Models for Segmenting and Label-
ing Sequence Data In Proceedings of the 18th
International Conference on Machine Learning
2001 (ICML 2001):282-289.

GuoDong Zhou Jian Su. 2002 Named Entity Recog-
nition using an HMM-based Chunk Tagger. In
Proceedings of the 40th Annual Meeting of
the Association for Computational Linguistics
(ACL), Philadelphia, Pennsylvania:473-480.

Asif Ekbal and Sivaji Bandyopadhyay. 2008. Ben-
gali Named Entity Recognition Using Support
Vector Machine. In Proceedings of the Work-
shop on Named Entity Recognition for South
and South East Asian Languages, Third Inter-
national Joint Conference on Natural Langauge
Processing (IJCNLP-08), Hyderabad, India: 51-
58.

Raymond Chiong and Wang Wei. 2006. Named En-
tity Recognition Using Hybrid Machine Learn-
ing Approach. 5th IEEE International Confer-
ence Cognitive Informatics, (ICCI-2006), Vol-
ume 1:578-583.

Branimir T. Todorovic, Svetozar R. Rancic, Ivica
M. Markovic, Edin H. Mulalic and Velimir M.
Ilic. 2008. Named Entity Recognition and Clas-
sification Using Context Hidden Markov Model.
9th Symposium on Neural Network Applications
in Electrical Engineering, NEUREL 2008, Bel-
grade, Serbia :43-46.

Alireza Mansouri, Lilly Suriani Affendey, and Ali
Mamat. 2008. Name Entity Recognition Ap-
proach. International Journal of Computer Sci-
ence and Network Security, 8(2):320-325.

Sitanath Biswas, S. Mohanty, S.P. Mishra. 2009.
A Hybrid Oriya Named Entity Recognition
System: Integrating HMM with MaxEnt. In
Proceedings of 2nd International Conference
Emerging Trends in Engineering and Technol-
ogy (ICETET 2009), Nagpur:639-643.

Xueqing Zhang, Zhen Liu, Huizhong Qiu, Yan Fu.
2009. A Hybrid Approach for Chinese Named
Entity Recognition in Music Domain. In Pro-
ceedings of Eighth IEEE International Confer-
ence on Dependable, Autonomic and Secure
Computing , Chengdu, China:677-681.

Nita Patil, Ajay Patil and B. V. Pawar. 2017.
HMM based Named Entity Recognition for in-
flectional language. IEEE International Confer-
ence on Computer, Communications, and Elec-
tronics (COMPTELIX 2017):565-572.

111


