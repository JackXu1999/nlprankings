Proceedings of the Biomedical NLP Workshop associated with RANLP 2017, pages 55–63,

Varna, Bulgaria, 8 September 2017.

https://doi.org/10.26615/978-954-452-044-1_008

55

Towards Conﬁdence Estimation for

Typed Protein-Protein Relation Extraction

Camilo Thorne and Roman Klinger

Institut f¨ur Maschinelle Sprachverarbeitung
University of Stuttgart, Stuttgart, Germany

{firstname.lastname}@ims.uni-stuttgart.de

Abstract

Systems which build on top of informa-
tion extraction are typically challenged to
extract knowledge that, while correct, is
not yet well-known. We hypothesize that
a good conﬁdence measure for relational
information has the property that such in-
teresting information is found between in-
formation extracted with very high con-
ﬁdence and very low conﬁdence. We
discuss conﬁdence estimation for the do-
main of biomedical protein-protein rela-
tion discovery in biomedical literature. As
facts reported in papers take some time
to be validated and recorded in biomedi-
cal databases, such task gives rise to large
quantities of unknown but potentially true
candidate relations. It is thus important to
rank them based on supporting evidence
rather than discard them.
In this paper,
we discuss this task and propose differ-
ent approaches for conﬁdence estimation
and a pipeline to evaluate such methods.
We show that the most straight-forward
approach, a combination of different con-
ﬁdence measures from pipeline modules
seems not to work well. We discuss this
negative result and pinpoint potential fu-
ture research directions.

1

Introduction

The ever increasing body of biomedical litera-
ture has motivated a growing interest over the
past 20 years in natural
language processing
(NLP) and information extraction (IE) techniques
to retrieve, organize and index the knowledge it
contains (Rodriguez-Esteban, 2009; Subramaniam
et al., 2003).
It has also spurred a number of
(shared) tasks and system competitions of which

the best known are the BioNLP Shared Task1 and
the BioCreative challenge2. Relevant subtasks
include named entity recognition (NER, Leaman
and Gonzalez, 2008), entity linking and normal-
ization to unique database identiﬁers (Zheng et al.,
2014), event (EE, Bj¨orne and Salakoski, 2015) and
relation extraction (RE, Tymoshenko et al., 2012;
Airola et al., 2008; Choi, 2016). The overall goal
is to identify biomedical entity mentions, disam-
biguate them w.r.t. biomedical databases and to
identify mentioned biomedical relations and, cru-
cially, discover new relations which are not avail-
able in structured resources yet.

When solving biomedical RE and IE tasks, the
standard focus is to build systems that achieve
high precision and recall at identifying known
relations in gold standards or
in biomedical
databases and ontologies. This focus usually over-
looks a key dimension for relation discovery: ex-
traction relevance or trust. Indeed, when applied
to new text in the form of, e.g., recently pub-
lished biomedical papers or papers from transver-
sal domains such as bioinformatics, most discov-
ered relations can arguably be expected to come
up as “false”, without being per se false – but
unrecorded in gold standards.
In other words,
discovered relations fall under one of three cate-
gories: (1) plainly true relations (as per biomedical
gold standards) (2) interesting relations that might
be true or false. (3) plainly false relationships (as
per biomedical gold standards). Our hypothesis
is that a useful conﬁdence measure estimates the
quality of relations in this order, as we exemplify
in Figure 1.

In such a scenario, rather than dismissing all
such unknown (but interesting) relations, the goal
is to return a ranking based on extraction conﬁ-

1http://2016.bionlp-st.org/
2http://www.biocreative.org/

56

dence (Cullota and McCallum, 2004). Conﬁdence
typically refers to some kind of scoring – for in-
stance a real number. This brings forth the prob-
lem of conﬁdence estimation. While it is clear
that the conﬁdence of a relation extracted from
biomedical text should be a function of the dif-
ferent sources of evidence on which it relies, it
is unclear (Q1) how to deﬁne a global conﬁdence
estimator for biomedical relation extraction, and
(Q2) how to evaluate it.

We hypothesize that relation discovery conﬁ-
dence scores rely on three main kinds of sources:

S1: The (aggregated) conﬁdence scores of the in-

dividual modules of the RE pipeline.

S2: The internal graph structure of the discovered

relations.

S3: Evidence gathered from external knowledge
sources, such as textual evidence or knowl-
edge retrieved or inferred from structured
knowledge sources (biomedical ontologies
and databases).

In this paper we outline a ﬁrst attempt to answer
questions (Q1) and (Q2) for the domain of protein-
protein relations and events, focusing on approach
S1. The main contributions of this paper are:
(1) We build a distantly supervised RE pipeline
based on BANNER (Leaman and Gonzalez, 2008)
for NER, TEES (Bj¨orne and Salakoski, 2015) for
EE and RE, and GNAT and Gnorm (Hacken-
berg et al., 2011; Wei et al., 2015) to link pro-
tein mentions to the STRING protein interaction
database (von Mering et al., 2005), to distantly
determine the truth and falsity of the discovered
typed protein-protein relations.
(2) We deﬁne
conﬁdence measures for each component of our
pipeline and analyze their impact on relation pre-
diction. (3) Finally, we propose and compare sev-
eral global conﬁdence estimators that aggregate
over these scores.

2 Evidence Sources for Conﬁdence
As said in the introduction, there are main sources
of evidence for biomedical relation discovery and
extraction, namely: prediction conﬁdence (S1),
graph analytics of the discovered relations (S2)
and domain knowledge gathering (S3). We dis-
cuss these in the following.
S1 Modules (e.g., NER or EE systems) in state-
of-the-art systems are typically underpinned by

IL-6

positive
regulation

...

STAT-3

...

true

TIPE2

growth
factor

negative Snail2
regulation

positive WSC
regulation domain

interesting

false

...

...

...

...

Figure 1: Discovered protein-protein (typed) rela-
tions. Notice how the bottom example is plainly
false (it states a regulation among hormones), and
the top one is plainly true (a known regulation).
We assume the one in the middle to represent a
more interesting result, as this fact is not in the
STRING database; however, PubMed/MEDLINE
abstract 28186089 mentions it (“(...) TIPE2 (...)
downregulated (...) Snail2 (...)”).

supervised classiﬁers that in addition to a pre-
diction, return a probability (e.g., logistic classi-
ﬁers) or a so-called margin (e.g., linear discrimi-
nant classiﬁers). We would expect interesting re-
lations whose individual components (e.g., entities
and events) were identiﬁed with a higher score,
to stand a higher chance of being true. To this
end, one can employ conﬁdence mixtures (Iversen
et al., 2008; Dawid et al., 1995). Given k ex-
perts, each returning a conﬁdence value ci ∈ R,
i = 1 . . . k, a conﬁdence aggregation is a function
ϕ(·) such that c = ϕ(c1, . . . , ck), where c ∈ R
is the global conﬁdence score. Global conﬁdences
thus aggregate partial conﬁdences assigned to the
partial tasks into which a complex task such as re-
lation discovery can be broken down, to produce
a global score. This method, the one actually de-
scribed in this paper, can be seen as a baseline con-
ﬁdence estimator for biomedical RE.

S2
Graph-based conﬁdence estimation tech-
niques on the other hand rely on the graph-
theoretical structure of extracted or discovered
protein interactions and interaction networks. This
makes sense because RE and EE systems (as the
ones we rely on in this paper) actually return such
graphs and interaction networks. In particular, one
can leverage literature in biomedical and cross-
domain link prediction (Lichtenwalter et al., 2010;
Peng et al., 2017; And et al., 2003). Such tech-

57

Last but not

niques generally aim at predicting new edges (bi-
nary relations) in entity graphs via techniques such
as similarity computation, weighted by properties
such as the centrality or prominence of the con-
nected entities – a measure that can be seen as a
kind of conﬁdence score. One can also exploit
shortest path statistics among detected proteins
(lengths of the paths, number of paths), as, intu-
itively the more relations between two proteins,
the more likely that a speciﬁc relation holds.
S3
least, external knowledge
sources can be used to, alone or in combination
with the previous two methods, derive conﬁdence
estimators for biomedical relation discovery. In-
deed, the STRING database itself describes a net-
work of protein interactions, which can be com-
bined with the interaction network built at dis-
covery and extraction time to gather further, gold
standard graph theoretical evidence for discov-
ered interactions. Another possibility is to use
techniques from the knowledge base population
and enrichment communities such as Wick et al.
(2013), reasoning over domain constraints and on
whether discovered interactions satisfy or violate
them (e.g., the third example in Figure 1 is clearly
false because its arguments are not proteins). Fi-
nally, one can also gather textual evidence, using
techniques borrowed from cognitive systems such
as IBM Watson (Murdock et al., 2012), exploit-
ing PubMed/MEDLINE itself to derive lexical evi-
dence.

3 Experiments

In this section, we describe our conﬁdence esti-
mation experiments for typed protein-protein in-
teraction extraction and discovery. We refer to an
ordered triple rel = (p1, r, p2), where r is an event
or relation type denoting a directed relation (e.g.,
an expression, an inhibition) between proteins p1
and p2 as typed interaction. Note that this task is a
subtask of event extraction (Kim et al., 2009) and
an extension to protein-protein interaction detec-
tion (PPIs), where we want to predict if a protein
pair (in any order) interacts in some way (Choi,
2016; Airola et al., 2008). Our whole pipeline is
depicted in Figure 2.

3.1 Datasets
We used two main datasets in our experiments:
Firstly, a large subset of MEDLINE from May 1992
to May 2017 (PMIDs 1376980 to 28211214). We

ignore languages other than English, and entries
without abstract. We also disregarded abstracts
that do not contain any mentions to protein or
genes. This corpus consists of 40,911,675 tokens
in 1,939,915 abstracts.

Secondly, to distantly evaluate discovered rela-
tions, we use the STRING database (von Mering
et al., 2005), which describes protein-protein rela-
tions. STRING was built by integrating different
databases (including the Gene Ontology (GO) and
the Kyoto Encyclopedia of Genes and Genomes
(KEGG)) and expert-curated text-mining-based
information. STRING covers around 9.6 million
protein entries and 1.3 billion interaction entries of
2031 unique organisms species. We focus on the
subset of human proteins and their interactions.
For network analysis, we use a Neo4j3 graph
database. From STRING, we use 20,458 unique
genes/proteins with 6,013,567 unique typed inter-
actions. They refer to 17,538 EntrezGene IDs.

3.2 Relation Extraction
To extract and discover relations in the MED-
LINE subset, we rely on two well-known state-
of-the-art systems for protein and gene detection
and protein-protein event and relation extraction,
namely BANNER and TEES (Leaman and Gon-
zalez, 2008; Bj¨orne and Salakoski, 2015).

BANNER is linear-chain conditional random
ﬁeld (CRF) NER system, that relies on an array
of pre-trained models, dictionary and gold corpora
for training and prediction. It uses the BIO format
to spot the beginning (B) and constituent words (I)
of a protein mention, and tokens that lie outside
(O) mentions. For this paper, we use a gene detec-
tion model trained on the GNormPlus4gene gold
corpus (Wei et al., 2015), which achieves 83 % F1.
Please note that we run BANNER separately from
TEEs and realign the results in a separate step in
the pipeline (see Figure 2).

TEES is a biomedical RE system, underpinned
by a multiclass support vector machine (SVM).
It relies on BANNER as a subcomponent to de-
tect entities and on the BioNLP 2013 shared
task data to estimate SVMs that detect (1) event
triggering words and their GENIA event types:
regulations, positive regulations, negative regula-
tions, (de)phosphorilations (2) the arguments of

3https://neo4j.com/
4We used this model for consistency with the GN systems
that we describe below, which also use models trained over
this corpus created for the BioCreative II GN shared task.

58

Figure 2: Overview of the relation extraction pipeline described in this paper (full pipeline).

Unit
PMIDs
Relations
s Proteins
Events
Causes
Themes
. General
Positive
Negative

t
n
e
m
e
l
E

l
u
g
e
R

Count
11773
21169
11726
864
5694
6032
4425
9830
6484

Table 1:
Event/Relation extraction statistics.
“Events” refers to event trigger words, “Relations”
refers to a relational structure connecting typed
events to cause–theme protein pairs by TEES, as
in Figure 3. All counts are unique counts.

the event or relation: its ﬁrst argument (cause) and
its second argument (theme).
It can also detect
complex event structures, event structures contain-
ing nested events, which we currently disregard.
For each of its predictions, TEES returns a conﬁ-
dence value in the form of an SVM margin (dis-
tance of the trigger or protein to its separating hy-
perplane). TEES achieves 50.74 % F1.

In order to verify if a candidate typed relation oc-
curs in STRING, and to build (silver) standards
for experimental analysis, we deﬁne a mapping
from (M1) a protein mention p to a canonical form
(norm(p)), i.e., STRING protein unique identi-
ﬁers (UIDs), and (M2) a relation/event type r to
a STRING interaction type (ev(r)).

Protein matching
Task (M1) is known in
biomedical literature as the protein normalization
task.
It has been object of active research since
the early 2000s, giving rise to the BioCreative
Gene Normalization (GN) shared task.
In this
paper, we use two state-of-the-art GN systems,
GNAT (Hackenberg et al., 2011), with a perfor-
mance of 86.7 % F1 and GNorm (Wei et al., 2015),
with a performance of 86.4 % F1. We denote this
method by gnN(p), for each GN system N and
protein mention p. GNAT and GNorm normalize
gene/protein mentions to EntrezGene UIDs, which
cover a subset of STRING protein UIDs.

Therefore, in order to increase normalization
recall, we resorted to a disambiguation-based
method. We relied on a STRING RESTful web-
service5 that returns, given a protein mention p,
a list of possible STRING canonical matches, to-
gether with a gloss (a small textual deﬁnition),
to build a custom bag-of-words disambiguation
method, that ranks candidates by computing the
cosine similarity of the gloss and the sentence in
which the mention occurs. We denote this method
by lk(p).

This gave rise to a protein normalization

method for protein mentions p summarized by:

gnN(p),

lk(p),
NA,

if gnN(p)↓,
if gnN(p)↑, lk(p)↓,
if gnN(p)↑, lk(p)↑,

(1)

for N ∈ {GNAT, GNorm}. By ↑ (resp. ↓) we
mean that the method returns no canonical (resp.
returns a canonical) STRING UID for mention p.

5https://string-db.org/cgi/help.pl?

&subpage=api

3.3 Relation Normalization

normN(p)=

59

Figure 3: Protein-protein relational structure extracted by our pipeline for the ﬁrst relation from Figure 1.
The leave nodes represent the protein entities, labeled with their STRING UID and BANNER conﬁdence.
The internal node represents the event in which they participate as arguments, labeled with its TEES
recognition conﬁdence. The labels on its outgoing edges represent cause–theme TEES labeling of its
protein arguments, and its TEES conﬁdence. Finally, the root represents the predicted event type.

Note that GNAT and GNorm were tuned for dis-
tinct, though related GN subtasks, namely human
GN and cross species GN, and can produce differ-
ent results. If no normalization method returns a
STRING UID, we consider the canonical protein
for mention p undeﬁned (NA).
Event type matching
To deal with (M2), we
relied on the other hand on a simple rule-based
method, that maps the three GENIA event types
returned by TEES GENIA event types to typed
and directed interactions in STRING: protein in-
hibitions, activations and expressions. As a GE-
NIA event type r may correspond to more than
one STRING interaction, we map them to sets of
interactions with

ev(r)=

{inhibitits},
{expresses,activates},
{expresses,activates}
∪{inhibits}

,

if r = R−,
if r = R+,

if r = R.

(2)



In other words, a TEES relation type r (a regula-
tion R, a negative regulation R−, or a positive reg-
ulation R+) will be mapped to (sets of) STRING
protein inhibitions, expressions and activations.
For N ∈ {GNAT, GNorm},
Relation matching
we determine a positive match for a candidate
relation (triple) (p1, r, p2) if for at least a value
t ∈ ev(r) the triple (normN(p1), t, normN(p2)) oc-
curs in the STRING database, negative otherwise.
If normN(pi), for i ∈ {1, 2}, returns no canoni-
cal STRING UID, we discard the candidate alto-
gether. As GNAT and GNorm produce different

normalizer
GNAT*
GNormPlus*

norm. relations
11723
8639

positive
973
544

Table 2: Silver standards obtained with our nor-
malization methods. By the asterisk we mean the
GN system plus our backoffs. By “norm.
rela-
tions” we mean the number of relational structures
for which protein pairs and event types could be
normalized to STRING interaction types and pro-
tein UIDs and by “positive” to those that actually
match interactions in STRING.

results, rather than aggregating results, we gen-
erated two separate silver standards, summarized
by Table 2. Both cover around 1/2 of the original
dataset of candidates and both are skewed towards
negative matches.

3.4 Conﬁdence Estimation
In this subsection we describe our global conﬁ-
dence estimation models. These models aggregate
conﬁdence values returned by the key components
of our pipeline, namely, BANNER and TEES for
proteins, and event/event types, as shown in Fig-
ure 3.
Component-wise conﬁdence
For every RE
candidate triple rel = (p1, r, p2) we compute the
following conﬁdence values:

Entity-level (marginal) conﬁdence (BANNER):
we return the so-called product gamma proba-
bility (Cullota and McCallum, 2004) of protein
theme (resp. cause) mentions p starting at position

Positive_regulation

increased:160.61

cause:6.27

theme:7.32

IL-6 (9606.ENSP00000258743):0.99

STAT3 (9606.ENSP00000264657):0.87

Western blot analysis showed that IL-6 increased JKA, STAT3, p-STAT3 and VEGF-C protein levels in the gastric cancer cells. (pmid 26750536)

60

kY

t in an abstract with BIO labels (st, . . . , st+k), de-
ﬁned by:

cfγt(p) =

γi(si)

(3)

i=t

(resp., cfγc(p) for cause mentions) where γi(si) =
αi(si) · βi(si)/P (w0, . . . , wi; Λ) is the normal-
ized product of the forward and backward Viterbi
lattice probabilities of label si ∈ {B, I} at po-
sition i, computed from BANNER’s underlying
CRF model Λ, and wi is a word token. This mea-
sure basically characterizes the likelihood that a
given span of MEDLINE tokens is indeed a pro-
tein.

From TEES, we use event-level conﬁdence
based on the margins in the SVM, namely cfev(r),
cfc(p1) and cft(p2) for event (type), cause, and
theme predictions.

In summary, we use ﬁve component-wise con-
ﬁdence features for a relation triple rel =
(p1, r, p2), namely, the BANNER product gamma
probability of theme proteins, the TEES margin
value for theme proteins, the BANNER product
gamma probability of cause proteins, the TEES
margin value for cause proteins, and the TEES
margin value for events/event types.
Conﬁdence aggregation Different conﬁdence
sources will have a different impact on their global
aggregate (Iversen et al., 2008; Dawid et al.,
1995). Such impact can be quantiﬁed as a weight,
set a priori or a posteriori by training a classiﬁer
over gold (or silver) data and plugging into the ag-
gregates the inferred weights (Liu et al., 2012).
For the experiments described in this paper we
chose the latter, and trained a logistic classiﬁer
over our silver MEDLINE datasets (see the next
subsection for a detailed description), and used
its coefﬁcients ~θ to compute the weights ~we by
(1) measuring their impact on classiﬁcation de-
viance (see Table 5), and (2) normalizing the val-
ues to a number between 0 and 1. We propose two
fundamentally different methods to aggregate the
separate conﬁdence values to one measure for a
triple rel.

The ﬁrst method assumes that global conﬁ-
dence is a linear combination of component-
wise conﬁdences for a relation rel (cfm, with
m ∈ {γt, γc, ev, c(p1), t(p2)}), namely,
their
(weighted) average:

cfavg =

·

1
5

wem · cfm

(4)

X

m

is

that

The

assumes

conﬁdence

second method

each
component-wise
totally inde-
pendent of each other (and hence independence
for each pipeline prediction), and deﬁnes global
conﬁdence as a (weighted) product:
wem · cfm

Y

cfprod =

(5)

m

We considered also unweighted versions of
the conﬁdence aggregators, by considering unit
weights ~we = (1, 1, 1, 1, 1)T , that assign the same
importance to all component-wise conﬁdences.
Evaluation
To evaluate our approach, we re-
lied on a number of different strategies and com-
binations thereof. In particular, we split our two
silver GNAT and GNORM datasets SN, into two
disjoint train TN and test EN subsets. Given how
unbalanced our data is, we, in addition, resam-
pled the training sets by (1) oversampling positive
matches, and (2) undersampling negative matches
until we obtained two balanced training sets SGNAT
and SGNorm each of 2000 relations. For testing, we
kept a set of 1000 unresampled relations each.

To learn the weights ~θ of the conﬁdence aggre-
gation models and hence of component-wise con-
ﬁdences, we trained a logistic classiﬁer over each
of our silver standards:
P (t0 =1|~c)=(1 + exp(−

θm · cfm))−1

X

(6)

m

where t0 = 1 if normalized triple rel
is in
STRING, m ∈ {γt, γc, ev, c(p1), t(p2)} and
~c = (cfγt, cfγc, cfev, cfc(p1), cft(p2))T . The pa-
rameters ~θ were learned by maximizing the like-
· (1 −
lihood L(~θ;TN) =

j π(~c(j); ~θ)r0(j)

Q

train dataset T
gnat train
gnorm train
gnat train
gnorm train

test dataset E
test gnat
test gnat
test gnorm
test gnorm

F1
0.688
0.658
0.766
0.733

Table 3: Evaluation of logistic models over the dif-
ferent possible train/test combinations of our vari-
ous silver standards. In bold, the combination with
the best performance. We used the best model
(gnat train) to derive the logistic model (Equa-
tion 6) and the weights used in the weighted con-
ﬁdence aggregation models.

61

cfγc > 0.978?
yes
no

cfγc > 0.84?
yes
no

n = 961

t/f: 40%/60%

cfγt > 0.997?
no
yes

n = 429

t/f: 38%/62%

cfγc > 1?

no

yes

cfγc > 0.993?
yes
no

n = 305

t/f: 75%/25%

cft > 4.361?
yes
no

n = 246

t/f: 63%/37%

cfev > 80.959?
yes
no

n = 224

t/f: 65%35%

n = 697

t/f: 40%/60%

n = 628

t/f : 59%/41%

n = 236

t/f: 40%/60%

n = 274

t/f: 60%/40%

Figure 4: Right: J48 decision tree for the GNAT silver standard (training set). Left: J48 decision tree for
the GNorm silver standard (training set). Nodes correspond to the component-wise conﬁdence features
deﬁned in Section 3.4. The higher a component-wise conﬁdence, the higher its information gain. Notice
how, in general, we observe a higher gain for TEES conﬁdence scores, plus some contribution coming
from the BANNER conﬁdence of theme proteins. We used for both models a pruning setup whereby we
imposed each tree leave to contain at least 150 relations. In the visualization, the leaves describe also the
distribution of positive (t) and negative (f) matches for each bin, and their size n (triples per bin).

estimator
cfprod (unweig.)
cfprod
cfavg
cfavg

(unweig.)

Kendall τ

0.041
0.041
0.032
0.050

p-value
0.127
0.127
0.210
0.056

Table 4: Correlation-based evaluation of the con-
ﬁdence aggregation models.
In bold, the model
with the highest τ value. No test was statistically
signiﬁcant (although one came close to p = 0.05).
In all cases, this indicates absence of correlation
with linking judgments. Unweighted models were
obtained by considering uniform weights (viz.,
~we = (1, 1, 1, 1, 1)T ).

π(~c(j); ~θ))1−r0(j) via iterative weighted least
squares. We tested each of the two ensuing lo-
gistic models over each of the two test datasets,
and chose the model with the highest F1, as seen
in Table 3.

The conﬁdence estimation models themselves
were evaluated following a methodology pro-
posed by Cullota and McCallum (2004) to evalu-
ate entity-level conﬁdence measures: measure the
correlation between matching judgments and rela-

feature
cfev
cft
cfc
cfγt
cfγc

deviance
6.200

p-value
0.013

17.803 2.451 · 10−05

4.858
2.370

0.028
0.124

22.667 1.926 · 10−06

Table 5: ANOVA/Analysis of deviance table for
the best logistic model from Table 3 (χ2-test). In
bold, the features with greater impact, both statis-
tically signiﬁcant with p < 0.01.

tion conﬁdence. Ideally, one would expect a bias
in conﬁdence towards positive matches. In this pa-
per, we considered Kendall’s τ correlation, which
is rank-sensitive and robust to ties.

Last, but not least, we used the logistic model
and the balanced datasets to conduct an ex-
ploratory analysis on the component-wise conﬁ-
dence themselves, to understand which, from all
of our pipeline’s components has a bigger im-
pact on global conﬁdence estimation. To this
end we relied on two separate methodologies: On
the one hand, we conducted an analysis of vari-

62

ance/deviance6 over the (optimal) logistic model’s
features. On the other hand, we inferred two de-
cision trees over our two training sets. Decision
trees rank component-wise conﬁdences cfm, w.r.t.
information gain. We used the J48 decision tree
classiﬁer7, that discretizes continuous variables.

4 Results and Discussion

The results of our conﬁdence aggregation experi-
ments are summarized by Tables 3–5 and Figure 4.
As Table 3 shows, the best logistic model was
Inter-
obtained over the GNAT training dataset.
estingly, the best result arose from cross-testing,
when be tested it of the GNorm dataset test corpus.
We conjecture that this might be due to a slightly
better generalization capacity of the GNAT nor-
malizer, as opposed to GNorm.

Regarding our conﬁdence estimation models
however, as Table 4 shows, our analysis returned
no observable correlation (all τ values are close
to zero), but without reaching statistical signiﬁ-
cance. Furthermore, of all estimators, the best (al-
beit by a very small margin) estimator was aver-
age, weighted conﬁdence. We interpret this neg-
ative result to mean that aggregating conﬁdences
alone, disregarding: (1) the performance and/or
conﬁdence of the different normalizations meth-
ods (2) the structural properties of discovered re-
lations, and (3) additional evidence gathered from
external sources is simply not enough to deﬁne
meaningful conﬁdence estimators.

Finally, as shown by Table 5 and Figure 4 both
the ANOVA and decision-tree/information gain
analysis point out that the most informative fea-
tures were the BANNER and TEES conﬁdences
for the arguments – the theme (2nd argument) and
the cause (1st argument) – of protein-protein rela-
tional structures. Interestingly event (TEES) con-
ﬁdences do not seem to play a major role. This
however seems consistent with the fact that TEES
models are optimized for recognizing theme-event
and cause-event pairs (by leveraging on the depen-
dency parse tree of the sentence), a harder task
than that of event recognition.

It suggests that while the aggregation of
component-wise conﬁdences is not a good global

6Logistic models are known in statistical literature as gen-
eralized linear models; in such cases rather than analyzing er-
ror variance as for linear models, one analyzes deviance, viz.,
prediction error.

7Weka

(http://www.cs.waikato.ac.nz/ml/

weka/) for our logistic and J48 models.

conﬁdence estimator, including them as features
of a more complex model encompassing a wider
array of evidence sources might still be useful. It
also suggests that normalization conﬁdence – the
last step in the pipeline – should be taken into ac-
count as the conﬁdence values coming from pro-
tein recognition have the most impact.

5 Conclusions & Future Work

In this paper we have proposed a conﬁ-
dence estimation methodology for biomedical
protein-protein typed interaction discovery from
PubMed/MEDLINE abstracts. Measuring conﬁ-
dence or trust is important because in this set-
ting not all false positives – interactions that are
not known to occur in biomedical databases –
may be necessarily false. This sorting by con-
ﬁdence should satisfy key criteria, namely that
true matches should be scored high, clearly false
matches low, and “interesting” relations some-
where in between.

To do so, we have proposed a pipeline that
builds upon state-of-the-art protein NER, protein-
protein EE and RE and GN systems,
to dis-
cover and distantly evaluate against the STRING
database protein-protein typed interactions. Then,
we have described a number of baseline conﬁ-
dence estimation techniques that aggregate the
conﬁdence prediction scores of the pipeline’s
components.

Our experiments and correlation analysis show
that, while the prediction conﬁdence of modules in
later stages of the pipeline seems to inﬂuence more
positive decisions, conﬁdence aggregation is not
enough to deﬁne estimation models satisfying the
criteria mentioned. We conjecture that this is due
to the fact that prediction conﬁdence alone does
not provide sufﬁcient evidence to rank relations.
Also, in this work, the conﬁdence of normaliza-
tion was not fully addressed. As further work we
plan to focus on more complex evidence gathering
methods.
Aknowledgements We thank J¨org Hackenberg
for his help running and integrating GNAT into
our pipeline, and Philippe Thomas for his com-
ments on our event mappings. This work was sup-
ported by a grant from the Ministry of Science,
Research and Arts of Baden-W¨urttemberg to Ro-
man Klinger.

63

References
Antti Airola, Sampo Pyysalo, Jari Bj¨orne, Tapio
Pahikkala, Filip Ginter, and Tapio Salakoski. 2008.
All-paths graph kernel for protein-protein interac-
tion extraction with evaluation of cross-corpus learn-
ing. BMC Bioinformatics 9(Suppl 11):S2.

Dennis Wilkinson And, Dennis Wilkinson,

and
Bernardo A. Huberman. 2003. A method for ﬁnd-
ing communities of related genes.
In Proceedings
of the National Academy of Sciences of the United
States of America. pages 5241–5248.

Jari Bj¨orne and Taio Salakoski. 2015.

Tees 2.2:
Biomedical event extraction for diverse corpora.
BMC Bioinformatics 16(16):S4.

Sung-Pil Choi. 2016. Extraction of proteinprotein in-
teractions (PPIs) from the literature by deep con-
volutional neural networks with various feature em-
beddings. Journal of Information Science .

Aron Cullota and Andrew McCallum. 2004. Conﬁ-
dence estimation for information extraction. In Pro-
ceedings of the 2004 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics. HLT-NAACL ’04, pages 109–112.

A. Dawid, M. DeGroot, J. Mortera, Roger Cooke,
S. French, C. Genest, M. Schervish, D. Lindley,
K. McConway, and R. Winkler. 1995. Coherent
combination of experts’ opinions. TEST: An Ofﬁ-
cial Journal of the Spanish Society of Statistics and
Operations Research 4(2):263–313.

J¨og Hackenberg, Marin Gerner, Maximilian Haeus-
sler, Ill´es Solt, Conrad Plake, Martin Schroder,
Graciela Gonzalez, Goran Nenadic, and Casey M.
Bergman. 2011. The GNAT library for local and
remote gene mention normalization. Bionformatics
27(19):2769–2771.

Edwin S Iversen, Giovanni Parmigiani, and Sin-
ing Chen. 2008. Multiple model evaluation ab-
sent
the gold standard through model combina-
tion. Journal of the American Statistical Association
103(483):897–909.

Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-
nobu Kano, and Jun’ichi Tsujii. 2009. Overview
of BioNLP ’09 shared task on event extraction. In
Proceedings of the Workshop on Current Trends in
Biomedical Natural Language Processing: Shared
Task. BioNLP ’09, pages 1–9.

Robert Leaman and Graciela Gonzalez. 2008. BAN-
NER: An executable survey of advances in biomed-
ical named entity recognition. In Proceedings of the
2008 Paciﬁc Symposium on Biocomputing. PSB ’08,
pages 652–63.

Ryan N. Lichtenwalter, Jake T. Lussier, and Nitesh V.
Chawla. 2010. New perspectives and methods in
link prediction.
In Proceedings of the 16th ACM
SIGKDD International Conference on Knowledge

Discovery and Data Mining. KDD ’10, pages 243–
252.

X. Liu, Amol Ghorpade, Y. L. Tu, and W. J. Zhang.
2012. A novel approach to probability distribution
aggregation. Information Science 188:269–275.

J. William Murdock, James Fan, Adam Lally, Hideki
Shima, and Branimir Boguraev. 2012. Textual ev-
idence gathering and analysis. IBM Journal of Re-
search and Development 56(3):8.

Jiajie Peng, Kun Bai, Xuequn Shang, Guohua Wang,
Hansheng Xue, Shuilin Jin, Liang Cheng, Yadong
Wang, and Jin Chen. 2017.
Predicting disease-
related genes using integrated biomedical networks.
BMC genomics 18(1):1043.

Raul Rodriguez-Esteban. 2009. Biomedical Text Min-
ing and Its Applications. PLoS Comput Biol 5(12).

L. Venkata Subramaniam, Sougata Mukherjea, Pankaj
Kankar, Biplav Srivastava, Vishal S. Batra, Pa-
sumarti V. Kamesam, and Ravi Kothari. 2003.
Information extraction from biomedical literature:
Methodology, evaluation and an application. In Pro-
ceedings of the Twelfth International Conference on
Information and Knowledge Management. CIKM
’03, pages 410–417.

Kateryna Tymoshenko, Swapna Somasundaran, Vinod-
kumar Prabhakaran, and Vinay Shet. 2012. Rela-
tion mining in the biomedical domain using entity-
level semantics.
In Proceedings of the 20th Eu-
ropean Conference on Artiﬁcial Intelligence. ECAI
’12, pages 780–785.

J.

Christian von Mering, Lars

Jensen, Berend
Snel, Sean D. Hooper, Markus Krupp, Mathidel
Foglierini, Nelly Jouffre, Martijn A. Huynen, and
Peer Bork. 2005. STRING: Known and predicted
protein-protein associations, integrated and trans-
ferred across organisms. Nucleic Acids Research
33(Suppl. 1):D433–D437.

Chih-Husuan Wei, Hung-Yu Kao, and Zhiyoung
Lu. 2015.
GNomrPlus: An integrative ap-
proach for tagging genes, gene families, and pro-
tein domains.
BioMed Research International
2015(2015):ID 918710.

Michael L. Wick, Sameer Singh, Ari Kobren, and An-
drew McCallum. 2013. Assessing conﬁdence of
knowledge base content with an experimental study
in entity resolution.
In Proceedings of the 2013
Workshop on Automated Knowledge Base Construc-
tion. AKBC@CIKM ’13, pages 13–18.

Jin Guang Zheng, Daniel Howsmon, Boliang Zhang,
Juergen Hahn, Deborah McGuinness,
James
Hendler, and Heng Ji. 2014. Entity linking for
biomedical literature.
In Proceedings of the ACM
8th International Workshop on Data and Text
Mining in Bioinformatics. DTMBIO ’14, pages 3–4.

