



















































ThinkMiners: Disorder Recognition using Conditional Random Fields and Distributional Semantics


Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 652–656,
Dublin, Ireland, August 23-24, 2014.

ThinkMiners: Disorder Recognition using Conditional Random Fields
and Distributional Semantics

Ankur Parikh Avinesh PVS Joy Mustafi Lalit Agarwalla Ashish Mungi
IBM India Pvt Ltd, IBM Software Group, Watson

{anparikh,pavinesh,jmustafi,lalit.agarwalla,r1amungi}@in.ibm.com

Abstract

In 2014, SemEval organized multiple chal-
lenges on natural language processing and
information retrieval. One of the task was
analysis of the clinical text. This challenge
is further divided into two tasks. The task
A of the challenge was to extract disor-
der mention spans in the clinical text and
the task B was to map each of the disor-
der mentions to a unique Unified Medical
Language System Concept Unique Iden-
tifier. We participated in the task A and
developed a clinical disorder recognition
system. The proposed system consists of
a Conditional Random Fields based ap-
proach to recognize disorder entities. The
SemEval challenge organizers manually
annotated disorder entities in 298 clini-
cal notes, of which 199 notes were used
for training and 99 for development. On
the test data, our system achieved the F-
measure of 0.844 for entity recognition in
relaxed and 0.689 in strict evaluation.

Keywords: medical language processing,
clinical concept extraction, conditional
random fields.

1 Introduction

Mining concepts from the electronic medical
records such as clinical reports, discharge sum-
maries as well as large number of doctor’s notes
has become an utmost important task for auto-
matic analysis in the medical domain. Identifica-
tion and mapping of the concepts like symptoms,
disorders, surgical procedures, body sites to a nor-
malized standards are usually the first steps to-

This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/

wards understanding natural language text in the
medical records.

In this paper, we describe a machine learning
based disorder recognition system for the Task 7A
of 2014 SemEval challenge. In Section 2 we give
a background of the existing solutions to tackle
the problem. Section 3 covers our approach in
detail, followed by evaluation and conclusion in
Section 4 and Section 5 respectively.

2 Background

In recent times, many systems have been de-
veloped to extract clinical concepts from vari-
ous types of clinical notes. The earlier nat-
ural language processing (NLP) systems were
mainly built heavily using domain knowledge
i.e. medical dictionaries. These systems in-
clude MetaMap (Aronson and Lang, 2010), Hi-
TEX (Zeng et al., 2006), KnowledgeMap (Denny
et al., 2003), MedLEE (Friedman et al., 1994),
SymText (Koehler, 1994) and Mplus (Christensen
et al., 2002). In the past couple of years, re-
searchers have been exploring the use of machine
learning algorithms in the clinical concept detec-
tion. To promote the research in this field many or-
ganizations such as ShARe/CLEF, SemEval have
organized a few clinical NLP challenges. In CLEF
2013 (Pradhan et al., 2013), the challenge was to
recognize medication-related concepts. Both rule-
based (Fan et al., 2013; Ramanan et al., 2013;
Wang and Akella, 2013) and machine learning
based methods as well as hybrid methods (Xia
et al., 2013; Osborne et al., 2013; Hervas et al.,
2013) were developed. In this shared-task sequen-
tial labeling algorithms (i.e., Conditional Random
Fields (CRF)) (Gung, 2013; Patrick et al., 2013;
Bodnari et al., 2013; Zuccon et al., 2013) and ma-
chine learning methods (i.e., Support Vector Ma-
chine (SVM)) (Cogley et al., 2013) have been
demonstrated to achieve promising performance
when provided with a large annotated corpus for

652



Figure 1: Dataset distribution

training.

3 Approach

Entity recognition has been tried in various do-
mains like news articles, Wikipedia, sports arti-
cles, financial reports and clinical texts. In clinical
text, entities can vary from medical procedures,
disorders, body site indicators etc. Clinical text
also presents with a peculiar concept of disjoint
disorders/entities. This phenomenon is common
in clinical domain compared to others and further
complicates entity extraction from clinical notes.

3.1 Data
The data consisted of around 298 notes from dif-
ferent clinical types including radiology reports,
discharge summaries, ECG and ECHO reports.
For each note, disorder entities were annotated
based on a pre-defined guidelines. The data set
was further divided into two, with 199 notes in the
training set and 99 notes in the development set.
The training set contains 5811 disorders where as
the development contained 5340 disorders. Figure
1 shows the distribution of the training and devel-
opment set respectively.

3.2 Data Preprocessing
In the pre-processing step we tokenized, lemma-
tized and tagged the text with part of speech us-
ing the Apache cTAKES1 (Savova et al., 2010).
Further, section and source meta data extraction is
done for the text in the documents.

In Named Entity Recognition (NER), when
solved using machine learning, the text is typically
converted to BIO format (Beginning, Inside and
Outside the entity). BIO representation means the

1https://ctakes.apache.org/

words in the text are assigned one of the follow-
ing tags B - begin, I - inside and O - outside of the
entity i.e. in this case a disorder. So now the task
of NER is a sequence labeling problem to assign
the labels to the tokens. Especially in the medical
domain, the challenge is more complicated due to
the presence of disjoint disorders (<10%), which
could not be solved using the traditional BIO-
notation. BIO approach works well with entities
which are consecutive. So, we took an enhanced
approach (Tang et al., 2013a) where the consec-
utive disorders are assigned traditional BIO tags
and for disjoint disorders we create two tag sets a)
D{B,I} : for disjoint entity words which are not
shared by multiple concepts; and b) H{B,I}: for
disjoint entity words which belong to more than
one disjoint concept.

The following examples show the annotations
of consecutive as well as disjoint disorders.

1: “The left atrium is moderately dilated.”
“The/O left/DB atrium/DI is/O moderately/O
dilated/DB ./O”

2: “The left & right atrium are moderately
dilated.”
“The/O left/DB &/O right/DB atrium/HB are/O
moderately/O dilated/HB ./O”

3.3 Sequence Labeling

We have used Conditional Random Fields (CRF),
a popular approach to solve sequence labeling
tasks. CRF++2 was used as an implementation of
CRF for our purpose.

2http://crfpp.googlecode.com/svn/trunk/doc/index.html

653



Feature set used for the learning algorithm:

• Word level features: words [-2,2], suffix and
prefix.

• Syntactic features: parts-of-speech(POS).

• Discourse features: source & section. Sen-
tence containing disorder mentions usually
have similar syntactic patterns based on sec-
tions (ex: ‘Past Medical History’) and source
type (ex: discharge summary, radiology re-
port). To capture this, source and section
meta data have been provided as a feature.

• Distributional semantics: We used a con-
textual similarity based approach from the
popular concept called NC-value (Frantzi et
al., 2000).

We followed the following steps to encap-
sulate the distributional semantics into the
learning model:

– For all the disorders in the training data
we created two sets of contextual words
namely context before (CBatrain) and
context after (CAatrain). These words
belong to open class (Noun, Verb, Ad-
jective, Adverb) allocated for each sec-
tion (Sj).

– Weights are calculated for the contex-
tual words.

Weight(btrain) =
freq(disorders,b)
freq(disorders)

– For each word in the test data we created
a similar sets of contextual words(CBa,
CAa) as above.

– Two scores are calculated for each
token based on the product of frequency
of the contextual word per section Sj
with weight calculated of that word in
the training set.

For each section (Sj):

NC−valueB(a) =
X

b�CBa,Sj

fa(btest)∗weight(btrain)

(1)

NC−valueA(a) =
X

b�CAa,Sj

fa(btest)∗weight(btrain)

(2)

where
a is the candidate term,

CBa is the set of context words of “a”
in a window of [-2,0],
CAa is the set of context words of “a”
in a window of [0,2],
Sj is a section like “Past Medical
History”, “Lab Reports” etc.
b is a word from CBa or CAa,
fa(btest) is the frequency of b as a term
context word of “a” in the test set,
weight(btrain) is the weight of b as term
context word of a disorder in the
training set,
NC-valueB(a) is the distributional
semantic score of contextual words
before the candidate term,
NC-valueA(a) is the distributional
semantic score of contextual words
after the candidate term.

– Further a similarity class is calculated
based on a set of thresholds on the
NC-value namely High-Sim, Med-Sim,
Low-Sim and assigned to the tokens.

Most of the features were similar to that of the pre-
vious approaches (Tang et al., 2013a; Tang et al.,
2012; Tang et al., 2013; Jiang et al., 2011) with an
addition of an innovative distributional semantics
based features (Nc-valueB , NC-valueA), which we
have tried and tested for concept mining in clinical
text.

4 Evaluation

The evaluation was done in two categories a) strict
evaluation: exact match, which requires the start-
ing and ending of the concept to be the same as
the gold standard data b) relaxed evaluation: here
the concepts don’t match exactly with the start and
end of the concept but may overlap.

In the strict and relaxed evaluation, the best F-
measure among our system was 0.689, 0.844 with-
out the distributional semantics where as best Pre-
cision was 0.907, 0.749 with the distributional se-
mantics as a feature. Table 1. shows the detailed
result.

5 Conclusion

Extraction of the concepts from the medical text
is the fundamental task in the process of analysing
patient data. In this paper we have tried a CRF
based approach to mine the disorder terms from
the clinical free text. We have tried various word

654



SemEval-2014 Strict Relaxed
Shared Task 7A Precision Recall F-measure Precision Recall F-measure
Disorder Recognition

0.734 0.65 0.689 0.892 0.802 0.844without Distributional
Semantics Feature
Disorder Recognition

0.749 0.617 0.677 0.907 0.758 0.826with Distributional
Semantics Feature

Table 1: Results of the system on test set

level, syntactic, discourse and distributional se-
mantic based features as adapted to the medical
domain.

We have observed an increase (+1.5%) in pre-
cision but a drastic fall (-4.4%) in recall while
using the distributional semantic feature. Ideally
this feature has to improve the results because it
takes contextual features into consideration. In our
opinion inappropriate scaling of the feature values
might have caused the drop. Further we would
like to investigate the use of large unlabeled data,
dependency tree based context and more experi-
ments have to be carried out like threshold setting,
feature value scaling to show better results. Also
due to license issues we could not use UMLS dic-
tionary. From our survey we figured out that 2-3%
of improvement has been observed when the con-
cepts from the dictionary are used.

References

B. Tang, H. Cao, Y. Wu, M. Jiang, and H. Xu.
2013. Recognizing clinical entities in hospital dis-
charge summaries using Structural Support Vector
Machines with word representation features. BMC
Med Inform Decis Mak, vol. 13 Suppl 1, p. S1.

M. Jiang, Y. Chen, M. Liu, S. T. Rosenbloom, S. Mani,
J. C. Denny, and H. Xu. 2011. A study of machine-
learning-based approaches to extract clinical enti-
ties and their assertions from discharge summaries.
J Am Med Inform Assoc, vol. 18, no. 5, pp. 601606.

B. Tang, Y. Wu, M. Jiang, Y. Chen, J. C. Denny, and H.
Xu. 2013. A hybrid system for temporal informa-
tion extraction from clinical text. J Am Med Inform
Assoc.

B. Tang, H. Cao, Y. Wu, M. Jiang, and H. Xu. 2012.
Clinical entity recognition using structural support
vector machines with rich features. in Proceedings
of the ACM sixth international workshop on Data
and text mining in biomedical informatics, New
York, NY, USA, pp. 1320.

C. Friedman, P. O. Alderson, J. H. Austin, J. J. Cimino,
and S. B. Johnson. 1994. A general natural-
language text processor for clinical radiology. J Am
Med Inform Assoc, vol. 1, no. 2, pp. 161174.

S. B. Koehler. 1994. SymText: a natural language un-
derstanding system for encoding free text medical
data. University of Utah.

L. M. Christensen, P. J. Haug, and M. Fiszman. 2002.
MPLUS: a probabilistic medical language under-
standing system. in Proceedings of the ACL-02
workshop on Natural language processing in the
biomedical domain - Volume 3, Stroudsburg, PA,
USA, pp. 2936.

J. C. Denny, P. R. Irani, F. H. Wehbe, J. D. Smithers,
and A. Spickard. 2003. The KnowledgeMap
Project: Development of a Concept-Based Medical
School Curriculum Database. AMIA Annu Symp
Proc, vol. 2003, pp. 195199.

G. K. Savova, J. J. Masanz, P. V. Ogren, J. Zheng,
S. Sohn, K. C. Kipper Schuler, and C. G. Chute.
2010. Mayo clinical Text Analysis and Knowledge
Extraction System (cTAKES): architecture, compo-
nent evaluation and applications. J Am Med Inform
Assoc, vol. 17, no. 5, pp. 507513.

Q. T. Zeng, S. Goryachev, S. Weiss, M. Sordo, S. N.
Murphy, and R. Lazarus. 2006. Extracting princi-
pal diagnosis, co-morbidity and smoking status for
asthma research: evaluation of a natural language
processing system. BMC Med Inform Decis Mak,
vol. 6, p. 30.

A. R. Aronson and F. M. Lang. 2010. An overview
of MetaMap: historical perspective and recent ad-
vances. J Am Med Inform Assoc, vol. 17, no. 3, pp.
229236.

. Uzuner, I. Solti, and E. Cadag. 2010. Extracting med-
ication information from clinical text. J Am Med
Inform Assoc, vol. 17, no. 5, pp. 514518.

Katerina Frantzi, Sophia Ananiadou, and Hideki Mima
2000. Automatic recognition of multi-word terms:.
the C-value/NC-value method. International Journal
on Digital Libraries 3(2):115–130.

655



James Cogley, Nicola Stokes and Joe Carthy. 2013.
Medical Disorder Recognition with Structural Sup-
port Vector Machines. Online Working Notes of the
CLEF 2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.

Robert Leaman, Ritu Khare and Zhiyong Lu. 2013.
NCBI at 2013 ShARe/CLEF eHealth Shared Task:
Disorder Normalization in Clinical Notes with
Dnorm. Online Working Notes of the CLEF 2013
Evaluation Labs and Workshop, 23 - 26 September,
Valencia - Spain.

James Gung. 2013. Using Relations for Identifica-
tion and Normalization of Disorders: Team CLEAR
in the ShARe/CLEF 2013 eHealth Evaluation Lab.
Online Working Notes of the CLEF 2013 Evaluation
Labs and Workshop, 23 - 26 September, Valencia -
Spain.

Hongfang Liu, Kavishwar Wagholikar, Siddhartha Jon-
nalagadda and Sunghwan Sohn. 2013. Integrated
cTAKES for Concept Mention Detection and Nor-
malization. Online Working Notes of the CLEF
2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.

Jon D. Patrick, Leila Safari and Ying Ou. 2013.
ShARe/CLEF eHealth 2013 Named Entity Recogni-
tion and Normalization of Disorders Challenge. On-
line Working Notes of the CLEF 2013 Evaluation
Labs and Workshop, 23 - 26 September, Valencia -
Spain.

Andreea Bodnari, Louise Deleger, Thomas Lavergne,
Aurelie Neveol and Pierre Zweigenbaum. 2013.
A Supervised Named-Entity Extraction System for
Medical Text. Online Working Notes of the CLEF
2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.

Guido Zuccon, Alexander Holloway, Bevan Koop-
man and Anthony Nguyen. 2013. Identify Disor-
ders in Health Records using Conditional Random
Fields and Metamap AEHRC at ShARe/CLEF 2013
eHealth Evaluation Lab Task 1. Online Working
Notes of the CLEF 2013 Evaluation Labs and Work-
shop, 23 - 26 September, Valencia - Spain.

Jung-wei Fan, Navdeep Sood and Yang Huang. 2013.
Disorder Concept Identification from Clinical Notes
An Experience with the ShARe/CLEF 2013 Chal-
lenge. Online Working Notes of the CLEF 2013
Evaluation Labs and Workshop, 23 - 26 September,
Valencia - Spain.

S. V. Ramanan, Shereen Broido and P. Senthil Nathan.
2013. Performance of a multi-class biomedical tag-
ger on clinical records. Online Working Notes of
the CLEF 2013 Evaluation Labs and Workshop, 23
- 26 September, Valencia - Spain.

Chunye Wang and Ramakrishna Akella. 2013. Perfor-
mance of a multi-class biomedical tagger on clinical
records. Online Working Notes of the CLEF 2013

Evaluation Labs and Workshop, 23 - 26 September,
Valencia - Spain.

Yunqing Xia, Xiaoshi Zhong, Peng Liu, Cheng Tan,
Sen Na, Qinan Hu and Yaohai Huang. 2013. Com-
bining MetaMap and cTAKES in Disorder Recog-
nition: THCIB at CLEF eHealth Lab 2013 Task 1.
Online Working Notes of the CLEF 2013 Evaluation
Labs and Workshop, 23 - 26 September, Valencia -
Spain.

John David Osborne, Binod Gyawali and Thamar
Solorio. 2013. Evaluation of YTEX and MetaMap
for clinical concept recognition. Online Working
Notes of the CLEF 2013 Evaluation Labs and Work-
shop, 23 - 26 September, Valencia - Spain.

Lucia Hervas, Victor Martinez, Irene Sanchez and
Alberto Diaz. 2013. UCM at CLEF eHealth
2013 Shared Task1. Online Working Notes of the
CLEF 2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.

Sameer Pradhan, Noemie Elhadad, Brett R. South,
David Martinez, Lee Christensen, Amy Vogel,
Hanna Suominen, Wendy W. Chapman and Guer-
gana Savova. 2013. Task 1: ShARe/CLEF eHealth
Evaluation Lab 2013. Online Working Notes of the
CLEF 2013 Evaluation Labs and Workshop, 23 - 26
September, Valencia - Spain.

656


