



















































Orwellian-times at SemEval-2019 Task 4: A Stylistic and Content-based Classifier


Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019), pages 976–980
Minneapolis, Minnesota, USA, June 6–7, 2019. ©2019 Association for Computational Linguistics

976

Orwellian-times at SemEval-2019 Task 4:
A Stylistic and Content-based Classifier

Jürgen Knauth
Institute of Computer Science

University of Goettingen
jknauth@uni-goettingen.de

Abstract

While fake news detection received quite a
bit of attention in recent years, hyperparti-
san news detection is still an underresearched
topic. This paper presents our work towards
building a classification system for hyperpar-
tisan news detection in the context of the Se-
mEval2019 shared task 4. We experiment with
two different approaches - a more stylistic one,
and a more content related one - achieving av-
erage results.

1 Introduction

Recent years have seen a noticeable change in the
political discourse: Political polarization has in-
creased and political opinions have become more
hyperpartisan (Doherty, 2017). This affects the
media, especially news media and is therefore a
topic of considerable interest for science and soci-
ety.

We present an approach for the detection of high
polarization and hyperpartisan news articles. Our
approach addresses stylistic and content related
features. The latter are implemented by identify-
ing n-grams that are typical for either a hyperpar-
tisan or a more balanced perspective.

1.1 The Task

The goal of the SemEval2019 Hyperpartisan News
Detection Task (Kiesel et al., 2019) is to build a
system capable of classifying arbitrary articles ei-
ther as non-hyperpartisan or hyperpartisan.

1.2 The Dataset

For building a classification system the organiz-
ers of the task provided several data sets extracted
from different American news sites:

a) a set of 600.000 articles for training (classifica-
tion: by publisher’s general orientation)

b) a set of 150.000 articles for validation (classifi-
cation: by publisher’s general orientation)

c) 645 training articles (classified individually by
humans using a crowd sourcing approach)

d) validation set (classified by publisher, un-
known size as this data set has been hidden dur-
ing the task)

e) validation set (classified individually, unknown
size as this data set has been hidden during the
task)

All data - the articles themselves as well as
the ground truth data - is provided in an propri-
etary but simple and well parsable XML format
defined by the task owners. The individual data
records includes a globally unique ID, the title,
the source URL and publication time. Addition-
ally the ground truth data for a) and b) contains
information about a left-right bias of the publisher
in general.

2 Related Work

Not so much research has been done in regard
to hyperpartisan news detection. Other work is
primarily addressing related fields such as ideol-
ogy detection, fake news detection. For exam-
ple (Hutto et al., 2015; Hamborg et al., 2018) ad-
dresses identification and quantification of media
bias. (Iyyer et al., 2014) addresses political ide-
ology detection using recursive neural networks.
(Rashkin et al., 2017) is analyzing language in
fake news for automated political fact-checking.
One interesting work directly targeting hyperpar-
tisan news is the work of (Potthast et al., 2018)
identifing hyperpartisan news articles via style.



977

3 Methodology

3.1 PoS Tagging

As we hypothesize that not all parts-of-speech are
equally important for distinguishing hyperparti-
san and non-hyperpartisan articles, we lemmatized
and pos-tagged the dataset.

Initially, we experimented with the TreeTagger
(Schmid, 1994), however since this turned out not
to be sufficiently robust for the noisy input data,
which included encoding errors as well as portions
of JavaScript code, we later adopted the Stanford
CoreNLP tagger (Manning et al., 2014).

3.2 Feature Extraction

We used a total of 108 features for our experi-
ments. The next sections discusses our features
in detail.

3.2.1 Linguistic Complexity and Style
Features

Basic complexity: We hypothesize that hyperpar-
tisan texts are stylistically less complex than non-
hyperpartisan texts (Potthast et al., 2018), hence
we implemented a number of features measuring
linguistic complexity. We measure the distribu-
tion characteristics of paragraph lengths, sentence
lengths and word lengths. Individual features were
derived from that data like minimum, maximum,
variance, mean, et cetera.

Number of words in main part-of-speech cate-
gories: We collect the number of verbs, nouns,
adjectives and adverbs in articles and derive dis-
tribution features from it. While not every part-of-
speech category will have the same importance we
rationalize that at least the distribution character-
istics of nouns, adjectives and adverbs could be a
style hint for hyperpartisan or non-hyperpartisan.

Simple form of lexical density: As “lexical den-
sity” we here consider the ratio of words being not
part of the NLTK stop-words in comparison to the
total number of words. The idea behind this fea-
ture is to detect articles with lower or higher in-
formation character and take some stylistic aspect
into account.

Huffman compression ratio: Our huffman com-
pression feature is used with similar intention.
First: The general idea behind huffman compres-
sion (Huffman, 1952) is to build a dictionary of
words ordered by frequency in a binary tree. This
is done in such a way that in the end high fre-
quency words can be encoded with a shorter bit

code than low frequency words. The rationale in
our approach here is to perform a compression of
individual articles: The better this compression
works the more an author of an article reuses his
own words. The more difficult this compression
is, the higher is the variety of words used by an
author. For speed reasons we intentionally do not
perform a full compression here but build a huff-
man compression tree and then estimate the size
the indices would take in a full compression. We
then put this information into relation to the total
number of tokens of an article and use this as a
feature.

Readability scores: A set of readability scores
is used. Readability scores express the simplicity
of a text in various different ways - at least to some
extent - as well as give a rough judgement for the
reading competence level of an audience required
to understand the text. We implemented features
based on four readability scores: ARI (Smith and
Senter, 1967), Coleman-Liau (Coleman and Liau,
1975), Flesch-Kincaid (Kincaid et al., 1975) and
Gunning-Fog (Gunning, 1952).

Vocabulary variety: The vocabulary variety
classifier is calculating the ratio of uniquely used
words in relation to the total number of words.
This way this classifier assists in judging the com-
plexity of the text in an article as well.

3.2.2 Arousal vs. Rationality
Distribution parameters of business words: We
assume that news articles addressing business re-
lated topics are inherently not particularly hyper-
partisan. Based on manual inspection of training
data, we therefore created a list of 27 words, which
we consider to be expressing business related top-
ics, for example “sales”, “growth”, “CEO”, “op-
portunity”, “revenue”, “Q1”, “shareholder” and
similar terms.

Distribution parameters of words of disgust: In
a similar way to business words the corpus lemmas
are judged whether they express some kind of dis-
gust. For this purpose a hand picked vocabulary of
246 words had been created from publically avail-
able online dictionaries such as LEO (LEO), Wic-
tionary (Wictionary) and similar that genuinely
express some kind of disgust. Though this dictio-
nary likely is not complete the assumption is, that
it gives a general insight into whether a writer ex-
presses disgust at least to some extend, e.g. “disac-
cord”, “rupture”, “distaste”, “scandalous” or even
words like “rotten”. We intended here not to detect



978

only archetypical words such as “awful” but also
more uncommon words that might typically not
be seen in news so frequently. The rationale be-
hind this is that we noticed the phenomenon of hy-
perpartisan authors to attempt to use a more vivid
and strong language with sometimes less common
words.

Cardinal number ratio: Detecting cardinal
numbers is another feature addressing very spe-
cific aspects of articles: The idea behind this fea-
ture is that more fact-based communication might
more likely make use of numbers in order to ex-
press and proof their positions. While we can not
check the truth of claims involving cardinal num-
bers we at least try to detect the quantity of such
claims.

Pronouns before “need” and “must”: Two fea-
ture detectors address pronouns directly proceed-
ing the words “need” or “must”. We noticed
hyperpartisan articles where the authors directly
address the reader and give advice how society
should proceed. This is done in an inclusive way,
so sequences like “we must (do sth)” or “we need
(to do sth)” could be observed.

3.2.3 Content Features
To address content specifically we implemented
features derived from the provided test data itself,
though this way these features can cover only lim-
ited and existing content.

Attributively used adjectives: According to the
theories behind framing in psychology, political
influence can be produced by repeating specific
kind of wordings (Wehling, 2016). We noticed
that this technique seems to be used sometimes
quite extensively by authors of more extreme posi-
tions in recent years as they have a quite unchang-
ing perspective about topics, persons and events.
For example in the manually classified data the
term “jewish” is used to characterize a follow-
ing noun about five times more often in hyper-
partisan than non-hyperpartisan articles, “holistic”
about 30 times and “immediate” only about a third
of the times compared to non-hyperpartisan news.
Based on this phenomenon a dictionary of adjec-
tives which discriminate a following noun have
been extracted from non-hyperpartisan and hyper-
partisan pos-tagged training data in a separate pro-
cessing process, resulting in 2720 adjectives for
our use. Our feature is then measuring whether
more non-hyperpartisan or hyperpartisan use of
such adjectives can be observed in an article.

Lemma-bigram similarity scores: While our
attributively-used-adjectives-feature focuses on
the adjectives themselves and is therefore a sin-
gle word feature, we additionally used lemma
based bigram features. We extracted all bigrams
in sentences for a window of four tokens from
the manually tagged training data (and for exper-
iments from the larger data set) and associated
them with either non-hyperpartisan or hyperpar-
tisan labels. For example the lemmas “obama”
directly followed by “administration” appear sig-
nificantly more often in hyperpartisan than non-
hyperpartisan articles. It’s even more extreme
with “obamacare” and “act”, sequences of “bad”
and “happen” or “disastrous” and “war”: The
latter having even no mentions at all in non-
hyperpartisan articles. Interestingly some bigrams
are less characteristic as one would expect: For
example “illegal” and “immigration” is used quite
frequently by both classes. Again other bigrams
seem to be more typical for non-hyperpartisan
news articles, e.g. “fake” and “story”.

For our implementation we determined the re-
lation of how often either hyperpartisan and non-
hyperpartisan bigrams appeared per paragraph:

f = (nH − nNH)/(nH + nNH) (1)

where nH and nNH refer to the number of
hyperpartisan/non-hyperpartisan bigrams. This
value will be positive or negative depending on
the surplus of non-hyperpartisan vs. hyperparti-
san bigrams encountered in unseen text. We do
this for directly adjacent lemmas, for two lemmas
skipping one token, two tokens and three tokens
and calculate the four medians so that we end up
with a set of feature values, each one expressing
content similarity to our reference data.

3.3 Machine Learning

We built two different models by training a sup-
port vector machine with an rbf-kernel (libsvm).
The first one is based only on the stylistic features
and has been submitted for the first evaluation run
of the task, the second one is based only on the
content features which has been submitted for the
second evaluation run of the task.

For training of the first model 100.000 arti-
cles have been selected by random with strati-
fied sampling, arriving at 25.000 articles classified
as hyperpartisan left, 25.000 hyperpartisan right
and 50.000 non-hyperpartisan. Selecting a sub-



979

Dataset Acc Prec Rec F1
M1 by-pub. 0.505 0.503 0.949 0.657
M2 by-pub. 0.537 0.530 0.658 0.587
M2 by-art. 0.671 0.654 0.729 0.689

Table 1: Results, Model 1 and Model 2 with validation
dataset used, accuracy, precision, recall and F1 score.

set of the available articles was necessary as part-
of-speech tagging with first the TreeTagger and
then the CoreNLP tagger took quite some time
to complete. As mentioned before we ran into
some tagging problems because of errors in the
corpus data and limited capabilities of the existing
Python adapters for CoreNLP. Additionally we en-
countered some problems with larger amounts of
data which surprisingly caused crashes in the C
implementation of the SVM (NuSVC of sklearn)
for unknown reasons. So in the end we limited
ourselves to these 100.000 random articles to cope
with these difficulties.

As we recognized during our work that the
training data classified by-pubisher was - by nature
- not so accurately labeled, we train our second
model on the gold standard data with 645 manu-
ally labeled articles to avoid any noise for our fea-
tures as much as possible. For this model we used
only the content features.

4 Results and Conclusions

To train our models we used the provided training
data “by-publisher” and “by-article” as described
in the last section. Evaluation runs have then been
performed on the validation data “by-publisher”
and “by-article” (which were hidden during the
duration of the shared task). The results can be
seen in table 1.

Model 1 (which was trained on the 100.000 ran-
domly picked articles focusing on style features)
was tested against the validation data labeled by-
publisher. Model 2 (which was trained on the 645
articles focusing on content features) was tested
against the validation data labeled by-publisher
and the validation data by-article in two separate
runs. Our model 1 achieved better results than
model 2 during our evaluation runs on the by-
publisher data. It has been selected by the orga-
nizers for ranking in the leader board.

Validation showed that our first model exhibits a
trend to judge articles too easily as being hyperpar-
tisan. Though our second model exhibits a trend

to more easily classify articles as hyperpartisan as
well, this effect is not that strong.

Our second, content feature model did not per-
form that well on the test data labeled by-publisher
than the first, the style-based model. Interestingly
it performed better on evaluation data labeled by-
article. As our training data of 645 articles for
that model is small the second model likely suf-
fers from overfitting.

5 Further Work

In this paper we have presented a binary classifica-
tion system that assign labels “non-hyperpartisan”
and “hyperpartisan” for articles. While we could
achieve some results in that field we still think that
more work is needed here.

Results of competing teams in the Se-
mEval2019 shared task indicate that our current
approach has not yet been explored to full extent
in that regard: Better classification could be pos-
sible. We assume that additional effort should be
taken in selecting more and better style and con-
tent features. Though stylistic approaches seem
to be promising – comp. (Potthast et al., 2018) –
we assume that future work should focus more on
content and empathic perception of the content by
the reader. For example sentiment could be taken
into consideration as news articles tend to have
different point of views on different topics. As
there exists a variety of different sentiment tools of
varying quality experiments need to be performed
to explore possibilities of improving our models.
Attempts in this regard have been undertaken by
ourselves already but could not be completed for
this shared task. Additionally it would be inter-
esting to combine both approaches, something we
were not able to explore sufficiently during this
shared task.

Acknowledgments

This work was funded by the ministry of science
and culture of Lower Saxony (”Holen und Hal-
ten”).

References
M. Coleman and T. L. Liau. 1975. A computer read-

ability formula designed for machine scoring. In
Journal of Applied Psychology, volume 60(2), pages
283–28.

Carroll Doherty. 2017. Key takeaways on amer-
icans growing partisan divide over political

https://doi.org/https://psycnet.apa.org/doiLanding?doi=10.1037%2Fh0076540
https://doi.org/https://psycnet.apa.org/doiLanding?doi=10.1037%2Fh0076540
http://www.pewresearch.org/fact-tank/2017/10/05/takeaways-on-americans-growing-partisan-divide-over-political-values/
http://www.pewresearch.org/fact-tank/2017/10/05/takeaways-on-americans-growing-partisan-divide-over-political-values/


980

values. http://www.pewresearch.org/
fact-tank/2017/10/05/takeaways-on-
americans-growing-partisan-divide-
over-political-values/. Accessed:
2019-02-21.

Robert Gunning. 1952. The technique of clear writing.
New York: McGraw-Hill.

Felix Hamborg, Karsten Donnay, and Bela Gipp. 2018.
Automated identification of media bias in news arti-
cles: an interdisciplinary literature review. Interna-
tional Journal on Digital Libraries.

D. A. Huffman. 1952. A method for the construction
of minimum-redundancy codes. Proceedings of the
IEEE, formerly Proceedings of the IRE, 40(9):1098–
1101.

C.J. Hutto, Dennis Folds, and Scott Appling. 2015.
Computationally detecting and quantifying the de-
gree of bias in sentence-level text of news stories. In
The First International Conference on Human and
Social Analytics, pages 30–34.

Mohit Iyyer, Peter Enns, Jordan Boyd-Graber, and
Ps Resnik. 2014. Political ideology detection using
recursive neural networks. In 52nd Annual Meet-
ing of the Association for Computational Linguis-
tics, ACL 2014 - Proceedings of the Conference, vol-
ume 1, pages 1113–1122.

Johannes Kiesel, Maria Mestre, Rishabh Shukla, Em-
manuel Vincent, Payam Adineh, David Corney,
Benno Stein, and Martin Potthast. 2019. Semeval-
2019 task 4: Hyperpartisan news detection. In Pro-
ceedings of The 13th International Workshop on Se-
mantic Evaluation (SemEval 2019). Association for
Computational Linguistics.

J. P. Kincaid, R. P. Fishburne, R. L. Rogers, and B. S.
Chissom. 1975. Derivation of new readability for-
mulas for navy enlisted personnel. Technical report.

LEO. Leo online dictionary. https://dict.leo.
org. Accessed: 2019-02-21.

libsvm. SVM implementation library libsvm.
https://www.csie.ntu.edu.tw/
˜cjlin/libsvm/index.html. Part of Scikit-
Learn; Authors: Chih-Chung Chang, Chih-Jen Lin;
Accessed: 2019-02-21.

Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The stanford corenlp natural language
processing toolkit. In Proceedings of 52nd Annual
Meeting of the Association for Computational Lin-
guistics: System Demonstrations, pages 55–60, Bal-
timore, Maryland. Association for Computational
Linguistics.

Martin Potthast, Johannes Kiesel, Kevin Reinartz,
Janek Bevendorff, and Benno Stein. 2018. A stylo-
metric inquiry into hyperpartisan and fake news. In

Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics, ACL 2018,
Melbourne, Australia, July 15-20, 2018, Volume 1:
Long Papers, pages 231–240. Association for Com-
putational Linguistics.

Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana
Volkova, and Yejin Choi. 2017. Truth of varying
shades: Analyzing language in fake news and polit-
ical fact-checking. In Proceedings of the 2017 Con-
ference on Empirical Methods in Natural Language
Processing, pages 2931–2937. Association for Com-
putational Linguistics.

Helmut Schmid. 1994. Probabilistic part-
of-speech tagging using decision trees.
http://www.cis.uni-muenchen.de/
˜schmid/tools/TreeTagger/. Accessed:
2019-02-21.

E. A. Smith and R. J. Senter. 1967. Automated read-
ability index. Technical report.

E. Wehling. 2016. Politisches Framing: Wie eine Na-
tion sich ihr Denken einredet - und daraus Politik
macht. Ullstein.

Wictionary. Wictionary, the free dictionary. http:
//en.wictionary.org. Accessed: 2019-02-
21.

http://www.pewresearch.org/fact-tank/2017/10/05/takeaways-on-americans-growing-partisan-divide-over-political-values/
http://www.pewresearch.org/fact-tank/2017/10/05/takeaways-on-americans-growing-partisan-divide-over-political-values/
http://www.pewresearch.org/fact-tank/2017/10/05/takeaways-on-americans-growing-partisan-divide-over-political-values/
http://www.pewresearch.org/fact-tank/2017/10/05/takeaways-on-americans-growing-partisan-divide-over-political-values/
http://www.pewresearch.org/fact-tank/2017/10/05/takeaways-on-americans-growing-partisan-divide-over-political-values/
https://doi.org/10.1007/s00799-018-0261-y
https://doi.org/10.1007/s00799-018-0261-y
https://doi.org/10.1109/JRPROC.1952.273898
https://doi.org/10.1109/JRPROC.1952.273898
https://doi.org/10.3115/v1/P14-1105
https://doi.org/10.3115/v1/P14-1105
https://dict.leo.org
https://dict.leo.org
https://dict.leo.org
https://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html
https://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html
https://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html
http://www.aclweb.org/anthology/P14-5010
http://www.aclweb.org/anthology/P14-5010
https://aclanthology.info/papers/P18-1022/p18-1022
https://aclanthology.info/papers/P18-1022/p18-1022
https://doi.org/10.18653/v1/D17-1317
https://doi.org/10.18653/v1/D17-1317
https://doi.org/10.18653/v1/D17-1317
http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/
http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/
http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/
http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/
https://apps.dtic.mil/dtic/tr/fulltext/u2/667273.pdf
https://apps.dtic.mil/dtic/tr/fulltext/u2/667273.pdf
http://en.wictionary.org
http://en.wictionary.org
http://en.wictionary.org

