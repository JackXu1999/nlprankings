



















































Towards Fine-grained Text Sentiment Transfer


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2013–2022
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

2013

Towards Fine-grained Text Sentiment Transfer
Fuli Luo1, Peng Li2, Pengcheng Yang1, Jie Zhou2,

Yutong Tan3, Baobao Chang1,4, Zhifang Sui1,4, Xu Sun1
1Key Lab of Computational Linguistics, Peking University

2Pattern Recognition Center, WeChat AI, Tencent Inc, China
3Computer Science and Technology, Beijing Normal University

4Peng Cheng Laboratory, China
luofuli@pku.edu.cn, patrickpli@tencent.com, yang pc@pku.edu.cn,

withtomzhou@tencent.com, tanyt@mail.bnu.edu.cn, {chbb,szf,xusun}@pku.edu.cn

Abstract

In this paper, we focus on the task of fine-
grained text sentiment transfer (FGST). This
task aims to revise an input sequence to satisfy
a given sentiment intensity, while preserving
the original semantic content. Different from
conventional sentiment transfer task that
only reverses the sentiment polarity (posi-
tive/negative) of text, the FTST task requires
more nuanced and fine-grained control of
sentiment. To remedy this, we propose a
novel Seq2SentiSeq model. Specifically,
the numeric sentiment intensity value is
incorporated into the decoder via a Gaussian
kernel layer to finely control the sentiment
intensity of the output. Moreover, to tackle
the problem of lacking parallel data, we
propose a cycle reinforcement learning
algorithm to guide the model training. In this
framework, the elaborately designed rewards
can balance both sentiment transformation
and content preservation, while not requiring
any ground truth output. Experimental results
show that our approach can outperform
existing methods by a large margin in both
automatic evaluation and human evaluation.
Our code and data, including outputs of
all baselines and our model are available
at https://github.com/luofuli/
Fine-grained-Sentiment-Transfer. 1

1 Introduction

Text sentiment transfer aims to rephrase the in-
put to satisfy a given sentiment label (value) while
preserving its original semantic content. It facil-
itates various NLP applications, such as automat-
ically converting the attitude of review and fight-
ing against offensive language in social media (dos
Santos et al., 2018).

Previous work (Shen et al., 2017; Li et al., 2018;
Luo et al., 2019) on text sentiment transfer mainly
focuses on the coarse-grained level: the reversal of

1Joint work between WeChat AI and Peking University.

Input Sentence

Tasty food and wonderful service.

Target
Sentiment

Output
Sentence

0.1 Horrible food and terrible service!
0.3 Plain food, slow service.
0.5 Food and service need improvement.
0.7 Good food and service.
0.9 Amazing food and perfect service!!

Target
Sentiment

Output
Sentence

0.1 Horrible food and terrible service!
0.3 Plain food, slow service.
0.5 Food and service need improvement.
0.7 Good food and service.
0.9 Amazing food and perfect service!!

Input Sentence: Tasty food and wonderful service.

Figure 1: An example of the input and output of the
fine-grained text sentiment transfer task. The output
reviews describe the same content (e.g. food/service) as
the input while expressing different sentiment intensity.

positive and negative sentiment polarity. They are
confined to scenarios where there are two discrete
sentiment labels. To achieve more nuanced and
precise sentiment control of text generation, we
turn to fine-grained text sentiment transfer (FTST)
which revises a sequence to satisfy a given senti-
ment intensity2, while keeping the semantic con-
tent unchanged. Taking Figure 1 as an example,
given the same input and five sentiment intensity
values ranging from 0 (most negative) to 1 (most
positive), the system generates five different out-
puts that satisfy the corresponding sentiment in-
tensity in a relative order.

There are two main challenges of FTST task.
First, it is tough to achieve fine-grained control
of the sentiment intensity when generating sen-
tence. Previous work about coarse-grained text
sentiment transfer usually uses a separate decoder
for each sentiment label (Xu et al., 2018; Zhang
et al., 2018b) or embeds each sentiment label
into a separate vector (Fu et al., 2018; Li et al.,
2018). However, these methods are not feasible
for fine-grained text sentiment transfer since the

2The sentiment intensity is a real-valued score between 0
and 1, following sentiment intensity prediction task in senti-
ment analysis (Zhang et al., 2017; Mohammad et al., 2018).

https://github.com/luofuli/Fine-grained-Sentiment-Transfer
https://github.com/luofuli/Fine-grained-Sentiment-Transfer


2014

target sentiment intensity value is a real value,
other than discrete labels. Second, parallel data3

is unavailable in practice. In other words, we can
only access the corpora which are labeled with
fine-grained sentiment ratings or intensity values.
Therefore, in the FTST task, we can not train a
generative model via ground truth outputs.

To tackle the two challenges mentioned above,
we propose two corresponding solutions. First,
in order to control the sentiment intensity of
the generated sentence, we propose a novel sen-
timent intensity controlled sequence-to-sequence
(Seq2Seq) model Seq2SentiSeq. It incorporates
the sentiment intensity value into the conventional
Seq2Seq model via a Gaussian kernel layer. By
this means, the model can encourage the genera-
tion of words whose sentiment intensity closer to
the given intensity value during decoding. Sec-
ond, due to the lack of parallel data, we can not
directly train the proposed model via MLE (max-
imum likelihood estimation). Therefore, we pro-
pose a cycle reinforcement learning algorithm to
guide the model training without any parallel data.
The designed reward can balance both sentiment
transformation and content preservation, while not
requiring any ground truth output.

Evaluation of the FTST task is also challeng-
ing and complex. In order to build a reliable auto-
matic evaluation, we collect human references for
FTST task on the Yelp review dataset4 via crowd-
sourcing and design a series of automatic metrics.

The main contributions of this work are summa-
rized as follows:

• We propose a sentiment intensity controlled
generative model Seq2SentiSeq, in which a
sentiment intensity value is introduced via a
Gaussian kernel layer to achieve fine-grained
sentiment control of the generated sentence.

• In order to adapt to non-parallel data, we de-
sign a cycle reinforcement learning algorithm
CycleRL to guide the model training in an
unsupervised way.

• Experiments show that the proposed ap-
proach can largely outperform state-of-the-
art systems in both automatic evaluation and
human evaluation.

3Parallel data in this paper denotes the corpus where each
pair of sentences describes the same content while expressing
the different sentiment intensity.

4https://www.yelp.com/dataset

2 Proposed Model

2.1 Task Definition
Given an input sequence x and a target sentiment
intensity value vy, the FTST task aims to gener-
ate a sequence y which not only expresses the tar-
get sentiment intensity vy, but also preserve the
original semantic content of the input x. Without
loss of generality, we limit the sentiment intensity
value vy ranging from 0 (most negative) to 1 (most
positive).

2.2 Seq2SentiSeq: Sentiment Intensity
Controlled Seq2Seq Model

Figure 2 presents a sketch of the proposed
Seq2SentiSeq model. The model is based on the
encoder-decoder framework, which takes a source
text x as the input and outputs a target sentence y
with the given sentiment intensity vy. In order to
control the sentiment intensity of y, we introduce
a Gaussian kernel layer into the decoder.

2.2.1 Encoder
We use a bidirectional RNN as the encoder to cap-
ture source content information. Each word in the
source sequence x = (x1, · · · , xm) is firstly rep-
resented by its semantic representation mapped by
semantic embedding Ec. The RNN reads the se-
mantic representations from both directions and
computes the forward hidden states {

−→
h i}mi=1 and

backward hidden states {
←−
h i}mi=1 for each word.

We obtain the final hidden representation of the i-
th word by concatenating the hidden states from
both directions hi = [

−→
h i;
←−
h i].

2.2.2 Decoder
Given the hidden representations {hi}mi=1 of the
input sequence x and the target sentiment intensity
value vy, the decoder aims to generate a sequence
y which not only describes the same content as
the input sequence x, but also expresses a close
sentiment intensity to vy.

In order to achieve the aim of controlling sen-
timent during decoding, we firstly embedded each
word with an additional sentiment representation,
besides the original semantic representation. The
semantic representation characterizes the semantic
content of the word, while the sentiment represen-
tation characterizes its sentiment intensity. For-
mally, the hidden state st of the decoder at time-
step t is computed as follows:

st = f
(
st−1, [Ec(yt−1);Es(yt−1)] , ct

)
(1)

https://www.yelp.com/dataset


2015

ℎ! ℎ" ℎ#…

Attention Layer

Encoder

"! "" "$Decoder

"$

#% #&
Target Sentiment

Intensity Value
'! = 0.9

Gaussian Kernel Layer

<eos>

Semantic Embeddings Sentiment Embeddings

",
$$

$$

%&(())

+ ($

The food is okay

%,(())

"- 0.9

The food is

good

",

extremely

The food is

not

%&

(,

($
+$% ($ +$&(($)sum

Encoder Decoder- .(

'!Thumbnail View

Figure 2: The proposed sequence to sentiment controlled sequence (Seq2SentiSeq) model.

where Es(yt−1) refers to the sentiment represen-
tation of the word yt−1 mapped by the sentiment
embedding matrix Es, Ec(yt−1) is the semantic
representation, and the context vector ct is com-
puted by an attention mechanism in the same way
as Luong et al. (2015).

Considering two goals of the FTST task: senti-
ment transformation and content preservation, we
model the final generation probability into a mix-
ture of semantic probability and sentiment proba-
bility, where the former evaluates content preser-
vation and the latter measures sentiment trans-
formation. Similar to the traditional Seq2Seq
model (Bahdanau et al., 2014), the semantic prob-
ability distribution over the whole vocabulary is
computed as follows:

pct = softmax(Wcst) (2)

where Wc is a trainable weight matrix.
The sentiment probability measures how close

the sentiment intensity of the generated sequence
to the target vy. Normally, each word has a
specific sentiment intensity. For example, the
word “okay” has a positive intensity around 0.6,
“good” is around 0.7, and “great” is around 0.8.
However, when involving to the previous gener-
ated words, the sentiment intensity of current gen-
erated word may be totally different. For exam-
ple, the phrase “not good” has a negative intensity
around 0.3, while “extremely good” is around 0.9.
That is to say, the sentiment intensity of each word
at time-step t should be decided by both the sen-
timent representation Es and the current decoder
state st. Therefore, we define a sentiment intensity

prediction function g(Es, st) as follows:

g(Es, st) = sigmoid(EsWsst) (3)

where Ws is a trainable parameter, and sigmoid is
used to scale the predicted intensity value to [0, 1].

Intuitively, in order to achieve fine-grained con-
trol of sentiment, words whose sentiment inten-
sities are closer to the target sentiment intensity
value vy should be assigned a higher probability.
Take Figure 2 as an example, at the 5-th time-step,
word “good” should be assigned a higher prob-
ability than word “bad”, thus the predicted inten-
sity value g(“good”, s4) is closer to the target sen-
timent intensity than g(“bad”, s4). To favor words
whose sentiment intensity is near vy, we introduce
a Gaussian kernel layer which places a Gaussian
distribution centered around vy, inspired by Lu-
ong et al. (2015) and Zhang et al. (2018a). Specif-
ically, the sentiment probability is formulated as:

ost =
1√
2πσ

exp

(
−
(
g(Es, st)− vy

)2
2σ2

)
(4)

pst = softmax(o
s
t ) (5)

where σ is the standard deviation.
To balance both sentiment transformation and

content preservation, the final probability distribu-
tion pt over the entire vocabulary is defined as a
mixture of two probability distributions:

pt = γp
s
t + (1− γ)pct (6)

where γ is the hyper-parameter that controls the
trade-off between two generation probabilities.



2016

Encoder Decoder

! "#
EncoderDecoder$%

&'

()

Sentiment
Scorer

$*

&)
Figure 3: Cycle reinforcement learning. Note that the
upper encoder-decoder model and the lower encoder-
decoder are just one Seq2SentiSeq model.

2.3 Training: Cycle Reinforcement Learning
A serious challenge of the FTST task is the lack
of parallel data. Since the ground truth output y is
unobserved, we can not directly use the maximum
likelihood estimation (MLE) for training. To rem-
edy this, we design a cycle reinforcement learning
(CycleRL) algorithm. An overview of the train-
ing process is summarized in Algorithm 1. Two
rewards are designed to encourage changing sen-
timent but preserving content, without the need of
parallel data. The definitions of the two rewards
and the corresponding gradients for Seq2SentiSeq
model S are introduced as follows.

2.3.1 Reward Design
We design the respective rewards for two goals
(sentiment transformation and content preserva-
tion) of the FTST task. Then, an overall reward r
is calculated to balance these two goals and guide
the model training.

Reward for sentiment transformation. A pre-
trained sentiment scorer is used to evaluate how
well the sampled sentence ŷ matches the target
sentiment intensity value vy. Specifically, the re-
ward for sentiment transformation is formulated
as:

rs = 1/(|vy − ϕ(ŷ)|+ 1) (7)

where ϕ refers to the pre-trained sentiment scorer
which is implemented as LSTM-based linear re-
gression model.

Reward for content preservation. Intuitively,
if the model performs well in content preserva-
tion, it is easy to back-reconstruct the source input
x. Therefore, we design the reward for content
preservation to be the probability of the model re-
constructing x based on the generated text ŷ and
the source sentiment intensity value vx.

rc = p(x|ŷ, vx; θ) (8)

where θ is the parameter of Seq2SentiSeq model.

Algorithm 1 The cycle reinforcement learning al-
gorithm for training Seq2SentiSeq.
Input: A corpora D = {(xi,i )} where each sequence xi is

labeled with a fine-grained sentiment label vi
1: Initial the pseudo-parallel data V0 = {(xi, ŷi)}
2: Pre-train Seq2SentiSeq model Sθ using V0
3: for each iteration t = 1, 2, ..., T do
4: Sample a sentence x from D
5: for k = 1, 2, ...,K do
6: Sample a intensity value v(k)y from interval [0, 1]
7: Generate a target sequence: ŷ(k) = S(x, v(k)y ; θ)
8: Compute sentiment reward r(k)s based on Eq. 7
9: Compute content reward r(k)c based on Eq. 8

10: Compute total reward r(k) based on Eq. 9
11: end for
12: Update θ using reward {r(k)}Kk=1 based on Eq. 11
13: Update θ using cycle reconstruction loss in Eq. 12
14: end for

Overall reward. To encourage the model to
improve both sentiment transformation and con-
tent preservation, the final reward r guiding the
model training is designed to be the harmonic
mean of the above two rewards:

r =
(
1 + β2

) rc · rs
(β2 · rc) + rs

(9)

where β is a harmonic weight that controls the
trade-off between two rewards.

2.3.2 Optimization
The goal of RL training is to minimize the negative
expected reward,

L(θ) = −
∑
k

r(k)pθ(ŷ
(k)|x) (10)

where ŷ(k) is the k-th sampled sequence accord-
ing to probability distribution p in Eq. 6, r(k) is
the reward of ŷ(k), and θ is the parameter of the
proposed model in Figure 2.

By means of policy gradient method (Williams,
1992), for each training example, the expected
gradient of Eq. 10 can be approximated as:

∇θL(θ) ' −
1

K

K∑
k=1

(
r(k) − b

)
∇θlog

(
pθ(ŷ

(k))
)

(11)
where K is the sample size and b is the greedy
search decoding baseline that aims to reduce the
variance of gradient estimate which is imple-
mented in the same way as Paulus et al. (2017).

Nevertheless, RL training strives to optimize a
specific metric which may not guarantee the flu-
ency of the generated text (Paulus et al., 2017), and



2017

usually faces the unstable training problems (Li
et al., 2017). The most direct way is to expose
the sentences which are from the training corpus
to the decoder and trained via MLE (also called
teacher-forcing). In order to expose the decoder to
the original sentence from the training corpus, we
borrow ideas from back-translation (Lample et al.,
2018a,b). Specifically, the model first generates a
sequence ŷ based on the input text x and the target
sentiment intensity value vy, and then reconstructs
the source input x based on ŷ and the source sen-
timent intensity value vx. Therefore, the gradient
of the cycle reconstruction loss is defined as:

∇θJ (θ) = ∇θlog
(
p
(
x|S(x, vy; θ), vx; θ

))
(12)

where S refers to the Seq2SeniSeq model.
Finally, we alternately update the model param-

eters θ based on Eq. 11 and Eq. 12.

3 Experimental Setup

In this section, we introduce the dataset, experi-
ment settings, baselines, and evaluation metrics.

3.1 Dataset

We conduct experiments on the Yelp dataset5,
which consists of a large number of product re-
views. Each review is assigned a sentiment rating
ranging from 1 to 5. Since the label inconsistency
between human is more serious in fine-grained
ratings, we average the ratings for the sentences
which have a Jaccard Similarity more than 0.9.
Then, averaged ratings are normalized between 0
and 1 as the sentiment intensity. Other data pre-
processing is the same as Shen et al. (2017). Fi-
nally, we obtain a total of 640K sentences. We
randomly hold 630K for training, 10K for valida-
tion, and 500 for testing. Even though the sen-
timent intensity distribution of training dataset is
not uniform, the proposed framework consists of
a uniform data augmentation which generates sen-
tences whose intensity is from interval [0, 1] with
a step of 0.05 to guide the model training (Step 6
in Algorithm 1).

3.2 Experiment Settings

We tune hyper-parameters on the validation set.
The size of vocabulary is set to 10K. Both the
semantic and sentiment embeddings are 300-
dimensional and are learned from scratch. We

5https://www.yelp.com/dataset

implement both encoder and decoder as a 1-layer
LSTM with a hidden size of 256, and the for-
mer is bidirectional. The batch size is 64. We
pre-train our model for 10 epochs with the MLE
loss using pseudo-parallel sentences conducted by
Jaccard Similarity, which is same as Liao et al.
(2018). Harmonic weight β in Eq. 9 is 1 and γ
in Eq. 6 is 0.5. The standard deviation σ is set
to 0.01 for yielding suitable peaked distributions.
The sample sizeK in Eq. 11 is set to 16. The opti-
mizer is Adam (Kingma and Ba, 2014) with 10−3

initial learning rate for pre-training and 10−5 for
cycleRL training. Dropout (Srivastava et al., 2014)
is used to avoid overfitting.

3.3 Baselines
We compare our proposed method with the follow-
ing two series of state-of-the-art systems.

Fine-grained systems aim to modify an input
sentence to satisfy a given sentiment intensity.
Liao et al. (2018) construct pseudo-parallel cor-
pus to train a model which is a combination of
a revised-VAE and a coupling component mod-
eling pseudo-parallel data with three extra losses
Lextra. What’s more, we also consider SC-
Seq2Seq (Zhang et al., 2018a) which is a speci-
ficity controlled Seq2Seq model proposed in dia-
logue generation. In order to adapt to this unsu-
pervised task, the proposed CycleRL training al-
gorithm is used to train the SC-Seq2Seq model.

Coarse-grained systems aim to reverse the sen-
timent polarity (positive/negative) of the input,
which can be regarded as a special case where the
sentiment intensity is set below average (negative)
or above average (positive). We compare our pro-
posed method with the following state-of-the-art
systems: CrossAlign (Shen et al., 2017), MultiDe-
coder (Fu et al., 2018), DeleteRetrieve (Li et al.,
2018) and Unpaired (Xu et al., 2018).

3.4 Evaluation Metrics
We adopt both automatic and human evaluation.

3.4.1 Automatic Evaluation
Automatic evaluation of FTST is an open and
challenging issue, thereby we adopt a combination
of multiple evaluation methods.

Content: To evaluate the content preservation
performance, we hired crowd-workers on Crowd-
Flower6 to write human references.7 For each

6https://www.crowdflower.com/
7We will release the collected human references and the

https://www.yelp.com/dataset
https://www.crowdflower.com/


2018

Model Automatic Evaluation Human EvaluationBLEU-1↑ BLEU-2↑ MAE↓ MRRR↑ PPL↓ Content↑ Sentiment↑ Fluency↑ Avg↑

Revised-VAE 22.6 7.2 0.24 0.62 102.2 2.64 2.52 2.13 2.43
Revised-VAE + Lextra 20.7 5.7 0.18 0.67 102.6 2.54 3.84 2.14 2.84
SC-Seq2Seq 23.9 3.8 0.25 0.69 41.2 2.37 3.85 3.41 3.21

Seq2SentiSeq 32.5 10.3 0.13 0.78 35.1 3.62 4.09 4.17 3.96

Human Reference 100.0 100.0 0.07 0.83 31.2 4.51 4.36 4.75 4.54

Table 1: Automatic evaluation and human evaluation in three aspects: Content (BLUE-1, BLUE-2), Sentiment
(MAE, MRRR) and Fluency (PPL). Avg shows the average human scores. ↑ denotes larger is better, and vice
versa. Bold denotes the best results.

review in the test dataset, crowd-workers are re-
quired to write five references with sentiment in-
tensity value from V ′ = [0.1, 0.3, 0.5, 0.7, 0.9].
Therefore, the BLEU (Papineni et al., 2002) score
between the human reference and the correspond-
ing generated text of the same sentiment intensity
can evaluate the content preservation performance.

Fluency: To measure the fluency, we calculate
the perplexity (PPL) of each generated sequence
via a pre-trained bi-directional LSTM language
model (Mousa and Schuller, 2017).

Sentiment: In order to measure how close the
sentiment intensity of outputs to the target inten-
sity values, we define three metrics. Given an in-
put sentence x and a list of target intensity val-
ues V = [v1, v2, ..., vN ], the corresponding out-
puts of the model are [ŷ1, ŷ2, ..., ŷN ]. We then
use a pre-trained sentiment regression scorer to
predict the sentiment intensity values of outputs
as V̂ = [v̂1, v̂2, ..., v̂N ]. Following Liao et al.
(2018), we use the mean absolute error (MAE =
1
N

∑N
i=1 |vi − v̂i|) between V and V̂ to measure

the absolute gap.
Moreover, for fine-grained text sentiment trans-

fer task, we expect that given a higher sentiment
intensity value, the model will generate a more
positive sentence. That is to say, the relative inten-
sity ranking of all generated sentences of the same
input is also important. Inspired by the Mean Re-
ciprocal Rank metric which is widely used in the
Information Retrieval area, we design a Mean Rel-
ative Reciprocal Rank (MRRR) metric to measure
the relative ranking

MRRR =
1

N

N∑
i=1

1

|rank(vi)− rank(v̂i)|+ 1
(13)

In addition, we also compare our model with the
coarse-grained sentiment transfer systems. In or-
der to make the results comparable, we define the

generated test samples of all baselines for reproducibility.

sentiment intensity larger/smaller than 0.5 as posi-
tive/negative results. Then we use a pre-trained bi-
nary TextCNN classifier (Kim, 2014) to compute
the classification accuracy.

3.4.2 Human Evaluation
We also perform human evaluation to assess the
quality of generated sentences more accurately.
Each item contains the source input, the sampled
target sentiment intensity value, and the output of
different systems. Then 500 items are distributed
to 3 evaluators, who are required to score the gen-
erated sentences from 1 to 5 based on the input
and target sentiment intensity value in terms of
three criteria: content, sentiment, fluency. Content
evaluates the content preservation degree. Senti-
ment refers to how much the output matches the
target sentiment intensity. Fluency is designed to
measure whether the generated texts are fluent.
For each metric, the average Pearson correlation
coefficient of the scores given by three evalua-
tors is greater than 0.71, which ensures the inter-
evaluator agreement.

4 Results and Discussion

4.1 Evaluation Results
The automatic evaluation and human evaluation
results are shown in Table 1. It shows that our ap-
proach achieves the best performance in all met-
rics. More specifically, we have the following ob-
servations: (1) The proposed model Seq2SentiSeq
obtains 8.6/3.1/0.98 points absolute improvement
over the best results on BLEU-1/BLEU-2/Content
score. It demonstrates the effectiveness of our
approach in improving the content preservation
of the input sentences. (2) Our model can more
precisely control the sentiment intensity from hu-
man scores on sentiment, and it can also obtain
both best results in sentiment mean absolute er-
ror (MAE) and relative sentiment rank (MRRR).



2019

Model Automatic Evaluation Human EvaluationBLEU-1↑ BLEU-2↑ MAE↓ MRRR↑ PPL↓ Content↑ Sentiment↑ Fluency↑ Avg↑

Full Model 32.5 10.3 0.13 0.78 35.1 3.62 4.09 4.17 3.96

w/o Pre-training 14.3 0.7 0.32 0.48 7.2 1.01 1.30 3.86 2.06
w/o Cycle reconstruction 16.5 2.3 0.31 0.41 70.1 1.92 1.48 3.16 2.19
w/o Reinforcement learning 25.7 4.1 0.22 0.63 46.0 2.69 3.74 3.80 3.41

Table 2: Automatic evaluation and human evaluation of ablation study.

Model neg-to-pos pos-to-neg

Multidecoder 54.3 50.2
CrossAlign 73.3 71.7
Unpaired 78.9 73.0
DeleteRetrieve 89.6 83.1

Revised-VAE 64.3 62.0
Revised-VAE + Lextra 89.3 77.9
SC-Seq2Seq 67.2 59.6
Seq2SentiSeq 89.4 83.5

Table 3: Binary sentiment classification accuracy of
the coarse-grained (upper) and fine-grained (lower) text
sentiment transfer systems. Bold denotes the best re-
sults of each task.

However, SC-Seq2Seq gets the second best MAE
score while Revised-VAE + Lextra gets the sec-
ond best MRRR score. We can infer that the two
models excel at different aspects. And MRRR pro-
vides a different perspective on the sentiment re-
sults. (3) The proposed model can generate more
fluent sentences than all baselines. The main rea-
son for these three phenomenons is that we design
two rewards that can directly ensure the content
preservation and sentiment transformation in the
cycle reinforcement training process. In addition,
the cycle reconstruction loss can effectively guar-
antee the fluency of generated sentences, which
has been further verified in the ablation study.

What’s more, we also simplify our task to the
setting of coarse-grained (positive/negative) sen-
timent transfer task. Table 3 shows the binary
sentiment accuracy of the representative systems.
We can find that the proposed model achieve the
best results over the fine-grained systems, and it is
comparable to the best coarse-grained system.

4.2 Ablation Study

In this section, we further discuss the impacts of
the components of the proposed model. We re-
train our model by ablating multiple components
of our model: without pre-training, without cy-
cle reconstruction (Eq. 12), without reinforcement
learning ( Eq. 11). Table 2 shows the correspond-
ing automatic and human evaluations. The perfor-

Input the beer isn’t bad, but the food was less than desirable.

Output Seq2SentiSeq

V=0.1 the beer is terrible, and the food was the worst.
V=0.3 the beer wasn’t bad, and the food wasn’t great too.
V=0.5 the food is ok, but not worth the drive to the strip.
V=0.7 the beer is good, and the food is great.
V=0.9 the wine is great, and the food is extremely fantastic.

Output Revised-VAE + Lextra

V=0.1 n’t no about about no when about that was when about
V=0.3 the beer sucks , but the food is not typical time.
V=0.5 the beer is cheap, but the food was salty and decor.
V=0.7 i just because decent management salty were impersonal.
V=0.9 n’t that about was that when was about as when was

Table 4: Example outputs with five sentiment intensity
values V ranging from 0 to 1.

mance declines most when without pre-training.
This reveals that reinforcement learning is heav-
ily dependent on pre-training as a warm start be-
cause it is hard for RL architecture to train from
scratch. Moreover, no pre-training will lead the
model to generate frequent words and short sen-
tence which gets low PPL score. What’s more, the
performance of ablated version without cycle re-
construction also drops significantly, since cycle
reconstruction plays an important role of teacher-
forcing in our paper. Finally, even though the pro-
posed Seq2SentiSeq without reinforcement learn-
ing can beat the best baseline in terms of human
average score, reinforcement learning still helps to
boost the performance of the proposed model by a
large margin.

4.3 Case Study

Table 4 shows the example outputs on the YELP
datasets with five sentiment intensity values. This
case demonstrates that our model can both pre-
serve the content (“beer”, “food”) and change
the sentiment to the desired intensity. More im-
portantly, our model can capture the subtle sen-
timent difference of the words or phrases, e.g.,
“the worst”→ “bad”→ “ok”→ “good”→ “ex-
tremely fantastic”. However, the Revised-VAE +
Lextra system does not show this sentiment trend
and may collapse when intensity value V is very



2020

Semantic Embeddings

Sentiment Embeddings

Figure 4: t-SNE visualization of the semantic embed-
dings (upper) and sentiment embeddings (lower) in the
Seq2SentiSeq model.

small (0.1) or very big (0.9). And our model some-
times may also suffer from semantic drift, e.g.,
“beer” is revised to “wine”.

4.4 Analysis on Sentiment Representation
We also conduct analysis to understand the senti-
ment representations of words introduced in our
model. We use the 1000 most frequent words
from the training dataset. Then, we use a human
annotated sentiment lexicon (Hutto and Gilbert,
2014) to classify them into three categories: pos-
itive, neutral and negative. After that, we get 112
positive words, 841 neutral words and 47 neg-
ative words. Finally, we apply t-SNE (Rauber
et al., 2016) to visualize both semantic and sen-
timent embeddings of the proposed model (Figure
2) when finished training. As shown in Figure 4,
we can see that the distributions of the two em-
beddings are significantly different. In the seman-
tic embedding space, most of the positive words
and negative words lie closely. On the contrary,
in the sentiment embedding space, positive words
are far from negative words. In conclusion, neigh-
bors on semantic embedding space are semanti-
cally related, while neighbors on sentiment em-
bedding space express a similar sentiment inten-
sity.

5 Related Work

Recently, there is a growing literature on the task
of unsupervised sentiment transfer. This task
aims to reverse the sentiment polarity of a sen-
tence but keep its content unchanged without par-
allel data (Fu et al., 2018; Tsvetkov et al., 2018;
Li et al., 2018; Xu et al., 2018; Lample et al.,
2019). However, there are few researches focus on
the fine-grained control of sentiment. Liao et al.
(2018) exploits pseudo-parallel data via heuristic
rules, thus turns this task to a supervised setting.
They then propose a model based on Variational
Autoencoder (VAE) to first disentangle the con-
tent factor and source sentiment factor, and then
combine the content with target sentiment factor.
However, the quality of the pseudo-parallel data is
not quite satisfactory, which seriously affects the
performance of the VAE model. Different from
them, we dynamically update the pseudo-parallel
data via on-the-fly back-translation (Lample et al.,
2018b) during training (Eq. 12).

There are some other tasks of NLP also show
interest in controlling the fine-grained attribute
of text generation. For example, Zhang et al.
(2018a) and Ke et al. (2018) propose to control
the specificity and diversity in dialogue genera-
tion. We borrow ideas from these works but the
motivation and proposed models of our work are
a far cry from them. The main differences are:
(1) Since sentiment is dependent on local context
while specificity is independent of local context,
there is a series of design in our model to take
the local context (or previous generated words) st
into consideration (e.g., Eq. 1, Eq. 3). (2) Due to
the lack of parallel data, we propose a cycle rein-
forcement learning algorithm to train the proposed
model (Section 2.3).

6 Conclusion

In this paper, we focus on solving the fine-
grained text sentiment transfer task, which is a
natural extension of the binary sentiment trans-
fer task but with more challenges. We propose
a Seq2SentiSeq model to achieve the aim of con-
trolling the fine-grained sentiment intensity of the
generated sentence. In order to train the proposed
model without any parallel data, we design a cy-
cle reinforcement learning algorithm. We apply
the proposed approach to the Yelp review dataset,
obtaining state-of-the-art results in both automatic
evaluation and human evaluation.



2021

Acknowledgments

This paper is supported by NSFC project
61751201, 61772040 and 61876004. The contact
authors are Baobao Chang and Zhifang Sui.

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2014. Neural machine translation by jointly
learning to align and translate. In Proceedings of
the International Conference on Learning Represen-
tations, ICLR 2014.

Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan
Zhao, and Rui Yan. 2018. Style transfer in text:
Exploration and evaluation. In Proceedings of the
Thirty-Second AAAI Conference on Artificial Intelli-
gence, AAAI-18, pages 663–670.

Clayton J. Hutto and Eric Gilbert. 2014. VADER: A
parsimonious rule-based model for sentiment anal-
ysis of social media text. In Proceedings of the
Eighth International Conference on Weblogs and
Social Media, ICWSM 2014.

Pei Ke, Jian Guan, Minlie Huang, and Xiaoyan Zhu.
2018. Generating informative responses with con-
trolled sentence function. In Proceedings of the
56th Annual Meeting of the Association for Compu-
tational Linguistics, ACL 2018.

Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP 2014, pages 1746–1751.

Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. In Proceedings
of International Conference on Learning Represen-
tations, ICLR 2014.

Guillaume Lample, Alexis Conneau, Ludovic Denoyer,
and Marc’Aurelio Ranzato. 2018a. Unsupervised
machine translation using monolingual corpora only.
In Proceedings of the International Conference on
Learning Representations, ICLR 2018.

Guillaume Lample, Myle Ott, Alexis Conneau, Lu-
dovic Denoyer, and Marc’Aurelio Ranzato. 2018b.
Phrase-based & neural unsupervised machine trans-
lation. In Proceedings of the 2018 Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP 2018, pages 5039–5049.

Guillaume Lample, Sandeep Subramanian, Eric Smith,
Ludovic Denoyer, Marc’Aurelio Ranzato, and Y-
Lan Boureau. 2019. Multiple-attribute text rewrit-
ing. In International Conference on Learning Rep-
resentations, ICLR 2019.

Jiwei Li, Will Monroe, Tianlin Shi, Sébastien Jean,
Alan Ritter, and Dan Jurafsky. 2017. Adversarial

learning for neural dialogue generation. In Proceed-
ings of the 2017 Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP 2017,
pages 2157–2169.

Juncen Li, Robin Jia, He He, and Percy Liang. 2018.
Delete, retrieve, generate: a simple approach to sen-
timent and style transfer. In Proceedings of the 2018
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2018, pages
1865–1874.

Yi Liao, Lidong Bing, Piji Li, Shuming Shi, Wai Lam,
and Tong Zhang. 2018. QuaSE: Sequence editing
under quantifiable guidance. In Proceedings of the
2018 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2018, pages 3855–
3864.

Fuli Luo, Peng Li, Jie Zhou, Pengcheng Yang, Baobao
Chang, Zhifang Sui, and Xu Sun. 2019. A dual rein-
forcement learning framework for unsupervised text
style transfer. In Proceedings of the 28th Interna-
tional Joint Conference on Artificial Intelligence, IJ-
CAI 2019.

Thang Luong, Hieu Pham, and Christopher D. Man-
ning. 2015. Effective approaches to attention-based
neural machine translation. In Proceedings of the
2015 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2015, pages 1412–
1421.

Saif Mohammad, Felipe Bravo-Marquez, Moham-
mad Salameh, and Svetlana Kiritchenko. 2018.
SemEval-2018 task 1: Affect in tweets. In Proceed-
ings of The 12th International Workshop on Seman-
tic Evaluation, SemEval@NAACL-HLT, pages 1–17.

Amr Eldesoky Mousa and Bjorn W Schuller. 2017.
Contextual bidirectional long short-term memory re-
current neural network language models: A genera-
tive approach to sentiment analysis. In Proceedings
of the 55th Annual Meeting of the Association for
Computational Linguistics, ACL 2017, pages 1023–
1032.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics, ACL 2002, pages 311–
318.

Romain Paulus, Caiming Xiong, and Richard Socher.
2017. A deep reinforced model for abstractive
summarization. In Proceedings of the Interna-
tional Conference on Learning Representations,
ICLR 2017.

Paulo E. Rauber, Alexandre X. Falcão, and Alexan-
dru C. Telea. 2016. Visualizing time-dependent data
using dynamic t-SNE. In Eurographics Conference
on Visualization, EuroVis 2016, pages 73–77.



2022

Cı́cero Nogueira dos Santos, Igor Melnyk, and Inkit
Padhi. 2018. Fighting offensive language on so-
cial media with unsupervised text style transfer. In
Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics, ACL 2018,
pages 189–194.

Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi S.
Jaakkola. 2017. Style transfer from non-parallel text
by cross-alignment. In Advances in Neural Informa-
tion Processing Systems, NIPS 2017, pages 6833–
6844.

Nitish Srivastava, Geoffrey E. Hinton, Alex
Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-
nov. 2014. Dropout: a simple way to prevent neural
networks from overfitting. In Journal of Machine
Learning Research, pages 1929–1958.

Yulia Tsvetkov, Alan W. Black, Ruslan Salakhutdi-
nov, and Shrimai Prabhumoye. 2018. Style trans-
fer through back-translation. In Proceedings of the
56th Annual Meeting of the Association for Compu-
tational Linguistics, ACL 2018, pages 866–876.

Ronald J. Williams. 1992. Simple statistical gradient-
following algorithms for connectionist reinforce-
ment learning. In Machine Learning, pages 229–
256.

Jingjing Xu, Xu Sun, Qi Zeng, Xiaodong Zhang, Xu-
ancheng Ren, Houfeng Wang, and Wenjie Li. 2018.
Unpaired sentiment-to-sentiment translation: A cy-
cled reinforcement learning approach. In Proceed-
ings of the 56th Annual Meeting of the Association
for Computational Linguistics, ACL 2018, pages
979–988.

Ruqing Zhang, Jiafeng Guo, Yixing Fan, Yanyan Lan,
Jun Xu, and Xueqi Cheng. 2018a. Learning to con-
trol the specificity in neural response generation. In
Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics, ACL 2018,
pages 1108–1117.

You Zhang, Hang Yuan, Jin Wang, and Xuejie Zhang.
2017. YNU-HPCC at EmoInt-2017: Using a CNN-
LSTM model for sentiment intensity prediction.
In Proceedings of the 8th Workshop on Computa-
tional Approaches to Subjectivity, Sentiment and So-
cial Media Analysis, WASSA@EMNLP 2017, pages
200–204.

Zhirui Zhang, Shuo Ren, Shujie Liu, Jianyong Wang,
Peng Chen, Mu Li, Ming Zhou, and Enhong Chen.
2018b. Style transfer as unsupervised machine
translation. In arXiv preprint arXiv:1808.07894.


