



















































Vagueness and Learning: A Type-Theoretic Approach


Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 151–159,
Dublin, Ireland, August 23-24 2014.

Vagueness and Learning: A Type-Theoretic Approach

Raquel Fernández
Institute for Logic, Language

and Computation
University of Amsterdam

raquel.fernandez@uva.nl

Staffan Larsson
Department of Philosophy, Linguistics

and Theory of Science
University of Gothenburg

sl@ling.gu.se

Abstract

We present a formal account of the mean-
ing of vague scalar adjectives such as ‘tall’
formulated in Type Theory with Records.
Our approach makes precise how percep-
tual information can be integrated into
the meaning representation of these pred-
icates; how an agent evaluates whether an
entity counts as tall; and how the proposed
semantics can be learned and dynamically
updated through experience.

1 Introduction

Traditional semantic theories such as those de-
scribed in Partee (1989) and Blackburn and
Bos (2005) offer precise accounts of the truth-
conditional content of linguistic expressions, but
do not deal with the connection between meaning,
perception and learning. One can argue, however,
that part of getting to know the meaning of lin-
guistic expressions consists in learning to identify
the individuals or the situations that the expres-
sions can describe. For many concrete words and
phrases, this identification relies on perceptual in-
formation. In this paper, we focus on characteris-
ing the meaning of vague scalar adjectives such
as ‘tall’, ‘dark’, or ‘heavy’. We propose a for-
mal account that brings together notions from tra-
ditional formal semanticswith perceptual informa-
tion, which allows us to specify how a logic-based
interpretation function is determined and modified
dynamically by experience.

The need to integrate language and percep-
tion has been emphasised by researchers work-
ing on the generation and resolution of referring

This work is licensed under a Creative Commons Attribution
4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http:
//creativecommons.org/licenses/by/4.0/

expressions (Kelleher et al., 2005; Reiter et al.,
2005; Portet et al., 2009) and, perhaps even more
strongly, on the field of robotics, where ground-
ing language on perceptual information is critical
to allow artificial agents to autonomously acquire
and verify beliefs about the world (Siskind, 2001;
Steels, 2003; Roy, 2005; Skocaj et al., 2010).
Most of these approaches, however, do not build
on theories of formal semantics for natural lan-
guage. Here we choose to formalise our account
in a theoretical framework known as Type Theory
with Records (TTR), which has been shown to be
suitable for formalising classic semantic aspects
such as intensionality, quantification, and nega-
tion (Cooper, 2005a; Cooper, 2010; Cooper and
Ginzburg, 2011) as well as less standard phenom-
ena such as linguistic interaction (Ginzburg, 2012;
Purver et al., 2014), perception and action (Dob-
nik et al., 2013), and semantic coordination and
learning (Larsson, 2009). In this paper we use
TTR to put forward an account of the semantics of
vague scalar predicates like ‘tall’ that makes pre-
cise how perceptual information can be integrated
into their meaning representation; how an agent
evaluates whether an entity counts as tall; and how
the proposed semantics for these expressions can
be learned and dynamically updated through lan-
guage use.

We start by giving a brief overview of TTR and
explaining how it can be used for classifying en-
tities as being of particular types integrating per-
ceptual information. After that, in Section 3, we
describe the main properties of vague scalar pred-
icates. Section 4 presents a probabilistic TTR for-
malisation of the meaning of ‘tall’, which captures
its context-dependence and its vague character. In
Section 5, we then offer an account of how that
meaning representation is acquired and updated
with experience. Finally, in Section 6 we discuss
related work, before concluding in Section 7.

151



2 Meaning as Classification in TTR

In this section we give a brief and hence inevitably
partial introduction to Type Theory with Records.
For more comprehensive introductions, we refer
the reader to Cooper (2005b) and Cooper (2012).

2.1 Type Theory with Records: Main Notions

As in any type theory, the most central notion in
TTR is that of a judgement that an object a is
of type T , written as a : T . In TTR judgements
are seen as fundamentally related to perception, in
the sense that perceiving inherently involves cate-
gorising what we perceive. Some common basic
types in TTR are Ind (the type of individuals) and
R+ (the type of positive real numbers). All basic
types are members of a special type Type. Given
types T1 and T2, we can create the function type
T1 → T2 whose domain are objects of type T1
and whose range are objects of type T2. Types
can also be constructed from predicates and ob-
jects P (a1, . . . , an). Such types are called ptypes
and correspond roughly to propositions in first or-
der logic. In TTR, propositions are types of proofs,
where proofs can be a variety of things, from situ-
ations to sensor readings (more on this below).

Next, we introduce records and record types.
These are structured objects made up of pairs 〈l, v〉
of labels and values that are displayed in a matrix:

(1) a. A record type:
`1 : T1
`2 : T2(`1)
. . .
`n : Tn(`1, `2, . . . , `n−1)



b. A record: r =


`1 = a1
`2 = a2
. . .
`n = an
. . .


Record r in (1b) is of the record type in (1a) if
and only if a1 : T1, a2 : T2(a1), . . . , and an :
Tn(a1, a2, . . . , an−1). Note that the record may
contain more fields but would still be of type (1a)
if the typing condition holds. Records and record
types can be nested so that the value of a label is
itself a record (or record type). We can use paths
within a record or record type to refer to specific
bits of structure: for instance, we can use r.`2 to
refer to a2 in (1b).

As can be seen in (1a), the labels `1, . . . `n in a
record type can be used elsewhere to refer to the
values associated with them. This is a common

way of constructing ptypes where the arguments
of a predicate are entities that have been intro-
duced before in the record type. A sample record
and record type are shown in (2).

(2)

x = acman= prf(man(a))
crun = prf(run(a))

 :
x : Indcman: man(x)

crun : run(x)


In (2), a is an entity of type individual and prf(P )
is used as a placeholder for proofs of ptypes P .
In the record type above, the ptypes man(x) and
run(x) constructed from predicates are dependent
on x (introduced earlier in the record type).

2.2 Perceptual Meaning

Larsson (2013) proposes a system formalised in
TTR where some perceptual aspects of meaning
are represented using classifiers. For example, the
meaning of ‘right’ (as in ‘to the right of ’) involves
a two-input perceptron classifier κright(w, t, r),
specified by a weight vector w and a threshold
t, which takes as input a context r including an
object x and a position-sensor reading srpos. The
sensor reading consists of a vector containing two
real numbers representing the space coordinates of
x. The classifier classifies x as either being to the
right on a plane or not.1

(3) if r :
[

x : Ind
srpos : RealVector

]
, then

κright(w, t, r) =
{

right(r.x) if (r.srpos · w) > t
¬ right(r.x) otherwise

As output we get a record type containing either a
ptype right(x) or its negation, ¬ right(x). Larsson
(2013) proposes that readings from sensors may
count as proofs of such ptypes. A classifier can
be used for judging x as being of a particular type
on the grounds of perceptual information. A per-
ceptual proof for right(x) would thus include the
output from the position sensor that is directed to-
wards x. Here, this output would be the space co-
ordinates of x.

3 Vague Scalar Predicates

Scalar predicates such as ‘tall’, ‘long’ and ‘ex-
pensive’, also called “relative gradable adjectives”
(Kennedy, 2007), are interpreted with respect to a

1We are here assuming that we have a definition of dot
product for TTR vectors a:RealVectorn and b:RealVectorn
such that a · b = Σni=1aibi = a1b1 + a2b2 + . . . + anbn. We
also implicitly assume that the weight vector and the sensor
reading vector have the same dimensionality.

152



scale, i.e., a dimension such as height, length, or
cost along which entities for which the relevant di-
mension is applicable can be ordered. This makes
scalar predicates compatible with degree morphol-
ogy, like comparative and superlative morphemes
(‘taller than’, ‘the longest’) and intensifier mor-
phemes such as ‘very’ or ‘quite’. In this pa-
per, our focus is on the so-called positive form of
these adjectives (e.g. ‘tall’ as opposed to ‘taller’
or ‘tallest’).

A property that distinguishes the positive form
from the comparative and the superlative forms is
its context-dependance. To take a common exam-
ple: If Sue’s height is 180cm, she may be appro-
priately described as a tall woman, but probably
not as a tall basketball player. Thus, what counts
as tall can vary from context to context, with the
most relevant contextual parameter being a com-
parison class relative to which the adjective is in-
terpreted (e.g., the set of women, the set of bas-
ketball players, etc.). In addition to being context-
dependent, positive-form scalar predicates are also
vague, in the sense that they give rise to borderline
cases, i.e., entities for which it is unclear whether
the predicate holds or not.

Vagueness is certainly a property that affects
most natural language expressions, not only scalar
adjectives. However, scalar adjectives have a
relatively simple semantics (they are often uni-
dimensional) and thus constitute a perfect case-
study for investigating the properties and effects of
vagueness on language use. Gradable adjectives
have received a high amount of attention in the
formal semantics literature. It is common to dis-
tinguish between two main approaches to their se-
mantics: delineation-based and degree-based ap-
proaches. The delineation approach is associated
with the work of Klein (1980), who proposes that
gradable adjectives denote partial functions de-
pendent on a comparison class. They partition the
comparison class into three disjoint sets: a positive
extension, a negative extension, and an extension
gap (entities for which the predicate is neither true
nor false). In contrast, degree-based approaches
assume a measure function m mapping individu-
als x to degrees on a particular scale (degrees of
height, degrees of darkness, etc.) and a standard
of comparison or degree threshold θ (again, de-
pendent on a comparison class) such that x be-
longs to the adjective’s denotation if m(x) > θ
(Kamp, 1975; Pinkal, 1979; Pinkal, 1995; Barker,

2002; Kennedy and McNally, 2005; Kennedy,
2007; Solt, 2011; Lassiter, 2011).

We build on degree approaches but adopt a
perception-based perspective and take a step fur-
ther to formalise how the meaning of these pred-
icates can be learned and constantly updated
through language use.

4 A Perceptual Semantics for ‘Tall’

To exemplify our approach, we will use the scalar
predicate ‘tall’ throughout.

4.1 Context-sensitivity

We first focus on capturing the context-
dependence of relative scalar predicates. For
this we define a type Tctxt as follows:

(4) Tctxt=

 c : Typex : c
h : R+


The context (ctxt) of a scalar predicate like ‘tall’
is a record of the type in (4), which includes: a
type c (typically a subtype of Ind) representing the
comparison class; an individual x within the com-
parison class (the argument of tall); a perceived
measure on the relevant scale(s), in this case the
perceived height h of x expressed as a positive real
number.

The context presupposes the acquisition of sen-
sory input from the environment. In particular, it
assumes that an agent using such a representation
is able to classify the entity in focus x as being
of type c and is able to use some height sensor to
obtain an estimate of x’s height (the value of h is
the sensor reading). We thus forgo the inclusion of
an abstract measure function in the representation.
In an artificial agent, this may be accomplished by
image processing software for detecting and mea-
suring objects in a digital image.

Besides the ctxt, we also assume a standard
threshold of tallness θtall of the type given in (5).
θtall is a function from a type specifying a com-
parison class to a height value, which corresponds
to a tallness threshold for that comparison class.
(In Section 5 we will discuss how such a threshold
may be computed.)

(5) θtall : Type→ R+
The meaning of ‘tall’ involves a classifier for tall-
ness, κtall, of the following type:

(6) κtall : (Type→ R+, Tctxt)→ Type

153



We define this classifier as a one-input perceptron
that compares the perceived height h of an indi-
vidual x to the relevant threshold θ determined by
a comparison class c. Thus, if θ : Type→ R+ and
r : Tctxt, then:

κtall(θ, r) =
{

tall(r.x) if r.h > θ(r.c)
¬tall(r.x) otherwise

Simplifying somewhat, we can represent the mea-
ning of ‘tall’, tall, as a record specifying the type
of context (Tctxt) where an utterance of ‘tall’ can
be made, the parameter of the tallness classifier
(the threshold θ), and a function f which is applied
to the context to produce the content of ‘tall’.

(7)

tall =



Tctxt=

 c : Typex : c
h : R+


θ = θtall
f = λr : Tctxt.[

sit = r
sit-type =

[
ctall : κtall(θ, r)

]]


The output of the function f is an Austinian propo-
sition (Cooper, 2005b): a judgement that a situa-
tion (sit, represented as a record r of type Tctxt),
is of a particular type (specified in sit-type). In the
case of tall, the context of utterance (which instan-
tiates r) is judged to be of the type where there is
an individual x which is either tall or not tall, ac-
cording to the output of the classifier κtall. The
context of utterance in the sit field will include the
height-sensor reading, which means that the sen-
sor reading is part of the proof of the sit-type indi-
cating that x is tall (or not, as the case may be).

Thus, to decide whether to refer to some indi-
vidual x as tall or to evaluate someone else’s utter-
ance describing x as tall, an agent applies the func-
tion tall.f to the current situation, represented as a
record r : Tctxt. As an example, let us consider a
situation that includes the context in (8), resulting
from observing John Smith as being 1.88 meters
tall (assuming this is our scale of tallness):

(8) ctxt =

 c = Humanx = john smith
h = 1.88


Let us assume that given the comparison class
Human, θtall(Human) = 1.87. In this case,
tall.f(ctxt) will compute as shown in (9). The re-
sulting Austinian proposition corresponds to the
agent’s judgement that the situation in sit is one
where John Smith counts as tall.

(9) λr : Tctxt.
[

sit = r
sit-type =

[
ctall : κtall(θtall, r)

] ]

(

 c = Humanx = john smith
h = 1.88

) =
sit =

 c = Humanx = john smith
h = 1.88


sit-type =

[
ctall : tall(john smith)

]


4.2 Vagueness
According to the above account, ‘tall’ has a
precise interpretation: given a degree of height
and a comparison class, the threshold sharply
determines whether tall applies or not. There
are several ways in which one can account for
vagueness—amongst others, by introducing per-
ceptual uncertainty (possibly inaccurate sensor
readings). Here, in line with Lassiter (2011), we
opt for substituting the precise threshold with a
noisy, probabilistic threshold. We consider the
threshold to be a normal random variable, which
can be represented by the parameters of its Gaus-
sian distribution, the mean µ and the standard de-
viation σ (the noise width).2

To incorporate this modification into our ap-
proach, we update the tallness classifier κtall we
had defined in (6) so that it now takes as parame-
ters µtall and σtall, both of them dependent on the
comparison class and hence of type Type→ R+.
The output of the classifier is now a probability
rather than a ptype such as tall(x) or¬tall(x). Be-
fore indicating how this probability is computed,
we give the type of the vague version of the clas-
sifier in (10) and the vague representation of the
meaning of ‘tall’ in (11).

(10)κtall : (Type→R+, Type→R+, Tctxt)→ [0, 1]
(11)

tall =



Tctxt=

 c : Typex : c
h : R+


µ = µtall
σ = σtall
f = λr : Tctxt.sit = rsit-type = [ctall : tall(r.x)]

prob = κtall(σ, µ, r)




2Which noise function may be the most appropriate is an

empirical question we do not tackle in this paper. Our choice
of Gaussian noise follows Schmidt et al. (2009)—see Sec-
tion 5.1.

154



The output of the function tall.f is now a prob-
abilistic Austinian proposition (Cooper et al.,
2014). Like before, the proposition expresses a
judgement that a situation sit is of a particular
type. But here the judgement is probabilistic—it
encodes the belief of an agent concerning the like-
lihood that sit is of a type where x counts as tall.

Since we take the noisy threshold to be a normal
random variable, given a particular µ and σ, we
can calculate the probability that the height r.h of
individual r.x counts as tall as follows:

κtall(µ, σ, r) =
1
2

[
1 + erf

(
r.h− µ(r.c)
σ(r.c)

√
2

)]
Here erf is the error function, defined as3

erf(x) =
2√
π

∫ x
t=0

e−t
2
dt

The error function defines a sigmoid shape (see
Figure 1), in line with the upward monotonicity
of ‘tall’. The output of κtall(µ, σ, r) corresponds
to the probability that h will exceed the normal
random threshold with mean µ and deviation σ.

Figure 1: Plot of the error function.

Let us consider an example. Assume that we have
µtall(Human) = 1.87 and σtall(Human) = 0.05
(see Section 5.1 below for justification of the latter
value). Let’s also assume the same ctxt as above
in (8). In this case, tall.f(ctxt) will compute as in
(12), given that

κtall(µtall, σtall,

c=Humanx=john smith
h=1.88

) =
1
2

[
1 + erf

(
1.88− 1.87

0.05
√

2

)]
= 0.579

3For an explanation of this standard definition, see http:
//en.wikipedia.org/wiki/Error_function,
which is the source of the graph in Figure 1.

(12) λr : Tctxt.

sit = rsit-type = [ctall : tall(r.x)]
prob = κtall(µtall, σtall, r)


(

 c = Humanx = john smith
h = 1.88

) =


sit =

 c = Humanx = john smith
h = 1.88


sit-type =

[
ctall : tall(john smith)

]
prob = 0.579


This probability can now be used in further prob-
abilistic reasoning, to decide whether to refer to
an individual x as tall, or to evaluate someone
else’s utterance describing x is tall. For exam-
ple, an agent may map different probabilities to
different adjective qualifiers of tallness to yield
compositional phrases such as ‘sort of tall’, ‘quite
tall’, ‘very tall’, ‘extremely tall’, etc. The mean-
ings of these composed adjectival phrases could
specify probability ranges trained independently.
Compositionality for vague perceptual meanings,
and the interaction between compositionality and
learning, is an exciting area for future research.4

5 Learning from Language Use

In this section we consider possibilities for com-
puting the noisy threshold we have introduced
in the previous section and discuss how such a
threshold and the probabilistic judgements it gives
rise to are updated with language use.

5.1 Computing the Noisy Threshold
We assume that agents keep track of judgements
made by other agents. More concretely, for a
vague scalar predicate like ‘tall’, we assume that
an agent will have at its disposal a set of obser-
vations consisting of entities of a particular type
T (a comparison class such as Human) that have
been judged to be tall, together with their observed
heights. Judgements of tallness may vary across
individuals—indeed, such variation (both inter-
and intra-individual) is a hallmark of vague pred-
icates. We use ΩTtall to refer to the set of heights
of those entities x : T that have been considered
tall by some individual. From this agent-specific
set of observations, which is constantly updated as
the agent is exposed to new judgements by other
individuals, we want to compute a noisy threshold,

4See Larsson (2013) for a sketch of compositionality for
perceptual meaning.

155



which the agent uses to make her own judgements
of tallness, as specified in (11).

Different functions can be used to compute µtall
and σtall from ΩTtall. What constitutes an appro-
priate function is an empirical matter and what
the most suitable function is possibly varies across
predicates (what may apply to ‘tall’ may not be
suitable for ‘dark’ or ‘expensive’, for example).
Hardly any work has been done on trying to iden-
tify how the threshold is computed from experi-
ence. A notable exception, however, is the work of
Schmidt et al. (2009), who collect judgements of
people asked to indicate which items are tall given
distributions of items of different heights. Schmidt
and colleagues then propose different probabilis-
tic models to account for the data and compare
their output to the human judgements. They ex-
plore two types of models: threshold-based mod-
els and category-based or cluster models. The best
performing models within these two types perform
equally well and the study does not identify any
advantages of one type over the other one. Since
we have chosen threshold models as our case-
study, we focus our attention on those here.

Each of the threshold models tested by Schmidt
et al. (2009) corresponds to a possible way of com-
puting the mean µtall of a noisy threshold from a
set of observations. The best performing threshold
model in their study is the relative height by range
model, where (in our notation):

(13) relative height by range (RH-R): µtall(T ) =
max(ΩTtall)− k · (max(ΩTtall)−min(ΩTtall))

Here max(ΩTtall) and min(Ω
T
tall) stand for the

maximum and the minimum height, respectively,
of the items that have been judged to be tall
by some individual. According to this threshold
model, any item within the top k% of the range
of heights that have been judged to be tall counts
as tall. The model includes two parameters, k and
a noise-width parameter that in our approach cor-
responds to σtall. Schmidt et al. (2009) report
that the best fit of their data was obtained with
k = 29% and σtall = 0.05.

5.2 Updating Vague Meanings

We now want to specify how the vague meaning
of ‘tall’ is updated as an agent is exposed to new
judgements via language use. Our setting so far
offers a straightforward solution to this: If a new
entity x : T with height h is referred to as tall, the

agent adds h to its set of observations ΩTtall and
recomputes µtall(Human), for instance using RH-
R as defined in (13). If RH-H is used, ideally the
value of k and σtall should be (re)estimated from
ΩTtall. For the sake of simplicity, however, here
we will assume that these two parameters take the
values experimentally validated by Schmidt et al.
(2009) and are kept constant. An update to µtall
will take place if it is the case that h > max(ΩTtall)
or h < min(ΩTtall). This in turn will trigger un
update to the probability outputted by κtall.

As an example, let us assume that our
initial set of observations is ΩHumantall =
{1.87, 1.92, 1, 90, 1.75, 1.80} (recall this corre-
sponds to the perceived heights of individuals
that have been described as tall by some agent).
This means that max(ΩHumantall ) = 1.92 and
min(ΩHumantall ) = 1.75. Hence, given (13):

(14) µtall(Human) =
1.92− 0.29 · (1.92− 1.75) = 1.87

Let’s assume we now make an observation where
a person of height 1.72 is judged to be tall. This
will mean that the set of observations is now
ΩHumantall = {1.87, 1.92, 1, 90, 1.75, 1.80, 1.72}
and consequently min(ΩHumantall ) = 1.72, which
yields an updated mean of the noisy threshold:

(15) µtall(Human) =
1.92− 0.29 · (1.92− 1.72) = 1.862

If we were to re-evaluate John Smith’s tallness in
light of this observation, we would get a new prob-
ability 0.64 that he is tall (in contrast to the earlier
probability of 0.579 given in (12)).

5.3 Possible Extensions

The set of observations ΩHumantall can be derived
from a set of Austinian propositions correspond-
ing to instances where people have been judged
to be tall. To update from an Austinian proposi-
tion p we simply add p.sit.h to ΩtallHuman and re-
compute µtall(p.c). Note that we are here treating
these Austinian propositions as non-probabilistic.
This seems to make sense since an addressee does
not have direct access to the probability associated
with the judgement of the speaker. If we were to
take these probabilities into account (for instance,
the use of a hedge in ‘sort of tall’ may be used
to make inferences about such probabilities), and
if those probabilities are not always 1, we would
need a different way of computing µtall than the

156



one specified so far.
Somewhat related to the point above, note that

in our approach we treat all judgements equally,
i.e., we do not distinguish between possible dif-
ferent levels of trustworthiness amongst speakers.
An agent who is told that an entity with height h
is tall adds that observation to its knowledge base
without questioning the reliability of the speaker.
This is clearly a simplification. For instance, there
is developmental evidence showing that children
are more sensitive to reliable speakers than to un-
reliable ones during language acquisition (Scofield
and Behrend, 2008).

6 Other Approaches
Within the literature in formal semantics, Las-
siter (2011) has put forward a proposal that ex-
tends in interesting ways earlier work by Barker
(2002) and shares some aspects with the account
we have presented here. Operating in a probabilis-
tic version of classical possible-worlds semantics,
Lassiter assumes a probability distribution over a
set of possible worlds and a probability distribu-
tion over a set of possible languages. Each pos-
sible language represents a precise interpretation
of a predicate like ‘tall’: tall1 = λx.x’s height ≥
5’6”; tall2 = λx.x’s height ≥ 5’7”; and so forth.
Lassiter thus treats “metalinguistic belief” (repre-
senting an agent’s knowledge of the meaning of
words) in terms of probability distributions over
precise languages. Since each precise interpreta-
tion of ‘tall’ includes a given threshold, this can
be seen as defining a probability distribution over
possible thresholds, similarly to the noisy thresh-
old we have used in our account. Lassiter, how-
ever, is not concerned with learning.

Within the computational semantics literature,
DeVault and Stone (2004) describe an imple-
mented system in a drawing domain that is able to
interpret and execute instructions including vague
scalar predicates such as ‘Make a small circle’.
Their approach makes use of degree-based seman-
tics, but does not take into account comparison
classes. This is possible in their drawing domain
since the kind of geometric figures it includes
(squares, rectangles, circles) do not have intrinsic
expected properties (size, length, etc). Their focus
is on modelling how the threshold for a predicate
such as ‘small’ is updated during an interaction
with the system given the local discourse context.
For instance, if the initial context just contains a
square, the size of that square is taken to be the

standard of comparison for the predicate ‘small’.
The user’s utterance ‘Make a small circle’ is then
interpreted as asking for a circle of an arbitrary
size that is smaller than the square.

In our characterisation of the context-sensitivity
of vague gradable adjectives in Section 4.1, we
have focused on their dependence on general com-
parison classes corresponding to types of entities
(such as Human, Woman, etc) with expected prop-
erties such as height. Thus, in contrast to DeVault
and Stone (2004), who focus on the local context
of discourse, we have focused on what could be
called the global context (an agent’s experience re-
garding types of entities and their expected prop-
erties). How these two types of context interact
remains an open question, which we plan to ex-
plore in our future work (see Kyburg and Morreau
(2000), Kemp et al. (2007), and Fernández (2009)
for pointers in this direction).

7 Conclusions and future work

Traditional formal semantics theories postulate a
fixed, abstract interpretation function that medi-
ates between natural language expressions and the
world, but fall short of specifying how this func-
tion is determined or modified dynamically by
experience. In this paper we have presented a
characterisation of the semantics of vague scalar
predicates such as ‘tall’ that clarifies how their
context-dependent meaning and their vague char-
acter are connected with perceptual information,
and we have also shown how this low-level per-
ceptual information (here, real-valued readings
from a height sensor) connects to high level logical
semantics (ptypes) in a probabilistic framework.
In addition, we have put forward a proposal for
explaining how the meaning of vague scalar ad-
jectives like ‘tall’ is dynamically updated through
language use.

Tallness is a function of a single value (height),
and is in this sense a uni-dimensional pred-
icate. Indeed, most linguistic approaches to
vagueness focus on uni-dimensional predicates
such as ‘tall’. However, many vague predicates
are multi-dimensional, including nouns for posi-
tions (‘above’), shapes (‘hexagonal’), and colours
(‘green’), amongst many others. Together with
compositionality (mentioned at the end of Sec-
tion 4.2), generalisation of the present account to
multi-dimensional vague predicates is an interest-
ing area of future development.

157



Acknowledgements

The first author acknowledges the support of the
Netherlands Organisation for Scientific Research
(NWO) and thanks the Centre for Language Tech-
nology at the University of Gothenburg for gen-
erously funding research visits that led to the
work presented in this paper. The second au-
thor acknowledges the support of Vetenskapsrådet,
project 2009-1569, Semantic analysis of interac-
tion and coordination in dialogue (SAICD); the
Department of Philosophy, Linguistics, and The-
ory of Science; and the Centre for Language Tech-
nology at the University of Gothenburg.

References
Chris Barker. 2002. The dynamics of vagueness. Lin-

guistics & Philosophy, 25(1):1–36.

Patrick Blackburn and Johan Bos. 2005. Represen-
tation and Inference for Natural Language: A First
Course in Computational Semantics. CSLI Publica-
tions.

Robin Cooper and Jonathan Ginzburg. 2011. Negation
in dialogue. In Proceedings of the 15th Workshop on
the Semantics and Pragmatics of Dialogue (SemDial
2011), Los Angeles (USA).

Robin Cooper, Simon Dobnik, Shalom Lappin, and
Staffan Larsson. 2014. A probabilistic rich type
theory for semantic interpretation. In Proceedings
of the EACL Workshop on Type Theory and Natural
Language Semantics (TTNLS).

Robin Cooper. 2005a. Austinian truth, attitudes and
type theory. Research on Language and Computa-
tion, 3(4):333–362, December.

Robin Cooper. 2005b. Austinian truth, attitudes and
type theory. Research on Language and Computa-
tion, 3:333–362.

Robin Cooper. 2010. Generalized quantifiers and clar-
ification content. In Paweł Łupkowski and Matthew
Purver, editors, Aspects of Semantics and Pragmat-
ics of Dialogue. SemDial 2010, 14th Workshop on
the Semantics and Pragmatics of Dialogue, Poznań.
Polish Society for Cognitive Science.

Robin Cooper. 2012. Type theory and semantics in
flux. In Ruth Kempson, Nicholas Asher, and Tim
Fernando, editors, Handbook of the Philosophy of
Science, volume 14: Philosophy of Linguistics. El-
sevier BV. General editors: Dov M. Gabbay, Paul
Thagard and John Woods.

David DeVault and Matthew Stone. 2004. Interpret-
ing vague utterances in context. In Proceedings of
the 20th International Conference on Computational
Linguistics (COLING’04), pages 1247–1253.

Simon Dobnik, Robin Cooper, and Staffan Larsson.
2013. Modelling language, action, and perception
in type theory with records. In Constraint Solving
and Language Processing, Lecture Notes in Com-
puter Science, pages 70–91. Springer.

Raquel Fernández. 2009. Salience and feature vari-
ability in definite descriptions with positive-form
vague adjectives. In Workshop on the Production
of Referring Expressions: Bridging the gap between
computational and empirical approaches to refer-
ence (CogSci’09).

Jonathan Ginzburg. 2012. The Interactive Stance. Ox-
ford University Press.

Hans Kamp. 1975. Two theories of adjectives. In
E. Keenan, editor, Formal Semantics of Natural Lan-
guage, pages 123–155. Cambridge University Press.

John Kelleher, Fintan Costello, and Josef van Genabith.
2005. Dynamically structuring, updating and inter-
relating representations of visual and linguistic dis-
course context. Artificial Intelligence, 167(1):62–
102.

Charles Kemp, Amy Perfors, and Joshua B. Tenen-
baum. 2007. Learning overhypotheses with hier-
archical bayesian models. Developmental Science,
10(3):307–321.

Christopher Kennedy and Louise McNally. 2005.
Scale structure, degree modification, and the seman-
tics of gradable predicates. Language, pages 345–
381.

Christopher Kennedy. 2007. Vagueness and grammar:
The semantics of relative and absolute gradable ad-
jectives. Linguistics and Philosophy, 30(1):1–45.

Ewan Klein. 1980. A semantics for positive and
comparative adjectives. Linguistics and Philosophy,
4:1–45.

Alice Kyburg and Michael Morreau. 2000. Fitting
words: Vague language in context. Linguistics and
Philosophy, 23:577–597.

Staffan Larsson. 2009. Detecting and learning from
lexical innovation in dialogue: a ttr account. In
Proceedings of the 5th International Conference on
Generative Approaches to the Lexicon.

Staffan Larsson. 2013. Formal semantics for percep-
tual classification. Journal of Logic and Computa-
tion.

Dan Lassiter. 2011. Vagueness as probabilistic linguis-
tic knowledge. In R. Nowen, R. van Rooij, U. Sauer-
land, and H. C. Schmitz, editors, Vagueness in Com-
munication. Springer.

Barbara Partee. 1989. Possible worlds in model-
theoretic semantics: A linguistic perspective. In
S. Allen, editor, Possible Worlds in Humanities, Arts
and Sciences, pages 93–123. Walter de Gruyter.

158



Manfred Pinkal. 1979. Semantics from different
points of view. In R. Bäurle, U. Egli, and A. von
Stechow, editors, How to Refer with Vague Descrip-
tions, pages 32–50. Springer-Verlag.

Manfred Pinkal. 1995. Logic and lexicon: the seman-
tics of the indefinite, volume 56 of Studies in Lin-
guistics and Philosophy. Springer.

François Portet, Ehud Reiter, Albert Gatt, Jim Hunter,
Somayajulu Sripada, Yvonne Freer, and Cindy
Sykes. 2009. Automatic generation of textual sum-
maries from neonatal intensive care data. Artificial
Intelligence, 173(7):789–816.

Matthew Purver, Julian Hough, and Eleni Gre-
goromichelaki. 2014. Dialogue and compound
contributions. In A. Stent and S. Bangalore, ed-
itors, Natural Language Generation in Interactive
Systems. Cambridge University Press.

Ehud Reiter, Somayajulu Sripada, Jim Hunter, Jin Yu,
and Ian Davy. 2005. Choosing words in computer-
generated weather forecasts. Artificial Intelligence,
167(1):137–169.

Deb Roy. 2005. Semiotic schemas: A framework for
grounding language in action and perception. Artifi-
cial Intelligence, 167(1):170–205.

L.A. Schmidt, N.D. Goodman, D. Barner, and J.B.
Tenenbaum. 2009. How tall is tall? composition-
ality, statistics, and gradable adjectives. In Proceed-
ings of the 31st annual conference of the cognitive
science society.

Jason Scofield and Douglas A Behrend. 2008. Learn-
ing words from reliable and unreliable speakers.
Cognitive Development, 23(2):278–290.

Jeffrey Mark Siskind. 2001. Grounding the lexical
semantics of verbs in visual perception using force
dynamics and event logic. Journal of Artificial In-
telligence Research, (15):31–90.

Danijel Skocaj, M Janicek, Matej Kristan, Geert-Jan M
Kruijff, Aleš Leonardis, Pierre Lison, Alen Vrecko,
and Michael Zillich. 2010. A basic cognitive sys-
tem for interactive continuous learning of visual
concepts. In Proceeding of the Workshop on Inter-
active Communication for Autonomous Intelligent
Robots, pages 30–36.

Stephanie Solt. 2011. Notes on the comparison class.
In Vagueness in communication, pages 189–206.
Springer.

Luc Steels. 2003. Evolving grounded communication
for robots. Trends in cognitive sciences, 7(7):308–
312.

159


