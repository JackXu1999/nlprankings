















































Multilevel Heuristics for Rationale-Based Entity Relation Classification in Sentences


Proceedings of the 27th International Conference on Computational Linguistics, pages 1145–1155
Santa Fe, New Mexico, USA, August 20-26, 2018.

1145

Multilevel Heuristics for Rationale-Based Entity Relation Classification in
Sentences

Shiou Tian Hsu, Mandar Chaudhary and Nagiza F. Samatova
North Carolina State University

shsu3@ncsu.edu, mschaudh@ncsu.edu, samatova@csc.ncsu.edu

Abstract

Rationale-based models provide a unique way to provide justifiable results for relation classifi-
cation models by identifying rationales (key words and phrases that a person can use to justify
the relation in the sentence) during the process. However, existing generative networks used to
extract rationales come with a trade-off between extracting diversified rationales and achieving
good classification results. In this paper, we propose a multilevel heuristic approach to regulate
rationale extraction to avoid extracting monotonous rationales without compromising classifica-
tion performance. In our model, rationale selection is regularized by a semi-supervised process
and features from different levels: word, syntax, sentence, and corpus. We evaluate our approach
on the SemEval 2010 dataset that includes 19 relation classes and the quality of extracted ra-
tionales with our manually-labeled rationales. Experiments show a significant improvement in
classification performance and a 20% gain in rationale interpretability compared to state-of-the-
art approaches.

1 Introduction

The goal of sentence-level entity relation classification is to infer how two target entities are semantically
associated in a sentence. It is a core NLP function that supports many high level tasks such as information
extraction and knowledge graph population (Hendrickx et al., 2009; Niu et al., 2012). Recent advances
in generative models facilitate improved classification performance along with justifiable results which
improves model interpretability. A generative model will first extract the most representative fragments
in the sentence that expresses the relation first, and augments the classifier with the rationales (Hsu et al.,
2018) . These representative fragments are called rationales as per (Zhang et al., 2016; Lei et al., 2016;
Hsu et al., 2018), and can be used to justify the results. We illustrate an example of rationale-based
models using an example sentence which expresses a Instrument-Agency(e2,e1) relationship between
the given target entities e1 = “attacker” and e2 = “instrument”:

Rationale based models: She had struggled violently with her [attacker]e1, who killed her with a
blunt [instrument]e2.
(words marked in bold and the entities are the major sources to infer the relation)

The most commonly used structure in generative models consists of two components: a Generator and
a Discriminator. The Generator extracts rationales from an input sentence in an unsupervised fashion; the
Discriminator, which is supervised, predicts the relation class utilizing the rationales. However, training
a good Generator can be essentially hard due to the mode collapse problem (Chen et al., 2016; Che et
al., 2017; Duhyeon and Hyunjung, 2018). Mode collapse is a commonly observed paradox where the
Generator attempts to extract varied rationales, but converges to select monotonous rationales because the
Discriminator failed to model diversified rationales. A collapsed Generator is not capable of providing

This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://
creativecommons.org/licenses/by/4.0/



1146

meaningful rationales since it extracts the same rationales repeatedly regardless of the context. However,
as shown in Figure 1, a collapsed Generator does not always lead to poor classification performance
when compared to a finely converged Generator.

Figure 1: A Generator can converge at collapsed rationales but still lead to good classification results.
Figure on the left shows the rationale distribution of a collapsed and a well-converged Generator that
uses a recurrent neural net . The well-converged Generator evenly selects rationales from a sentence,
while the collapsed Generator selects rationales close to the beginning of the sentence. This is because
the best scenario for Discriminator is that some rationales are repetitively selected and optimized in every
training iteration, which is difficult for the Generator. Eventually, the Generator learns to exploit position
features since it is less diversified than words. Figure on the right shows that a collapsed Generator does
not necessarily deteriorate the classification performance.

One of the major causes of mode collapse is the lack of regularizing terms to smooth out the Genera-
tor(Chen et al., 2016; Arjovsky and Bottou, 2017; Salimans et al., 2016). In this paper, we aim to improve
the rationale-based models for relation classification by introducing semi-supervised capacity and addi-
tion regularizing force to the Generator to prevent mode collapsing. In our Generator, we develop a
multilevel heuristic to replace the context-focused recurrent neural net used by existing approach(Hsu et
al., 2018). Our Generator jointly considers features from different levels of the dataset such as contextual
words, target entities, sentence syntax features, rationale-relation closeness, and global word distribution
in corpus. The details of our improved Generator are shown in Figure 2.

Our Generator jointly considers several aspects such as contextual words, target entities, word distri-
bution in corpus, sentence grammatical features, and selected rationale-relation closeness to regularize
rationale selection.

We evaluate our model on the SemEval 2010 Task 8 dataset which includes 19 relation classes. Specif-
ically, we use F1 score to measure the quality of extracted rationales and the classification performance.
Given the absence of ground-truth of rationales in the dataset, we manually label the test set and make it
publicly available1. We empirically demonstrate an improvement in interpretability of the rationales by
20% compared to Hsu et al. (2018), and also an improvement in the F1 score of 90.7 compared to 89.5
in the state-of-the-art model. We summarize the contributions of our approach as follows:

• We propose a multilevel heuristics approach to avoid mode collapse in rationale-based relation
classification models.
• We empirically demonstrate our model produces improved relation classification performance and

more interpretable rationales compared to other models
• We provide a labeled set of rationales that can be used for evaluation in future rationale research.

2 Related Work

Research for improving generative neural networks have gained much interest in the research community
due to the effectiveness and versatility of these models. These improvements can be divided into two
categories: architecture-oriented and divergence-oriented.

1https://github.ncsu.edu/shsu3/rationale-improvement



1147

Figure 2: Figure on the left and the right shows the Generator in Hsu et al. (2018) and our proposed
multilevel heuristics Generator respectively. The Word heuristic measures the relative closeness of each
word in the sentence to every relation class. The Entity heuristic uses the target entities to regulate the
Word heuristic. The Relation heuristic contains predictions of the relation from a standalone convolu-
tional neural net model and is also used used to regulate the Word heuristic. The Word heuristic is then
summed and weighted by the Syntax heuristic, which considers both, the word distance to entities, and
Part-of-Speech labels. The Corpus heuristic is obtained by word-relation distribution in the corpus. The
Rationale heuristic is the semi-supervised component which is based on rationales from the previous
training iteration.

The Generative Adversarial Network (GAN) (Goodfellow et al., 2014) is the one of most representa-
tive model in the architecture-oriented group. Goodfellow et al. (2014) proposed a modified generative
model using an adversarial minimax-game formulation. The objective of GAN is to jointly train a Gen-
erator and Discriminator, where the loss for Discriminator and the reward for Generator comes from
failed attempts to determine ground-truths from the emulated results created by Generator. However,
the adversary process in GAN is the major source of mode collapse, hence further extensions of GAN
aimed towards addressing this issue. For example, InfoGan (Chen et al., 2016) proposed to maximize
the mutual information between a subset of the noise variables with the observations to produce disen-
tangled unsupervised representations. Salimans et al. (2016) proposed to use semi-supervised training
and label-smoothing to help GAN converge to Nash Equilibrium between the Generator and the Dis-
criminator. Duhyeon and Hyunjung (2018) proposed RFGAN to implicitly regularize the discriminator
using representative features extracted from the data distribution. In VEEGAN (Srivastava et al., 2017),
the authors suggested to jointly train an extra Reconstructor with the Generator which is an approximate
reverse action of the Generator to encode noise.

Another group of methods have aimed to reduce mode collapse in generative models by modifying the
joint loss functions used between the Generator and Discriminator. In Arjovsky et al. (2017), the authors
theoretically showed that the KullbackLeibler (KL) divergence often used in GAN was one of the source
of instability. Based on this discovery, Arjovsky and Bottou (2017) proposed Wasserstein distance to
measure the similarity between the fake and real data to make stabler Generator. Gulrajani et al. (2017)
introduce the gradient penalty for regularizing the divergence as an alternative to gradient clipping used
in Arjovsky and Bottou (2017) to capture stronger movements in gradients . In DRAGAN (Kodali et
al., 2017), they proposed to regulate sharp gradients in the Discriminator, which often happens at some
undesired local equilibria between Generator and Discriminator. Roth et al. (2017) proposed another
type of regularization that breaks down the divergence into different Discriminator output to achieve
stability.

We position our work closer to the first category since we can view the multilevel heuristics used in our
model close to a combination of models in the first category. The Word and Corpus heuristic are derived
from data distribution similar to RFGAN, and the Relation and Rationale heuristic are substantially
close to the semi-supervised learning techniques used in Salimans et al. (2016). However, our work
is not exclusive to the second category as the Word heuristic included idea close to Roth et al. (2017)
where the divergence in the Word heuristic maps to label level in Discriminator instead of treating the
Discriminator as a whole.



1148

On a final note, we would like to mention that this work shares some resemblance with (Giuliano
et al., 2006) and can be potentially considered as its extension. In Giuliano et al. (2006), the authors
utilize several shallow linguistic information for relation classification, such as word-relation frequency
or POS to avoid dependent syntactic information. In this work, the fundamental difference is that all
token-based computations are replaced by embeddings which are more generalizable when considering
words of semantic relatedness. Additionally, the training phase is carried out by the adversarial process.

3 Rationale Generation Framework

We describe the framework for rationale-based approach in the following. Consider an input sentence x
= {xt}Tt=1, where e1 and e2 are given target entities of interest and e1 and e2 ⊂ {x1, x2, ..., xT }. The
goal of relation classification is thus to use (x,e1,e2) to predict the relationship y between e1 and e2. We
call this prediction process as encoding and denote it as enc(x,e1,e2).

Following Hsu et al. (2018), we consider this rationale based model as an adversarial problem the goal
of the Generator is to generate rationales r that enc(r,x,e1,e2) can outperform all other sets of rationales
in enc(r̃,x,e1,e2). In Hsu et al. (2018), they split the Generator into two steps: the Generator and the
Selector. The Generator first generates candidates gen(x,e1,e2), which samples c = {ct}Tt=1 from the
input where ct ∈ [0, 1] and it represents whether xt should be considered as a rationale ; the Selector then
samples rationales r from c and is represented as sel(c,e1,e2). We illustrate the framework in Figure 3.

A difference against other generative works is worth noting: in Lei et al. (2016), rationales are defined
as a sequence of words in a customer review that are directly related to different rating aspects. This is
because in Lei et al. (2016), the assumption is that the reviews contain convoluted sentiments, and the
goal of a rationale is to disentangle the sentiments. In effect, the goal of r in Lei et al. (2016) is to serve
as a proxy of x that makes enc(r) approximate to enc(x). while our goal is to find r that outperform
all possible short enumerations of x in enc(r,x,e1,e2).

Figure 3: The model structure from Hsu et al. (2018) with a sample input sentence and the given entities.
The Generator selects candidate rationales, and the Selector enumerates all possible combinations of
candidates with entities and selects one ‘best performing candidate set’. An adversary Generator and
Selector carry out the same process using a randomized approach. Candidate sets are then transformed
into a vector representation by the Encoder and are evaluated against the ground-truth. Rewards are
fed back to the Generator if the Encoder is able to identify candidate sets that are generated randomly,
while the Selector is rewarded if the best performing rationale candidate set outperforms the one in
the adversary. The best performing candidate set from Selector is finally considered as the extracted
rationales, and then used in the Encoder to predict entity relation.



1149

4 Model

In this section, we describe each component of the framework. We begin by explaining the Encoder to
formalize the goal of relation classification.

4.1 Encoder

Given an input training tuple (x,e1,e2,y), where x = {xt}Tt=1, and y is the one-hot L dimensional vector
representing the relation class. The goal of the Encoder enc(r,x,e1,e2) is to produce a probability
distribution ŷ that approximates to y as formulated as follows (N is the size of the training set):

loss =

|N |∑
i=1

−yi · log(ŷi) (1)

The Encoder produces ŷ by encoding (r,x,e1,e2) as a vector representation and then projects it to the y
space. This vector representation can further break down to a sentence vector Vx and a rationale vector
Vr. We produce Vx through CNN using the same model as Kim (2014) which encodes the sentence
through a continuous window approach, where K are the set of sizes for the windows. To produce Vr,
we implement a RNN model using GRU cells that reads the rationales and target entities. Since RNN
is order sensitive, the rationales and the entities are sorted based on their position in the sentence before
applying the RNN model.

Vx = CNN(x)

Vr = RNN([r, e1, e2])

ŷ = enc(r,x, e1, e2)

= softmax(Wenc · [Vr, Vx, e1, e2] + benc)
(2)

4.2 Generator

The goal of the Generator gen(x) is to derive a set of binary variables c = {ct}Tt=1 by sampling from
probability scores s = {st}Ts=1, where ct ∈ [0, 1] indicates whether xt is chosen as a candidate rationale
and st is computed by the multilevel heuristics. We represent it as c ∼ gen(x).

In contrast to Hsu et al. (2018) which uses an RNN model for Generator, we adopted a set of logistic
regression models with several feed-forward networks to facilitate the Generator. The reason being, an
RNN model can be difficult to train and might be susceptible to mode collapse if not carefully tuned.
In the Generator, the number of logistic regression models is equal to L which is the number of classes
in y. Each word in the sentence is first moderated by the Entity heuristic he, which is obtained from
the target entities and fed through the logistic regression models to obtain the Word heuristic hw ={
{hwlt}

L
l=1

}T
t=1

. Each hwlt can be considered as a probability of xt being chosen as a rationale if the

given sentence is of relation class l. The second step is to compute the Relation heuristic hr = {hrl}Ll=1
and the Syntax heuristic hst that are applied to the Word heuristic. The Relation heuristic initializes the
relation with a random guess using the whole sentence. The heuristic is then trained through a CNN
model which similar to the CNN model we used to compute V x. The Syntax heuristic hst is obtained
from a feed forward neural network that takes as input (1) word distance to target entities, and (2) Part of
Speech (POS) tags. The output, slocalt , is obtained by combining the Word, Entity, Syntax and Relation
heuristics, and it represents local sentence information score.

The final score st is then computed by applying the Corpus and Rationale heuristics to slocalt . The
Corpus heuristic hc = {hcl}Ll=1 contains binary values computed by sorting and selecting the frequent
K words in each relation class in the training set. The Rationale heuristic hra = {hral}Ll=1 also contains
binary values which are based on taking the top portion of the Word heuristic for each relation class, but
the Word heuristic considered here is not moderated by entities when computing the Rationale heuristic.
The Corpus and Rationale heuristics capture the association between the words and relations are in
the dataset. To leverage this information, we construct a global heuristic, sglobalt , by computing an
element-wise multiplication of hc and hra. Note that sglobalt can be seen as a self-learning resource for
semi-supervised learning because the Rationale heuristic is based on the results from previous iterations.



1150

Accordingly, sglobalt will not be used in testing and will only be included after several training iterations
have completed. Finally, before applying sglobalt to the final score st we apply a dynamically computed
weight factor CR to slocalt and s

global
t . We formulate all the heuristics in the following equation,

he = sigmoid(Whe · [e1, e2] + bhe)
hwt = sigmoid(Whw · (xt � he) + bhe)
hr = CNN(x)

hst = sigmoid(Whs · [POSt, positiont])
CR = sigomid(WCR · hr′ + bCR)

slocalt = hwt · T (hr) · hs
(T stands for transpose function)

sglobalt = hc� hra

st = st · (1− CR) + sglobalt CR

(3)

In the most simplistic Generator, the probability that xt is chosen is conditionally independent of all
other x. In other words, we can sample candidate c from a uniform distribution using the probability
scores, s. However, we observe that the target rationales in the dataset often consist of few words - for
example “room inside apartment”. Therefore, we added the following Equation (4) to limit the number
of rationales selected, c, to be at most J .

ct =

{
1, sort({(st > rand(0, 1)) · st}Tt=1)[1 : J ]
0, otherwise

(4)

c = {ct}Tt=1

4.3 Selector

The last component of the model is the Selector sel(c), where the goal of the Selector is to decide the
number of rationales best suited for the prediction. The Selector is facilitated by a simple feed-forward
network that outputs a number from 1 ∼ J by scoring rationale sets of length ranging from 1 ∼ J based
on the top ranked st ∗ ct. During training, all rationale sets will be forwarded to the Encoder, and the
training label for Selector will be the size of the set that obtains the least training loss in Encoder. This
Selector is identical to the one in Hsu et al. (2018) and is defined as follows:

ĉjt =

{
1, sort({ct · st}Tt=1)[1 : j], j ∈ [1 : J ]
0, otherwise

ĉj = {ĉjt}
T

t=1,where ĉ
j
t = 1

score(ĉj) =Wc · enc(ĉj ,x, e1, e2)

scoresj = softmax({score(ĉj)}Jj=1)j

ˆscoresj =

{
1 , j = argmax(scores)

0 , otherwise

r = {xt},where ĉjt = 1, j = argmax(scores)
(5)

4.4 Joint Objective and Adversarial Training

We formulate the joint loss function in the following to bind the components.
As described earlier, the goal of the Generator and the Selector is not to emulate x with r due to the

nature of this research. In effect, the Generator and the Selector are not competing against the Encoder,
but instead with an adversary Generator, for which we use a randomized approach. The adversary Gen-
erator will sample c̃ randomly from x. The adversary rationales r̃ will then be selected using c̃ as per
Equation (4). r̃ will be passed to the Encoder to generate a projection ỹ onto the target dimension. We
compare ỹ with ŷ in terms of their similarity to y and is denoted by D ∈ {0, 1}. D = 1 when ŷ is
closer to y compared to ỹ, and is noted as a ‘model success case’, meanwhile 1−D = 1 for the opposite
situation and is noted as an ‘adversary success case’. The objective for the Generator and Encoder reacts
differently to the two different cases, where the Encoder optimize whichever rationales that performs
better, and the Generator rewards the selected rationales in model success case and penalize in the other
case. We further split ŷ, ỹ andD into ŷj , ỹj ,Dj and j ∈ [1 : J ], whereDj represents that ŷj outperforms
ỹj when using j rationales. Finally, we introduce a penalizing factor P j when j 6= argmax(scores) to
penalize the gradients from poor performing cases. We summarize as follows:



1151

f(s
′jl
t ) = −log(s

′jl
t ) · c

j
t · yi+

− log(1− s
′jl
t ) · c

j
t · (1− yi)

f(cjt ) = −log(st) · c
j
t − log(1− st) · (1− c

j
t )

fy(ŷ
j
i ) = −yi · log(ŷ

j
i )

Lenc =
J∑
j=1

P j
[
Djfy(ŷj) + (1−Dj)fy(ỹj)

]

Lsel =
J∑
j=1

−Dj ∗ ˆscoresj ∗ log(scoresj)

Lgen =
J∑
j=1

T∑
t=1

[
Djf(ĉjt )− (1−Dj)f(c̃

j
t )

]
+

J∑
j=1

T∑
t=1

L∑
l=1

[
Djf(ŝjlt )− (1−Dj)f(s̃

jl
t )

]
(6)

The final joint objective and the expected cost is defined as:

L(r,x, e1, e2, y) = Lgen + Lsel + Lenc

min
θeθgθs

∑
(x,e1,e2,y)∈N

Er∼sel(c),c∼gen(x)L(r,x, e1, e2, y) (7)

where θe, θg, θs are the parameters used in the Encoder, Generator and Selector respectively.

5 Experiments

5.1 Dataset

We evaluate our approach by performing experiments on the SemEval 2010 Task 8 dataset. A collection
of sentences is provided with marked target entities and ground-truth for the relation between the entities.

The dataset contains 10,717 sentences, where 8000 entries are used in training. There are 9 types
of relationships plus an “Other” class (Table 1). Relationship types (except for “Other”) are expressed
bi-directionally, making 19 classes in total. Following SemEval 2010’s protocol, we used the macro-F1
metric in the experiment, excluding all cases of the “Other” class.

Besides the original SemEval 2010 Task 8 data, we asked 3 human annotators to label rationales used
in the test set. Annotators were asked to choose 0-3 rationales for each test sentence based on their
intuition. Each annotator is asked to roughly annotate one-third of the test set. Distribution of rationales
are as follows: no-rationales:2%, 1-rationale:57%, 2-rationales:38% and 3-rationales:2%. Note that we
did not annotated the training set.

Cause-Effect Component-Whole Content-Container
Entity-Destination Entity-Origin Instrument-Agency
Member-Collection Message-Topic Product-Producer

Table 1: Relation classes in SemEval 2010 task 8

5.2 Experimental Setup

We now describe in detail the parameters used in our experiments. We initialize the word vectors with
the GoogleNews2 corpus. The CNN filter size was initialized to 50. We use at most 3 rationales and set
the penalizing factor Pj to 0.1 based on our analysis of the training set. Due to the lack of sufficient sam-
ples in certain relation classes, we ignored the relationship directionality while computing the Relation
heuristic. Finally, the dimensionality of the POS tag vectors and the position vectors is set to 25, and the
Generator is set to ignore nouns, articles and adjectives.

2https://code.google.com/p/word2vec



1152

Finally, after training for 10 iterations, the Generator includes the output from the Corpus and Ratio-
nale heuristics. TheK frequently used words in the Corpus heuristic are computed for each relation class,
where the threshold for Kl is 10% of number of sentences of the given l relation class. The Rationale
heuristic selects the top 25% of words, hwl, output by the Word heuristic.

We used the Adagrad optimizer in our experiments and the learning rate is initialized to 0.01, and
reduces by 10% after every iteration. During each training iteration, we sample 25 times from the
Generator, and re-sample 25 times when training the Selector and the Encoder.

5.3 Results

We present a comparison of relation classification between our model and the state-of-the-art models in
Table 2. Dependency tree models are neural network models that work with word dependency tree parsed
by a grammar parser. Each model utilizes the dependency tree differently. For instance MVRNN (Socher
et al., 2012) uses the whole dependency tree, while SPTree (Miwa and Bansal, 2016) experiments using
the entire tree and the nodes on the path that connect the target entities. We refer to the models that do
not use a dependency tree as independent models.

Classifier F1
Manually Engineered Models
SVM(Rink and Harabagiu, 2010) 82.2
Dependency Tree Models
RNN (Socher et al., 2012) 77.6
MVRNN (Socher et al., 2012) 82.4
FCM (Yu et al., 2014) 83.0
Hybrid FCM (Gormley et al., 2015) 83.4
DepNN (Liu et al., 2015) 83.6
DRNNs (Xu et al., 2015) 85.6
SPTree (Miwa and Bansal, 2016) 84.5

Classifier F1
Independent Models
CNN & softmax (Zeng et al., 2014) 82.7
Stackforward(Nguyen and Grishman, 2015) 83.4
Vote-bidirect (Nguyen and Grishman, 2015) 84.1
Vote-backward (Nguyen and Grishman, 2015) 84.1
ATT-Input-CNN (Wang et al., 2016) 87.5
ATT-Pooling-CNN (Wang et al., 2016) 88.0
Rationale Models
Proxy-Rationale-1(Hsu et al., 2018) 84.5
Proxy-Rationale-2(Hsu et al., 2018) 85.3
Proxy-Rationale-3(Hsu et al., 2018) 87.8
GAN(Hsu et al., 2018) 89.5
Our Model 90.7

Table 2: Comparisons with benchmarking models

Table 3, presents a detailed comparison between the different variations of our model and other
rationale-based models. We evaluate the rationale quality using macro-F1, where precision and recall
are computed by taking the intersection between the generated and the manually labeled rationales.

Rationale Models Relation F1 Rationale F1
Proxy-Rationale-1(Hsu et al., 2018) 84.5 6.3
Proxy-Rationale-2(Hsu et al., 2018) 85.3 22.2
Proxy-Rationale-3(Hsu et al., 2018) 87.8 26.1
GAN(Hsu et al., 2018) 89.5 33.2
Our Model prior global heuristics sglobal 89.5 37.1
Our Model after global heuristics sglobal 90.7 53.2

Table 3: Comparisons between variations and with rationale models

Finally, we summarize a few samples of rationales chosen from the test set in Table 4. We observe
that the extracted rationales are similar to the rationales chosen manually and they can be used to infer
the relationship between entities.



1153

Relation Class Selected rationales with target entities

Cause-Effect
dipse1 caused by ... y-rayse2, livere1 ... cause ... hypertensione2
plaintiffse1 ...resulting from ... explosione2 , storme1 generated by ... colde2

Component-Whole
sitee1 is part of ... networke2 , cabinete1 encloses ... woofere2,
laddere1 comprises ... stepse2 , crocodilee1 has ... snout e2

Content-Container
gunse1 are locked in safee2, grenadee1 hidden inside canistere2
spidere1 was contained in ... boxe2, suitcasee1 full ... bookse2

Entity-Destination
weaponse1 ... delivered to ... navye2, moneye1 ... into ... custodye1
childrene1 were handed over to relativese2, watere1 ... been poured into ... rivere2

Entity-Origin
squirrele1 popped out of ... shirte2, robberse1 ... away from scenee2
gasese1 emanated from ... sourcese2, starche1 is source of sugarse2

Instrument-Agency
mechanice1 tightens ... with spannere2, intellecte1 wields pene2
projecte1 uses arte2 as instrument, gives ... best practicese1 for programmerse2

Member-Collection
bloate1 of hippopotamusese2, formatione1 comprised of ... dragoonse2
surgeone1 is part of the teame2 , sergeante1 in armye2

Message-Topic
caveatse1 outlined ... e-maile2, speeche1 ... about conversatione2
speeche1 was summary of ... problemse2, parameterse1 described texte2

Product-Producer
production materialse1 by industriese2 , productse1 grown by ... defendante2
engineerse1 ... devised ... methode2, investment firme1 co-founded by ... heade2

Table 4: List of words/phrases that are selected as rationales in test set by our model. Additional words
are denoted as ... if they are located between entities and rationales but are not selected as rationales.

6 Discussion and Future Goals

6.1 Logistic Regressions and RNN

The major difference between this work and the previous rationale-based research is that we designed
the Generator without a sequential RNN model. Specifically, we developed a layer by layer process
that considers different levels of text information for three reasons. First, in relation classification, the
excess sequential modeling power from RNN is not required since rationales are often an extremely small
span of words. Also, rationales are often strongly-related to POS tags which can be used to replace the
sequence information. Second, the purpose of rationales in relation classification is to augment features
and illuminate how the model derives the answer. This is different from other tasks like aspect-level
sentiment classification in Lei et al. (2016) where the rationales are treated as a compression of the
input. Although more empirical experiments are required, we hypothesize that this simpler multilevel
heuristic approach suits better for tasks with simpler rationales. Finally, dropping RNN can help the
model parallelize and also less prone to mode collapse and gradient vanishing.

6.2 Axillary Information

The improvement in rationale interpretability comes from regularizing the Generator through a wide set
of knowledge sources, like the Relation, the Corpus and the Rationale heuristic, and we believe this can
be further improved by including more knowledge sources. For example, the Entity heuristic can be
improved by annotating entities through a large open source data such Wikipedia, or the Corpus heuristic
can be more diverse with distant supervision tricks. However, the amount of axillary information to
include and to what degree is a challenge in itself.

Another major difference is that the Generator is directly related to the relation-labels through the
Relation and Word heuristics, which is different from Hsu et al. (2018) where the Generator is not aware
of the ground-truth. This can be a potential challenge when the diversity of relation vastly increases.
To be more specific, the number of relations in some knowledge graph population tasks can be more
than a few thousands, which can lead to severe label imbalance issues. Also, we notice several relation
classes share the same rationales, like ‘of’ is commonly seen in Member-Collection and Component-



1154

Whole relations. This can be unfavorable for the Word heuristic since our approach assumes rationales
are more heterogeneous than homogeneous between different relations. A potential solution is to cluster
or introduce hierarchical structures to the relations thereby reducing diversity.

6.3 Potential Applications: Noise-Reduction in Distant Supervision
A potential application of this work, besides classifying relations and providing interpretable results, is
to help reduce noise in distant supervision for relation classification. Distant supervision is a commonly
used approach in relation classification where producing ground-truth data is expensive. Distant super-
vision exploits a simple assumption: if a sentence s contains an entity-relation pair (e1, relation, e2)
that exists in a trustworthy knowledge source, then s can be a training data for the relation. As a result,
distant supervision often contains many noisy false-negative training samples and degrades the result.
To reduce the noise, one can penalize sentences that do not contain commonly used rationales for the
relation.

7 Conclusion

In this paper, we have proposed an improved rationale-based model for entity relation classification.
In our model, besides context word information, we also moderate rationale generation with multiple
heuristics computed from different text level features. With multilevel heuristics, we successfully reduce
the variability in the Generator to achieve meaningful rationales. Quantitative analysis demonstrates that
our model improves both classification performance and the rationale quality. Finally, we provide an
annotated test set for rationales, which can be used in future related research to evaluate rationales.

Acknowledgments

We thank the COLING reviewers for their detailed and insightful feedback, and also thank the annotators
for their intensive efforts for developing the annotated set. This material is based upon work supported
in whole or in part with funding from LAS. Any opinions, findings, conclusions, or recommendations
expressed in this material are those of the author(s) and do not necessarily reflect the views of the LAS
and/or any agency or entity of the United States Government.

References
Martin Arjovsky and Leon. Bottou. 2017. Towards principled methods for training generative adversarial net-

works. In arXiv preprint arXiv:1701.04862.

Martin Arjovsky, Soumith Chintala, and Leon. Bottou. 2017. Wasserstein gan. In arXiv preprint
arXiv:1701.07875, 2017.

Tong Che, Yanran Li, Athul Paul Jacob, Yoshua Bengio, and Wenjie. Li. 2017. Mode regularized generative
adversarial networks. In ICLR.

Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. 2016. Infogan: Inter-
pretable representation learning by information maximizing generative adversarial nets. In NIPS.

Bang Duhyeon and Shim Hyunjung. 2018. Improved training of generative adversarial networks using represen-
tative features. In arxiv: preprint arXiv:1801.09195.

Claudio Giuliano, Alberto Lavelli, and Lorenza Romano. 2006. Exploiting shallow linguistic information for
relation extraction from biomedical literature. In 11th Conference of the European Chapter of the Association
for Computational Linguistics.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville,
and Yoshua Bengio. 2014. Generative adversarial nets. In NIPS, pages 2672–2680.

Matthew R Gormley, Mo Yu, and Mark Dredze. 2015. Improved relation extraction with feature-rich composi-
tional embedding models. In EMNLP, pages 1774–1784.

Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron. Courville. 2017. Improved
training of wasserstein gans. In arXiv preprint arXiv:1704.00028.



1155

Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid Ó Séaghdha, Sebastian Padó, Marco
Pennacchiotti, Lorenza Romano, and Stan Szpakowicz. 2009. Semeval-2010 task 8: Multi-way classification
of semantic relations between pairs of nominals. In NAACL HLT, pages 94–99.

Shiou Tian Hsu, Changsung Moon, Paul Jones, and Nagiza Samatova. 2018. An interpretable generative adver-
sarial approach to classification of latent entity relations from unstructured sentences. In AAAI.

Yoon Kim. 2014. Convolutional neural networks for sentence classification. In EMNLP, pages 1746–1751.

Naveen Kodali, Jacob Abernethy, James Hays, and Zsolt. Kira. 2017. On convergence and stability of gans. In
arXiv preprint arXiv:1705.07215.

Tao Lei, Regina Barzilay, and Tommi Jaakkola. 2016. Rationalizing neural predictions. In EMNLP, pages 107–
117.

Yang Liu, Furu Wei, Sujian Li, Heng Ji, Ming Zhou, and Houfeng Wang. 2015. A dependency-based neural
network for relation classification. In ACL, pages 285–290.

Makoto Miwa and Mohit Bansal. 2016. End-to-end relation extraction using lstms on sequences and tree struc-
tures. In ACL, pages 1105–1116.

Thien Huu Nguyen and Ralph Grishman. 2015. Combining neural networks and log-linear models to improve
relation extraction. In IJCAI Workshop on Deep Learning for Artificial Intelligence (DLAI).

Feng Niu, Ce Zhang, Christopher Ré, and Jude W Shavlik. 2012. Deepdive: Web-scale knowledge-base construc-
tion using statistical learning and inference. VLDS, 12:25–28.

Bryan Rink and Sanda Harabagiu. 2010. Utd: Classifying semantic relations by combining lexical and semantic
resources. In SemEval, pages 256–259.

Kevin Roth, Aurelien Lucchi, Sebastian Nowozin, and Thomas Hofmann. 2017. Stabilizing training of generative
adversarial networks through regularization. In NIPS.

Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. 2016. Improved
techniques for training gans. In Advances in Neural Information Processing Systems (NIPS), pages 2234–2242.

Richard Socher, Brody Huval, Christopher D Manning, and Andrew Y Ng. 2012. Semantic compositionality
through recursive matrix-vector spaces. In EMNLP, pages 1201–1211.

Akash Srivastava, Lazar Valkov, Chris Russell, Michael U. Gutmann, and Charles Sutton. 2017. Veegan: Reduc-
ing mode collapse in gans using implicit variational learning. In NIPS.

Linlin Wang, Zhu Cao, Gerard de Melo, and Zhiyuan Liu. 2016. Relation classification via multi-level attention
cnns. In ACL, pages 1298–1307.

Kun Xu, Yansong Feng, Songfang Huang, and Dongyan Zhao. 2015. Semantic relation classification via convo-
lutional neural networks with simple negative sampling. In EMNLP, pages 536–540.

Mo Yu, Matthew Gormley, and Mark Dredze. 2014. Factor-based compositional embedding models. In NIPS,
pages 95–101.

Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. 2014. Relation classification via convolu-
tional deep neural network. In COLING, pages 2335–2344.

Ye Zhang, Iain Marshall, and Byron C Wallace. 2016. Rationale-augmented convolutional neural networks for
text classification. In EMNLP, pages 795–804.


