



















































Interaction Quality Estimation Using Long Short-Term Memories


Proceedings of the SIGDIAL 2017 Conference, pages 164–169,
Saarbrücken, Germany, 15-17 August 2017. c©2017 Association for Computational Linguistics

Interaction Quality Estimation Using Long Short-Term Memories

Niklas Rach1, Wolfgang Minker1, and Stefan Ultes2
1Institute of Communication Engineering, Ulm University

{vorname.nachname}@uni-ulm.de
2Department of Engineering, University of Cambridge, UK

su259@cam.ac.uk

Abstract

For estimating the Interaction Quality (IQ)
in Spoken Dialogue Systems (SDS), the
dialogue history is of significant impor-
tance. Previous works included this infor-
mation manually in the form of precom-
puted temporal features into the classifi-
cation process. Here, we employ a deep
learning architecture based on Long Short-
Term Memories (LSTM) to extract this
information automatically from the data,
thus estimating IQ solely by using cur-
rent exchange features. We show that it
is thereby possible to achieve competitive
results as in a scenario where manually
optimized temporal features have been in-
cluded.

1 Introduction

The increasing complexity of Spoken Dialogue
Systems (SDS) and the requirements that come
with this progress made automatized recognition
and modeling of user states crucial to ensure natu-
ral and user adaptive interaction. User Satisfac-
tion (US) is one important part of such a state.
On the dialogue level (i.e. after the interaction is
complete), it provides a measure for the interac-
tion and allows to compare different SDS (Walker
et al., 1997) or to learn appropriate dialogue strate-
gies (Walker, 2000; Ultes et al., 2017a). However,
if US is available in each turn, it can also be used
for user adaptation (Ultes et al., 2011, 2012, 2016,
2014a).

In the scope of this work we focus on the Inter-
action Quality (IQ) as a turn-wise approach to US
and propose a deep learning architecture to esti-
mate it solely using exchange parameters1. In do-
ing so, we show that with the proposed approach,

1An exchange is a system turn followed by a user turn.

manually optimized, pre-computed temporal in-
formation (as employed in previous work) is no
longer required.

Diverse approaches for estimating the US were
already proposed, including n-gram models (Hara
et al., 2010) and Hidden Markov Models (Hi-
gashinaka et al., 2010a; Engelbrech et al., 2009)
in different scenarios. Although the results were
above the random baseline, the respective im-
provement was only minor. As it was discussed by
Higashinaka et al. (2010b), one difficulty of this
task lies in the subjective nature of US since it de-
pends on the appreciation of the user.

IQ is a more objective approach to US that relies
on the rating of experts instead of users (Schmitt
and Ultes, 2015) and thus closes the gap between
subjective valuation and objective criteria. The re-
spective rating is given on a scale between 1 (ex-
tremely unsatisfied) and five (satisfied) after lis-
tening to audio records of the dialogue in ques-
tion. A detailed study on the correlation between
the IQ and a measure of the real US was provided
by Ultes et al. (2013) and various approaches
including Hidden Markov Models (Ultes et al.,
2014b; Ultes and Minker, 2014), Support Vector
Machines (Schmitt et al., 2011; Ultes and Minker,
2013), Ordinal Regression (El Asri et al., 2014)
and Recurrent Neural Networks (Pragst et al.,
2017) have been employed to estimate the IQ from
exchange parameters. Although the results show a
significant improvement to alternative approaches,
the classification relies in each case on precom-
puted features modeling the dialogue history (so
called temporal features).

Despite the good results, using temporal fea-
tures requires insight into the correlations between
the dialogue history and the IQ score as the time-
span covered by the temporal information signifi-
cantly influences the outcome (Ultes et al., 2017b).
The required knowledge about this correlation is

164



usually not accessible and likely to be domain de-
pendent thus rendering the respective approaches
inflexible. In contrast, we employ a deep learn-
ing classifier to extract the required temporal in-
formation automatically and show that in doing
so it is possible to achieve competitive results by
only using exchange level parameters. In addition,
we show that findings of previous works regard-
ing the optimal amount of temporal information to
be included may be retrieved in our approach by
slightly varying the input sequences. Finally, the
usability of our proposed architecture in real-life
scenarios is discussed by looking at the percent-
age of usable IQ guesses.

The remainder of this paper is as follows: In
Section 2 we discuss the LSTM based neural net-
work architecture followed by a discussion of the
employed data in Section 3. Section 4 presents the
experiments and results and we close with a brief
conclusion and outlook in Section 5.

2 LSTM-based Interaction Quality
Estimation

Recurrent Neural Networks (RNN) include tem-
poral correlations in the data into the classification
process and are thus suitable for sequential tasks
such as the one at hand. However, common ap-
proaches have shown to be inefficient in learning
long-term dependencies (Bengio et al., 1994) due
to a vanishing (or exploding) gradient. To tackle
this problem, Hochreiter et al. (1997) introduced
an architecture, called Long Short-Term Memory
(LSTM) that allows to preserve temporal informa-
tion, even if the correlated events are separated by
a longer time. Since previous works showed that
long time correlations are of importance for esti-
mating the IQ, we consider LSTM a suitable ap-
proach for the reviewed scenario.

The herein employed architecture is thus built
of a LSTM unit, consisting of two stacked LSTM
cells, followed by a two-layer perceptron unit with
sigmoid activation functions. The latter one is
given as

FMLP : yt → (g2 ◦ g1)(yt) (1)
gi(yt) = sigm(W Ti yt + bi) (2)

whereWi denotes the weight matrix, bi a bias vec-
tor and sigm the element-wise sigmoid function.
A LSTM cell on the other hand can be seen as
function

f : xt, ct−1, ht−1 → ht, ct (3)

with ht the output state, ct the internal cell state
and xt the input of the LSTM at time step t. In a
multilayer scenario, the input of a layer is the out-
put of the previous one. A deeper discussion of the
LSTM architecture including the respective for-
mulas is provided for example in (Zaremba et al.,
2014). The complete LSTM unit can thus be writ-
ten as a function FLSTM that processes a given
input through two LSTM layers and maps it to an
output state yt. Combining this description with
equation 1 yields

zt = (FMLP ◦ σ ◦ FLSTM )(xt) (4)

for the whole net with zt the final IQ mapping of
the input and σ the softmax normalization func-
tion. In the reviewed scenario, each LSTM layer
consisted of 48 nodes whereas the perceptron unit
had 48 nodes in the hidden layer and five nodes in
the output layer. Therefore, the two LSTM layers
are employed to extract the temporal information
whereas the following perceptron layers serve as
classifier that maps the output of the LSTM unit to
the respective IQ scale. The whole net is depicted
in Figure 1 and was implemented using Google’s
Tensorflow library (Abadi et al., 2016). Optimiza-
tion was done by use of the Adaptive Gradient Al-
gorithm (Duchi et al., 2011).

Figure 1: Sketch of the deep learning architec-
ture in use. The left part contains the two stacked
LSTM cells followed by a softmax normalization
unit. The output is fed into a two layer perceptron
with sigmoid activation functions.

3 The LEGO Corpus

To appropriately compare our results, we employ
the LEGO coprus (Schmitt et al., 2012)—the same
corpus as the authors of previous work. It is based
on the ”Let’s Go Bus Information System” of
the Carnegie Mellon university in Pittsburg (Raux
et al., 2006) and consists of 200 dialogues includ-
ing 4884 system-user exchanges. Each exchange
was assigned with features from three instances of

165



s1 u1 s2 u2 s3 u3 sn un…

e1 e2 e3 en

en… en-1en-2e1 e2 e3 en+1 … exchange level parameters

window level parameters: {#}, {Mean}, etc.

dialogue level parameters: #, Mean, etc.

Figure 2: The three parameter levels including the temporal features of the window and the dialogue
level (Schmitt et al., 2012).

the SDS, namely the Automatic Speech Recog-
nition (ASR), Natural Language Understanding
(NLU) and the Dialogue Manager (DM). Further-
more, the corpus was annotated with an IQ rat-
ing by three experts following specific guidelines
to achieve an objective measure (Schmitt et al.,
2011). In doing so, an inter-annotator agreement
of κ = 0.54 was achieved. For the final IQ score,
the median of all three ratings was taken. To in-
clude temporal features into the corpus, three dif-
ferent interaction levels that are depicted in Fig-
ure 2 were considered:

• The exchange level contains all features re-
garding the current system-user exchange.

• The window level includes counts and means
of numerical exchange level features from the
previous n exchanges, where n is referred to
as window size.

• The dialogue level contains counts and means
of numerical exchange level features from all
previous exchanges.

The term temporal features thus refers to features
of the window and dialogue level. The influence
of these two additional levels as well as the choice
of n on the automatized estimation of the IQ were
studied (Ultes et al., 2017b) and serve as a baseline
for this work.

4 Experiments and Results

In this section we discuss the results of the em-
ployed classifier in estimating the IQ for the anno-
tated LEGO corpus. To distinguish the contribu-
tion of the parameters derived from different SDS
instances to the IQ, three feature sets were em-
ployed that consisted of features assigned to the
ASR, the DM and both:

ASR: ASRRecognitionStatus (string, status of the
ASR), Modality (string, input modality of
the user, either speech or dtmf ), ExMo

(string, expected modality of the user in-
put, either speech, dtmf, both or none), AS-
RConfidence (float, confidence score of the
ASR), Barged-In? (boolean, true if sys-
tem was interrupted by the user), UnExMo?
(boolean, true if the actual input modality
did not match the expected one), WPUT (in-
teger, words per user turn), UTD (float, ut-
terance turn duration)

DM: ActivityType (string, type of activity), Role-
Name (string, function of the system turn),
RePromt? (boolean, true if the current turn
is a repromt), WPST (integer, words per
system turn), DD (float, dialogue duration),
RoleIndex (integer, tries necessary to get a
desired response from the user)

Parameters that are either constant or task-related
were discarded, including the two features from
the NLU. To represent all parameters as a numer-
ical input vector, non-numerical features were en-
coded in a one-hot vector. As in previous work, we
used 10-fold cross validation to evaluate the out-
comes. The results are compared in terms of Un-
weighted Average Recall2 (UAR), Cohen’s (lin-
early weighted) Kappa (Cohen, 1968) and Spear-
man’s Rho (Spearman, 1904) to the ones achieved
by Ultes et al. (2017b) with the best window size
n = 9, the full feature set and a Support Vector
Machine (SVM). Our results as well as the base-
line value are shown in Table 1. For all three
measures, the results with the full feature set are
competitive to the baseline. Whereas the UAR is
slightly below the reference value, κ and ρ show
a small improvement. The results for the two sub-
sets are visibly below the baseline for both UAR
and κ whereas the DM value of ρ equals the re-
spective reference value. Moreover, the DM fea-
tures yield better results than the ASR features
and thus contribute more to the overall IQ value,

2The arithmetic average of all class-wise recalls.

166



features #TF UAR κ ρ

LSTM ASR+DM 0 0.548 0.684 0.832

LSTM ASR 0 0.502 0.636 0.796
LSTM DM 0 0.516 0.654 0.812

SVM ASR+DM 25 0.549 0.679 0.812

Table 1: The results of the LSTM approach
in comparison to the SVM baseline (Ultes et al.,
2017b), including the number of handcrafted tem-
poral features in use (#TF) for each scenario.

which is in line with the outcomes of previous
work (Ultes et al., 2015). It is stressed that none of
the feature sets employed for the LSTM uses hand-
crafted temporal features nor needs them. Thus,
we conclude that our approach is indeed capa-
ble of extracting the required temporal informa-
tion automatically.

In addition, we investigate the temporal infor-
mation extracted by the trained classifier by mea-
suring the impact of one system-user exchange
on following estimates. This allows a compari-
son of the extracted information in the herein dis-
cussed scenario with the manually set window size
in previous work. To this end, we replaced the
input vector of the second system-user exchange
e2 in each dialogue Di = (ei1, e

i
2, .., e

i
L) of the

corpus {D1, ..., DM} by the input associated with
one out of 20 randomly picked exchanges ejr (j ∈
{1, . . . ,M}) with assigned IQ value of 1. The
modified dialogues

D̃i = (ei1, e
j
r, ..., e

i
L) (5)

were then fed through a trained model of the 10-
fold cross validation and the results were com-
pared to the ones achieved with the original data
by computing the sum of the absolute errors of
each class. This was repeated for all 20 random
picks and all 10 models (we employed different
random picks for each model). The mean of this
error over all dialogues, all trained models and all
random picks for the replaced exchange was de-
termined and is shown as a function of the system-
user exchange number in Figure 3. This error indi-
cates the impact one exchange has on the IQ esti-
mate of following exchanges. We see that from
exchange number 9 to exchange number 12 the
error clearly decreases. A comparison with the
referenced work shows that this drop is in the
same range as the optimal window size n = 9
(that would correspond to exchange number 11).

0.3

0.5

0.7

0 5 10 15 20

err

#ex

Figure 3: Mean error caused by the replacement
of the second system-user exchange by a random
picked exchange as a function of the exchange
number.

Therefore the impact of the exchange in question
is decreased in the same range as in a scenario
were this impact is controlled manually. This in-
dicates that similar temporal information that was
employed therein is automatically extracted by our
architecture.

In many classification scenarios, the classes are
not ordered which means that in the case of a
wrong guess it is irrelevant which class was cho-
sen. However, as the IQ is an ordered scale, the
distance of the wrong guess to the real class is
of interest, especially in view of the application.
We therefore compute the amount of guesses in
which the classification was wrong only by one
point (e.g. an instant of IQ 1 classified as IQ 2
or vice versa). This percentage δ can be derived
directly from the confusion matrix C as

δ =
1
N

(
K−1∑
k=1

Ck,k+1 +
K∑

k=2

Ck,k−1) (6)

with N the number of total entries of C and K
the number of classes, i.e. the dimension of C.
Adding this value to the Accuracy (ACC) gives a
percentage of usable guesses of the classifier. The
results for the architecture used in this work and
the best feature set (ASR + DM) are ACC=0.57
and δ=0.37, resulting in a sum of 0.94. In other
words, considering a real-life scenario, 94% of the
classifiers guesses could be used, for example for
user adaptation. Again, these results are compared
to the ones achieved with a SVM and the setup
of (Ultes et al., 2017b) with a sum of 0.91. Evi-
dently, the deep learning classifier outperforms the
SVM approach in this metric.

5 Conclusion and Outlook

In this work, we investigated the estimation of the
IQ with a deep learning classifier by only using ex-

167



change level parameters. It was shown that by use
of the presented architecture, precomputed tempo-
ral features are no longer required and the IQ can
be estimated with an UAR of 0.548. The results
are competitive to the ones achieved with a SVM
classifier and the whole feature set in earlier work.
In addition, we compared the temporal informa-
tion extracted by the classifier with the optimal
window size from previous work and showed that
our results match previous findings. Finally, the
usability of the employed classifier in applications
was discussed by computing the percentage of us-
able guesses in such a case. The result of 94% is
below the outcome of the 0.91 achieved with the
SVM and a complete feature set. Moreover, since
our approach does not require any domain depen-
dent information, it is much more flexible.

It is reasonable to assume that the difficulty of
estimating the interaction quality and the amount
of temporal information that is required rely on the
complexity of the system and the interaction. Al-
though the herein presented slot filling dialogue is
comparatively basic, the IQ is influenced not only
by technical aspects (e.g., the quality of the speech
recognition) but also by the ability of the system to
react appropriately. This influence is even stronger
in more advanced tasks, where the user satisfac-
tion (and thus the IQ as well) may also depend on
the ability of the system to appropriately react on
the users state including for example emotions and
culture. Although this task differs from the one
addressed here, we assume the presented architec-
ture to be a good starting point for these scenarios
as well due to its above discussed flexibility.

Thus, for future work the performance of this
architecture in different scenarios and systems will
be of interest, especially in systems were the IQ
depends on additional aspects. Moreover, apply-
ing the presented architecture to estimate other
user states or features used for user adaptation is
also in the focus of future work.

Acknowledgments

This work is part of a project that has received
funding from the European Unions Horizon 2020
research and innovation programme under grant
agreement No 645012.

References
Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene

Brevdo, Zhifeng Chen, Craig Citro, Greg S Corrado,

Andy Davis, Jeffrey Dean, Matthieu Devin, et al.
2016. Tensorflow: Large-scale machine learning on
heterogeneous distributed systems. arXiv preprint
arXiv:1603.04467 .

Yoshua Bengio, Patrice Simard, and Paolo Frasconi.
1994. Learning long-term dependencies with gradi-
ent descent is difficult. IEEE transactions on neural
networks 5(2):157–166.

Jacob Cohen. 1968. Weighted kappa: Nominal scale
agreement provision for scaled disagreement or par-
tial credit. Psychological bulletin 70(4):213.

John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. Journal of Machine
Learning Research 12(Jul):2121–2159.

Layla El Asri, Hatim Khouzaimi, Romain Laroche, and
Olivier Pietquin. 2014. Ordinal regression for in-
teraction quality prediction. In International Con-
ference on Acoustics, Speech and Signal Processing
(ICASSP). IEEE, pages 3245–3249.

Klaus-Peter Engelbrech, Florian Gödde, Felix Hartard,
Hamed Ketabdar, and Sebastian Möller. 2009. Mod-
eling user satisfaction with Hidden Markov Model.
Proceedings of the SIGDIAL 2009 Conference: The
10th Annual Meeting of the Special Interest Group
on Discourse and Dialogue (September):170–177.

Sunao Hara, Norihide Kitaoka, and Kazuya Takeda.
2010. Estimation method of user satisfaction using
n-gram-based dialog history model for spoken dia-
log system. In LREC.

Ryuichiro Higashinaka, Yasuhiro Minami, Kohji
Dohsaka, and Toyomi Meguro. 2010a. Modeling
user satisfaction transitions in dialogues from over-
all ratings. In Proceedings of the 11th Annual Meet-
ing of the Special Interest Group on Discourse and
Dialogue. Association for Computational Linguis-
tics, pages 18–27.

Ryuichiro Higashinaka, Yasuhiro Minami, Kohji
Dohsaka, and Toyomi Meguro. 2010b. Model-
ing User Satisfaction Transitions in Dialogues from
Overall Ratings. Proceedings of the 11th Annual
Meeting of the Special Interest Group on Discourse
and Dialogue pages 18–27.

Sepp Hochreiter and Jürgen Schmidhuber. 1997.
Long short-term memory. Neural computation
9(8):1735–1780.

Louisa Pragst, Stefan Ultes, and Wolfgang Minker.
2017. Recurrent neural network interaction qual-
ity estimation. In Kristiina Jokinen and Graham
Wilcock, editors, Dialogues with Social Robots: En-
ablements, Analyses, and Evaluation, Springer Sin-
gapore, Singapore, pages 381–393.

Antoine Raux, Dan Bohus, Brian Langner, Alan W
Black, and Maxine Eskenazi. 2006. Doing research
on a deployed spoken dialogue system: one year of
let’s go! experience. In INTERSPEECH.

168



Alexander Schmitt, Benjamin Schatz, and Wolfgang
Minker. 2011. Modeling and predicting quality in
spoken human-computer interaction. Proceedings
of the SIGDIAL 2011 Conference pages 173–184.

Alexander Schmitt and Stefan Ultes. 2015. Interaction
quality: assessing the quality of ongoing spoken di-
alog interaction by expertsand how it relates to user
satisfaction. Speech Communication 74:12–36.

Alexander Schmitt, Stefan Ultes, and Wolfgang
Minker. 2012. A parameterized and annotated spo-
ken dialog corpus of the cmu let’s go bus infor-
mation system. In International Conference on
Language Resources and Evaluation (LREC). pages
3369–337.

Charles Spearman. 1904. The proof and measurement
of association between two things. The American
journal of psychology 15(1):72–101.

Stefan Ultes, Hüseyin Dikme, and Wolfgang Minker.
2014a. First insight into quality-adaptive dialogue.
In International Conference on Language Resources
and Evaluation (LREC). pages 246–251.

Stefan Ultes, Hüseyin Dikme, and Wolfgang Minker.
2016. Dialogue Management for User-Centered
Adaptive Dialogue. In Alexander I. Rudnicky, An-
toine Raux, Ian Lane, and Teruhisa Misu, editors,
Situated Dialog in Speech-Based Human-Computer
Interaction, Springer International Publishing,
Cham, pages 51–61. https://doi.org/10.1007/978-3-
319-21834-2 5.

Stefan Ultes, Robert ElChab, and Wolfgang Minker.
2014b. Application and evaluation of a condi-
tioned hidden markov model for estimating interac-
tion quality of spoken dialogue systems. In Natu-
ral Interaction with Robots, Knowbots and Smart-
phones, Springer, pages 303–312.

Stefan Ultes, Tobias Heinroth, Alexander Schmitt, and
Wolfgang Minker. 2011. A theoretical framework
for a user-centered spoken dialog manager. In
Ramón López-Cózar and Tetsunori Kobayashi, ed-
itors, Proceedings of the Paralinguistic Informa-
tion and its Integration in Spoken Dialogue Sys-
tems Workshop. Springer New York, New York,
NY, pages 241–246. https://doi.org/10.1007/978-1-
4614-1335-6 24.

Stefan Ultes, Juliana Miehle, and Wolfgang Minker.
2017a. On the applicability of a user satisfaction-
based reward for dialogue policy learning. In Pro-
ceedings of the 8th International Workshop On Spo-
ken Dialogue Systems (IWSDS).

Stefan Ultes and Wolfgang Minker. 2013. Improving
Interaction Quality Recognition Using Error Correc-
tion. Proceedings of the SIGDIAL 2013 Conference
(August):122–126.

Stefan Ultes and Wolfgang Minker. 2014. Interaction
quality estimation in spoken dialogue systems using
hybrid-hmms. In Proceedings of the 15th Annual

Meeting of the Special Interest Group on Discourse
and Dialogue (SIGDIAL). Association for Compu-
tational Linguistics, pages 208–217.

Stefan Ultes, Marı́a Jesús Platero Sánchez, Alexander
Schmitt, and Wolfgang Minker. 2015. Analysis of
an extended interaction quality corpus. In Natural
Language Dialog Systems and Intelligent Assistants,
Springer, pages 41–52.

Stefan Ultes, Alexander Schmitt, and Wolfgang
Minker. 2012. Towards quality-adaptive spoken
dialogue management. In NAACL-HLT Work-
shop on Future directions and needs in the
Spoken Dialog Community: Tools and Data
(SDCTD 2012). Association for Computational
Linguistics, Montréal, Canada, pages 49–52.
http://www.aclweb.org/anthology/W12-1819.

Stefan Ultes, Alexander Schmitt, and Wolfgang
Minker. 2013. On Quality Ratings for Spoken Di-
alogue Systems – Experts vs. Users. Proceedings of
the 2013 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies (June):569–578.

Stefan Ultes, Alexander Schmitt, and Wolfgang
Minker. 2017b. Analysis of temporal features for
interaction quality estimation. In Dialogues with So-
cial Robots, Springer, pages 367–379.

Marilyn Walker. 2000. An application of reinforce-
ment learning to dialogue strategy selection in a spo-
ken dialogue system for email. Journal of Artificial
Intelligence Research 12:387–416.

Marilyn A. Walker, Diane J. Litman, Candace A.
Kamm, Alicia Abella, Marilyn A. Walker, Diane J.
Litman, Candace A. Kamm, and Alicia Abella.
1997. Paradise. Proceedings of the eighth con-
ference on European chapter of the Association
for Computational Linguistics - pages 271–280.
https://doi.org/10.3115/979617.979652.

Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals.
2014. Recurrent neural network regularization.
arXiv preprint arXiv:1409.2329 .

169


