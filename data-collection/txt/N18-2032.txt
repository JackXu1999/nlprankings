



















































Introducing Two Vietnamese Datasets for Evaluating Semantic Models of (Dis-)Similarity and Relatedness


Proceedings of NAACL-HLT 2018, pages 199–205
New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics

Introducing two Vietnamese Datasets for Evaluating Semantic Models of
(Dis-)Similarity and Relatedness

Kim Anh Nguyen and Sabine Schulte im Walde and Ngoc Thang Vu
Institut für Maschinelle Sprachverarbeitung

Universität Stuttgart
Pfaffenwaldring 5B, 70569 Stuttgart, Germany

{nguyenkh,schulte,thangvu}@ims.uni-stuttgart.de

Abstract
We present two novel datasets for the low-
resource language Vietnamese to assess mod-
els of semantic similarity: ViCon comprises
pairs of synonyms and antonyms across word
classes, thus offering data to distinguish be-
tween similarity and dissimilarity. ViSim-400
provides degrees of similarity across five se-
mantic relations, as rated by human judges.
The two datasets are verified through stan-
dard co-occurrence and neural network mod-
els, showing results comparable to the respec-
tive English datasets.

1 Introduction

Computational models that distinguish between
semantic similarity and semantic relatedness (Bu-
danitsky and Hirst, 2006) are important for many
NLP applications, such as the automatic genera-
tion of dictionaries, thesauri, and ontologies (Bie-
mann, 2005; Cimiano et al., 2005; Li et al., 2006),
and machine translation (He et al., 2008; Mar-
ton et al., 2009). In order to evaluate these mod-
els, gold standard resources with word pairs have
to be collected (typically across semantic rela-
tions such as synonymy, hypernymy, antonymy,
co-hyponymy, meronomy, etc.) and annotated for
their degree of similarity via human judgements.

The most prominent examples of gold standard
similarity resources for English are the Ruben-
stein & Goodenough (RG) dataset (Rubenstein
and Goodenough, 1965), the TOEFL test ques-
tions (Landauer and Dumais, 1997), WordSim-
353 (Finkelstein et al., 2001), MEN (Bruni et al.,
2012), SimLex-999 (Hill et al., 2015), and the lex-
ical contrast datasets by (Nguyen et al., 2016a,
2017). For other languages, resource examples
are the translation of the RG dataset to German
(Gurevych, 2005), the German dataset of paradig-
matic relations (Scheible and Schulte im Walde,

2014), and the translation of WordSim-353 and
SimLex-999 to German, Italian and Russian (Le-
viant and Reichart, 2015). However, for low-
resource languages there is still a lack of such
datasets, which we aim to fill for Vietnamese, a
language without morphological marking such as
case, gender, number, and tense, thus differing
strongly from Western European languages.

We introduce two novel datasets for Viet-
namese: a dataset of lexical contrast pairs ViCon
to distinguish between similarity (synonymy) and
dissimilarity (antonymy), and a dataset of seman-
tic relation pairs ViSim-400 to reflect the contin-
uum between similarity and relatedness. The two
datasets are publicly available.1 Moreover, we ver-
ify our novel datasets through standard and neural
co-occurrence models, in order to show that we
obtain a similar behaviour as for the correspond-
ing English datasets SimLex-999 (Hill et al., 2015),
and the lexical contrast dataset (henceforth Lex-
Con), cf. Nguyen et al. (2016a).

2 Related Work

Over the years a number of datasets have been col-
lected for studying and evaluating semantic sim-
ilarity and semantic relatedness. For English,
Rubenstein and Goodenough (1965) presented a
small dataset (RG) of 65 noun pairs. For each pair,
the degree of similarity in meaning was provided
by 15 raters. The RG dataset is assumed to re-
flect similarity rather than relatedness. Finkelstein
et al. (2001) created a set of 353 English noun-
noun pairs (WordSim-353)2, where each pair was
rated by 16 subjects according to the degree of
semantic relatedness on a scale from 0 to 10.
Bruni et al. (2012) introduced a large test collec-

1
www.ims.uni-stuttgart.de/data/vnese_sem_datasets

2
www.cs.technion.ac.il/˜gabr/resources/data/

wordsim353

199



tion called MEN3. Similar to WordSim-353, the
authors refer to both similarity and relatedness
when describing the MEN dataset, although the
annotators were asked to rate the pairs accord-
ing to relatedness. Unlikely the construction of
the RG and WordSim-353 datasets, each pair in
the MEN dataset was only evaluated by one rater
who ranked it for relatedness relative to 50 other
pairs in the dataset. Recently, Hill et al. (2015)
presented SimLex-999, a gold standard resource
for the evaluation of semantic representations con-
taining similarity ratings of word pairs across dif-
ferent part-of-speech categories and concreteness
levels. The construction of SimLex-999 was mo-
tivated by two factors, (i) to consistently quantify
similarity, as distinct from association, and apply
it to various concept types, based on minimal in-
tuitive instructions, and (ii) to have room for the
improvement of state-of-the-art models which had
reached or surpassed the human agreement ceiling
on WordSim-353 and MEN, the most popular ex-
isting gold standards, as well as on RG. Scheible
and Schulte im Walde (2014) presented a collec-
tion of semantically related word pairs for Ger-
man and English,4 which was compiled via Ama-
zon Mechanical Turk (AMT)5 human judgement
experiments and comprises (i) a selection of tar-
gets across word classes balanced for semantic
category, polysemy, and corpus frequency, (ii) a
set of human-generated semantically related word
pairs (synonyms, antonyms, hypernyms) based on
the target units, and (iii) a subset of the generated
word pairs rated for their relation strength, includ-
ing positive and negative relation evidence.

For other languages, only a few gold standard
sets with scored word pairs exist. Among oth-
ers, Gurevych (2005) replicated Rubenstein and
Goodenough’s experiments after translating the
original 65 word pairs into German. In later
work, Gurevych (2006) used the same experimen-
tal setup to increase the number of word pairs to
350. Leviant and Reichart (2015) translated two
prominent evaluation sets, WordSim-353 (associ-
ation) and SimLex-999 (similarity) from English
to Italian, German and Russian, and collected the
scores for each dataset from the respective native
speakers via crowdflower6.

3
clic.cimec.unitn.it/˜elia.bruni/MEN

4
www.ims.uni-stuttgart.de/data/sem-rel-database/

5
www.mturk.com

6
www.crowdflower.com/

3 Dataset Design

3.1 Criteria

Semantic similarity is a narrower concept than
semantic relatedness and holds between lexical
terms with similar meanings. Strong similarity is
typically observed for the lexical relations of syn-
onymy and co-hyponymy. For example, in Viet-
namese “đội” (team) and “nhóm” (group) repre-
sents a synonym pair; “ô_tô” (car) and “xe_đạp”
(bike) is a co-hyponymy pair. More specifi-
cally, words in the pair “ô_tô” (car) and “xe_đạp”
(bike) share several features such as physical (e.g.
bánh_xe / wheels) and functional (e.g. vận_tải
/ transport), so that the two Vietnamese words
are interchangeable regarding the kinds of trans-
portation. The concept of semantic relatedness is
broader and holds for relations such as meronymy,
antonymy, functional association, and other “non-
classical relations” (Morris and Hirst, 2004). For
example, “ô_tô” (car) and “xăng_dầu” (petrol)
represent a meronym pair. In contrast to similar-
ity, this meronym pair expresses a clearly func-
tional relationship; the words are strongly associ-
ated with each other but not similar.

Empirical studies have shown that the predic-
tions of distributional models as well as humans
are strongly related to the part-of-speech (POS)
category of the learned concepts. Among oth-
ers, Gentner (2006) showed that verb concepts are
harder to learn by children than noun concepts.

Distinguishing antonymy from synonymy is
one of the most difficult challenges. While
antonymy represents words which are strongly as-
sociated but highly dissimilar to each other, syn-
onymy refers to words that are highly similar in
meaning. However, antonyms and synonyms often
occur in similar context, as they are interchange-
able in their substitution.

3.2 Resource for Concept Choice:
Vietnamese Computational Lexicon

The Vietnamese Computational Lexicon (VCL)7

(Nguyen et al., 2006) is a common linguistic
database which is freely and easily exploitable
for automatic processing of the Vietnamese lan-
guage. VCL contains 35,000 words corresponding
to 41,700 concepts, accompanied by morphologi-
cal, syntactic and semantic information. The mor-
phological information consists of 8 morphemes

7
https://vlsp.hpda.vn/demo/?page=vcl

200



including simple word, compound word, redu-
plicative word, multi-word expression, loan word,
abbreviation, bound morpheme, and symbol. For
example, “bàn” (table) is a simple word with def-
inition “đồ thường làm bằng gỗ, có mặt phẳng và
chân đỡ . . . ” (pieces of wood, flat and supported by
one or more legs . . . ). The syntactic information
describes part-of-speech, collocations, and subcat-
egorisation frames. The semantic information in-
cludes two types of constraints: logical and se-
mantic. The logical constraint provides category
meaning, synonyms and antonyms. The semantic
constraint provides argument information and se-
mantic roles. For example, “yêu” (love) is a verb
with category meaning “emotion” and antonym
“ghét” (hate).

VCL is the largest linguistic database of its kind
for Vietnamese, and it encodes various types of
morphological, syntactic and semantic informa-
tion, so it presents a suitable starting point for the
choice of lexical units for our purpose.

3.3 Choice of Concepts
3.3.1 Concepts in ViCon
The choice of related pairs in this dataset was
drawn from VCL in the following way. We ex-
tracted all antonym and synonym pairs accord-
ing to the three part-of-speech categories: noun,
verb and adjective. We then randomly selected
600 adjective pairs (300 antonymous pairs and 300
synonymous pairs), 400 noun pairs (200 antony-
mous pairs and 200 synonymous pairs), and 400
verb pairs (200 antonymous pairs and 200 synony-
mous pairs). In each part-of-speech category, we
balanced for the size of morphological classes in
VCL, for both antonymous and synonymous pairs.

3.3.2 Concepts in ViSim-400
The choice of related pairs in this dataset was
drawn from both the VLC and the Vietnamese
WordNet8 (VWN), cf. Nguyen et al. (2016b). We
extracted all pairs of the three part-of-speech cat-
egories: noun, verb and adjective, according to
five semantic relations: synonymy, antonymy, hy-
pernymy, co-hoponymy and meronymy. We then
sampled 400 pairs for the ViSim-400 dataset, ac-
counting for 200 noun pairs, 150 verb pairs and
50 adjective pairs. Regarding noun pairs, we bal-
anced the size of pairs in terms of six relations:
the five extracted relations from VCL and VWN,

8
http://viet.wordnet.vn/wnms/

and an “unrelated” relation. For verb pairs, we
balanced the number of pairs according to five
relations: synonymy, antonymy, hypernymy, co-
hyponymy, and unrelated. For adjective pairs, we
balanced the size of pairs for three relations: syn-
onymy, antonymy, and unrelated. In order to se-
lect the unrelated pairs for each part-of-speech cat-
egory, we paired the unrelated words from the se-
lected related pairs at random. From these ran-
dom pairs, we excluded those pairs that appeared
in VCL and VWN. Furthermore, we also balanced
the number of selected pairs according to the sizes
of the morphological classes and the lexical cate-
gories.

3.4 Annotation of ViSim-400
For rating ViSim-400, 200 raters who were native
Vietnamese speakers were paid to rate the degrees
of similarity for all 400 pairs. Each rater was asked
to rate 30 pairs on a 0–6 scale; and each pair was
rated by 15 raters. Unlike other datasets which
performed the annotation via Amazon Mechani-
cal Turk, each rater for ViSim-400 conducted the
annotation via a survey which detailed the exact
annotation guidelines.

The structure of the questionnaire was moti-
vated by the SimLex-999 dataset: we outlined
the notion of similarity via the well-understood
idea of the six relations included in the ViSim-400
dataset. Immediately after the guidelines of the
questionnaire, a checkpoint question was posed to
the participants to test whether the person under-
stood the guidelines: the participant was asked
to pick the most similar word pair from three
given word pairs, such as kiêu_căng/kiêu_ngạo
(arrogant/cocky) vs. trầm/bổng (high/low) vs.
cổ_điển/biếng (classical/lazy). The annotators
then labeled the kind of relation and scored the de-
gree of similarity for each word pair in the survey.

3.5 Agreement in ViSim-400
We analysed the ratings of the ViSim-400 annota-
tors with two different inter-annotator agreement
(IAA) measures, Krippendorff’s alpha coefficient
(Krippendorff, 2004), and the average standard de-
viation (STD) of all pairs across word classes.
The first IAA measure, IAA-pairwise, computes
the average pairwise Spearman’s ρ correlation be-
tween any two raters. This IAA measure has
been a common choice in previous data collec-
tions in distributional semantics (Padó et al., 2007;
Reisinger and Mooney, 2010; Hill et al., 2015).

201



Adj Noun Verb
0

2

4

6

0

2

4

6

0

2

4

6

ANT COHYPO HOLO HYPE SYN UNREL

Figure 1: Distribution of scored pairs in ViSim-400 across parts-of-speech and semantic relations.

All Noun Verb Adjective

IAA-Mean ρ 0.86 0.86 0.86 0.78
IAA-Pairwise ρ 0.79 0.76 0.78 0.75
Krippendorff’s α 0.78 0.76 0.78 0.86
STD 0.87 0.87 0.90 0.82

Table 1: Inter-annotator agreements measured by
Spearman’s ρ, Krippendorff’s α, and the average stan-
dard deviation (STD) of all pairs across word classes.

The second IAA measure, IAA-mean, compares
the average correlation of the human raters with
the average of all other raters. This measure would
smooth individual annotator effects, and serve as
a more appropriate “upper bound” for the per-
formance of automatic systems than IAA-pairwise
(Vulić et al., 2017). Finally, Krippendorff’s α co-
efficient reflects the disagreement of annotators
rather than their agreement, in addition to correct-
ing for agreement by chance.

Table 1 shows the inter-annotator agreement
values, Krippendorff’s α coefficient, and the re-
sponse consistency measured by STD over all
pairs and different word classes in ViSim-400.
The overall IAA-pairwise of ViSim-400 is ρ =
0.79, comparing favourably with the agreement on
the SimLex-999 dataset (ρ = 0.67 using the same
IAA-pairwise measure). Regarding IAA-mean,
ViSim-400 also achieves an overall agreement of
ρ = 0.86, which is similar to the agreement in
Vulić et al. (2017), ρ = 0.86. For Krippendorff’s
α coefficient, the value achieves α = 0.78, also
reflecting the reliability of the annotated dataset.

Furthermore, the box plots in Figure 1 present
the distributions of all rated pairs in terms of
the fine-grained semantic relations across word
classes. They reveal that –across word classes–
synonym pairs are clearly rated as the most simi-
lar words, and antonym as well as unrelated pairs

are clearly rated as the most dissimilar words. Hy-
pernymy, co-hyponymy and holonymy are in be-
tween, but rather similar than dissimilar.

4 Verification of Datasets

In this section, we verify our novel datasets Vi-
Con and ViSim-400 through standard and neural
co-occurrence models, in order to show that we
obtain a similar behaviour as for the correspond-
ing English datasets.

4.1 Verification of ViSim-400

We adopt a comparison of neural models on
SimLex-999 as suggested by Nguyen et al.
(2016a). They applied three models, a Skip-gram
model with negative sampling SGNS (Mikolov
et al., 2013), the dLCE model (Nguyen et al.,
2016a), and the mLCM model (Pham et al., 2015).
Both the dLCE and the mLCM models integrated
lexical contrast information into the basic Skip-
gram model to train word embeddings for distin-
guishing antonyms from synonyms, and for re-
flecting degrees of similarity.

The three models were trained with 300 di-
mensions, a window size of 5 words, and 10
negative samples. Regarding the corpora, we
relied on Vietnamese corpora with a total of
≈145 million tokens, including the Vietnamese
Wikipedia,9 VNESEcorpus and VNTQcorpus,10

and the Leipzig Corpora Collection for Viet-
namese11 (Goldhahn et al., 2012). For word seg-
mentation and POS tagging, we used the open-
source toolkit UETnlp12 (Nguyen and Le, 2016).
The antonym and synonym pairs to train the

9
https://dumps.wikimedia.org/viwiki/latest/

10
http://viet.jnlp.org/

download-du-lieu-tu-vung-corpus
11
http://wortschatz.uni-leipzig.de/en/download

12
https://github.com/phongnt570/UETnlp

202



dLCE and mLCM models were extracted from
VWN consisting of 49,458 antonymous pairs and
338,714 synonymous pairs. All pairs which ap-
peared in ViSim-400 were excluded from this set.

Table 2 shows Spearman’s correlations ρ, com-
paring the scores of the three models with the hu-
man judgements for ViSim-400. As also reported
for English, the dLCE model produces the best
performance, SGNS the worst.

SGNS mLCM dLCE

ViSim-400 0.37 0.60 0.62
SimLex-999 0.38 0.51 0.59

Table 2: Spearman’s correlation ρ on ViSim-400 in
comparison to SimLex-999, cf. Nguyen et al. (2016a).

In a second experiment, we computed the co-
sine similarities between all word pairs, and used
the area under curve (AUC) to distinguish be-
tween antonyms and synonyms. Table 3 presents
the AUC results of the three models. Again, the
models show a similar behaviour in comparison to
SimLex-999, where also the dLCE model outper-
forms the two other models, and the SGNS model
is by far the worst.

Model Noun Verb Adj

ViSim-400
SGNS 0.66 0.63 0.70
mLCM 0.81 0.92 0.96
dLCE 0.92 0.95 0.98

SimLex-999
SGNS 0.66 0.65 0.64
mLCM 0.69 0.71 0.85
dLCE 0.72 0.81 0.90

Table 3: AUC scores for distinguishing antonyms from
synonyms in ViSim-400.

4.2 Verification of ViCon

In order to verify ViCon, we applied three co-
occurrence models to rank antonymous and syn-
onymous word pairs according to their cosine
similarities: two standard co-occurrence mod-
els based on positive point-wise mutual informa-
tion (PPMI) and positive local mutual information
(PLMI) (Evert, 2005) as well as an improved fea-
ture value representation weightSA as suggested
by Nguyen et al. (2016a). For building the vec-
tor space co-occurrence models, we relied on the
same Vietnamese corpora as in the previous sec-
tion. For inducing the word vector representations
via weightSA, we made use of the antonymous
and synonymous pairs in VWN, as in the previ-

ous section, and then removed all pairs which ap-
peared in ViCon. Optionally, we applied singular
value decomposition (SVD) to reduce the dimen-
sionalities of the word vector representations.

As in Nguyen et al. (2016a), we computed the
cosine similarities between all word pairs, and
then sorted the pairs according to their cosine
scores. Average Precision (AP) evaluated the three
vector space models. Table 4 presents the results
of the three vector space models with and with-
out SVD. As for English, the results on the Viet-
namese dataset demonstrate significant improve-
ments (χ2,∗ p < .001) of weightSA over PPMI
and PLMI, both with and without SVD, and across
word classes.

ADJ NOUN VERBMetric
SYN ANT SYN ANT SYN ANT

PPMI 0.70 0.38 0.68 0.39 0.69 0.38
PLMI 0.59 0.44 0.61 0.42 0.63 0.41
weightSA 0.93* 0.31* 0.94* 0.31 0.96 0.31
PPMI + SVD 0.76 0.36 0.66 0.40 0.81 0.34
PLMI + SVD 0.49 0.51 0.55 0.46 0.51 0.49

ViCon

weightSA + SVD 0.91* 0.32* 0.81* 0.34* 0.92* 0.32*
PLMI 0.56 0.46 0.60 0.42 0.62 0.42
weightSA 0.75 0.36 0.66 0.40 0.71 0.38
PLMI + SVD 0.55 0.46 0.55 0.46 0.58 0.44

LexCon

weightSA + SVD 0.76* 0.36* 0.66 0.40 0.70* 0.38*

Table 4: AP evaluation of co-occurrence models on Vi-
Con in comparison to LexCon (Nguyen et al., 2016a).

5 Conclusion

This paper introduced two novel datasets for the
low-resource language Vietnamese to assess mod-
els of semantic similarity: ViCon comprises syn-
onym and antonym pairs across the word classes
of nouns, verbs, and adjectives. It offers data
to distinguish between similarity and dissimilar-
ity. ViSim-400 contains 400 word pairs across
the three word classes and five semantic relations.
Each pair was rated by human judges for its de-
gree of similarity, to reflect the continuum be-
tween similarity and relatedness. The two datasets
were verified through standard co-occurrence and
neural network models, showing results compara-
ble to the respective English datasets.

Acknowledgments

The research was supported by the Ministry of
Education and Training of the Socialist Republic
of Vietnam (Scholarship 977/QD-BGDDT; Kim-
Anh Nguyen), and the DFG Collaborative Re-
search Centre SFB 732 (Kim-Anh Nguyen, Sabine
Schulte im Walde, Ngoc Thang Vu).

203



References

Chris Biemann. 2005. Ontology learning from text: A
survey of methods. LDV Forum 20(2):75–93.

Elia Bruni, Gemma Boleda, Marco Baroni, and Nam-
Khanh Tran. 2012. Distributional semantics in tech-
nicolor. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics. Jeju Island, Korea, pages 136–145.

Alexander Budanitsky and Graeme Hirst. 2006. Evalu-
ating WordNet-based measures of lexical semantic
relatedness. Computational Linguistics 32(1):13–
47.

Philipp Cimiano, Andreas Hotho, and Steffen Staab.
2005. Learning concept hierarchies from text cor-
pora using formal concept analysis. Journal of Arti-
ficial Intelligence Research 24(1):305–339.

Stefan Evert. 2005. The Statistics of Word Cooccur-
rences. Ph.D. thesis, University of Stuttgart.

Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan
Ruppin. 2001. Placing search in context: The con-
cept revisited. In Proceedings of the 10th Interna-
tional Conference on World Wide Web. Hong Kong,
Hong Kong, pages 406–414.

Dedre Gentner. 2006. Why verbs are hard to learn. In
Kathryn A. Hirsh-Pasek and Roberta M. Golinkoff,
editors, Action meets word: How Children Learn
Verbs, Oxford University Press, pages 544–564.

Dirk Goldhahn, Thomas Eckart, and Uwe Quasthoff.
2012. Building large monolingual dictionaries at
the Leipzig corpora collection: From 100 to 200
languages. In Proceedings of the 8th International
Conference on Language Resources and Evaluation.
pages 759–765.

Iryna Gurevych. 2005. Using the structure of a concep-
tual network in computing semantic relatedness. In
Proceedings of the 2nd International Joint Confer-
ence on Natural Language Processing. Jeju Island,
Republic of Korea, pages 767–778.

Iryna Gurevych. 2006. Thinking beyond the nouns:
Computing semantic relatedness across parts of
speech. In Proceedings of Sprachdokumen-
tation & Sprachbeschreibung, 28. Jahrestagung
der Deutschen Gesellschaft für Sprachwissenschaft.
Bielefeld, Germany, page 226.

Xiaodong He, Mei Yang, Jianfeng Gao, Patrick
Nguyen, and Robert Moore. 2008. Indirect-HMM-
based hypothesis alignment for combining outputs
from machine translation systems. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing. Honolulu, Hawaii, pages 98–
107.

Felix Hill, Roi Reichart, and Anna Korhonen. 2015.
Simlex-999: Evaluating semantic models with gen-
uine similarity estimation. Computational Linguis-
tic 41(4):665–695.

Klaus Krippendorff. 2004. Content Analysis: An Intro-
duction to its Methodology. Sage Publications.

Thomas K. Landauer and Susan T. Dumais. 1997. A
solution to Plato’s problem: The latent semantic
analysis theory of acquisition, induction and rep-
resentation of knowledge. Psychological Review
104(2):211–240.

Ira Leviant and Roi Reichart. 2015. Judgment lan-
guage matters: Multilingual vector space models for
judgment language aware lexical semantics. CoRR
abs/1508.00106.

Mu Li, Yang Zhang, Muhua Zhu, and Ming Zhou.
2006. Exploring distributional similarity-based
models for query spelling correction. In Proceed-
ings of the 44th Annual Meeting of the Association
for Computational Linguistics. Sydney, Australia,
pages 1025–1032.

Yuval Marton, Chris Callison-Burch, and Philip
Resnik. 2009. Improved statistical machine trans-
lation using monolingually-derived paraphrases. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing. Singa-
pore, pages 381–390.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed represen-
tations of words and phrases and their composition-
ality. In Proceedings of the 26th International Con-
ference on Neural Information Processing Systems.
Lake Tahoe, Nevada, pages 3111–3119.

Jane Morris and Graeme Hirst. 2004. Non-classical
lexical semantic relations. In Proceedings of the
HLT-NAACL Workshop on Computational Lexical
Semantics. Boston, Massachusetts, pages 46–51.

Kim Anh Nguyen, Sabine Schulte im Walde, and
Ngoc Thang Vu. 2017. Distinguishing antonyms
and synonyms in a pattern-based neural network. In
Proceedings of the 15th Conference of the European
Chapter of the Association for Computational Lin-
guistics. Valencia, Spain, pages 76–85.

Kim-Anh Nguyen, Sabine Schulte im Walde, and
Thang Vu. 2016a. Integrating distributional lex-
ical contrast into word embeddings for antonym-
synonym distinction. In Proceedings of the 54th An-
nual Meeting of the Association for Computational
Linguistics. Berlin, Germany, pages 454–459.

Phuong-Thai Nguyen, Van-Lam Pham, Hoang-An
Nguyen, Huy-Hien Vu, Ngoc-Anh Tran, and Thi-
Thu-Ha Truong. 2016b. A two-phase approach for
building a Vietnamese WordNet. In Proceedings of
the 8th Global WordNet Conference. Bucharest, Ro-
mania, pages 259–264.

204



Thi Minh Huyen Nguyen, Laurent Romary, Mathias
Rossignol, and Xuan Luong Vu. 2006. A lexicon
for Vietnamese language processing. Language Re-
sources and Evaluation 40(3-4):291–309.

Tuan-Phong Nguyen and Anh-Cuong Le. 2016. A
hybrid approach to Vietnamese word segmentation.
In Proceedings of the International Conference on
Computing Communication Technologies, Research,
Innovation, and Vision for the Future. Hanoi, Viet-
nam, pages 114–119.

Sebastian Padó, Ulrike Padó, and Katrin Erk. 2007.
Flexible, corpus-based modelling of human plausi-
bility judgements. In Proceedings of the joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning. Prague, Czech Republic.

Nghia The Pham, Angeliki Lazaridou, and Marco Ba-
roni. 2015. A multitask objective to inject lexical
contrast into distributional semantics. In Proceed-
ings of the 53rd Annual Meeting of the Association
for Computational Linguistics and the 7th Interna-
tional Joint Conference on Natural Language Pro-
cessing. Beijing, China, pages 21–26.

Joseph Reisinger and Raymond Mooney. 2010. A
mixture model with sharing for lexical semantics.
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing. Cam-
bridge, Massachusetts, pages 1173–1182.

Herbert Rubenstein and John B. Goodenough. 1965.
Contextual correlates of synonymy. Communica-
tions of the ACM 8(10):627–633.

Silke Scheible and Sabine Schulte im Walde. 2014. A
database of paradigmatic semantic relation pairs for
German nouns, verbs and adjectives. In Proceedings
of the COLING Workshop Lexical and Grammati-
cal Resources for Language Processing. Dublin, Ire-
land, pages 111–119.

Ivan Vulić, Daniela Gerz, Douwe Kiela, Felix Hill,
and Anna Korhonen. 2017. Hyperlex: A large-scale
evaluation of graded lexical entailment. Computa-
tional Linguistics 43(4):781–835.

205


