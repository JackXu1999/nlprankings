



















































Linguistic Template Extraction for Recognizing Reader-Emotion and Emotional Resonance Writing Assistance


Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 775–780,

Beijing, China, July 26-31, 2015. c©2015 Association for Computational Linguistics

Linguistic Template Extraction for Recognizing Reader-Emotion and
Emotional Resonance Writing Assistance

Yung-Chun Chang1,2, Cen-Chieh Chen1,3, Yu-Lun Hsieh1,3, Chien Chin Chen2, Wen-Lian Hsu1∗
1Institute of Information Science, Academia Sinica, Taipei, Taiwan

2Department of Information Management, National Taiwan University, Taipei, Taiwan
3Department of Computer Science, National Chengchi University, Taipei, Taiwan

1{changyc,can,morphe,hsu}@iis.sinica.edu.tw, 2patonchen@ntu.edu.tw

Abstract

In this paper, we propose a flexi-
ble principle-based approach (PBA) for
reader-emotion classification and writ-
ing assistance. PBA is a highly auto-
mated process that learns emotion tem-
plates from raw texts to characterize an
emotion and is comprehensible for hu-
mans. These templates are adopted to pre-
dict reader-emotion, and may further assist
in emotional resonance writing. Results
demonstrate that PBA can effectively de-
tect reader-emotions by exploiting the syn-
tactic structures and semantic associations
in the context, thus outperforming well-
known statistical text classification meth-
ods and the state-of-the-art reader-emotion
classification method. Moreover, writers
are able to create more emotional reso-
nance in articles under the assistance of the
generated emotion templates. These tem-
plates have been proven to be highly inter-
pretable, which is an attribute that is diffi-
cult to accomplish in traditional statistical
methods.

1 Introduction

The Internet has rapidly grown into a powerful
medium for disseminating information. People
can easily share experiences and emotions anytime
and anywhere on social media websites. Human
feelings can be quickly collected through emotion
classification, as these emotions reflect an individ-
ual’s feelings and experiences toward some sub-
ject matters (Turney, 2002; Wilson et al., 2009).
Moreover, people can obtain more sponsorship
opportunities from manufacturers if their articles
about a certain product are able to create more
emotional resonance in the readers. Therefore,

∗Corresponding author

emotion classification has been attracting more
and more attention, e.g., Chen et al. (2010), Purver
and Battersby (2012).

Emotion classification aims to predict the emo-
tion categories (e.g., happy or angry) of the given
text (Quan and Ren, 2009; Das and Bandyopad-
hyay, 2009). There are two aspects of emotions
in texts, namely, writer’s and reader’s emotions.
The former concerns the emotion expressed by
the writer of the text, and the latter concerns
the emotion a reader had after reading it. Rec-
ognizing reader-emotion is different and may be
even more complex than writer-emotion (Lin et
al., 2008; Tang and Chen, 2012). A writer may
directly express her emotions through sentiment
words. By contrast, reader-emotion possesses a
more perplexing nature, as even common words
can invoke different types of reader-emotions de-
pending on the reader’s personal experiences and
knowledge (Lin et al., 2007). For instance, a sen-
tence like “Kenya survivors describe deadly at-
tack at Garissa University” is simply stating the
facts without any emotion, but may invoke emo-
tions such as angry or worried in its readers.

In light of this rationale, we propose a principle-
based approach (PBA) for reader-emotion classifi-
cation. It is a highly automated process that in-
tegrates various types of knowledge to generate
discriminative linguistic templates that can be ac-
knowledged as the essential knowledge for hu-
mans to understand different kinds of emotions.
PBA recognizes reader-emotions of documents us-
ing an alignment algorithm that allows a template
to be partially matched through a statistical scor-
ing scheme. Experiments demonstrate that PBA
can achieve a better performance than other well-
known text categorization methods and the state-
of-the-art reader-emotion classification method.
Furthermore, we adopt these generated templates
to assist in emotional resonance writing. Results
show that writers are able to generate more emo-

775



−2log
[

p(w)N(w∧E)(1−p(w))N(E)−N(w∧E)p(w)N(w∧¬E)(1−p(w))N(¬E)−N(w∧¬E)
p(w|E)N(w∧E)(1−p(w|E))N(E)−N(w∧E)p(w|¬E)N(w∧¬E)(1−p(w|¬E))N(¬E)−N(w∧¬E)

]
(1)

tional resonance in readers after exploiting these
templates, demonstrating the capability of PBA in
extracting templates with high interpretability.

2 Extracting Emotion Templates from
Raw Text

PBA attempts to construct emotion templates
through recognition of crucial elements using a
three-layered approach. First, since keywords
contain important information, PBA learns reader-
emotion specific keywords using an effective
feature selection method, log likelihood ratio
(LLR) (Manning and Schütze, 1999). It employs
Equation (1) to calculate the likelihood of the
assumption that the occurrence of a word w in
reader-emotionE is not random. In (1),E denotes
the set of documents of the reader-emotion in the
training data; N(E) and N(¬E) denote the num-
bers of documents that do or do not contain this
emotion, respectively; and N(w ∧ E) is the num-
ber of documents with emotion E and having w.
The probabilities p(w), p(w|E), and p(w|¬E) are
estimated using maximum likelihood estimation.
A larger LLR value is considered closely associ-
ated with an emotion. Words in the training data
are ranked by LLR values, and the top 200 are in-
cluded in our emotion keyword list.

Next, named entities (NEs) have been shown
to improve the performance of identifying top-
ics (Bashaddadh and Mohd, 2011). Thus, we uti-
lize Wikipedia to semi-automatically label NEs
with their semantic classes, which can be con-
sidered as a form of generalization. Wikipedia’s
category tags are used to label NEs recognized
by the Stanford NER1. If there are more than
one category tag for an NE, we select the most
dominant one with the highest number of as-
sociated Wikipedia pages. The assumption is
that the generality of a tag is indicated by the
number of Wikipedia pages that are linked to
it. For example, a query “奥巴马 (Obama)”
to the Wikipedia would return a page titled
“贝拉克.奥巴马 (Barack Obama)”. Within this
page, there are a number of category tags such
as “民主党 (Democratic Party)” and “美国总统

1http://nlp.stanford.edu/software/CRF-NER.shtml

(Presidents of the United States)”. Suppose
“美国总统 (Presidents of the United States)” has
more out-going links, we will label “奥巴马
(Obama)” as “[美国总统] (Presidents of the
United States)”. We also annotate those NEs
not found in Wikipedia with their category tags.
In this manner, we can transform plain NEs
to a more general class and increase the cov-
erage of each label. Finally, to incorporate
richer semantic context, we exploit the Extended
HowNet (E-HowNet) (Chen et al., 2005) after
the above processes to tag the remaining text
with sense labels. Figure 1 illustrates crucial
element labeling process. Consider the clause
Cn = “奥巴马又代表民主党赢得美国总统选举
(Obama, representing the Democratic Party, won
the U.S. Presidential election)”. First, “奥巴马
(Obama)” is found in the emotion keyword list
and tagged. Then, NEs like “民主党 (Democratic
Party)” and “总统选举 (Presidential election)”
are recognized and tagged as “{政党 (Party)}”
and “{总统选举 (Presidential election)}”. Sub-
sequently, other terms such as “代表 (represent)”
and “赢得 (won)” are labeled with their corre-
sponding E-HowNet senses. Finally, we obtain the
sequence “[奥巴马] : {代表} : {政党} : {得到}
: {国家} : {总统选举} ([Obama] : {represents}
: {party} : {got} : {country} : {Presidential elec-
tion}).” This three-layered labeling process serves
as a generalization of the raw text for capturing
crucial elements used in the template generation
stage that follows.

The emotion template generation process aims
at automatically constructing representative tem-
plates consisting of a sequence of crucial el-
ements. We observed that the rank-frequency
distribution of the elements follows the Zipf’s
law (Manning and Schütze, 1999). Thus, we
rank the templates according to their frequency,
and adopt a dominating set algorithm (Johnson,
1974) to use the top 20% templates to cover the
rest. First, we constructed a directed graph G =
{V,E}, in which vertices V contains all crucial
element sequences {CES1, · · · , CESm} in each
emotion, and edgesE represent the dominating re-
lations between sequences. If CESx dominates
CESy, there is an edge CESx → CESy. A

776



A clause Cn in an article:

sequence of crucial elements

Obama, representing the Democratic Party, won the U.S. Presidential election again

Domain 
Keyword

Semantic 
Class

Lexical 
Database

Filtering

{ }
Barack Obama[ ]
Barack Obama[ ]

Barack Obama[ ]
Barack Obama[ ]

Party { }country { }Presidential elections
{ }represent { }Party get{ } }country { }Presidential elections{
{ }represent { }Party get{ } }country { }Presidential elections{

Figure 1: Crucial element labeling process.

dominating relation is defined as follows. 1) Cru-
cial element sequences with high frequency are
selected as candidate dominators. 2) Longer se-
quences dominate shorter ones if their head and
tail elements are identical. The intermediate el-
ements are treated as insertions and/or deletions,
which can be scored based on their distribution in
this emotion during the matching process. Lastly,
we preserve top 100 most prominent and distinc-
tive ones from approximately 55,000 sequences
based on the dominating rate. This process serves
as a kind of dimension reduction and facilitates the
execution of our matching algorithm.

3 Template Matching for Inference

We believe that human perception of an emotion is
through recognizing important events or semantic
contents. For instance, when an article contains
strongly correlated words such as “Japan (coun-
try)”, “Earthquake (disaster)”, and “Tsunami (dis-
aster)” simultaneously, it is natural to conclude
that this article is more likely to elicit emotions
like depressed and worried rather than happy and
warm. Following this line of thought, PBA uses
an alignment algorithm (Needleman and Wun-
sch, 1970) to measure the similarity between tem-
plates and texts. It enables a single template to
match multiple semantically related expressions
with appropriate scores. For each clause in a doc-
ument dj , we first label crucial elements CE =
{ce1, · · · , cen}, followed by the matching proce-
dure that compares all sequences in CE from dj
to all emotion templates ET = {et1, · · · , etj} in

each emotion category, and calculates the scores.
Within the alignment matching, a statistical based
scoring criterion is used to score insertions, dele-
tions, and substitutions as described below. The
emotion ei with the highest sum of scores defined
in (2) is considered as the winner.

Emotion(dj)

= arg max
ei∈E

∑
etn∈ETci ,cem∈CEdj

∆(etn, cem)

=
∑
k

∑
l

∆(etn · slk, cem · cel) (2)

where slk and cel represent the kth slot of etn and
lth element of cem, respectively. Details for scor-
ing matched and unmatched elements are as fol-
lows. If etn·slk and cem·cel are identical, we add a
matched score (MS) obtained from the LLR value
of cel if it matches a keyword. Otherwise, the
score is determined by multiplying the frequency
of the crucial element in category ci by a normal-
izing factor λ = 100, as in (3). On the other hand,
an unmatched element is given a score of insertion
or deletion. The insertion score (IS), defined as
(4), can be accounted for by the inversed entropy
of this element, which represents the uniqueness
or generality of it among categories. And the dele-
tion score (DS), defined as (5), is computed from
the log frequency of this crucial element in this
emotion category.

777



MS (cel) =


LLRcel , if cel ∈ keyword
λ

fcel
m∑
i=1

fcei

, otherwise (3)

IS (cel) =
1

−
m∑
i=1

P (celci ) · log2(P (celci ))
(4)

DS (ce
l
) = log

fcel
m∑
i=1

fcei

(5)

4 Experiments

4.1 Dataset and Setting

We collected a corpus of Chinese news articles
from Yahoo! Kimo News2, in which each article
is given votes from readers with emotion tags in
eight categories: angry, worried, boring, happy,
odd, depressing, warm, and informative. We con-
sider the voted emotions as the reader’s emotion
toward the news. Following previous studies such
as Lin et al. (2007) and Lin et al. (2008) that used
a similar source, we exclude “informative” as it is
not considered as an emotion category. To ensure
the quality of our evaluation, only articles with
a clear statistical distinction between the highest
vote of emotion and others determined by t-test
with a 95% confidence level are retained. Finally,
47,285 out of 68,026 articles are kept, and divided
into the training set and the test set, each contain-
ing 11,681 and 35,604 articles, respectively.

4.2 Reader’s Emotion Classification

Several classification methods are implemented
and compared. Naı̈ve Bayes (McCallum et al.,
1998) serves as the baseline, denoted as NB. In
addition, a probabilistic graphical model that uses
LDA as document representation to train an SVM
classifier that determines a document as either rel-
evant or irrelevant (Blei et al., 2003), denotes as
LDA. Next, an emotion keyword-based model, de-
noted as KW, is trained using SVM to test the
effect of our keyword extraction approach. CF
is the state-of-the-art reader-emotion recognition
method that combines various features including
bigrams, words, metadata, and emotion category
words (Lin et al., 2007). For evaluation, we adopt

2https://tw.news.yahoo.com

the accuracy measures as used by Lin et al. (2007),
and compute the macro-average (AM ) and micro-
average (Aµ). Table 1 shows a comprehensive
evaluation of PBA and other methods3.

Emotion Accuracy(%)NB LDA KW CF PBA
angry 47.00 74.21 79.21 83.71 87.83
worried 69.56 92.83 81.96 87.50 75.80
boring 75.67 76.21 84.34 87.52 90.52
happy 37.90 67.59 80.97 86.27 88.94
odd 73.90 85.40 77.05 84.25 83.34
depressing 73.76 81.43 85.00 87.70 92.15
warm 75.09 87.09 79.59 85.83 91.91
AM 58.11 76.10 80.36 85.80 86.43
Aµ 52.78 74.16 80.81 85.70 88.56

Table 1: Comparison of the accuracies of five
reader-emotion classification systems.

Since NB only considers surface word weight-
ings and ignore inter-word relations, it only
achieved an accuracy of 58.11%. By contrast,
LDA includes both keywords and long-distance re-
lations, thus greatly outperforms NB with an over-
all accuracy of 76.10%. It even obtained the high-
est accuracy of 92.83% for the emotions “worried”
and “odd” among all methods. Notably, KW can
bring about substantial proficiency in detecting the
emotions, which indicates that reader-emotion can
be recognized effectively by using only the LLR
scores of keywords. Meanwhile, CF achieved a
satisfactory overall accuracy around 85%, due to
the combined lexical feature sets (e.g., charac-
ter bigrams, word dictionary, and emotion key-
words), paired with metadata of the articles. For
instance, we found that many sports-related ar-
ticles invoke the emotion “happy”. Specifically,
45% of all “happy” instances are sports-related,
and a sports-related article has a 31% chance of
having the emotion tag “happy”. Hence, the high
accuracy of the emotion category “happy” could
be the result of people’s general enthusiasm over
sports rather than a particular event. On top of
that, PBA can generate distinctive emotion tem-
plates to capture variations of similar expressions,
thus achieving better outcome. For instance, the
template “{国家 country}” : [发生 occur] : [地震
earthquake] : {劫难 disaster}” is generated by PBA

3The dictionary required by all methods is constructed
by removing stop words according to (Zou et al., 2006),
and retaining tokens that make up 90% of the accumu-
lated frequency. As for unseen events, we used the Laplace
smoothing in NB. LDA is implemented using a toolkit
(http://nlp.stanford.edu/software/tmt/tmt-0.4/).

778



for the emotion “worried”. It is perceivable that
this template is relaying information about dis-
astrous earthquakes in a country, and such news
often makes readers worry. The ability to yield
such emotion-specific, human interpretable tem-
plates could account for the outstanding perfor-
mance of PBA.

4.3 Reader’s Emotion Templates Suggestion
in Emotional Resonance Writing

This experiment aims at testing the effectiveness
of the emotion templates in aiding writers to com-
pose articles with stronger emotional resonance.
Here, we only consider coarse-grained emotion
categories (i.e., positive and negative). Thus, fine-
grained emotions like happy, warm, and odd are
merged into ‘positive’, while angry, boring, de-
pressing, and worried are merged into ‘negative’.
10 templates for each of the fine-grained emo-
tions are selected, resulting in 30 and 40 templates
for the two coarse-grained emotions, respectively.
We recruited seven writers to compose two arti-
cles that they think will trigger positive and neg-
ative emotions without using templates (denoted
as NT). Then, we asked them to compose two
more articles with the aid of templates (denoted
as WT). Afterwards, all articles are randomly or-
ganized into a questionnaire to test the emotional
resonance. Subjects are required to perform two
tasks: 1) answer ‘positive’, ‘neutral’, or ‘negative’
2) give a score according to the five-point Likert
scale (Likert, 1932) for a given emotion. In the
end, 42 effective responses are gathered. For Task
1, the score is defined as the number of matching
responses and answers. As for Task 2, the score is
the sum of all articles. Higher scores indicate bet-
ter emotional resonance between writers and read-
ers. Figure 2 shows the sum of scores in Task 1
from all subjects, grouped by writer. As for Task 2,
Figure 3 shows the average score across subjects,
grouped by writers. In both tasks, we can see that
higher scores are obtained after using templates,
indicating that emotion templates can indeed assist
writers in creating stronger emotional resonance in
their composition.

To sum up, results show that PBA can gener-
ate emotion templates that not only help machines
predict reader’s emotion, but also effectively aid
writers in creating a stronger emotional resonance
with the readers.

0

10

20

30

40

50

60

W1 W2 W3 W4 W5 W6 W7

Task-1

NT WT

Figure 2: Comparison of the number of correct
emotional response before and after utilizing tem-
plates.

0

1

2

3

4

5

W1 W2 W3 W4 W5 W6 W7

Task-2

NT WT

Figure 3: Degree of emotional resonance between
writers and readers.

5 Conclusion

In this paper, we present PBA, a flexible, highly
automated, and human-interpretable approach
for reader-emotion classification. By capturing
prominent and representative patterns in texts,
PBA can effectively recognize the reader-emotion.
Results demonstrate that PBA outperforms other
reader-emotion detection methods, and can assist
writers in creating higher emotional resonance. In
the future, we plan to further refine and employ it
to other NLP applications. Also, additional work
can be done on combining statistical models into
different components of PBA.

Acknowledgments

We are grateful to the anonymous reviewers for
their insightful comments. This research was sup-
ported by the Ministry of Science and Technology
of Taiwan under grant MOST 103-3111-Y-001-
027, 103-2221-E-002-106-MY2, and NSC102-
3113-P-001-006.

779



References
Omar Mabrook A Bashaddadh and Masnizah Mohd.

2011. Topic detection and tracking interface with
named entities approach. In Proceedings of the In-
ternational Conference on Semantic Technology and
Information Retrieval (STAIR), pages 215–219.

David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent Dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993–1022.

Keh-Jiann Chen, Shu-Ling Huang, Yueh-Yin Shih, and
Yi-Jun Chen. 2005. Extended-HowNet - a represen-
tational framework for concepts. In Proceedings of
OntoLex 2005 - Ontologies and Lexical Resources
IJCNLP-05 Workshop.

Ying Chen, Sophia Yat Mei Lee, Shoushan Li, and
Chu-Ren Huang. 2010. Emotion cause detec-
tion with linguistic constructions. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics, pages 179–187.

Dipankar Das and Sivaji Bandyopadhyay. 2009. Word
to sentence level emotion tagging for bengali blogs.
In Proceedings of the ACL-IJCNLP 2009 Confer-
ence, pages 149–152.

David S. Johnson. 1974. Approximation algorithms
for combinatorial problems. Journal of Computer
and System Sciences, 9(3):256 – 278.

Rensis Likert. 1932. A technique for the measurement
of attitudes. Archives of Psychology, 140:1–55.

Kevin Hsin-Yih Lin, Changhua Yang, and Hsin-Hsi
Chen. 2007. What emotions do news articles trig-
ger in their readers? In Proceedings of the 30th An-
nual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval,
pages 733–734.

Kevin Hsin-Yih Lin, Changhua Yang, and Hsin-Hsi
Chen. 2008. Emotion classification of online news
articles from the reader’s perspective. In Proceed-
ings of the 2008 IEEE/WIC/ACM International Con-
ference on Web Intelligence and Intelligent Agent
Technology, volume 1, pages 220–226.

Christopher D Manning and Hinrich Schütze. 1999.
Foundations of statistical natural language process-
ing. MIT press.

Andrew McCallum, Kamal Nigam, et al. 1998. A
comparison of event models for naive bayes text
classification. In AAAI-98 workshop on learning for
text categorization, volume 752, pages 41–48.

Saul B Needleman and Christian D Wunsch. 1970.
A general method applicable to the search for simi-
larities in the amino acid sequence of two proteins.
Journal of Molecular Biology, 48(3):443–453.

Matthew Purver and Stuart Battersby. 2012. Experi-
menting with distant supervision for emotion classi-
fication. In Proceedings of the 13th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 482–491.

Changqin Quan and Fuji Ren. 2009. Construction
of a blog emotion corpus for chinese emotional ex-
pression analysis. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Language
Processing, volume 3, pages 1446–1454.

Yi-jie Tang and Hsin-Hsi Chen. 2012. Mining senti-
ment words from microblogs for predicting writer-
reader emotion transition. In Proceedings of the 8th
International Conference on Language Resources
and Evaluation (LREC), pages 1226–1229.

Peter D Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th An-
nual Meeting of the Association for Computational
Linguistics, pages 417–424.

Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2009. Recognizing contextual polarity: An explo-
ration of features for phrase-level sentiment analy-
sis. Computational Linguistics, 35(3):399–433.

Feng Zou, Fu Lee Wang, Xiaotie Deng, Song Han, and
Lu Sheng Wang. 2006. Automatic construction of
chinese stop word list. In Proceedings of the 5th
WSEAS International Conference on Applied Com-
puter Science, pages 1010–1015.

780


