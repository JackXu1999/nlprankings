















































Evaluation of Morphological Embeddings for English and Russian Languages


Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for NLP, pages 77–81
Minneapolis, USA, June 6, 2019. c©2019 Association for Computational Linguistics

77

Evaluation of Morphological Embeddings for English and Russian
Languages

Vitaly Romanov
Innopolis University, Innopolis,

Russia
v.romanov@innopolis.ru

Albina Khusainova
Innopolis University, Innopolis,

Russia
a.khusainova@innopolis.ru

Abstract

This paper evaluates morphology-based em-
beddings for English and Russian languages.
Despite the interest and introduction of sev-
eral morphology-based word embedding mod-
els in the past and acclaimed performance im-
provements on word similarity and language
modeling tasks, in our experiments, we did
not observe any stable preference over two of
our baseline models - SkipGram and FastText.
The performance exhibited by morphological
embeddings is the average of the two baselines
mentioned above.

1 Introduction

One of the most significant shifts in the area of nat-
ural language processing is to the practical use of
distributed word representations. Collobert et al.
(2011) showed that a neural model could achieve
close to state-of-the-art results in Part of Speech
(POS) tagging and chunking by relying almost
only on word embeddings learned with a language
model. In modern language processing architec-
tures, high quality pre-trained representations of
words are one of the major factors of the resulting
model performance.

Although word embeddings became ubiqui-
tous, there is no single benchmark on evaluating
their quality (Bakarov, 2018), and popular intrin-
sic evaluation techniques are subject to criticism
(Gladkova and Drozd, 2016). Researchers very of-
ten rely on intrinsic evaluation, such as semantic
similarity or analogy tasks. While intrinsic evalu-
ations are simple to understand and conduct, they
do not necessarily imply the quality of embed-
dings for all possible tasks (Gladkova et al., 2016).

In this paper, we turn to the evaluation of mor-
phological embeddings for English and Russian
languages. Over the last decade, many approaches
tried to include subword information into word

representations. Such approaches involve addi-
tional techniques that perform segmentation of a
word into morphemes (Arefyev N.V., 2018; Virpi-
oja et al., 2013). The presumption is that we can
potentially increase the quality of distributional
representations if we incorporate these segmenta-
tions into the language model (LM).

Several approaches that include morphology
into word embeddings were proposed, but the
evaluation often does not compare proposed em-
bedding methodologies with the most popular em-
bedding vectors - Word2Vec, FastText, Glove. In
this paper, we aim at answering the question of
whether morphology-based embeddings can be
useful, especially for languages with rich mor-
phology (such as Russian). Our contribution is the
following:

1. We evaluate simple SkipGram-based (SG-
based) morphological embedding models
with new intrinsic evaluation BATS dataset
(Gladkova et al., 2016)

2. We compare relative gain of using morpho-
logical embeddings against Word2Vec and
FastText for English and Russian languages

3. We test morphological embeddings on sev-
eral downstream tasks other than language
modeling, i.e., mapping embedding spaces,
POS tagging, and chunking

The rest of the paper is organized as fol-
lows. Section 2 contains an overview of exist-
ing approaches for morphological embeddings and
methods of their evaluation. Section 3 explains
embedding models that we have tested. Section
4 explains our evaluation approaches. Section 5
describes results.



78

2 Related work

The idea to include subword information into
word representation is not new. The question is
how does one obtain morphological segmentation
of words. Very often, researchers rely on the unsu-
pervised morphology mining tool Morfessor (Vir-
pioja et al., 2013).

Many approaches use simple composition, e.g.,
sum, of morpheme vectors to define a word em-
bedding. Botha and Blunsom (2014) were one
of the first to try this approach. They showed a
considerable drop in perplexity of log-bilinear lan-
guage model and also tested their model on word
similarity and downstream translation task. The
translation task was tested against an n-gram lan-
guage model. Similarly, Qiu et al. (2014) tweak
CBOW model so that besides central word it can
predict target morphemes in this word. Final em-
beddings of morphemes are summed together into
the word embedding. They test vectors on analog-
ical reasoning and word similarity, showing that
incorporating morphemes improves semantic sim-
ilarity. El-kishky et al. (2018) develop their own
morpheme segmentation algorithm and test the re-
sulting embeddings on the LM task with SGNS
objective. Their method achieved lower perplex-
ity than FastText and SG.

A slightly different approach was taken by Cot-
terell and Schütze (2015) who optimized a log-
bilinear LM model with a multitask objective,
where the second objective is to guess the next
morphological tag. They test resulting vector
similarity against string distance (morphologically
close words have similar substrings) and find that
their vectors surpass Word2Vec by a large margin.

Bhatia et al. (2016) construct a hierarchical
graphical model that incorporates word morphol-
ogy to predict the next word and then optimize the
variational bound. They compare their model with
Word2Vec and the one described by Botha and
Blunsom (2014). They found that their method
improves results on word similarity but is inferior
to approach by Botha and Blunsom (2014) in POS
tagging.

Another group of methods tries to incorporate
arbitrary morphological information into embed-
ding model. Avraham and Goldberg (2017) ob-
serve that it is impossible to achieve both high
semantic and syntactic similarity on the Hebrew
language. Instead of morphemes, they use other
linguistic tags for the word, i.e., lemma, the

word itself, and morphological tag. Chaudhary
et al. (2018) took the next level of a similar ap-
proach. Besides including morphological tags,
they include morphemes and character n-grams,
and study the possibility of embedding transfer
from Turkish to Uighur and from Hindi to Ben-
gali. They test the result on NER and monolingual
machine translation.

Another approach that deserves being men-
tioned here is FastText by Bojanowski et al.
(2017). They do not use morphemes explicitly, but
instead rely on subword character n-grams, that
store morphological information implicitly. This
method achieves high scores on both semantic and
syntactic similarities, and by far is the most popu-
lar word embedding model that also captures word
morphology.

There are also approaches that investigate the
impact of more complex models like RNN and
LSTM. Luong et al. (2013) created a hierarchical
language model that uses RNN to combine mor-
phemes of a word to obtain a word representa-
tion. Their model performed well on word sim-
ilarity task. Similarly, Cao and Rei (2016) cre-
ate Char2Vec BiLSTM for embedding words and
train a language model with SG objective. Their
model excels at the syntactic similarity.

3 Embedding techniques

In this work, we test three embedding models on
English and Russian languages: SkipGram, Fast-
Text, and MorphGram. The latter one is similar
to FastText with the only difference that instead
of character n-grams we model word morphemes.
This approach was often used in previous research.

All three models are trained using the negative
sampling objective

1

T

T∑
t=1

∑
−m≤j≤m,j 6=0

log σ(s(wj , wt))+

k∑
i=1

Ew∼Pn(wt) [log σ(s(w,wt))] (1)

In the case of SG, the similarity function s is the
inner product of corresponding vectors. FastText
and MorphGram are using subword units. We use
the same approach to incorporate subword infor-
mation into the word vector for both models:



79

s(wj , wt) =
∑

s∈Swt

vTs vwj

where Swt is the set of word segmentations into
n-grams or morphemes. We use Gensim1 as the
implementation for all models (Řehůřek and So-
jka, 2010). For MorphGram, we utilize FastText
model and substitute the function that computes
character n-grams for the function that performs
morphological segmentation.

4 Experiments and Evaluation

To understand the effect of using morphemes for
training word embeddings, we performed intrin-
sic and extrinsic evaluations of SG, FastText, and
MorphGram model for two languages - English
and Russian. Russian language, in contrast to En-
glish, is characterized by rich morphology, which
makes this pair of languages a good choice for ex-
ploring the difference in the effect of morphology-
based models.

4.1 Data and Training Details

We used the first 5GB of unpacked English and
Russian Wikipedia dumps2 as training data.

For training both SG and FastText we used
Gensim library, for MorphGram - we adapted
Gensim’s implementation of FastText by break-
ing words into morphemes instead of n-grams,
all other implementation details left unchanged.
Training parameters remain the same as in the
original FastText paper, except the learning rate
was set to 0.05 at the beginning of the training,
and vocabulary size was constrained to 100000
words. Morphemes for English words were gen-
erated with polyglot3, and for Russian - with
seq2seq segmentation tool4.

When reporting our results in tables, we will re-
fer for FastText as FT and MorphGram as Morph.

4.2 Similarity

One of the intrinsic evaluations often used for
word embeddings is a similarity test - given word
pairs with human judgments of similarity degree

1https://radimrehurek.com/gensim
2https://dumps.wikimedia.org/
3https://polyglot.readthedocs.io/en/

latest/index.html
4https://github.com/kpopov94/morpheme_

seq2seq

SG FT Morph

en 0.37 0.35 0.36
ru 0.24 0.19 0.19

Table 1: Correlation between human judgments and
model scores for similarity datasets, Spearman’s ρ.

SG FT Morph

en
Google Semantic 65.34 48.75 57.52
Google Syntactic 55.88 75.10 61.16

BATS 29.67 33.33 32.71

ru
Translated Semantic 39.11 25.59 34.69
Translated Syntactic 32.71 59.29 43.68

Synthetic 24.52 36.78 27.06

Table 2: Accuracy of models on different analogies
tasks.

for words in each pair, human judgments are com-
pared with model scores—the more is the corre-
lation, the better model “understands” semantic
similarity of words. We used SimLex-999 (Hill
et al., 2015) dataset—the original one for English
and its translated by Leviant and Reichart (2015)
version for Russian, for evaluating trained embed-
dings. Out-of-vocabulary words were excluded
from tests for all models. The results are presented
in Table 1.

We see that SG beats the other two models
on similarity task for both languages, and Mor-
phGram performs almost the same as Fasttext.

4.3 Analogies

Another type of intrinsic evaluations is analo-
gies test, where the model is expected to answer
questions of the form A is to B as C is to D,
D should be predicted. For English, we used
Google analogies dataset introduced by Mikolov
et al. (Mikolov et al., 2013a) and BATS collec-
tion (Gladkova et al., 2016). For Russian, we used
a partial translation5 of Mikolov’s dataset, and a
synthetic dataset by Abdou et al. (2018).

Again, we excluded all out-of-vocabulary
words from tests. We report accuracy for differ-
ent models in Table 2.

Interestingly, MorphGram is between SG and
FastText in semantic categories for both lan-
guages, and between FastText and SG for syntactic
categories for English.

5https://rusvectores.org/static/
testsets/



80

SG FT Morph

ru-en 1-nn 56.27 55.58 53.51
ru-en 10-nn 78.96 78.82 77.03

Table 3: Accuracy of supervised mapping from Rus-
sian to English using different models, searching
among first and ten nearest neighbors.

4.4 Mapping Embedding Spaces

Here we introduce a new type of evaluation—it fo-
cuses on a cross-lingual task of mapping two em-
bedding spaces for different languages. The core
idea is to transform embedding spaces such that
after this transformation the vectors of words in
one language appear close to the vectors of their
translations in another language. We were inter-
ested to see if using morphemes has any benefits
to perform this kind of mapping.

We map embeddings using a train seed dictio-
nary (dictionary with word meanings) and state
of the art supervised mapping method by Artetxe
et al. (2018), and calculate the accuracy of the
mapping on the test dictionary. In short, the
essence of this method is to find optimal orthogo-
nal transforms for both embedding spaces to map
them to a shared space based on a seed dictionary,
plus some additional steps such as embeddings
normalization. For each model—SG, FastText,
and MorphGram, we mapped Russian and English
embeddings trained using this model. We used the
original implementation6 for mapping (supervised
option), and ground-truth train/test dictionaries
provided by Facebook for their MUSE7 library.
We report 1-nn and 10-nn accuracy: whether the
correct translation was found as a first nearest
neighbor or among 10 nearest neighbors of a word
in the mapped space. See the results in Table 3.

We observe no positive impact of using Mor-
phGram for mapping word embedding spaces.

4.5 POS Tagging and Chunking

Other tasks where incorporation of morphology
can be crucial are the tasks of POS Tagging and
chunking. We use a simple CNN-based architec-
ture introduced in (Collobert et al., 2011), with
one projection layer, one convolutional layer, and
the final logit layer. The only input features we
use are the embeddings from corresponding mod-

6https://github.com/artetxem/vecmap
7https://github.com/facebookresearch/

MUSE

SG FT Morph

en 0.9824 0.9754 0.9722
ru 0.8817 0.8899 0.8871

Table 4: Accuracy on POS task

SG FT Morph

en 0.8966 0.9034 0.8985
ru 0.8442 0.8548 0.8534

Table 5: Accuracy on Chunk task

els. The English language embeddings are tested
with Conll2000 dataset which contains 8935 train-
ing sentences and 44 unique POS tags. The dataset
for the Russian language contains 49136 sentences
and 458 unique POS tags. Due to time constraint,
we train models only for a fixed number of epochs:
50 for English and 20 for Russian (iterations re-
duced due to a larger training set). The results for
POS and chunking are given in Tables 4 and 5 cor-
respondingly. It is interesting to note that SG em-
beddings perform better for English on POS task,
but for Russian, embeddings that encode more
syntactic information always perform better.

5 Results

In this paper, we compared three word embedding
approaches for English and Russian languages.
The main inquiry was about the relevance of pro-
viding morphological information to word em-
beddings. Experiments showed that morphology-
based embeddings exhibit qualities intermediate
between semantic driven embedding approaches
as SkipGram and character-driven one as FastText.
Morphological embeddings studied here showed
average performance on both semantic and syntac-
tic tests. We also studied the application of mor-
phological embeddings on two downstream tasks:
POS tagging and chunking. For English language,
SG provided the best results for POS, whereas
FastText gave the best result on chunking task.
For Russian, FastText showed better performance
on both tasks. Morphological embeddings, again,
showed average results. We recognize that the dif-
ference in the results on downstream task can be
considered marginal. We also did not observe im-
provements from morphological embeddings on
word similarity dataset compared to other models.



81

References
Mostafa Abdou, Artur Kulmizev, and Vinit Ravis-

hankar. 2018. Mgad: Multilingual generation of
analogy datasets. In Proceedings of the Eleventh In-
ternational Conference on Language Resources and
Evaluation (LREC-2018).

Popov K.P. Arefyev N.V., Gratsianova T.Y. 2018. 24rd
International Conference on Computational Linguis-
tics and Intellectual Technologies.

Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2018.
Generalizing and improving bilingual word embed-
ding mappings with a multi-step framework of linear
transformations. In Thirty-Second AAAI Conference
on Artificial Intelligence.

Oded Avraham and Yoav Goldberg. 2017. The inter-
play of semantics and morphology in word embed-
dings. arXiv preprint arXiv:1704.01938.

Amir Bakarov. 2018. A survey of word em-
beddings evaluation methods. arXiv preprint
arXiv:1801.09536.

Parminder Bhatia, Robert Guthrie, and Jacob Eisen-
stein. 2016. Morphological priors for proba-
bilistic neural word embeddings. arXiv preprint
arXiv:1608.01056.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching word vectors with
subword information. Transactions of the Associa-
tion for Computational Linguistics, 5:135–146.

Jan Botha and Phil Blunsom. 2014. Compositional
morphology for word representations and language
modelling. In International Conference on Machine
Learning, pages 1899–1907.

Kris Cao and Marek Rei. 2016. A joint model for word
embedding and word morphology. arXiv preprint
arXiv:1606.02601.

Aditi Chaudhary, Chunting Zhou, Lori Levin, Gra-
ham Neubig, David R. Mortensen, and Jaime G.
Carbonell. 2018. Adapting Word Embeddings to
New Languages with Morphological and Phonolog-
ical Subword Representations.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12(Aug):2493–2537.

Ryan Cotterell and Hinrich Schütze. 2015. Morpho-
logical word-embeddings. In Proceedings of the
2015 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1287–1292.

Ahmed El-kishky, Frank Xu, Aston Zhang, Stephen
Macke, and Jiawei Han. 2018. Entropy-Based Sub-
word Mining with an Application to Word Embed-
dings. pages 12–21.

Anna Gladkova and Aleksandr Drozd. 2016. Intrinsic
evaluations of word embeddings: What can we do
better? In Proceedings of the 1st Workshop on Eval-
uating Vector-Space Representations for NLP, pages
36–42.

Anna Gladkova, Aleksandr Drozd, and Satoshi Mat-
suoka. 2016. Analogy-based detection of morpho-
logical and semantic relations with word embed-
dings: What works and what doesn’t. In Proceed-
ings of the NAACL-HLT SRW, pages 47–54, San
Diego, California, June 12-17, 2016. ACL.

Felix Hill, Roi Reichart, and Anna Korhonen. 2015.
Simlex-999: Evaluating semantic models with (gen-
uine) similarity estimation. Computational Linguis-
tics, 41(4):665–695.

Ira Leviant and Roi Reichart. 2015. Judgment lan-
guage matters: Multilingual vector space models for
judgment language aware lexical semantics. CoRR,
abs/1508.00106.

Thang Luong, Richard Socher, and Christopher Man-
ning. 2013. Better word representations with recur-
sive neural networks for morphology. Proceedings
of the Seventeenth Conference on Computational
Natural Language Learning, pages 104—-113.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013a. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.

Siyu Qiu, Qing Cui, Jiang Bian, Bin Gao, and Tie-Yan
Liu. 2014. Co-learning of word representations and
morpheme representations. In Proceedings of COL-
ING 2014, the 25th International Conference on
Computational Linguistics: Technical Papers, pages
141–150.

Radim Řehůřek and Petr Sojka. 2010. Software Frame-
work for Topic Modelling with Large Corpora. In
Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks, pages 45–50, Val-
letta, Malta. ELRA. http://is.muni.cz/
publication/884893/en.

Sami Virpioja, Peter Smit, Stig-Arne Grönroos, Mikko
Kurimo, et al. 2013. Morfessor 2.0: Python imple-
mentation and extensions for morfessor baseline.


