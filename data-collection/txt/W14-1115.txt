



















































Disambiguation of Period Characters in Clinical Narratives


Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 96–100,
Gothenburg, Sweden, April 26-30 2014. c©2014 Association for Computational Linguistics

Disambiguation of Period Characters in Clinical Narratives

Markus Kreuzthaler and Stefan Schulz
Institute for Medical Informatics, Statistics and Documentation

Medical University of Graz
<markus.kreuzthaler,stefan.schulz>@medunigraz.at

Abstract

The period character’s meaning is highly
ambiguous due to the frequency of ab-
breviations that require to be followed
by a period. We have developed a hy-
brid method for period character disam-
biguation and the identification of abbre-
viations, combining rules that explore reg-
ularities in the right context of the pe-
riod with lexicon-based, statistical meth-
ods which scrutinize the preceding token.
The texts under scrutiny are clinical dis-
charge summaries. Both abbreviation de-
tection and sentence delimitation showed
an accuracy of about 93%. An error anal-
ysis demonstrated potential for further im-
provements.

1 Introduction

The full stop, or period character, is ambiguous.
As well as its use as a sentence delimiter, it is often
collocated with abbreviations (“Prof.”), occurs in
numeric expressions (“13.2 mg”), including dates,
and appears in a series of special names such as
Web addresses. Minor variations exist between
languages and dialects (for example the use of the
period as decimal delimiter), and rule variations
exist that guide its collocation with abbreviations.
The character-wise analysis of text can produce a
clear distinction between (i) period characters that
are enclosed between two alphanumeric charac-
ters, and (ii) period characters that are adjacent to
at least one non-alphabetic character. Whereas in
the former case the period character can be consid-
ered an internal part of a token, the latter allows for
two interpretations:

1. Period characters that are mandatorily collo-
cated with abbreviations; and

2. Period characters as sentence delimiters.

We focus on text produced by physicians at
the point of care, either directly or via dictation.
The sublanguage of clinical narratives is charac-
terized, among other peculiarities such as mis-
spellings, punctuation errors, and incomplete sen-
tences, by the abundance of acronyms and abbre-
viations (Meystre et al., 2008). It is for this reason
that we focus here on the use of the period char-
acter to distinguish between sentence limits and
abbreviations.

A snippet from a medical text illustrates some
typical phenomena:

3. St.p. TE eines exulz.
sek.knot.SSM (C43.5) li Lab.
majus. Level IV, 2,42 mm
Tumordurchm.

In “3.” the period marks an ordinal num-
ber; “St.p.” is the abbreviation of “Status
post” (state after); “TE” is an acronym de-
rived from “Totale Exzision”. “Exulz.” and
“Tumordurchm.” are ad-hoc abbreviations for
“exulzerierendes” and “Tumordurchmesser” (tu-
mour diameter), respectively. “sek.knot.SSM”
is an ill-formed agglutination of two abbrevia-
tions and one acronym. In correctly formatted
text, they would be separated by spaces (“sek.
knot. SSM”). The abbreviation “sek.” (sec-
ondary) is written in a common lexicalized form,
whereas “knot.” is, once again, an ad-hoc cre-
ation. “SSM” is an acronym for “Superfiziell Spre-
itendes Melanom”. “C43.5” is a code from the
International Classification of Diseases1. “Lab.”
means “Labium”, a common anatomical abbrevi-
ation. “IV” is not an acronym, but a Roman num-
ber. “2,42” is a decimal number, demonstrating
that the comma rather than the period is used as
a decimal separator in German texts. Finally, the
abbreviation “Tumordurchm.” exemplifies that

1http://www.who.int/classifications/icd/en/

96



the period can play a double role, viz. to mark an
abbreviation and to conclude a sentence.

In this paper we will describe and evaluate a
methodology that is able to identify and distin-
guish the following: (i) periods that act as sentence
delimiters after ordinary words (such as the period
after “majus”) marked as NSD (normal sentence
delimiter); (ii) periods as abbreviation markers in
the middle of a sentence, marked as MAM (mid-
sentence abbreviation marker), and (iii) periods
that are both abbreviation markers and sentence
delimiters, marked as EAM (end-sentence abbre-
viation marker). From this ternary distinction, two
binary tasks can be derived, viz. the detection of
abbreviations (MAM and EAM), and the detection
of sentence endings (NSD and EAM).

2 Materials and Methods

2.1 Data

We used 1,696 discharge summaries extracted and
anonymized from a clinical information system.
They had an average word count of 302, with a
mean of 55 period characters per document. The
texts were divided into a learning set (1.526 doc-
uments) and an evaluation set (170 documents).
Two word lists were created in advance: (i) a med-
ical domain dictionary (MDDict) with a high cov-
erage of domain-specific terms, excluding abbre-
viations, and (ii) a closed-class dictionary (CC-
Dict) containing common, domain-independent
word forms.

For MDDict, words were harvested from
three sources: a free dictionary of contempo-
rary German2, a word list created out of raw
text extracted from a medical dictionary on CD-
ROM (Pschyrembel, 1997), and medical texts and
forum postings from a patient-centered website3.
The final list comprised approximately 1.45 mil-
lion types, which were subsequently indexed with
Lucene4. This dictionary was modified during a
second step by two Web resources containing
German abbreviations5,6. We accumulated about
5,800 acronym and abbreviation tokens, which
were then removed from the Lucene-indexed dic-
tionary, in order to transform MDDict into a re-
source mostly devoid of abbreviations.

2http://sourceforge.net/projects/germandict/
3http://www.netdoktor.at/
4https://lucene.apache.org/core/
5http://de.wikipedia.org/wiki/Medizinische Abkürzungen
6http://de.wiktionary.org/wiki/Kategorie:Abkürzung

Strukturen  re. , nekrotische  Tumorforma                                                                       

Token 
Delimiter 

Left 
Token 

Punctuation 
String 

Right 
Token 

Token 
Delimiter 

TDel      LToken   PStr              RToken       TDel      

Period 

Left context             Right context 

Figure 1: Period pattern and zoning of left and
right context.

For CCDict we harvested closed-class words
from a German web resource7, i.e. prepositions,
determiners, conjunctions, and pronouns, together
with auxiliary and modal verbs. The purpose of
this was to arrive at a comprehensive list of word
forms that can only be capitalized at the beginning
of a sentence.

Figure 1 shows the pattern used to identify peri-
ods of interest for this study. The right and the left
context were zoned as followed: The string to the
left of the period until the preceding token delim-
iter is the “Left Token” (LToken). The sequence
of spaces, line breaks, or punctuation marks to the
right of the period (“Punctuation String”) is iden-
tified as PStr. The following token, spanning from
the first alphanumeric character to the character
left to the next delimiter, is named RToken.

2.2 Context evaluation
The right context is evaluated first (Algorithm
1). It is based on the following assumptions: (i)
Whenever a period terminates a sentence, the first
character in the following token is capitalized. For
a subset of words this can be ascertained by look-
ing up the closed word class dictionary CCDict
(the restriction to “closed classes” is due to the fact
that German nouns are mandatorily capitalized, in-
cluding nominalized adjectives and verbs); (ii) A
sentence can never be split by a line break, there-
fore a period that precedes the break necessarily
marks the end of the previous sentence; (iii) Most
punctuation signs that follow a period strongly in-
dicate that the period character here plays the role
of an abbreviation marker and does not coincide
with an end-of-sentence marker. Only in the case
where a decision could not be achieved using the

7http://www.deutschegrammatik20.de/

97



if RToken begins with lower case character
then
→MAM;

else
if decapitalized RToken matches closed
class token then
→ EAM or NSD;

else
if If PStr contains punctuation
character then
→MAM;

else
if If PStr contains a line break
then
→ NSD or EAM;

else
→ NSD or MAM or EAM;

end
end

end
end

Algorithm 1: Rule-based decision algorithm for
the right context of a period.

algorithm is the left context investigated.
The evaluation of the left context extends the

approach from Kiss and Strunk (2002), who used
the log likelihood ratio (Dunning, 1993) for abbre-
viation detection:

logλ = −2log(L(H0)/L(HA))
H0 is the hypothesis that the occurrence of a pe-
riod is independent of the preceding word, HA the
hypothesis that it is not independent.

We use four scaling functions S1 – S4. The
period character is symbolized by •; C(word, •)
and C(word,¬•) describe the co-occurrence fre-
quency counts. The primary logλ is modified
by sequential composition. Following Kiss and
Strunk (2002), S1 enhances the initial logλ if
C(word, •) is greater than C(word,¬•). S2
varies from−1 to 1 depending on C(word, •) and
C(word,¬•). S3 leads to a reduction of logλ de-
pending on the length of the preceding word. We
introduced a fourth scaling function S4, which re-
flects the fact that most abbreviations are proper
substrings of the shortened original word (e.g.
“exulz.” = “exulzerierend”), with N being the
sum of all found substring matches in the form
subwordi∗ for every subwordi in subword1 •
subword2 • . . . subwordn• in a Lucene search re-

sult.

S4(logλ) : logλ+N(word, •)
This also includes those abbreviations which

have an internal period, such as “St.p”. The reason
why the last scaling function contains an addition,
is to accommodate for cases where C(word, •) <
C(word,¬•) even when word is an abbreviation.
These cases, for which the weighted logλ is nega-
tive, could then nevertheless be pushed to the pos-
itive side in the result of a strong S4.

For the final decision in favor of an abbrevi-
ation, we required that the following two condi-
tions hold: (i) (S1 ◦ S2 ◦ S3 ◦ S4)(logλ) > 0;
(ii) the length of the abbreviation candidate was
within the 95% confidence interval, given the sta-
tistical distribution of all abbreviation candidates
that exhibited a significant collocation (p < 0.01),
C(word, •) > C(word,¬•), and MDDict not
containing word.

3 Results

For the evaluation methodology, a gold standard
was created by a random selection of 500 text
frames, centered around a period with its left and
right context (each 60 characters) from the evalu-
ation set. The two authors rated each period in the
center of the snippet as being an NSD, a MAM
or an EAM. A subset of 100 was rated by both
authors in order to compute the inter-rater agree-
ment. We obtained a Cohen’s kappa (Di Euge-
nio and Glass, 2004, Hripcsak and Heitjan, 2002)
of 0.98, when rating both abbreviation vs. non-
abbreviation, and sentence delimiter vs. non sen-
tence delimiter, respectively. Accuracy, true and
false negative rates (Manning et al., 2008), are
computed for the two processing steps in isolation.
This required making some default assumptions
for the cases in which the result was ambiguous.
The assumptions are based on frequency distribu-
tions of the three values in the learning set. The
left context processing detects abbreviations, but
is unable to distinguish between EAM and MAM.
As the frequency of MAM is much higher, this
value is set wherever NSD is discarded. In the pro-
cessing of the right context, the algorithm may fail
to disambiguate between NSD vs. EAM, or even
terminate with any decision (NSD vs. EAM vs.
MAM), cf. Algorithm 1. In the latter case MAM
is set, as this was determined to be the most fre-
quent phenomenon in the learning data (0.53). In

98



the former case, NSD is given preference over
EAM, which has a low frequency in the learn-
ing set (0.03). Table 1 shows accuracy and false
positive / negative rates obtained by left, right and
combined context evaluations.

Accuracy Fpos Fneg
Abbreviation detection

Left 0.914 0.035 0.136
Right 0.880 0.162 0.051
L & R 0.928 0.060 0.082

Sentence delimitation
Left 0.902 0.107 0.077
Right 0.884 0.014 0.211
L & R 0.934 0.062 0.065

Table 1: Abbreviation detection and sentence de-
limitation results.

It is remarkable that the combination of both al-
gorithms only produces a moderate gain in accu-
racy. For the minimization of certain false nega-
tives and false positives, it can be advantageous to
consider the right or left context separately. For in-
stance, the right context algorithm alone is better
at minimizing false positive sentence recognitions,
whereas the left context algorithm is better suited
at minimizing cases of false positive abbreviation
detections. Apart from known issues such as the
above mentioned parsing problems, for which the
reader needs to be familiar with the domain and
the style of the documents, the analysis of mis-
classifications revealed several weaknesses: sen-
sitivity to spelling and punctuation errors (espe-
cially missing spaces after periods) and abbrevia-
tions that can also be read as a normal word (e.g.
“Mal.” for “Malignität” or “Mal” (time)), and ab-
breviations that are still present in MDDict.

4 Related Work

The detection of short forms (abbreviations,
acronyms) is important due to their frequency in
medical texts (Meystre et al., 2008). Several au-
thors studied their detection, normalization, and
context-dependent mapping to long forms (Xu et
al., 2012). CLEF 2013 (Suominen et al., 2013)
started a task for acronym/abbreviation normal-
ization, using the UMLS8 as target terminology.
An F-Measure of 0.89 was reported by Patrick et
al. (2013). Four different methods for abbrevia-

8http://www.nlm.nih.gov/research/umls/

tion detection were tested by Xu et al. (2007). The
fourth method (a decision tree classifier), which
additionally used features from knowledge re-
sources, performed best with a precision of 91.4%
and a recall of 80.3%. Therefore Wu et al. (2011)
compared machine learning methods for abbrevi-
ation detection. Word formation, vowel combina-
tions, related content from knowledge bases, word
frequency in the overall corpus, and local context
were used as features. The random forest classi-
fier performed best with an F-Measure of 94.8%.
A combination of classifiers lead to the highest
F-Measure of 95.7%. Wu et al. (2012) compared
different clinical natural language processing sys-
tems on handling abbreviations in discharge sum-
maries, resulting in MedLEE performing best with
an F-Score of 0.60. A prototypical system, meet-
ing real-time constraints, is described in Wu et
al. (2013).

5 Conclusion and Outlook

We have presented and evaluated a method for
disambiguating the period character in German-
language medical narratives. It is a combination
of a simple rule set and a statistical approach
supported by lexicons. Whereas the crafting of
the rule base considers peculiarities of the docu-
ment language, primarily by exploiting language-
specific capitalization rules, the processing of the
external language resources and the statistical
methodology are unsupervised. Given these pa-
rameters, the accuracy values of about 93% for
both abbreviation detection and sentence delin-
eation are satisfactory, especially when one con-
siders that the texts are error laden and highly
compact, which also resulted in large numbers of
ad-hoc abbreviations. We expect that with a lim-
ited training effort this rate can still be raised fur-
ther. We are aware that the described period dis-
ambiguation procedure should be embedded into
an NLP processing pipeline, where it must be pre-
ceded by a cleansing process that identifies “hid-
den” periods and restores the adherence to basic
punctuation rules by inserting white spaces where
necessary. An improved result can facilitate the
creation of a sufficiently large, manually annotated
corpus, which could then be used as the basis for
the application of machine learning methods. Fur-
thermore, the impact of the different modifications
regarding the left context approach must be evalu-
ated in more detail.

99



References
Barbara Di Eugenio and Michael Glass. 2004. The

kappa statistic: A second look. Computational lin-
guistics, 30(1):95–101.

T Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Lin-
guistics, 19(1):61–74.

George Hripcsak and Daniel F Heitjan. 2002. Mea-
suring agreement in medical informatics reliabil-
ity studies. Journal of biomedical informatics,
35(2):99–110.

T Kiss and J Strunk. 2002. Scaled log likelihood ratios
for the detection of abbreviations in text corpora. In
Proceedings of the 19th International Conference on
Computational Linguistics – Volume 2, pages 1–5.
Association for Computational Linguistics.

Christopher D Manning, Prabhakar Raghavan, and
Hinrich Schütze. 2008. Introduction to informa-
tion retrieval, volume 1. Cambridge university press
Cambridge.

S M Meystre, GK Savova, KC Kipper-Schuler, and
JF Hurdle. 2008. Extracting information from tex-
tual documents in the electronic health record: a re-
view of recent research. Yearbook of Medical Infor-
matics, 35:128–144.

JD Patrick, L Safari, and Y Ou. 2013.
ShaARe/CLEF eHealth 2013 Normalization of
Acronyms/Abbreviation Challenge. In CLEF 2013
Evaluation Labs and Workshop Abstracts - Working
Notes.

Pschyrembel. 1997. Klinisches Wörterbuch. CD-
ROM Version 1/97.

Hanna Suominen, Sanna Salanterä, Sumithra Velupil-
lai, Wendy W Chapman, Guergana Savova, Noemie
Elhadad, Sameer Pradhan, Brett R South, Danielle L
Mowery, Gareth JF Jones, et al. 2013. Overview
of the share/clef ehealth evaluation lab 2013.
In Information Access Evaluation. Multilinguality,
Multimodality, and Visualization, pages 212–231.
Springer.

Y Wu, ST Rosenbloom, JC Denny, A Miller, S Mani,
Giuse DA, and H Xu. 2011. Detecting abbrevia-
tions in discharge summaries using machine learn-
ing methods. In AMIA Annual Symposium Proceed-
ings, volume 2011, pages 1541–1549.

Y Wu, JC Denny, ST Rosenbloom, RA Miller,
DA Giuse, and H Xu. 2012. A comparative study of
current clinical natural language processing systems
on handling abbreviations in discharge summaries.
In AMIA Annual Symposium Proceedings, volume
2012, pages 997–1003.

Y Wu, JC Denny, ST Rosenbloom, Randolph A Miller,
Dario A Giuse, Min Song, and Hua Xu. 2013. A
prototype application for real-time recognition and

disambiguation of clinical abbreviations. In Proc.
of the 7th International Workshop on Data and Text
Mining in Biomedical Informatics, pages 7–8.

H Xu, PD Stetson, and C Friedman. 2007. A study
of abbreviations in clinical notes. In AMIA Annual
Symposium Proceedings, volume 2007, pages 821–
825.

H Xu, PD Stetson, and C Friedman. 2012. Combin-
ing corpus-derived sense profiles with estimated fre-
quency information to disambiguate clinical abbre-
viations. In AMIA Annual Symposium Proceedings,
volume 2012, pages 1004–1013.

100


