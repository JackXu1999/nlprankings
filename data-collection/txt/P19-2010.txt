



















































Automated Cross-language Intelligibility Analysis of Parkinson's Disease Patients Using Speech Recognition Technologies


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 74–80
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

74

Automated Cross-language Intelligibility Analysis of Parkinson’s Disease
Patients Using Speech Recognition Technologies

Nina Hosseini-Kivanani 1, Juan Camilo Vásquez-Correa2, 3, Manfred Stede4, Elmar Nöth2
1International Experimental and Clinical Linguistics (IECL), University of Potsdam, Germany

2 Pattern Recognition Lab, Friedrich-Alexander University Erlangen-Nüremberg, Germany
3 Faculty of Engineering, University of Antioquia UdeA, Medellı́n, Colombia

4Applied Computational Linguistics, University of Potsdam, Germany
{hosseinikiva, stede}@uni-potsdam.de

jcamilo.vasquez@udea.edu.co
elmar.noeth@fau.de

Abstract
Speech deficits are common symptoms among
Parkinson’s Disease (PD) patients. The auto-
matic assessment of speech signals is promis-
ing for the evaluation of the neurological state
and the speech quality of the patients. Re-
cently, progress has been made in applying
machine learning and computational methods
to automatically evaluate the speech of PD pa-
tients. In the present study, we plan to an-
alyze the speech signals of PD patients and
healthy control (HC) subjects in three differ-
ent languages: German, Spanish, and Czech,
with the aim to identify biomarkers to discrim-
inate between PD patients and HC subjects and
to evaluate the neurological state of the pa-
tients. Therefore, the main contribution of this
study is the automatic classification of PD pa-
tients and HC subjects in different languages
with focusing on phonation, articulation, and
prosody. We will focus on an intelligibility
analysis based on automatic speech recogni-
tion systems trained on these three languages.
This is one of the first studies done that consid-
ers the evaluation of the speech of PD patients
in different languages. The purpose of this re-
search proposal is to build a model that can
discriminate PD and HC subjects even when
the language used for train and test is differ-
ent.

1 Introduction

Parkinsons disease (PD) (i.e. Shaking palsy
(Parkinson, 2002)) is the second most common
neurodegenerative disorder after Alzheimers dis-
ease. PD displays a great prevalence in individuals
of advanced age (Dexter and Jenner, 2013), espe-
cially, over the age of fifty (Fahn, 2003). The signs
and symptoms of PD can significantly influence
the quality of life of patients. They are grouped

into two categories: motor and non-motor symp-
toms. Speech impairments are one of the earliest
manifestations in PD patients.

Early diagnosis of PD is a vital challenge in
this field. The first step in analyzing this disease
is the development of markers of PD progression
through collecting data from several cohorts. To
reach this aim, different clinical rating scales have
been developed, such as the Unified Parkinson’s
Disease Rating Scale (UPDRS), Movement Dis-
orders Society - UPDRS (MDS-UPDRS) 1 (Goetz
et al., 2008) and Hoehn & Yahr (H & Y) staging,
(Visser et al., 2006).

The UPDRS is the most widely used rating tool
for the clinical evaluation of PD patients. The ex-
amination requires observation and interview by
a professional clinician. The scale is distributed
into 4 sections: (i) Mentation, behavior and mood,
(ii) Activities of daily living (ADL), (iii) Motor
sections, and (iv) Motor complications.

One of the most common motor problems is
related to speech impairments in PD (Jankovic,
2008). Most of the patients with PD show dis-
abilities in speech production. The most common
speech disturbances are monotonic speech, hypo-
phonia (a speech weakness in the vocal muscula-
ture and vocal sounds) and hypokinetic dysarthria.
These symptoms reduce the intelligibility of the
patients, and affect different aspects of the speech
production such as articulation, phonation, nasal-
ity, and prosody (Little et al., 2009; Goetz et al.,
2008; Ramig et al., 2001). Therefore, there is a
great interest to develop tools or methods to eval-
uate and improve the speech production of PD pa-
tients.

1MDS-UPDRS is the most updated version of the UP-
DRS.



75

Recently, there has been a proliferation of new
speech recognition-based tools for the acoustic
analysis of PD. The use of speech recognition
software in clinical examinations could make a
powerful supplement to the state-of-the-art sub-
jective reports of experts and clinicians that are
costly and time-consuming (e.g., Little et al.,
2009; Hernandez-Espinosa et al., 2002). In the
clinical field, the detection of PD is a complex task
due to the fact that the symptoms of this disease
are more related to clinicians’ observations and
perception of the way patients move and speak.

Recently, machine learning tools are used to de-
velop speech recognition systems that make the
whole process of objective evaluation and recogni-
tion faster and more accurate than analytical clini-
cians’ methods (Yu and Deng, 2016; Hernandez-
Espinosa et al., 2002). Using machine learning
techniques to extract acoustic features for detect-
ing the PD has become widely used in recent stud-
ies (e.g., Dahl et al., 2012; Little et al., 2009).

Automatic speech recognition (ASR) systems
are used to decode and transcribe oral speech. In
other words, the goal of ASR systems is to find and
recognize the words that best represent the acous-
tic signal. For example, automatic speech recog-
nition systems are used to evaluate how speech in-
telligibility is affected by the disease.

This study will seek to further investigate the
speech patterns of HC and PD groups using
recordings from patients speaking in German,
Spanish, and Czech. Most of the previous studies
only considered recordings in one language and
focused on it for detecting PD, but in this study,
we plan to evaluate the effect of the PD in three
different languages.

2 Related work: ASR for detecting PD
symptoms

Speech can be measured by acoustic tools sim-
ply using aperiodic vibrations in the voice. The
field of speech recognition has been improved
in recent years by research in computer-assisted
speech training system for therapy (Beijer and Ri-
etvel, 2012) machine learning techniques, which
can lead to establish efficient biomarkers to dis-
criminate HC from people with PD (e.g., Orozco-
Arroyave et al., 2013).

There are a vast number of advanced tech-
niques to design ASR systems: hybrid Deep Neu-

ral Networks-Hidden Markov Models (DNN 2-
HMM) (Hinton et al., 2012) and Convolutional
Neural Networks (CNN) (Abdel-Hamid et al.,
2014). Deep neural networks have recently re-
ceived increasing attention in speech recognition
(Canevari et al., 2013). Other studies have high-
lighted the strength of the DNN-HMM framework
for speech recognition (e.g., Dahl et al., 2012).

On the other hand, regarding the assessment of
PD from speech, Skodda et al. (2011) assessed
the progression of speech impairments of PD from
2002 to 2012 in a longitudinal study by only using
a statistical test to evaluate changes in aspects re-
lated to voice, articulation, prosody, and fluency of
the recorded speech.

Orozco-Arroyave et al. (2016) considered more
than one language for producing isolated words
for discriminating PDs from HCs. The character-
ization and classification processes were based on
a method on the systematic separation of voiced
and unvoiced segments of speech in their study.
Vásquez-Correa et al. (2017) analyzed the ef-
fect of acoustic conditions on different algorithms.
The obtained detection accuracy of PD speech was
reported and shown that the background noise af-
fect the performance of the different algorithms.
However, most of these systems are not yet capa-
ble of automatically detecting speech impairment
of individual speech sounds, which are known
to have an impact on speech intelligibility (Zhao
et al., 2010; Ramaker et al., 2002).

Our goal is to develop robust ASR systems for
pathological speech and incorporate the ASR tech-
nology to detect their speech intelligibility prob-
lems. A major interest is to investigate acoustic
features in the mentioned languages (differences
and similarities), including gender differences be-
tween subject (HC & PD) groups. The overall pur-
pose of this project is to address the question of
whether cross-lingual speech intelligibility among
PDs and HCs can help the recognition system to
detect the correct disease. The classification of
PD from speech in different languages has to be
carefully conducted to avoid bias towards the lin-
guistic content present in each language. For in-
stance, Czech and German languages are richer
than Spanish language in terms of consonant pro-
duction, which may cause that it is easier to pro-
duce consonant sounds by Czech PD patients than

2DNN is a feed-forward neural network that has more
than one layer of hidden units between its inputs and its out-
puts (Hinton et al., 2012).



76

by Spanish PD patients. In addition, with the
use of transfer learning strategies, a model trained
with utterances from one language can be used as
a base model to train a model in a different lan-
guage.

After reviewing the aforementioned literature,
the main contribution of our research for modeling
speech signals in PD patients is twofold:

• This is one of the first cross-lingual stud-
ies done to evaluate speech of people with
PD. This work requires a database consisting
of recordings of different languages. There
is currently a lack of cross-lingual research,
which provides reliable classification meth-
ods for assessing PDs’ speech available in the
literature.

• Using speech data is expected to help the de-
velopment of a diagnostic of PD patients.

This project seeks to bridge the gap in speech
recognition for speech of PD, with the hope of
moving towards a higher adoption rate of ASR-
based technologies in the diagnosis of patients.

3 The set-up of the ASR system

In this work, we will build an ASR system to rec-
ognize the speech of patients of Parkinson’s Dis-
ease. The task of ASR is to convert this raw au-
dio into text. The ASR system is created based
on three models: acoustic model (i.e. to recognize
phonemes), pronunciation model (i.e. to map se-
quence of phonemes into word sequences), and
language model (i.e. to estimate probabilities of
word sequences). We place particular emphasis
on the acoustic model portion of the system. We
also provide some acoustic models output features
that could be used in future speech recognition of
PD severity in the clinical field. Ravanelli et al.
(2019) stated that along with the improvement of
ASR systems, several deep learning frameworks
(e.g., TensorFlow (Abadi et al., 2016)) in machine
learning are also widely used.

The next section describes the process for mod-
eling the intelligibility of PD speech followed by
the description of processes whether the speech
signal is from PD patient or from HC subjects.

3.1 Training
The proposed ASR system will be developed us-
ing a standard state-of-the-art architecture hybrid
DNN-HMM (see Nassif et al., 2019 for more

information about the existing models in ASR),
built using the Kaldi speech recognition toolkit
3. The preprocessing (i.e. Feature extraction) of
the acoustic signal into usable parameters (i.e. la-
bel computation) tries to remove any acoustic in-
formation that is not useful for the task; it will
be done before beginning to train the acoustic
model. In this study, we will use Mel-frequency
Cepstral coefficients (MFCC) and Mel filter bank
energies (e.g., compute-mfcc-feats and compute-
fbank-feats) to train the acoustic models of the
ASR systems. The task of calculating MFCCs
from acoustic features is to characterize an under-
lying signal using spectrograms and represent the
shape of the vocal tract including tongue, teeth etc.

It was observed that filter bank (fbank), one of
the most popular speech recognition features, per-
forms better than MFCCs when used with deep
neural networks (Hinton et al., 2012). The purpose
of using acoustic model is to help us to get bound-
aries of the phoneme labels. The acoustic models
will be trained based on different acoustic features
extracted in Kaldi ”nnet3” recipes. The extracted
acoustic features and the observation probabilities
of our ASR system will be used to train the hybrid
DNN-HMM acoustic model. The performance of
an ASR system will be measured by Word Error
Rate (WER) of the transcript produced by the sys-
tem against the target transcript.

PyTorch: PyTorch is one of the most well
known deep learning toolkit that facilitates the de-
sign of neural architectures. This tool will be used
to design new DNN architectures to improve the
performance of the ASR system. We will addition-
ally use PyTorch-Kaldi (Ravanelli et al., 2019),
to train4 deep neural network based models (e.g.,
DNNs, CNNs, and Recurrent Neural Networks
(RNNs) models) and traditional machine learning
classifier. Ravanelli et al. (2019) stated that this
PyTorch-Kaldi toolkit acts like an interface with
different speech recognition features in it and can
be used as a state-of-the-art in the field of ASR
(See Figure 1). Figure 1 is shown the general
methodology that will be applied in this research.

3Kaldi: http://kaldi-asr.org/doc/
4PyTorch-Kaldi:https://github.com/

mravanelli/pytorch-kaldi

http://kaldi-asr.org/doc/
https://github.com/mravanelli/pytorch-kaldi
https://github.com/mravanelli/pytorch-kaldi


77

Figure 1: ASR system architecture that will be used in
this study (Ravanelli et al., 2019).

4 Methods

4.1 Data
The data of this study comes from an extended ver-
sion of PC-GITA database for Spanish (Orozco-
Arroyave et al., 2014), German (Skodda et al.,
2011), and Czech (Rusz et al., 2011) with more
recordings from PDs and HCs. The database con-
sists of both PD and HC subjects.

All subjects were asked to do multiple types of
speaking tasks to understand how speech changes
in different conditions, due to the fact that voice
variation is difficult to identify without human ex-
perience (Jeancolas et al., 2017). The speech di-
mensions considered in this project are phonation,
articulation and prosody (See Figure 2).

Figure 2: Speech dimensions: Phonation, Articulation
and Prosody.

For each subject, speech material includes
(i) sustained vowel phonation; participants were
asked to phonate vowels for several seconds;,
(ii) rapid syllable repetition (ideally Diadochoki-
netic (DDK)); participants were asked to produce
such as /pa-ta-ka/, /pa-ka-ta/, /pe-ta-ka/, /pa/, /ta/,

and /ka/, (iii) connected speech, consisting of:,
(iv) reading a specific text, and (v) spontaneous
speech.

This dataset consists of speech samples
recorded from 88 PD and 88 HC German speak-
ing participants, 50 PD and 50 HC Spanish
speaking participants (balanced in age and gen-
der), and 20 PD and 16 HC Czech speaking
participants. These speech samples were assessed
by expert neurologists using UPDRS-III and
H & Y scales. Their neurological labels were
reported based on the UPDRS-III and H & Y
scales (mean± SD) for each PD group:

• PD-German: UPDRS-III (22.7 ± 10.9), H&Y (2.4 ±
0.6)

• PD-Spanish: UPDRS-III (36.7 ± 18.7), H&Y (2.3 ±
0.8)

• PD-Czech: UPDRS-III (17.9± 7.3), H&Y (2.2± 0.5)

Further details are shown in Table 1:

Language HC PDFemale Male Female Male

German n= 44(63.8± 12.7 )
n= 44

(62.6± 15.2)
n= 41

(66.2± 9.7)
n= 47

(66.7± 8.4)

Spanish n= 25(61.4± 7.0)
n= 25

(60.3± 11.6)
n= 25

(60.7± 7.3)
n= 25

(61.6± 11.2)

Czech — n= 16(61.8± 13.3) —
n= 20

(61± 12)

Table 1: Age information of HC and PD subjects in
the study (n = number of participant) & the mean and
standard deviation are in the parenthesis (Mean±SD).

Although the size of the data is not big enough,
the vocabulary that was used by the patients in
the capture process of the speech was fixed. This
aspect compensates the need to have a huge cor-
pus to evaluate a vocabulary dependent task like
the assessment of pathological speech (see Parra-
Gallego et al., 2018).

4.2 Sample
Praat software (Boersma and Weenink, 2016) is
used for segmenting speech, extracting acoustics
features, removing silence from beginning and
end of speech file and visualization of speech
data. Generally, spoken words, represented as
sound waves, have two axes: time on the x-
axis and amplitude on the y-axis. Figure 3 illus-
trates the example of input feature maps extracted
from the speech signal which shows the selected
spectrograms (the audio waveform is encoded as
a representation) of PD and HC subjects when
they pronounce the syllable /pa-ta-ka/ that con-
vey 3-dimensional information in 2 dimensions



78

(a) HC (b) PD

Figure 3: Top: Raw waveforms of /pa-ta-ka/ (x-axis: time; y-axis: amplitude). Middle: Spectrograms (x-axis:
time; y-axis: frequency; shading: amplitude (energy), darker means higher). Bottom: the word-level annotation
of the signal.

(i.e. Time: x-axis, Frequency: y-axis, and Ampli-
tude: color intensity). The proposed model will
be able to identify specific aspects in the speech
related to the pronunciation of consonants, which
are the most affected aspects of the speech of the
patients due to the disease. The segmentation pro-
cess will be performed using a trained model to de-
tect phonological classes, like those ones used in
the previous studies (Vásquez-Correa et al., 2019;
Cernak et al., 2017). Figure 3 shows the possi-
ble differences in articulation and phonation in PD
and HC subjects. By using Praat, the speech sam-
ples of syllable /pa-ta-ka/ will be segmented into
vowel and consonant frames. The contour of HC
sample is more stable than the obtained contour
from PD sample. In each sample, silences will be
removed from the beginning and the end of each
token, using Praat.

5 Conclusion

In this research proposal, we introduced and de-
scribed the background for speech recognition of
PD patients. The focus is on Parkinsons disease
speech recognition based on the acoustic analysis
of their voice. A brief overview of clinical and
machine learning research in this field was pro-
vided. The goal is to improve the ASR system to
be able to model and detect PD patients indepen-
dently from their language by taking speech as an
input and using machine learning and natural lan-
guage processing technologies to advance health-
care and provide an overview of the patients men-

tal health. All in all, the proposed method should
be able to detect the patient with PD and discrimi-
nate them from HC subjects.

References
Martn Abadi, Paul Barham, Jianmin Chen, Zhifeng

Chen, Andy Davis, Jeffrey Dean, Matthieu Devin,
Sanjay Ghemawat, Geoffrey Irving, Michael Isard,
Manjunath Kudlur, Josh Levenberg, Rajat Monga,
Sherry Moore, Derek G Murray, Benoit Steiner,
Paul Tucker, Vijay Vasudevan, Pete Warden, Mar-
tin Wicke, Yuan Yu, Xiaoqiang Zheng, and Google
Brain. 2016. TensorFlow: A System for Large-
Scale Machine Learning TensorFlow: A system for
large-scale machine learning. In In 12th {USENIX}
Symposium on Operating Systems Design and Im-
plementation ({OSDI} 16), pages 265–283.

Ossama Abdel-Hamid, Abdel Rahman Mohamed, Hui
Jiang, Li Deng, Gerald Penn, and Dong Yu. 2014.
Convolutional neural networks for speech recogni-
tion. IEEE Transactions on Audio, Speech and Lan-
guage Processing, 22(10):1533–1545.

Lilian Beijer and Toni Rietvel. 2012. Potentials of
Telehealth Devices for Speech Therapy in Parkin-
son’s Disease. In Diagnostics and Rehabilitation of
Parkinson’s Disease. InTech, pages 379–402.

Paul Boersma and David Weenink. 2016. Praat: Doing
phonetics by computer (Version 6.0. 14). Retrieved
from (last access: 29.04. 2018).

Claudia Canevari, Leonardo Badino, Luciano Fadiga,
and Giorgio Metta Rbcs. 2013. Cross-corpus and
cross-linguistic evaluation of a speaker-dependent
DNN-HMM ASR system using EMA data. In In
Speech Production in Automatic Speech Recognition
(In SPASR-2013), pages 29–33.

https://tensorflow.org.
https://tensorflow.org.
https://tensorflow.org.
https://doi.org/10.1109/TASLP.2014.2339736
https://doi.org/10.1109/TASLP.2014.2339736
https://doi.org/10.5772/17865
https://doi.org/10.5772/17865
https://doi.org/10.5772/17865
http://www.isca-speech.org/archive
http://www.isca-speech.org/archive
http://www.isca-speech.org/archive


79

Milos Cernak, Juan Rafael Orozco-Arroyave, Frank
Rudzicz, Heidi Christensen, Juan Camilo Vásquez-
Correa, and Elmar Nöth. 2017. Characterisation
of voice quality of Parkinson’s disease using dif-
ferential phonological posterior features. Computer
Speech and Language, 46(June):196–208.

George E. Dahl, Dong Yu, Li Deng, and Alex Acero.
2012. Context-dependent pre-trained deep neural
networks for large-vocabulary speech recognition.
IEEE Transactions on Audio, Speech and Language
Processing, 20(1):30–42.

David T. Dexter and Peter Jenner. 2013. Parkinson dis-
ease: from pathology to molecular disease mecha-
nisms. Free Radical Biology and Medicine, 62:132–
144.

Stanley Fahn. 2003. Description of Parkinson’s Dis-
ease as a Clinical Syndrome. Annals of the New York
Academy of Sciences, 991(1):1–14.

Christopher G. Goetz, Barbara C. Tilley, Stephanie R.
Shaftman, Glenn T. Stebbins, Stanley Fahn, Pablo
Martinez-Martin, Werner Poewe, Cristina Sampaio,
Matthew B. Stern, Richard Dodel, Bruno Dubois,
Robert Holloway, Joseph Jankovic, Jaime Kuli-
sevsky, Anthony E. Lang, Andrew Lees, Sue Leur-
gans, Peter A. LeWitt, David Nyenhuis, C. Warren
Olanow, Olivier Rascol, Anette Schrag, Jeanne A.
Teresi, Jacobus J. van Hilten, and Nancy LaPelle.
2008. Movement Disorder Society-sponsored revi-
sion of the Unified Parkinson’s Disease Rating Scale
(MDS-UPDRS): Scale presentation and clinimetric
testing results. Movement Disorders, 23(15):2129–
2170.

Carlos Hernandez-Espinosa, Pedro Gomez-Vilda,
Juan I. Godino-Llorente, and Santiago Aguilera-
Navarro. 2002. Diagnosis of vocal and voice dis-
orders by the speech signal. In Proceedings of the
IEEE-INNS-ENNS International Joint Conference
on Neural Networks. IJCNN 2000. Neural Comput-
ing: New Challenges and Perspectives for the New
Millennium, pages 253–258. IEEE.

Geoffrey Hinton, Li Deng, Dong Yu, George Dahl,
Abdel Rahman Mohamed, Navdeep Jaitly, Andrew
Senior, Vincent Vanhoucke, Patrick Nguyen, Tara
Sainath, and Brian Kingsbury. 2012. Deep neu-
ral networks for acoustic modeling in speech recog-
nition: The shared views of four research groups.
IEEE Signal Processing Magazine, 29(6):82–97.

Joseph Jankovic. 2008. Parkinsons disease: clinical
features and diagnosis. Journal of Neurology, Neu-
rosurgery & Psychiatry, 79(4):368–376.

Laetitia Jeancolas, Habib Benali, Badr-Eddine
Benkelfat, Graziella Mangone, Jean-Christophe
Corvol, Marie Vidailhet, Stephane Lehericy, and
Dijana Petrovska-Delacretaz. 2017. Automatic
detection of early stages of Parkinson’s disease
through acoustic voice analysis with mel-frequency
cepstral coefficients. In International Conference

on Advanced Technologies for Signal and Image
Processing (ATSIP), pages 1–6. IEEE.

Max A Little, Patrick E McSharry, Eric J Hunter, Jen-
nifer Spielman, and Lorraine O Ramig. 2009. Suit-
ability of dysphonia measurements for telemonitor-
ing of Parkinson’s disease. IEEE transactions on
bio-medical engineering, 56(4):1015.

Ali Bou Nassif, Ismail Shahin, Imtinan Attili, Moham-
mad Azzeh, and Khaled Shaalan. 2019. Speech
Recognition Using Deep Neural Networks: A Sys-
tematic Review. IEEE Access, 7:19143–19165.

Juan R. Orozco-Arroyave, Julin D. Arias-Londoño, Je-
sus Francisco V. Bonilla, Mara C. Gonzalez-Rátiva,
and Elmar Nöth. 2014. New Spanish speech corpus
database for the analysis of people suffering from
Parkinson’s disease. In Language Resources and
Evaluation Conference, LREC, pages 342–347.

Juan R. Orozco-Arroyave, Julin D. Arias-Londoño,
Jess F. Vargas-Bonilla, and Elmar Nöth. 2013. Anal-
ysis of Speech from People with Parkinsons Disease
through Nonlinear Dynamics. In International con-
ference on nonlinear speech processing, pages 112–
119. Springer, Berlin, Heidelberg.

Juan R. Orozco-Arroyave, Juan C. Vádsquez-Correa,
Florian Honig, Julin D. Arias-Londono, Jess F.
Vargas-Bonilla, Sabine Skodda, Jan Rusz, and El-
mar Nöth. 2016. Towards an automatic monitoring
of the neurological state of Parkinson’s patients from
speech. ICASSP, IEEE International Conference on
Acoustics, Speech and Signal Processing - Proceed-
ings, 2016-May(March):6490–6494.

James Parkinson. 2002. An Essay on the Shaking
Palsy. The Journal of Neuropsychiatry and Clinical
Neurosciences, 14(2):223–236.

Luis F. Parra-Gallego, Toms Arias-Vergara, Juan C.
Vásquez-Correa, Nicanor Garcia-Ospina, Juan R.
Orozco-Arroyave, and Elmar Nöth. 2018. Auto-
matic Intelligibility Assessment of Parkinsons Dis-
ease with Diadochokinetic Exercises. pages 223–
230. Springer, Cham.

Claudia Ramaker, Johan Marinus, Anne Margarethe
Stiggelbout, and Bob Johannes van Hilten. 2002.
Systematic evaluation of rating scales for impair-
ment and disability in Parkinson’s disease. Move-
ment Disorders, 17(5):867–876.

Lorraine Olson Ramig, Steven Gray, Kristin Baker,
Kim Corbin-Lewis, Eugene Buder, Erich Luschei,
Hillary Coon, and Marshall Smith. 2001. The aging
voice: A review, treatment data and familial and ge-
netic perspectives. Folia Phoniatrica et Logopaed-
ica, 53(5):252–265.

Mirco Ravanelli, Titouan Parcollet, and Yoshua Ben-
gio. 2019. The PyTorch-Kaldi Speech Recognition
Toolkit. ICASSP 2019 - 2019 IEEE International
Conference on Acoustics, Speech and Signal Pro-
cessing (ICASSP), pages 6465–6469.

https://doi.org/10.1016/j.csl.2017.06.004
https://doi.org/10.1016/j.csl.2017.06.004
https://doi.org/10.1016/j.csl.2017.06.004
https://doi.org/10.1109/TASL.2011.2134090
https://doi.org/10.1109/TASL.2011.2134090
https://doi.org/10.1016/j.freeradbiomed.2013.01.018
https://doi.org/10.1016/j.freeradbiomed.2013.01.018
https://doi.org/10.1016/j.freeradbiomed.2013.01.018
https://doi.org/10.1111/j.1749-6632.2003.tb07458.x
https://doi.org/10.1111/j.1749-6632.2003.tb07458.x
https://doi.org/10.1002/mds.22340
https://doi.org/10.1002/mds.22340
https://doi.org/10.1002/mds.22340
https://doi.org/10.1002/mds.22340
https://doi.org/10.1109/ijcnn.2000.860781
https://doi.org/10.1109/ijcnn.2000.860781
https://doi.org/10.1109/MSP.2012.2205597
https://doi.org/10.1109/MSP.2012.2205597
https://doi.org/10.1109/MSP.2012.2205597
https://doi.org/10.1136/JNNP.2007.131045
https://doi.org/10.1136/JNNP.2007.131045
https://doi.org/10.1109/ATSIP.2017.8075567
https://doi.org/10.1109/ATSIP.2017.8075567
https://doi.org/10.1109/ATSIP.2017.8075567
https://doi.org/10.1109/ATSIP.2017.8075567
https://doi.org/10.1109/TBME.2008.2005954
https://doi.org/10.1109/TBME.2008.2005954
https://doi.org/10.1109/TBME.2008.2005954
https://doi.org/10.1109/ACCESS.2019.2896880
https://doi.org/10.1109/ACCESS.2019.2896880
https://doi.org/10.1109/ACCESS.2019.2896880
https://doi.org/10.1007/978-3-642-38847-7{_}15
https://doi.org/10.1007/978-3-642-38847-7{_}15
https://doi.org/10.1007/978-3-642-38847-7{_}15
https://doi.org/10.1109/ICASSP.2016.7472927
https://doi.org/10.1109/ICASSP.2016.7472927
https://doi.org/10.1109/ICASSP.2016.7472927
https://doi.org/10.1176/jnp.14.2.223
https://doi.org/10.1176/jnp.14.2.223
https://doi.org/10.1007/978-3-030-00353-1{_}20
https://doi.org/10.1007/978-3-030-00353-1{_}20
https://doi.org/10.1007/978-3-030-00353-1{_}20
https://doi.org/10.1002/mds.10248
https://doi.org/10.1002/mds.10248
https://doi.org/10.1159/000052680
https://doi.org/10.1159/000052680
https://doi.org/10.1159/000052680
https://doi.org/10.1109/ICASSP.2019.8683713
https://doi.org/10.1109/ICASSP.2019.8683713


80

Jan Rusz, Roman Cmejla, Hana Ruzickova, and Evzen
Ruzicka. 2011. Quantitative acoustic measurements
for characterization of speech and voice disorders in
early untreated Parkinsons disease. The Journal of
the Acoustical Society of America, 129(1):350–367.

Sabine Skodda, Wenke Visser, and Uwe Schlegel.
2011. Vowel Articulation in Parkinson’s Disease.
Journal of Voice, 25(4):467–472.

Juan C. Vásquez-Correa, Philipp Klumpp, Juan R.
Orozco-Arroyave, and Elmar Nöth. 2019. Phonet:
a Tool Based on Gated Recurrent Neural Networks
to Extract Phonological Posteriors from Speech. In
Proceedings of INTERSPEECH conference (Under
review).

Juan C. Vásquez-Correa, Joan Serrà, Juan R. Orozco-
Arroyave, Jess F. Vargas-Bonilla, and Elmar Nöth.
2017. Effect of acoustic conditions on algo-
rithms to detect Parkinson’s disease from speech.
ICASSP, IEEE International Conference on Acous-
tics, Speech and Signal Processing - Proceedings,
pages 5065–5069.

Martine Visser, Albert F.G. Leentjens, Johan Marinus,
Anne M. Stiggelbout, and Jacobus J. van Hilten.
2006. Reliability and validity of the Beck depres-
sion inventory in patients with Parkinson’s disease.
Movement Disorders, 21(5):668–672.

Dong Yu and Li Deng. 2016. Automatic Speech
Recognition-A Deep Learning Approach. Springer
london limited.

Ying J. Zhao, Hwee L. Wee, Yiong H. Chan, Soo H.
Seah, Wing L. Au, Puay Ngoh Lau, Emmanuel C.
Pica, Shu Ch. Li, Nan Luo, and Louis C S Tan. 2010.
Progression of Parkinson’s disease as evaluated by
Hoehn and Yahr stage transition times. Movement
Disorders, 25(6):710–716.

https://doi.org/10.1121/1.3514381
https://doi.org/10.1121/1.3514381
https://doi.org/10.1121/1.3514381
https://doi.org/10.1016/J.JVOICE.2010.01.009
https://doi.org/10.1109/ICASSP.2017.7953121
https://doi.org/10.1109/ICASSP.2017.7953121
https://doi.org/10.1002/mds.20792
https://doi.org/10.1002/mds.20792
https://doi.org/10.1002/mds.22875
https://doi.org/10.1002/mds.22875

