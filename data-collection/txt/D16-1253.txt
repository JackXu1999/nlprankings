



















































Bilingually-constrained Synthetic Data for Implicit Discourse Relation Recognition


Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2306–2312,
Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics

Bilingually-constrained Synthetic Data for Implicit Discourse Relation
Recognition

Changxing Wu1,2, Xiaodong Shi1,2∗, Yidong Cheng1,2, Yanzhou Huang1,2, Jinsong Su3
Fujian Key Lab of the Brain-like Intelligent Systems, Xiamen University, China1

School of Information Science and Technology, Xiamen University, China2

School of Software, Xiamen University, China3

{wcxnlp, huangyanzhou163}@163.com
{mandel, ydchen, jssu}@xmu.edu.cn

Abstract

To alleviate the shortage of labeled data, we
propose to use bilingually-constrained syn-
thetic implicit data for implicit discourse re-
lation recognition. These data are extracted
from a bilingual sentence-aligned corpus ac-
cording to the implicit/explicit mismatch be-
tween different languages. Incorporating
these data via a multi-task neural network
model achieves significant improvements over
baselines, on both the English PDTB and Chi-
nese CDTB data sets.

1 Introduction

Discovering the discourse relation between two sen-
tences is crucial to understanding the meaning of
a coherent text, and also beneficial to many down-
stream NLP applications, such as question answer-
ing and machine translation. Implicit discourse re-
lation recognition (DRRimp) remains a challenging
task due to the absence of strong surface clues like
discourse connectives (e.g. but). Most work re-
sorts to large amounts of manually designed features
(Soricut and Marcu, 2003; Pitler et al., 2009; Lin et
al., 2009; Louis et al., 2010; Rutherford and Xue,
2014), or distributed features learned via neural net-
work models (Braud and Denis, 2015; Zhang et al.,
2015; Ji and Eisenstein, 2015). The above methods
usually suffer from limited labeled data.

Marcu and Echihabi (2002) attempt to create la-
beled implicit data automatically by removing con-
nectives from explicit instances, as additional train-
ing data. These data are usually called as syn-

∗Corresponding author.

thetic implicit data (hereafter SynData). How-
ever, Sporleder and Lascarides (2008) argue that
SynData has two drawbacks: 1) meaning shifts
in some cases when removing connectives, and 2)
a different word distribution with the real implicit
data. They also show that using SynData directly
degrades the performance. Recent work seeks to de-
rive valuable information from SynData while fil-
tering noise, via domain adaptation (Braud and De-
nis, 2014; Ji et al., 2015), classifying connectives
(Rutherford and Xue, 2015) or multi-task learning
(Lan et al., 2013; Liu et al., 2016), and shows
promising results.

ch: [社会     认为     有       青少年      问题,]Arg1 

en: [society reckons the existence of youth problems, ]Arg1

implicit=但是  [很多    青少年       认为   自己       没   问题.]Arg2

but [many young people do not think there is anything 

wrong with them.]Arg2 

     society reckon  existence  youth problems, 

but  many  young people  think  themselves no problems.

Figure 1: An example illustrating the implicit/explicit mis-
match between Chinese (ch) and English (en). A Chinese im-

plicit instance is translated into an English explicit one. In the

PDTB, a discourse instance is defined as a connective (e.g. but)

taking two arguments (Arg1 and Arg2).

Different from previous work, we propose to con-
struct bilingually-constrained synthetic implicit data
(called BiSynData) for DRRimp, which can alle-
viate the drawbacks of SynData. Our method is
inspired by the findings that a discourse instance ex-
pressed implicitly in one language may be expressed
explicitly in another. For example, Zhou and Xue

2306



(2012) show that the connectives in Chinese omit
much more frequently than those in English with
about 82.0% vs. 54.5%. Li et al. (2014a) further
argue that there are about 23.3% implicit/explicit
mismatchs between Chinese/English instances. As
illustrated in Figure 1, a Chinese implicit instance
where the connective �´ is absent, is translated
into an English explicit one with the connective but.
Intuitively, the Chinese instance is a real implicit
one which can be signaled by but. Hence, it could
potentially serve as additional training data for the
Chinese DRRimp, avoiding the different word dis-
tribution problem of SynData. Meanwhile, for the
English explicit instance, it is very likely that remov-
ing but would not lose any information since its Chi-
nese counterpart �´ can be omitted. Therefore it
could be used for the English DRRimp, alleviating
the meaning shift problem of SynData.

We extract our BiSynData from a Chinese-
English sentence-aligned corpus (Section 2). Then
we design a multi-task neural network model to in-
corporate the BiSynData (Section 3). Experimen-
tal results, on both the English PDTB (Prasad et al.,
2008) and Chinese CDTB (Li et al., 2014b), show
that BiSynData is more effective than SynData
used in previous work (Section 4). Finally, we re-
view the related work (Section 5) and draw conclu-
sions (Section 6).

2 BiSynData

Formally, given a Chinese-English sentence pair
(Sch, Sen), we try to find an English explicit in-
stance (Arg1en, Arg2en, Connen) in Sen1, and a
Chinese implicit instance (Arg1ch, Arg2ch) in Sch,
where (Arg1en, Arg2en, Connen) is the transla-
tion of (Arg1ch, Arg2ch). In most cases, dis-
course relations should be preserved during trans-
lating, so the connective Connen is potentially
a strong indicator of the discourse relation be-
tween not only Arg1en and Arg2en, but also
Arg1ch and Arg2ch. Therefore, we can con-
struct two synthetic implicit instances labeled by
Connen, denoted as 〈(Arg1en, Arg2en), Connen〉
and 〈(Arg1ch, Arg2ch), Connen〉, respectively. We
refer to these synthetic instances as BiSynData be-

1In our experiments, we use the pdtb-parser toolkit (Lin et
al., 2014) to identify English explicit instances.

cause they are constructed according to the bilingual
implicit/explicit mismatch.

Conn. Freq. Conn. Freq.
and 14294 while 1031
if 2580 before 822
as 1951 also 552

when 1521 since 511
but 1122 because 503

Table 1: Top 10 most frequent connectives in our BiSynData.

In our experiments, we extract our BiSynData
from a combined corpus (FBIS and HongKong
Law), with about 2.38 million Chinese-English sen-
tence pairs. We generate 30,032 synthetic En-
glish instances and the same number of Chinese in-
stances, with 80 connectives, as our BiSynData.
Table 1 lists the top 10 most frequent connec-
tives in our BiSynData, which are roughly con-
sistent with the statistics of Chinese/English im-
plicit/explicit mismatches in (Li et al., 2014a). Ac-
cording to connectives and their related relations
in the PDTB, in most cases, and and also indi-
cate the Expansion relation, if and because the
Contigency relation, before the Temporal rela-
tion, and but the Comparison relation. Connec-
tives as, when, while and since are ambiguous.
For example, while can indicate the Comparison
or Temporal relation. Overall, our constructed
BiSynData covers all four main discourse rela-
tions defined in the PDTB.

With our BiSynData, we define two connec-
tive classification tasks: 1) given (Arg1en, Arg2en)
to predict the connective Connen, and 2) given
(Arg1ch, Arg2ch) to predict Connen. We incorpo-
rate the first task to help the English DRRimp, and
the second for the Chinese DRRimp. It is worthy
to note that we use English connectives themselves
as classification labels rather than mapping them to
relations in both tasks.

3 Multi-Task Neural Network Model

We design a Multi-task Neural Network Model (de-
noted as MTN ), which incorporates a connective
classification task on BiSynData (auxiliary task)
to benefit DRRimp (main task). In general, the more
related two tasks are, the more powerful a multi-task
learning method will be. In the current problem, the

2307



two tasks are essentially the same, just with differ-
ent output labels. Therefore, as illustrated in Fig-
ure 2, MTN shares parameters in all feature layers
(L1-L3) and uses two separate classifiers in the clas-
sifier layer (L4). For each task, given an instance
(Arg1, Arg2), MTN simply averages embeddings
of words to represent arguments, as vArg1 and vArg2 .
These two vectors are then concatenated and trans-
formed through two non-linear hidden layers. Fi-
nally, the corresponding softmax layer is used to
perform classification.

3

mainw

3

auxw

1w 2w

Main Task

Aux Task

1L 2L 3L 4L

1Argv

2Argv

Figure 2: MTN with four layers L1-L4.

MTN ignores the word order in arguments and
uses two hidden layers to capture the interactions
between two arguments. The idea behind MTN is
borrowed from (Iyyer et al., 2015), where a deep
averaging network achieves close to the state-of-
the-art performance on text classification. Though
MTN is simple, it is easy to train and efficient on
both memory and computational cost. In addition,
the simplicity of MTN allows us to focus on mea-
suring the quality of BiSynData.

We use the cross-entropy loss function and mini-
batch AdaGrad (Duchi et al., 2011) to optimize pa-
rameters. Pre-trained word embeddings are fixed.
We find that fine-tuning word embeddings during
training leads to severe overfitting in our experi-
ments. Following Liu et al. (2016), we alternately
use two tasks to train the model, one task per epoch.
For tasks on both the PDTB and CDTB, we use the
same hyper-parameters. The dimension of word em-
bedding is 100. We set the size of L2 to 200, and
L3 to 100. ReLU is used as the non-linear func-
tion. Different learning rates 0.005 and 0.001 are
used in the main and auxiliary tasks, respectively. To
avoid overfitting, we randomly drop out 20% words

in each argument following Iyyer et al. (2015). All
hyper-parameters are tuned on the development set.

4 Experiments

We evaluate our method on both the English PDTB
and Chinese CDTB data sets. We tokenize English
data and segment Chinese data using the Stanford
CoreNLP toolkit (Manning et al., 2014). The En-
glish/Chinese Gigaword corpus (3rd edition) is used
to train the English/Chinese word embeddings via
word2vec (Mikolov et al., 2013), respectively. Due
to the skewed class distribution of test data (see Sec-
tion 4.1), we use the macro-averaged F1 for perfor-
mance evaluation.

4.1 On the PDTB

Following Rutherford and Xue (2015), we perform a
4-way classification on the top-level discourse rela-
tions: Temporal (Temp), Comparison (Comp),
Contigency (Cont) and Expansion (Expa). Sec-
tions 2-20 are used as training set, sections 0-1
as development set and sections 21-22 as test set.
The training/test set contains 582/55 instances for
Temp, 1855/145 for Comp, 3235/273 for Cont
and 6673/538 for Expa. The top 20 most frequent
connectives in our BiSynData are considered in
the auxiliary task, with 28,013 synthetic English in-
stances in total.

STN MTNbi
Temp P 33.33 34.48

R 14.55 18.18
F1 20.25 23.81

Comp P 38.54 42.11
R 25.52 33.10
F1 30.71 37.07

Cont P 38.36 44.22
R 41.03 40.66
F1 39.65 42.37

Expa P 59.60 62.56
R 66.36 71.75
F1 62.80 66.84

macro F1 38.35 42.52
Table 2: Results of 4-way classification on the PDTB.

Table 2 shows the results of MTN combining our
BiSynData (denoted as MTNbi) on the PDTB.

2308



STN means we train MTN with only the main
task. On the macro F1, MTNbi gains an improve-
ment of 4.17% over STN . The improvement is sig-
nificant under one-tailed t-test (p<0.05). A closer
look into the results shows that MTNbi performs
better across all relations, on the precision, recall
and F1 score, except a little drop on the recall of
Cont. The reason for the recall drop of Cont is
not clear. The greatest improvement is observed on
Comp, up to 6.36% F1 score. The possible reason
is that only while is ambiguous about Comp and
Temp, while as, when and since are all ambigu-
ous about Temp and Cont, among top 10 connec-
tives in our BiSynData. Meanwhile the amount
of labeled data for Comp is relatively small. Over-
all, using BiSynData under our multi-task model
achieves significant improvements on the English
DRRimp. We believe the reasons for the improve-
ments are twofold: 1) the added synthetic English
instances from our BiSynData can alleviate the
meaning shift problem, and 2) a multi-task learning
method is helpful for addressing the different word
distribution problem between implicit and explicit
data.

Considering some of the English connectives
(e.g., while) are highly ambiguous, we compare our
method with ones that uses only unambiguous con-
nectives. Specifically, we first discard as, when,
while and since in top 20 connectives, and get
22,999 synthetic instances. Then, we leverage these
instances in two different ways: 1) using them in our
multi-task model as above, and 2) using them as ad-
ditional training data directly after mapping unam-
biguous connectives into relations. Both methods
using only unambiguous connectives do not achieve
better performance. One possible reason is that these
synthetic instances become more unbalanced after
discarding ones with ambiguous connectives.

We also compare MTNbi with recent systems us-
ing additional training data. Rutherford and Xue
(2015) select explicit instances that are similar to the
implicit ones via connective classification, to enrich
the training data. Liu et al. (2016) use a multi-task
model with three auxiliary tasks: 1) conn: connec-
tive classification on explicit instances, 2) exp: re-
lation classification on the labeled explicit instances
in the PDTB, and 3) rst: relation classification on
the labeled RST corpus (William and Thompson,

System macro F1
1 Rutherford and Xue (2015) 40.50
2 Liu et al. (2016) conn 38.09
3 Liu et al. (2016) exp 39.03
4 Liu et al. (2016) rst 40.67
5 Liu et al. (2016) conn+exp+rst 44.98
6 MTNbi 42.52

Table 3: Comparison with recent systems on the PDTB. conn+
exp+ rst means using three auxiliary tasks simultaneously.

1988), which defines different discourse relations
with that in the PDTB. The results are shown in Ta-
ble 3. Although Liu et al. (2016) achieve the state-
of-the-art performance (Line 5), they use two ad-
ditional labeled corpora. We can find that MTNbi
(Line 6) yields better results than those systems in-
corporating SynData (Line 1, 2 and 3), or even the
labeled RST (Line 4). These results confirm that
BiSynData can indeed alleviate the disadvantages
of SynData effectively.

4.2 On the CDTB

Four top-level relations are defined in the CDTB,
including Transition (Tran), Causality (Caus),
Explanation (Expl) and Coordination (Coor).
We use instances in the first 50 documents as test
set, second 50 documents as development set and re-
maining 400 documents as training set. We conduct
a 3-way classification because of only 39 instances
for Tran. The training/test set contains 682/95 in-
stances for Caus, 1143/126 for Expl and 2300/347
for Coor. The top 20 most frequent connectives
(excluding and)2 in our BiSynData are consid-
ered in the auxiliary task, with 13,899 synthetic Chi-
nese instances in total. The results are shown in
Table 4. Compared with STN , MTNbi raises the
macro F1 from 55.44% to 58.28%. The improve-
ment is significant under one-tailed t-test (p<0.05).
Therefore, BiSynData is also helpful for the Chi-
nese DRRimp.

Because of no reported results on the CDTB, we
use MTN with two different auxiliary tasks as base-
lines: 1) exp: relation classification on the labeled

2Including and degrades the performance slightly. A pos-
sible reason is that and can be related to both the Expl and
Coor relations in the CDTB, and instances marked by and ac-
count for about half of our BiSynData.

2309



STN MTNbi
Caus P 47.92 52.94

R 24.21 28.42
F1 32.17 36.99

Expl P 54.62 53.47
R 56.35 61.11
F1 55.47 57.04

Coor P 74.36 78.02
R 83.57 83.86
F1 78.70 80.83

macro F1 55.44 58.28
Table 4: Results of 3-way classification on the CDTB.

explicit instances in the CDTB, including 466 in-
stances for Caus, 201 for Expl and 974 for Coor.
2) conn: connective classification on explicit in-
stances from the Xinhua part of the Chinese Giga-
word corpus. We collect explicit instances with the
top 20 most frequent Chinese connectives and sam-
ple 20,000 instances for the experiment. Both exp
and conn can be considered as tasks on SynData.
The results in Table 5 show that MTN incorporat-
ing BiSynData (Line 3) performs better than using
SynData (Line 1 and 2), for the task on the CDTB.

System macro F1
1 MTNexp 56.42
2 MTNconn 56.86
3 MTNbi 58.28

Table 5: MTN with different auxiliary tasks on the CDTB.

5 Related Work

One line of research related to DRRimp tries to
take advantage of explicit discourse data. Zhou et
al. (2010) predict the absent connectives based on
a language model. Using these predicted connec-
tives as features is proven to be helpful. Biran and
McKeown (2013) aggregate word-pair features that
are collected around the same connectives, which
can effectively alleviate the feature sparsity prob-
lem. More recently, Braud and Denis (2014) and Ji
et al. (2015) consider explicit data from a different
domain, and use domain adaptation methods to ex-
plore the effect of them. Rutherford and Xue (2015)
propose to gather weakly labeled data from explicit
instances via connective classification, which are

used as additional training data directly. Lan et al.
(2013) and Liu et al. (2016) combine explicit and
implicit data using multi-task learning models and
gain improvements. Different from all the above
work, we construct additional training data from a
bilingual corpus.

Multi-task neural networks have been success-
fully used for many NLP tasks. For example, Col-
lobert et al. (2011) jointly train models for the Part-
of-Speech tagging, chunking, named entity recogni-
tion and semantic role labeling using convolutional
network. Liu et al. (2015) successfully combine the
tasks of query classification and ranking for web
search using a deep multi-task neural network. Lu-
ong et al. (2016) explore multi-task sequence to
sequence learning for constituency parsing, image
caption generation and machine translation.

6 Conclusion

In this paper, we introduce bilingually-constrained
synthetic implicit data (BiSynData), which are
generated based on the bilingual implicit/explicit
mismatch, into implicit discourse relation recogni-
tion for the first time. On both the PDTB and CDTB,
using BiSynData as the auxiliary task significantly
improves the performance of the main task. We
also show that BiSynData is more beneficial than
the synthetic implicit data typically used in previous
work. Since the lack of labeled data is a major chal-
lenge for implicit discourse relation classification,
our proposed BiSynData can enrich the training
data and then benefit future work.

Acknowledgments

We would like to thank all the reviewers for their
constructive and helpful suggestions on this paper.
This work is partially supported by the Natural Sci-
ence Foundation of China (Grant Nos. 61573294,
61303082, 61672440), the Ph.D. Programs Founda-
tion of Ministry of Education of China (Grant No.
20130121110040), the Fund of Research Project
of Tibet Autonomous Region of China (Grant No.
Z2014A18G2-13), and the Natural Science Founda-
tion of Fujian Province (Grant No. 2016J05161).

2310



References

Or Biran and Kathleen McKeown. 2013. Aggregated
Word Pair Features for Implicit Discourse Relation
Disambiguation. In Proceedings of ACL (Volume 2:
Short Papers), pages 69–73, Sofia, Bulgaria.

Chloé Braud and Pascal Denis. 2014. Combining
Natural and Artificial Examples to Improve Implicit
Discourse Relation Identification. In Proceedings of
COLING, pages 1694–1705, Dublin, Ireland.

Chloé Braud and Pascal Denis. 2015. Comparing Word
Representations for Implicit Discourse Relation Clas-
sification. In Proceedings of EMNLP, pages 2201–
2211, Lisbon, Portugal.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011.
Natural Language Processing (Almost) from Scratch.
Journal of Machine Learning Research, 12(1):2493–
2537.

John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive Subgradient Methods for Online Learning
and Stochastic Optimization. The Journal of Machine
Learning Research, 12:2121–2159.

Mohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber,
and Hal Daumé III. 2015. Deep Unordered Com-
position Rivals Syntactic Methods for Text Classifi-
cation. In Proceedings of ACL-IJCNLP, pages 1681–
1691, Beijing, China.

Yangfeng Ji and Jacob Eisenstein. 2015. One Vector is
Not Enough: Entity-Augmented Distributed Seman-
tics for Discourse Relations. In Transactions of the
Association for Computational Linguistics, volume 3,
pages 329–344.

Yangfeng Ji, Gongbo Zhang, and Jacob Eisenstein. 2015.
Closing the Gap: Domain Adaptation from Explicit
to Implicit Discourse Relations. In Proceedings of
EMNLP, pages 2219–2224, Lisbon, Portugal.

Man Lan, Yu Xu, and Zhengyu Niu. 2013. Leveraging
Synthetic Discourse Data via Multi-task Learning for
Implicit Discourse Relation Recognition. In Proceed-
ings of ACL, pages 476–485, Sofia, Bulgaria.

Junyi Jessy Li, Marine Carpuat, and Ani Nenkova.
2014a. Cross-lingual Discourse Relation Analysis:
A Corpus Study and a Semi-supervised Classification
System. In Proceedings of COLING : Technical Pa-
pers, pages 577–587, Dublin, Ireland.

Yancui Li, Wenhe Feng, Jing Sun, Fang Kong, and
Guodong Zhou. 2014b. Building Chinese Dis-
course Corpus with Connective-driven Dependency
Tree Structure. In Proceedings of EMNLP, pages
2105–2114, Doha, Qatar.

Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng. 2009.
Recognizing Implicit Discourse Relations in the Penn

Discourse Treebank. In Proceedings of EMNLP,
pages 343–351, PA, USA.

Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2014. A
PDTB-styled End-to-end Discourse Parser. Natural
Language Engineering, 20(02):151–184.

Xiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng,
Kevin Duh, and Ye-Yi Wang. 2015. Representation
Learning Using Multi-task Deep Neural Networks for
Semantic Classification and Information Retrieval. In
Proceedings of NAACL, pages 912–921, Denver, Col-
orado.

Yang Liu, Sujian Li, Xiaodong Zhang, and Zhifang Sui.
2016. Implicit Discourse Relation Classification via
Multi-Task Neural Networks. In Proceedings of AAAI,
pages 2750–2756, Arizona, USA.

Annie Louis, Aravind Joshi, Rashmi Prasad, and Ani
Nenkova. 2010. Using Entity Features to Classify
Implicit Discourse Relations. In Proceedings of SIG-
DIAL, pages 59–62, PA, USA.

Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol
Vinyals, and Lukasz Kaiser. 2016. Multi-task Se-
quence to Sequence Learning. In Proceedings of
ICLR, pages 1–10, San Juan, Puerto Rico.

Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David McClosky.
2014. The Stanford CoreNLP Natural Language Pro-
cessing Toolkit. In Proceedings of ACL (System
Demonstrations), pages 55–60, Maryland, USA.

Daniel Marcu and Abdessamad Echihabi. 2002. An Un-
supervised Approach to Recognizing Discourse Rela-
tions. In Proceedings of ACL, pages 368–375, PA,
USA.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient Estimation of Word Represen-
tations in Vector Space. CoRR, abs/1301.3781.

Emily Pitler, Annie Louis, and Ani Nenkova. 2009. Au-
tomatic Sense Prediction for Implicit Discourse Rela-
tions in Text. In Proceedings of ACL-IJCNLP, pages
683–691, PA, USA.

Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The Penn Discourse TreeBank 2.0. In
Proceedings of LREC, volume 24, pages 2961–2968,
Marrakech, Morocco.

Attapol T. Rutherford and Nianwen Xue. 2014. Dis-
covering Implicit Discourse Relations Through Brown
Cluster Pair Representation and Coreference Patterns.
In Proceedings of EACL, pages 645–654, Gothenburg,
Sweden.

Attapol Rutherford and Nianwen Xue. 2015. Improving
the Inference of Implicit Discourse Relations via Clas-
sifying Explicit Discourse Connectives. In Proceed-
ings of NAACL, pages 799–808, Denver, Colorado.

2311



Radu Soricut and Daniel Marcu. 2003. Sentence Level
Discourse Parsing Using Syntactic and Lexical Infor-
mation. In Proceedings of NAACL, pages 149–156,
PA, USA.

Caroline Sporleder and Alex Lascarides. 2008. Using
Automatically Labelled Examples to Classify Rhetori-
cal Relations: An Assessment. Natural Language En-
gineering, 14(3):369–416.

Mann William and Sandra Thompson. 1988. Rhetorical
structure theory: Towards a Functional Theory of Text
Organization. Text, 8(3):243–281.

Biao Zhang, Jinsong Su, Deyi Xiong, Yaojie Lu, Hong
Duan, and Junfeng Yao. 2015. Shallow Convolu-
tional Neural Network for Implicit Discourse Relation
Recognition. In Proceedings of EMNLP, pages 2230–
2235, Lisbon, Portugal.

Yuping Zhou and Nianwen Xue. 2012. PDTB-style dis-
course annotation of Chinese text. In Proceedings of
ACL, pages 69–77, Jeju Island, Korea.

Zhi-Min Zhou, Yu Xu, Zheng-Yu Niu, Man Lan, Jian
Su, and Chew Lim Tan. 2010. Predicting Discourse
Connectives for Implicit Discourse Relation Recogni-
tion. In Proceedings of COLING, pages 1507–1514,
PA, USA.

2312


