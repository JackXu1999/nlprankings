



















































Complementary Strategies for Low Resourced Morphological Modeling


Proceedings of the 15th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, pages 54–65
Brussels, Belgium, October 31, 2018. c©2018 The Special Interest Group on Computational Morphology and Phonology

https://doi.org/10.18653/v1/P17

54

Complementary Strategies for Low Resourced Morphological Modeling

Alexander Erdmann and Nizar Habash
Computational Approaches to Modeling Language Lab

New York University Abu Dhabi
United Arab Emirates

{ae1541,nizar.habash}@nyu.edu

Abstract

Morphologically rich languages are challeng-
ing for natural language processing tasks due
to data sparsity. This can be addressed either
by introducing out-of-context morphological
knowledge, or by developing machine learning
architectures that specifically target data spar-
sity and/or morphological information. We
find these approaches to complement each
other in a morphological paradigm modeling
task in Modern Standard Arabic, which, in ad-
dition to being morphologically complex, fea-
tures ubiquitous ambiguity, exacerbating spar-
sity with noise. Given a small number of out-
of-context rules describing closed class mor-
phology, we combine them with word embed-
dings leveraging subword strings and noise re-
duction techniques. The combination outper-
forms both approaches individually by about
20% absolute. While morphological resources
already exist for Modern Standard Arabic,
our results inform how comparable resources
might be constructed for non-standard dialects
or any morphologically rich, low resourced
language, given scarcity of time and funding.

1 Introduction

Morphologically rich languages pose many chal-
lenges for natural language processing tasks. This
often takes the shape of data sparsity, as the in-
crease in the number of possible inflections for
any given core concept leads to a lower aver-
age word frequency of individual (i.e., unique)
word types. Hence, models have fewer chances
to learn about types based on their in-context
behavior. One common, albeit time consuming
response to this challenge is to introduce out-
of-context morphological knowledge, hand craft-
ing rules to relate forms inflected from the same
lemma. The other common response is to adopt
machine learning architectures specifically target-
ing data sparsity and/or morphological informa-

tion. We find these two responses to be comple-
mentary in a paradigm modeling task for Modern
Standard Arabic (MSA).

MSA is characterized by morphological rich-
ness and extreme orthographic ambiguity, com-
pounding the issue of data sparsity with noise
(Habash, 2010). Despite its challenges, MSA
is relatively well resourced, with many solutions
for morphological analysis and disambiguation
leveraging large amounts of annotated data, hand
crafted rules, and/or sophisticated neural archi-
tectures (Khoja and Garside, 1999; Habash and
Rambow, 2006; Smrž, 2007; Graff et al., 2009;
Pasha et al., 2014; Abdelali et al., 2016; Inoue
et al., 2017; Zalmout and Habash, 2017). Such
resources and techniques, however, are not avail-
able or not viable for the many under resourced
and often mutually unintelligible dialects of Ara-
bic (DA), which are similarly morphologically
rich and highly ambiguous (Chiang et al., 2006;
Erdmann et al., 2017). Many recent efforts seek
to develop morphological resources for DA, but
most are under developed or specific to one di-
alect (Habash et al., 2012; Eskander et al., 2013;
Jarrar et al., 2014; Al-Shargi et al., 2016; Eskan-
der et al., 2016a; Khalifa et al., 2016, 2017; Zribi
et al., 2017; Zalmout et al., 2018; Khalifa et al.,
2018).

This work does not aim to develop a full mor-
phological analysis and disambiguation resource,
but to inform how one might be most efficiently
developed for any DA variety or similarly low re-
sourced language, given scarcity of time and fund-
ing. For such a resource to be practical and eas-
ily extendable to new DA varieties, it must take
as input the natural, highly ambiguous orthogra-
phy. Thus, we do not rely on constructed phono-
logical representations to clarify ambiguities, as is
common practice when modeling morphology for
its own sake (Cotterell et al., 2016, 2017). To in-



55

form how such a resource should be developed,
we evaluate minimally rule based and unsuper-
vised techniques for clustering words that belong
to the same paradigm in MSA. We primarily use
pre-existing MSA resources only for evaluation,
constraining resource availability to emulate DA
settings during training, as we lack the resources
to evaluate our techniques in DA. Our best sys-
tem combines a minimal set of rules describing
closed class morphology with word embeddings
that leverage subword strings and noise reduc-
tion strategies. The former, despite being cheaper
and easier to produce than other rule-based sys-
tems, provides valuable out-of-context morpho-
logical knowledge, which the latter complements
by modeling the in-context behavior of words and
morphemes. Combining the techniques outper-
forms either individually by about 20% absolute.

2 Morphology and Ambiguity

Arabic morphology is structurally and function-
ally complex. Structurally, paradigms are rela-
tively large. Component cells convey morpho-
syntactic properties at a much finer granularity
than English. Functionally, many morphologi-
cal processes are non-concatenative, or templatic.
Arabic roots are lists of de-lexicalized radicals,
which must be mapped onto a template to derive
a word. The derived word will then exhibit some
predictable semantic and morpho-syntactic rela-
tionship to the root, based on its template. For ex-
ample, the root X X P r d d,1 having to do with re-
sponding, could take a singular nominal template
where geminates are collapsed, becoming XP rd,
‘response’, or a so-called broken plural template,
separating the geminate with a long vowel to be-
come XðXP rdwd, ‘responses’. Arabic orthography
complicates the issue further, as diacritics mark-
ing short vowels, gemination, and case endings
are typically not written. In addition to causing
frequent lexical ambiguity among forms that are
pronounced differently, this also causes templatic
processes to appear to be concatenative or com-
pletely disappear. For example, deriving ‘to cool’
XQK. brd (fully diacritized, X

��Q
�
K. bar∼ad) from ‘cold-

ness’ XQK. brd (fully diacritized, XQ
�
K. bar.d) involves

doubling the second root letter and adding a short
vowel before the third, yet these templatic changes
usually disappear in the orthography.

1Arabic transliteration is presented in the Habash-Soudi-
Buckwalter scheme (Habash et al., 2007).

Most templatic processes are derivational, de-
riving new core meanings with separate paradigms
from a shared root. Inflectional processes gener-
ally concatenate affixes to a shared stem to realize
different cells in the same paradigm. Broken plu-
rals however, like XðXP rdwd, are a notable excep-
tion, resulting from a templatic inflectional pro-
cess. Approximately 55% of all plurals are broken
(Alkuhlani and Habash, 2011).

Arabic is further characterized by frequent cliti-
cization of prepositions, conjunctions, and ob-
ject pronouns. Thus, a single syntactic word can
take many cliticized forms, potentially becoming
homonymous with inflections of unrelated lemmas
or distinct cells in the same paradigm. The XQK. brd,
‘response’–‘coldness’ ambiguity exemplifies this.
The ‘response’ meaning interprets H. b as a cliti-
cized preposition meaning ‘with’, while the ‘cold-
ness’ meaning interprets H. b as the first root radi-
cal. To investigate how these morphological traits
affect our ability to model paradigms, we define
the following morphological structures.

Paradigm All words that share a certain lemma
comprise a paradigm, e.g., in Figure 1, the
paradigm of verbal lemma �X �P rad∼, ‘to respond’,
contains the four words connected to it by a solid
line. Ambiguity within the paradigm is referred
to as syncretism, and is very common in Ara-
bic. For example, the present tense second per-
son masculine singular form is syncretic with the
third person feminine singular in verbs, as shown
by XQ�K trd, ‘you[masc.sing]/she respond(s)’. Addi-
tionally, orthography normalizes short vowel dis-
tinctions between past tense second person mas-
culine, second person feminine, and first person
forms (and sometimes third person feminine), thus
causing

��
HX

�
X �P radadta, �H

�
X

�
X �P radadti, and

��
HX

�
X �P

radadtu, respectively, to be orthographically syn-
cretic. Cliticized forms can also cause unique syn-
cretisms, e.g., A 	KXQK. brdnA has two possible inter-
pretations from the same lemma X ��Q�K. bar∼ad, ‘to
cool’. If the final suffix A 	K nA is interpreted as a
past tense verbal exponent, it means ‘we cooled’,
whereas if it is interpreted as a cliticized personal
pronoun, it becomes ‘he/it cooled us’.

Subparadigm At or below the paradigm level,
subparadigms are comprised of all words that
share the same lemma ambiguity. Lemma ambi-
guity refers to the set of all lemmas a word could
have been derived from out of context. Hence, XQK.



56

Figure 1: A clan of two families with two paradigms each, connected by both derivational and coincidental
ambiguities. Line dotting style is only used to visually distinguish paradigm membership.

brd and A 	KXQK. brdnA form a subparadigm, being the
only words in Figure 1 which can all be derived
exclusively from lemmas, �X �P rad∼, ‘response’, XQ�K.
bard, ‘coldness’, and X ��Q�K. bar∼ad, ‘to cool’.

Family At or above the paradigm level, a fam-
ily is comprised of all paradigms which can be
linked via derivational ambiguity, such that all
paradigms are derived from the same root. Thus,
all forms mapping to the two paradigms which in
turn map to the root X P H. b r d, relating to cold,
constitute a single family. The subparadigm of
XQK. brd and A

	
KXQK. brdnA link the two component

paradigms via derivational ambiguity.2

Clan At or above the family level, a clan is com-
prised of all families which can be linked by coin-
cidental ambiguity. Thus, the subparadigm of XQK.
brd and A 	KXQK. brdnA, whose derivational ambiguity
joins the paradigms of the X P H. b r d family, also
connects that family to the unrelated X X P r d d
family via coincidental ambiguity. This is caused
by the multiple possible analyses of H. b as either
a cliticized preposition or a root letter.

3 Experiments

In this section, we describe the data, design, and
models used in our experiments.

2The linguistic concept of derivational family differs from
ours in that it does not require any ambiguous forms to be
shared by derivationally related paradigms. However, identi-
fying such derivational families automatically is non-trivial.
Even if the shared root can be identified, it can be difficult
to determine whether the root is mono or polysemous, e.g.,
P ¨

�
 š ς r could refer to hair, poetry, or feeling. Regard-

less, our definition of family better serves our investigation
into the effects of ambiguity.

3.1 Data

To train word embedding models, we use a cor-
pus of 500,000 Arabic sentences (13 million
words) randomly selected from the corpus used
in Almahairi et al. (2016). This makes our find-
ings more generalizable to DA, as many dialects
have similar amounts of available data (Erdmann
et al., 2018). We clean our corpus via standard
preprocessing3 and analyze each word out of con-
text with SAMA (Graff et al., 2009) to get the set
of possible fully diacritized lemmas from which it
could be derived.4

To build an evaluation set, we sum the frequen-
cies of all types within each paradigm and bucket
paradigms based on frequency. We randomly se-
lect evaluation paradigms such that all 10 buck-
ets contribute at least 10 paradigms each. For
all selected paradigms, any paradigms from the
same clan are also selected, allowing us to as-
sume that the paradigms included in the evalua-
tion set are independent of those that are not in-
cluded. Paradigms with only a single type are
discarded, as these are not interesting for analy-
sis. Our resulting EVAL set contains 1,036 words
from 91 paradigms and a great deal of ambiguity
at all levels of abstraction (see Table 1). Because
we prohibit paradigms from entering EVAL with-
out the rest of their clan, EVAL also exhibits the
desirable property of reflecting a generally realis-
tic distribution of ambiguity: 36% of its vocab-
ulary are lemma ambiguous as compared to 39%
for the entire corpus.

3We remove the rarely used diacritics and Alif/Ya normal-
ize (El Kholy and Habash, 2012).

4We exclude words from the embedding model and eval-
uation set if they either cannot be analyzed by SAMA, only
receive proper noun analyses, or if they do not also occur in
the larger Arabic Gigaword corpus (Parker et al., 2011). This
controls for many idiosyncrasies.



57

Count Ambiguous Non-derivationallyAmbiguous
Clan 49 18 5

Family 55 24 11
Paradigm 91 60 14

Subparadigm 116 48 6
Word 1,036 372 85

Table 1: Statistics from the EVAL set. Morpholog-
ical structures by level of abstraction. Ambiguous
structures contain at least one lemma ambiguous
form. Non-derivationally ambiguous structures
contain at least one coincidentally lemma ambigu-
ous form.

Figure 2: Best clustering strategies for two
paradigms–dotted versus dashed ovals–given sin-
gle or multi prototype vocabulary representations.

3.2 Approach and Evaluation Metric

We build single and multi prototype representa-
tions of the entire vocabulary, then examine how
well they reflect the paradigms in EVAL. Each
representation can be thought of as a tree where
each word is a leaf at depth 0, i.e., W1, W2, and
W3 in Figure 2. Descending down the tree, words
are clustered with other words’ branches at subse-
quent depths until the clustering algorithm finishes
or the root is reached where all words in the vo-
cabulary are clustered together. All trees use some
model of word similarity to guide clustering. In
multi prototype representations, a word’s leaf pro-
totype at depth 0 can be copied and grafted onto
other words’ branches at non-zero depths before
those branches are clustered to its own. Such is the
case of W2, which is copied as W ′2 at depth 1 of
W3’s branch before W3’s branch connects to W2’s.
This enables partially overlapping paradigms to be
modeled, like those in Figure 2.

We evaluate the trees via average maximum F-
score. For each word in EVAL, we descend from
its leaf, at each depth calculating an F-score for

the overlap between the words that have been
clustered to the leaf’s branch so far and the leaf
word’s known paradigm mates, i.e., the set of
words sharing at least one lemma with the leaf.
Thus, paradigms are soft clusters in our represen-
tation, in that, for each word in a paradigm, its set
of proposed paradigm mates need not be consis-
tent with any of its proposed paradigm mates’ sets
of proposed paradigm mates. We then take the
best F-score for each leaf word in EVAL, regard-
less of the depth level at which it was achieved,
and average these maximum F-scores. This re-
flects how cohesively paradigms are represented
in the tree.5 Additionally, we report the average
depth at which templatic and concatenatively re-
lated paradigm mates are added.

Because we evaluate via average maximum F-
score, this metric represents the potential perfor-
mance of any given model. Future work will
address predicting the depth level where aver-
age maximum F-score is achieved for a given
leaf word via rule-based and/or empirical tech-
niques that have proven successful for related
tasks (Narasimhan et al., 2015; Soricut and Och,
2015; Cao and Rei, 2016; Bergmanis and Gold-
water, 2017; Sakakini et al., 2017).

3.3 Word Similarity Models

We use the following word similarity models for
clustering words in single and multi prototype tree
representations.

LEVENSHTEIN The LEVENSHTEIN baseline
uses only orthographic edit distances to form a
multi prototype tree. At each depth level i, the
branch will include every word which has an
edit distance of i when compared to the leaf.
Transitivity does not hold in this model, as words
x and y could be in each other’s depth 1 branch,
but the fact that z is in y’s depth 1 branch does not
imply its inclusion in x’s depth 1 branch. If the
edit distance between x and z is greater than 1,
copies, or additional prototypes must be made of x
and y. Because morphology involves complicated
processes that cannot be explained merely via
orthographic similarity, we predict this model will
perform poorly. Still, this baseline is useful to
ensure that other models are learning something

5To control for idiosyncratic paradigms, we calculated a
macro F-score averaged over the average maximum F-scores
of individual paradigms, though we do not report this as re-
sults were not significantly different.



58

from words’ in-context behavior or out-of-context
morphological knowledge beyond what can be
superficially induced from edit distances.

DELEX We use a de-lexicalized (DELEX) mor-
phological analyzer to predict morphological re-
latedness. The analyzer covers all MSA closed-
class affixes and clitics and their allowed combi-
nations in open class parts-of-speech (POS); how-
ever there is no information about stems and lem-
mas in the model.6 The affixes and clitics and their
compatibility rules were extracted from SAMA
(Graff et al., 2009). They are relatively cheap to
create for any DA or other languages. The inde-
pendent, expensive component of SAMA is the in-
formation regarding stems and lemmas, which we
used to form our evaluation set. We are inspired by
Darwish (2002), who demonstrated the creation of
an Arabic shallow analyzer in one day. Our ap-
proach can be easily extended to DA at least in a
similar manner to Salloum and Habash (2014).

To determine if two MSA words are possibly
in the same paradigm, we do the following: (1) we
use the analyzer to identify all potential stems with
corresponding POS for each word (these stems
are simply the leftover string after removing any
prefixal and suffixal strings which match a prefix-
suffix combination deemed compatible by SAMA);
(2) each stem is deterministically converted into an
orthographic root as per Eskander et al. (2013) by
removing Hamzas (the set of letters representing
the glottal stop phoneme, i.e., Z ’,


@ Â, @


Ǎ,

�
@ Ā, ð' ŵ,

Zø' ŷ), long vowels ( @ A, ø



y, ð w, ø ý), and reduc-

ing geminate consonants (e.g., XXP rdd → XP rd);
(3) two words are determined to be possibly from
the same paradigm if there exists a possible ortho-
graphic root–POS analysis shared by both words.

DELEX builds a multi prototype tree with a
maximum depth of 1. For each leaf word, it uses
the above algorithm to identify all words in the
vocabulary which can possibly share a paradigm
with the leaf word, and grafts them into the branch.
Hence, a word can belong to more than one hy-
pothesized paradigm. Because DELEX has access

6The system includes 15 basic prefixes/proclitics ( @ A, È@
Al, H. b,

	
¬ f, ú




	
¯ fy, ¼ k, È l, B lA, AÓ mA, 	à n,  s, �H t, ð w, ø




y, and φ) in 84 unique combinations; and 30 suffixes/enclitics
( @ A, 	à@ An, �H@ At, è h, Aë hA, Ñë hm, AÒë hmA, 	áë hn, ¼ k, Õ»

km, AÒ» kmA, 	á» kn, 	à n, A 	K nA, ú



	
G ny, �è ~, �H t, A�K tA, 	àA�K tAn,

Õç
�
' tm, AÖ

�
ß tmA, 	á�K tn, ú




�
G ty, 	á�


�
K tyn, ð w, @ð wA, 	àð wn, ø



y, 	áK


yn and φ) in 193 unique combinations.

to valuable morphological knowledge, we predict
it will be a competitive baseline. Furthermore, it
should produce nearly perfect recall, only miss-
ing rare exceptional forms, e.g., broken plurals
that introduce new consonants such as l .×@QK. brAmj,

‘programs’, the plural of l .×A
	
KQK. brnAmj, ‘program’.

We expect its precision to be weak because it
lacks lexical or stem-pattern information, leading
to rampant clustering of derivationally related and
unrelated forms. For example, a word like �è 	QKAg.
jAŷz~, ‘prize’ (true root 	P ð h. j w z) receives the

orthographic root 	P h. j z (long vowel, hamza let-
ter, and suffix are dropped), which clusters it with
unrelated forms such as Z 	Qk. jz’, ‘part’ (true root
Z 	P h. j z ’), and

	Qk. jz, ‘shearing’ (true root 	P 	P h.
j z z).

Word Embedding Models (W2V, FT, and FT+)
We use different word embedding models to build
single prototype representations of the vocabulary
via binary hierarchical clustering (Müllner et al.,
2013). In order to analyze the effects of data spar-
sity, we do not impose a minimum word frequency
count, but learn vectors for the entire vocabulary.
At depth 0, we consider each leaf word to be its
own branch. Descending down the tree, we it-
eratively join the closest two branches based on
Ward distance (Ward Jr, 1963). Joined branches
are represented by the centroid of their component
words’ vectors (though, as in other models, we do
not include the leaf word as a match when calcu-
lating average maximum F-score). We continue it-
erating until only a single root remains containing
the entire vocabulary.

These trees are single prototype because the in-
put embeddings only provide one vector for each
word, regardless of whether or not it is ambiguous
in any way. While this is a limitation for these
models,7 existing multi prototype word embed-
dings generally model sense ambiguity, which is
easier to capture (though harder to evaluate) given
the unsupervised settings in which embeddings are
typically trained (Reisinger and Mooney, 2010;
Huang et al., 2012; Chen et al., 2014; Bartunov
et al., 2016). Adapting multi prototype embed-

7A single prototype oracle that always correctly maps
non-lemma ambiguous words to their paradigm and maps
lemma ambiguous words only to their largest possible
paradigm scores 97% (92% specifically on lemma ambigu-
ous types). This represents the best possible performance for
single prototype models.



59

dings to model lemma ambiguities is non-trivial,
especially without lots of supervision. We leave
this for future work.

Because trees built from word embeddings are
all constructed via the same binary clustering al-
gorithm, the depths at which templatic and con-
catenatively inflected paradigm mates are joined
in Table 2 are comparable vertically across W2V,
FT, and FT+ as well as horizontally. However, the
multi prototype trees are shorter and fatter, such
that the templatic and concatenative average join
depths are only comparable horizontally with each
other, i.e., within the same model.

W2V The Gensim implementation of
WORD2VEC (Mikolov et al., 2013a; Řehůřek
and Sojka, 2010) uses the SkipGram algorithm
with 200 dimensions and a context window of 5
tokens on either side of the target word. As this
does not have access to any subword information
and is specifically designed for semantics, not
morphology, we predict that it will not perform
well in our evaluation.

FT We train a FASTTEXT (Bojanowski et al.,
2016) implementation with the same parameters
as W2V, except a word’s vector is the sum of its
SkipGram vector and that of all its component
character n-grams between length 2 and 6. Since
short vowels are not written, many Arabic affixes
are only one character. With FASTTEXT bookend-
ing words with start/end symbols in its internal
representation, outermost single-letter affixes are
functionally two characters. By inducing knowl-
edge of such affixes, these character n-gram pa-
rameters outperform the language agnostic range
of 3 to 6 proposed by Bojanowski et al. (2016).

With the ability to model how subword strings
behave in context, FT should outperform both
LEVENSHTEIN and W2V, though without access
to scholar seeded knowledge of morphological
structures, it is difficult to predict how FT will
compare with DELEX. Errors may arise from clus-
tering words based on affixes indicative of syn-
tactic behavior instead of the stem, which indi-
cates paradigm membership. Also, if the word
is infrequent and contains no semantically dis-
tinct subword string with higher frequency, the
embeddings will be noisy. Frequency and noise
also interact with the hubbiness, or crowdedness
of the embedding region, as rural regions will re-
quire less precision in the vectors to cluster well,

whereas there is little room for noise in crowded
urban regions where many similar but morpholog-
ically unrelated words could interfere.

FT+ We build another FT model by concatenat-
ing the vectors learned from two variant FT mod-
els, one with the normal window size of 5 and one
with a narrow window size of 1. Both are trained
on a preprocessed corpus where phrases have been
probabilistically identified in potentially unique
distributions over multiple copies of each sen-
tence, as described in Erdmann et al. (2018).8 This
technique attempts to better model syntactic cues–
which are better encoded with narrow context win-
dows (Pennington et al., 2014; Trask et al., 2015;
Goldberg, 2016; Tu et al., 2017)–while avoiding
treating non-compositional phrases as composi-
tional, and also learning from multiple, poten-
tially complementary phrase-chunkings of every
sentence. By combining these sources of infor-
mation, FT+ is designed to learn more meaningful
vectors without requiring additional data. We pre-
dict it will uniformly outperform FT by reducing
noise in the handling of sparse forms like infre-
quent inflections–a hallmark of morphologically
rich languages.

FT+&DELEX We make unique copies for each
leaf word’s branch extending all the way to the
root in the single prototype FT+ tree. Then, for
each leaf word, at every depth of its branch copy,
we use DELEX to prune any words which could
not share an orthographic root with the leaf word.
Pruning is local to that branch copy, and does not
affect the branch copies of paradigm mates which
had originally been proposed by FT+ before mak-
ing branch copies. This makes FT+&DELEX a
multi-prototype model. After pruning, the F-score
is recalculated for each depth of each leaf word’s
branch and a new average maximum F-score is re-
ported. Because FT+ encodes information regard-
ing the in-context behavior of words, it is quite
complementary to the out-of-context morpholog-
ical knowledge supplied by DELEX. We predict
this model will outperform all others.

8For control, we compared every possible combination of
narrow and wide window sizes (1 or 5), dimension sizes (200
or 400), and techniques for phrase identification (none, deter-
ministic (Mikolov et al., 2013b), and probabilistic (Erdmann
et al., 2018)), but none approached the performance achieved
with the parameters used in FT+.



60

Word Similarity Multi Averaged Scores Join Depth
Model Prototype Max F-Score Precision Recall Concat Temp

LEVENSHTEIN X 22.0 35.5 23.4 3.5 4.1
DELEX X 52.9 41.6 99.3 1.0 1.0

W2V 2.1 6.7 28.1 17.1 17.4
FT 39.2 66.0 44.2 13.7 16.8

FT+ 50.2 71.8 52.9 13.3 16.4
FT+&DELEX X 71.5 74.0 81.3 13.3 16.4

Table 2: Scores for clustering words with their paradigm mates in tree representations built from different
models of word similarity. Scores are calculated as described in Section 3.2, with precision and recall
extracted from the depth that maximizes F and then averaged over all words in EVAL. Join depths refer to
the average depth at which templatic or concatenatively related paradigm mates are added to the branch.

4 Results and Discussion

The results in Table 2 provide strong evidence in
support of our hypotheses. The only model per-
forming worse than the LEVENSHTEIN edit dis-
tance baseline is W2V, which only understands the
in-context, semantic behavior of words. By be-
ing able to learn morphological knowledge from
in-context behavior of subword strings, FT greatly
improves over both W2V and LEVENSHTEIN,
demonstrating that it learns far more than can be
inferred from out-of-context subword strings, i.e.,
edit distance, or in-context distributional seman-
tic knowledge without any morphology, i.e., W2V.
As predicted, FT+ improves uniformly over FT in
all categories, presumably by reducing noise in
the vectors of infrequent inflections. Interestingly,
with no access to subword information, W2V per-
forms equally poorly on both templatic and con-
catenatively related paradigm mates, whereas FT
and FT+ greatly improve on concatenative mates,
but not templatic ones. This is likely because FT
and FT+ can identify patterns in subword strings,
but not in non-adjacent characters.

DELEX’s strong baseline performance demon-
strates that simple, out-of-context, de-lexicalized
knowledge of morphology is sufficient to out-
perform the best word embedding model that
only learns from words’ in-context behaviors.
However, given the complementarity between
DELEX’s knowledge and the information FT+ can
learn, it is not surprising that the combination of
these techniques, FT+&DELEX, far outperforms
either system individually.

Specific Examples We discuss a number
of examples that illustrate the variety in
the behavior and complementarity of rule-
based DELEX, embedding-based FT+, and the
combined FT+&DELEX models. For each

example, we specify the strength of the max-
imum F-score for the three models as such:9

strengthDELEX+strengthFT+→strengthFT+&DELEX,
e.g., LOW+MID→HI denotes poor DELEX and
mediocre FT+ performance on a word, yielding
high performance in the combined model.

• �è 	QKAg. jAŷz~, ‘prize’ (LOW+HI→HI)
This word has high orthographic root ambigu-
ity since its second morphological root radical
is a Hamza. This results in matching words
with unrelated true roots like Z 	Qk. jz’, ‘part’ and
	Qk. jz, ‘shearing’ under DELEX. It also has

high root fertility, in that different paradigms
can come from the same true root, like 	QK� A

�
g.

jAŷz, ‘permissible’, further challenging DELEX.
FT+ does relatively better, capturing the word’s
other inflections, even the broken plural 	QK @ñk.
jwAŷz, as their in-context behavior is similar to
�
è 	Q


KAg. jAŷz~. Interesting recall errors by FT+ in-

clude semantically and orthographically similar
�
è 	Q


KA

	
¯ fAŷz~, ‘winner[fem.sing]’. The combina-

tion yields a perfect F-score.

• 	àñ«QîE
 yhrςwn, ‘they rush’ (HI+LOW→HI)
This word has an unambiguous orthographic
root with no root fertility, resulting in a perfect
F-score for DELEX. However, FT+ misses sev-
eral inflections such as ¨Qî 	E nhrς , ‘we rush’,

and �I«Qëð whrςt, ‘and I/you/she rushed’. FT+
also makes many semantically and/or syntacti-
cally similar precision errors: 	àñ«Qå�
 ysrςwn,
‘they hurry’, 	àñ«PA�
 ySArςwn, ‘they wrestle’,
and 	àñ«Q�®K
 yqrςwn, ‘they ring (a bell)’. The
combination leads to a perfect F-score.

• ú


¾J
ÓA

	
JK
X dynAmyky, ‘dynamic’ (HI+HI→HI)

This word has an unambiguous orthographic
9The strength designation HI is used for F-scores above

75%, LOW for scores below 25%, and MID for the rest.



61

root based on a foreign borrowing and relatively
unique semantics and subword strings. Thus, it
achieves a perfect F-score in all three models.

• @ðQå��J 	K @ AntšrwA, ‘they spread out’
(MID+MID→HI)
This word has high orthographic root ambiguity
(and, incidentally, fertility) due to the presence
of 	à n and �H t, which could belong to a root,
template, or prefix. This leads to a 63% F-score
under DELEX with many precision errors:
èPA

�


�
�
	
K @ AntšArh, ‘his spreading out’, PðA ��� 	Kð

wntšAwr, ‘we discuss’, and ¼PA ��� 	K ntšArk, ‘we
collaborate’. FT+ scores only 47%, proposing
semantically related but morphologically unre-
lated or only derivationally related forms: e.g.,
Qå

�

�
J
	
JÓ mntšr, ‘spread out’ (adjective), and @ð 	Q»QÖ

�
ß

tmrkzwA, ‘they centralized’ (antonym). This
semantic knowledge however, complements
DELEX’s knowledge, such that the combination
is almost perfect (98%).

• Z 	­» kf’, ‘efficient’ (LOW+LOW→LOW)
While 17% of words are LOW in DELEX and
28% in FT+, only 4% are LOW in FT+&DELEX.
This word exemplifies that 4%, occupying the
gap between DELEX’s knowledge and FT+’s. It
has an extremely ambiguous orthographic root
due to the true root containing a Hamza and the
first letter being interpretable as a proclitic or
root radical. Thus, DELEX achieves 2% F. FT+
is only slightly better (5%). It is likely that this
word’s low frequency is the main contributor to
its noisy embedding, as it only appears once in
our corpus. The combination F-score is thus,
only 11%.

5 Related Work

This work builds on several others addressing
word embeddings and computational morphology.

Word Embeddings Word embeddings are
trained by predicting either a target word given its
context (Continuous Bag of Words) or elements
of the context given a target (SkipGram) in
unannotated corpora (Mikolov et al., 2013a), with
the learned vectors modeling how words relate
to each other. Embeddings have been adapted
to incorporate word order (Trask et al., 2015) or
subword information (Bojanowski et al., 2016) to
motivate the learned vectors to specifically capture
syntactic, morphological, or other similarities.

Word embeddings are generally single proto-
type models, in that they learn one vector for each
word, which can be problematic for ambiguous
forms (Reisinger and Mooney, 2010; Huang et al.,
2012; Chen et al., 2014). Bartunov et al. (2016)
propose a multi prototype model that learns dis-
tinct vectors for distinct meanings of types based
on variation in the contexts within which they ap-
pear. Gyllensten and Sahlgren (2015), argue that
single prototype embeddings actually can model
ambiguity because the defining characteristics of
a word’s different meanings typically manifest in
different dimensions of the highly dimensional
vector space. They find ambiguous words’ rela-
tive nearest neighbors in a relative neighborhood
graph often correlate with distinct meanings. Such
works however, deal with sense ambiguity, or ab-
stract semantic distinctions between different us-
ages of a word with potentially the same morpho-
syntactic properties and core meaning. Evalu-
ation usually requires linking to large semantic
databases which, for Arabic, are still underdevel-
oped (Black et al., 2006; Badaro et al., 2014; El-
razzaz et al., 2017).

Computational Morphology This field of
study includes rule-based, machine learning, and
hybrid approaches to modeling morphology. The
traditional approach is to hand write rules to
identify the morphological properties of words
(Beesley, 1998; Khoja and Garside, 1999; Habash
and Rambow, 2006; Smrž, 2007; Graff et al.,
2009; Habash, 2010). These can be used for
out-of-context analysis–which SAMA (Graff
et al., 2009) performs for MSA–or they can be
combined with machine learning approaches that
leverage information from the context in which a
word appears. MADAMIRA (Pasha et al., 2014),
for example, is trained on an annotated corpus
to disambiguate SAMA’s analyses based on the
surrounding sentence.

Other systems use machine learning without
rules. They can train on annotated data, like
Faruqui et al. (2016) who learn morpho-syntactic
lexica from a small seed, or they can learn with-
out supervision, like Luo et al. (2017) who induce
"morphological forests" of derivationally related
words by predicting suffixes and prefixes based on
the vocabulary alone. Some approaches seek to
be language independent. MORFESSOR (Creutz
and Lagus, 2005), for instance, segments words
based on unannotated text. However, it deter-



62

ministically produces context-irrelevant segmen-
tations, causing error propagation in languages
like Arabic, characterized by high lexical ambigu-
ity (Saleh and Habash, 2009; Pasha et al., 2014).
A few systems have incorporated word embed-
dings to perform segmentation (Narasimhan et al.,
2015; Soricut and Och, 2015; Cao and Rei, 2016),
with some attempting to model and analyze re-
lations between underlying morphemes as well
(Bergmanis and Goldwater, 2017; Sakakini et al.,
2017), though none of these distinguish between
inflectional and derivational morphology. Eskan-
der et al. (2016b) propose another segmentation
system using Adaptor Grammars for six typolog-
ically distinct languages. Snyder and Barzilay
(2010) actually use multiple languages simultane-
ously, finding the parallels between them useful
for disambiguation in morphological and syntac-
tic tasks.

Our work is closely related to Avraham and
Goldberg (2017), who train embeddings on
a Hebrew corpus with disambiguated morpho-
syntactic information appended to each token.
Similarly, Cotterell and Schütze (2015) "guide"
German word embeddings with morphological an-
notation, and Gieske (2017) use morphological in-
formation encoded in word embeddings to inflect
German verbs. For Arabic, Rasooli et al. (2014)
induce paradigmatic knowledge from raw text to
produce unseen inflections, and Eskander et al.
(2013) identify orthographic roots and use them
to extract features for paradigm completion given
annotated data. While we adopt the concept of
approximating the linguistic root with an ortho-
graphic root, we do not use annotated data where
the stem has already been determined as in Eskan-
der et al. (2013). Thus, we generate all possible
orthographic roots for a given word instead of just
one, as discussed in Section 3.3.

Sakakini et al. (2017) provide an alternative
unsupervised technique for extracting roots in
Semitic languages, however, we chose to adopt
the orthographic root concept instead for several
reasons. Firstly, despite performing comparably
with other empirical techniques, Sakakini et al.
(2017)’s root extractor is not extremely accurate.
While our implementation generates potentially
multiple orthographic roots with imperfect preci-
sion, the near perfect recall is useful for pruning
without propogating error. A major reason why we
find DELEX and FT+ to complement one another

is the independence of the orthographic root ex-
traction rules and the distributional statistics lever-
aged by word embeddings. Sakakini et al. (2017)’s
root extractor however, depends on embeddings to
identify roots. Furthermore, their root extractor
cannot be used to generate multi prototype mod-
els as it only produces one root per word. Finally,
despite orthographic roots’ dependance on hand
written rules, we show that these rules are very
few, such that adapting Sakakini et al. (2017)’s
root extractor to a new language or dialect would
not necessarily require any less effort than writing
new rules.

6 Conclusion and Future Work

In this work, we demonstrated that out-of-context,
rule-based knowledge of morphological structure,
even in minimal supply, greatly complements
what word embeddings can learn about morphol-
ogy from words’ in-context behaviors. We dis-
cussed how Arabic’s morphological richness and
many forms of ambiguity interact with different
word similarity models’ ability to represent mor-
phological structure in a paradigm clustering task.
Our work quantifies the value of leveraging sub-
word information when learning embeddings and
the further value of noise reduction techniques tar-
geting the sparsity caused by complex morphol-
ogy. Our best performing model uses out-of-
context rules to prune unlikely paradigm mates
suggested by our best embedding model, achiev-
ing an F-score of 71.5% averaged over our eval-
uation vocabulary. Our results inform how one
would most cost effectively construct morphologi-
cal resources for DA or similarly under resourced,
morphologically complex languages.

Our future work will target templatic morpho-
logical processes which still challenge our best
model, requiring knowledge of patterns realized
over non-adjacent characters. We will also ad-
dress errors due to ambiguity, either by adapt-
ing multi prototype embedding models to cap-
ture morphological ambiguity, including knowl-
edge of paradigm structure in our de-lexicalized
rules, or by using disambiguated lemma frequen-
cies to model ambiguity probabilistically. In ap-
plying this work to DA, we will additionally
need to address the issue of noisy, unstandardized
spelling. We will also investigate different knowl-
edge transfer techniques to leverage the many re-
sources available for MSA.



63

References
Ahmed Abdelali, Kareem Darwish, Nadir Durrani, and

Hamdy Mubarak. 2016. Farasa: A fast and furious
segmenter for Arabic. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Demon-
strations, pages 11–16.

Faisal Al-Shargi, Aidan Kaplan, Ramy Eskander, Nizar
Habash, and Owen Rambow. 2016. Morphologi-
cally annotated corpora and morphological analyz-
ers for Moroccan and Sanaani Yemeni Arabic. In
10th Language Resources and Evaluation Confer-
ence (LREC 2016).

Sarah Alkuhlani and Nizar Habash. 2011. A Corpus
for Modeling Morpho-Syntactic Agreement in Ara-
bic: Gender, Number and Rationality. In Proceed-
ings of the 49th Annual Meeting of the Association
for Computational Linguistics (ACL’11), Portland,
Oregon, USA.

Amjad Almahairi, Kyunghyun Cho, Nizar Habash, and
Aaron C. Courville. 2016. First result on Arabic
neural machine translation. CoRR, abs/1606.02680.

Oded Avraham and Yoav Goldberg. 2017. The inter-
play of semantics and morphology in word embed-
dings. arXiv preprint arXiv:1704.01938.

Gilbert Badaro, Ramy Baly, Hazem Hajj, Nizar
Habash, and Wassim El-Hajj. 2014. A large scale
Arabic sentiment lexicon for Arabic opinion mining.
In Proceedings of the EMNLP 2014 Workshop on
Arabic Natural Language Processing (ANLP), pages
165–173.

Sergey Bartunov, Dmitry Kondrashkin, Anton Osokin,
and Dmitry Vetrov. 2016. Breaking sticks and ambi-
guities with adaptive skip-gram. In Artificial Intelli-
gence and Statistics, pages 130–138.

Kenneth Beesley. 1998. Arabic morphology using only
finite-state operations. In Proceedings of the Work-
shop on Computational Approaches to Semitic Lan-
guages, pages 50–7, Montereal.

Toms Bergmanis and Sharon Goldwater. 2017. From
segmentation to analyses: A probabilistic model for
unsupervised morphology induction. In Proceed-
ings of the 15th Conference of the European Chap-
ter of the Association for Computational Linguistics:
Volume 1, Long Papers, volume 1, pages 337–346.

William Black, Sabri Elkateb, Horacio Rodriguez,
Musa Alkhalifa, Piek Vossen, Adam Pease, and
Christiane Fellbaum. 2006. Introducing the Arabic
wordnet project. In Proceedings of the third inter-
national WordNet conference, pages 295–300. Cite-
seer.

Piotr Bojanowski, Edouard Grave, Armand Joulin,
and Tomas Mikolov. 2016. Enriching word vec-
tors with subword information. arXiv preprint
arXiv:1607.04606.

Kris Cao and Marek Rei. 2016. A joint model for word
embedding and word morphology. arXiv preprint
arXiv:1606.02601.

Xinxiong Chen, Zhiyuan Liu, and Maosong Sun. 2014.
A unified model for word sense representation and
disambiguation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1025–1035.

David Chiang, Mona Diab, Nizar Habash, Owen Ram-
bow, and Safiullah Shareef. 2006. Parsing Arabic
Dialects. In Proceedings of EACL, Trento, Italy.
EACL.

Ryan Cotterell, Christo Kirov, John Sylak-Glassman,
Géraldine Walther, Ekaterina Vylomova, Patrick
Xia, Manaal Faruqui, Sandra Kübler, David
Yarowsky, Jason Eisner, and Mans Hulden. 2017.
CoNLL-SIGMORPHON 2017 shared task: Uni-
versal morphological reinflection in 52 languages.
CoRR, abs/1706.09031.

Ryan Cotterell, Christo Kirov, John Sylak-Glassman,
David Yarowsky, Jason Eisner, and Mans Hulden.
2016. The SIGMORPHON 2016 shared task—
morphological reinflection. In Proceedings of the
2016 Meeting of SIGMORPHON, Berlin, Germany.
Association for Computational Linguistics.

Ryan Cotterell and Hinrich Schütze. 2015. Morpho-
logical word-embeddings. In Proceedings of the
2015 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1287–1292.

Mathias Creutz and Krista Lagus. 2005. Unsupervised
morpheme segmentation and morphology induction
from text corpora using Morfessor 1.0. Helsinki
University of Technology.

Kareem Darwish. 2002. Building a shallow Arabic
morphological analyzer in one day. In Computa-
tional Approaches to Semitic Languages, an ACL’02
Workshop, pages 47–54, Philadelphia, PA.

Ahmed El Kholy and Nizar Habash. 2012. Ortho-
graphic and morphological processing for English–
Arabic statistical machine translation. Machine
Translation, 26(1-2):25–45.

Mohammed Elrazzaz, Shady Elbassuoni, Khaled Sha-
ban, and Chadi Helwe. 2017. Methodical evaluation
of Arabic word embeddings. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers), pages
454–458, Vancouver, Canada.

Alexander Erdmann, Nizar Habash, Dima Taji, and
Houda Bouamor. 2017. Low resourced machine
translation via morpho-syntactic modeling: The
case of dialectal arabic. In Proceedings of MT Sum-
mit 2017, Nagoya, Japan.

Alexander Erdmann, Nasser Zalmout, and Nizar
Habash. 2018. Addressing noise in multidialectal
word embeddings. In Proceedings of the 56th An-
nual Meeting of the Association for Computational
Linguistics (Volume 2: Short Papers), volume 2,
pages 558–565.

Ramy Eskander, Nizar Habash, and Owen Rambow.
2013. Automatic extraction of morphological lex-
icons from morphologically annotated corpora. In



64

Proceedings of the 2013 conference on empiri-
cal methods in natural language processing, pages
1032–1043.

Ramy Eskander, Nizar Habash, Owen Rambow, and
Arfath Pasha. 2016a. Creating resources for Dialec-
tal Arabic from a single annotation: A case study on
Egyptian and Levantine. In Proceedings of COLING
2016, the 26th International Conference on Compu-
tational Linguistics: Technical Papers, pages 3455–
3465, Osaka, Japan.

Ramy Eskander, Owen Rambow, and Tianchun Yang.
2016b. Extending the use of adaptor grammars
for unsupervised morphological segmentation of un-
seen languages. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers, pages 900–910.

Manaal Faruqui, Ryan McDonald, and Radu Soricut.
2016. Morpho-syntactic lexicon generation using
graph-based semi-supervised learning. Transac-
tions of the Association for Computational Linguis-
tics, 4:1–16.

Sharon Gieske. 2017. Inflecting verbs with word em-
beddings: A systematic investigation of morpholog-
ical information captured by German verb embed-
dings. Master’s thesis, University of Amsterdam.

Yoav Goldberg. 2016. A primer on neural network
models for natural language processing. J. Artif. In-
tell. Res.(JAIR), 57:345–420.

David Graff, Mohamed Maamouri, Basma Bouziri,
Sondos Krouna, Seth Kulick, and Tim Buckwal-
ter. 2009. Standard Arabic morphological analyzer
(SAMA) version 3.1. Linguistic Data Consortium
LDC2009E73.

Amaru Cuba Gyllensten and Magnus Sahlgren.
2015. Navigating the semantic horizon using
relative neighborhood graphs. arXiv preprint
arXiv:1501.02670.

Nizar Habash, Ramy Eskander, and Abdelati Hawwari.
2012. A morphological analyzer for Egyptian Ara-
bic. In Proceedings of the twelfth meeting of the
special interest group on computational morphology
and phonology, pages 1–9. Association for Compu-
tational Linguistics.

Nizar Habash and Owen Rambow. 2006. MAGEAD:
a morphological analyzer and generator for the Ara-
bic dialects. In Proceedings of the 21st International
Conference on Computational Linguistics and the
44th annual meeting of the Association for Compu-
tational Linguistics, pages 681–688. Association for
Computational Linguistics.

Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.
2007. On Arabic Transliteration. In A. van den
Bosch and A. Soudi, editors, Arabic Computa-
tional Morphology: Knowledge-based and Empiri-
cal Methods. Springer.

Nizar Y Habash. 2010. Introduction to Arabic natural
language processing, volume 3. Morgan & Clay-
pool Publishers.

Eric H Huang, Richard Socher, Christopher D Man-
ning, and Andrew Y Ng. 2012. Improving word

representations via global context and multiple word
prototypes. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics: Long Papers-Volume 1, pages 873–882. Asso-
ciation for Computational Linguistics.

Go Inoue, Hiroyuki Shindo, and Yuji Matsumoto.
2017. Joint prediction of morphosyntactic cate-
gories for fine-grained Arabic part-of-speech tag-
ging exploiting tag dictionary information. In Pro-
ceedings of the 21st Conference on Computational
Natural Language Learning (CoNLL 2017), pages
421–431, Vancouver, Canada. Association for Com-
putational Linguistics.

Mustafa Jarrar, Nizar Habash, Diyam Akra, and Nasser
Zalmout. 2014. Building a corpus for Palestinian
Arabic: a preliminary study. In Proceedings of
the EMNLP 2014 Workshop on Arabic Natural Lan-
guage Processing (ANLP), pages 18–27.

Salam Khalifa, Nizar Habash, Fadhl Eryani, Ossama
Obeid, Dana Abdulrahim, and Meera Al Kaabi.
2018. A Morphologically Annotated Corpus of
Emirati Arabic. In Proceedings of the Eleventh In-
ternational Conference on Language Resources and
Evaluation (LREC 2018), Miyazaki, Japan.

Salam Khalifa, Sara Hassan, and Nizar Habash.
2017. A morphological analyzer for Gulf Arabic
verbs. WANLP 2017 (co-located with EACL 2017),
page 35.

Salam Khalifa, Nasser Zalmout, and Nizar Habash.
2016. Yamama: Yet another multi-dialect Arabic
morphological analyzer. In Proceedings of COLING
2016, the 26th International Conference on Compu-
tational Linguistics: System Demonstrations, pages
223–227.

Shereen Khoja and Roger Garside. 1999. Stemming
Arabic text. Lancaster, UK, Computing Depart-
ment, Lancaster University.

Jiaming Luo, Karthik Narasimhan, and Regina Barzi-
lay. 2017. Unsupervised learning of morphological
forests. arXiv preprint arXiv:1702.07015.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013a. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013b. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in neural information processing
systems, pages 3111–3119.

Daniel Müllner et al. 2013. fastcluster: Fast hierar-
chical, agglomerative clustering routines for R and
Python. Journal of Statistical Software, 53(9):1–18.

Karthik Narasimhan, Regina Barzilay, and Tommi
Jaakkola. 2015. An unsupervised method for un-
covering morphological chains. arXiv preprint
arXiv:1503.02335.

Robert Parker, David Graff, Ke Chen, Junbo Kong, and
Kazuaki Maeda. 2011. Arabic Gigaword Fifth Edi-
tion. LDC catalog number No. LDC2011T11, ISBN
1-58563-595-2.



65

Arfath Pasha, Mohamed Al-Badrashiny, Ahmed El
Kholy, Ramy Eskander, Mona Diab, Nizar Habash,
Manoj Pooleery, Owen Rambow, and Ryan Roth.
2014. MADAMIRA: A Fast, Comprehensive Tool
for Morphological Analysis and Disambiguation of
Arabic. In In Proceedings of LREC, Reykjavik, Ice-
land.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP), pages 1532–1543.

Mohammad Sadegh Rasooli, Thomas Lippincott, Nizar
Habash, and Owen Rambow. 2014. Unsupervised
morphology-based vocabulary expansion. In Pro-
ceedings of the 52nd Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), volume 1, pages 1349–1359.

Radim Řehůřek and Petr Sojka. 2010. Software Frame-
work for Topic Modelling with Large Corpora. In
Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks, pages 45–50, Val-
letta, Malta. ELRA. http://is.muni.cz/
publication/884893/en.

Joseph Reisinger and Raymond J Mooney. 2010.
Multi-prototype vector-space models of word mean-
ing. In Human Language Technologies: The 2010
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 109–117. Association for Computational Lin-
guistics.

Tarek Sakakini, Suma Bhat, and Pramod Viswanath.
2017. Fixing the infix: Unsupervised discovery
of root-and-pattern morphology. arXiv preprint
arXiv:1702.02211.

Ibrahim M. Saleh and Nizar Habash. 2009. Automatic
extraction of lemma-based bilingual dictionaries for
morphologically rich languages. In Proceedings of
MT Summit, Ottawa, Canada.

Wael Salloum and Nizar Habash. 2014. ADAM: An-
alyzer for Dialectal Arabic Morphology. Journal
of King Saud University-Computer and Information
Sciences, 26(4):372–378.

Otakar Smrž. 2007. Functional Arabic Morphology.
Formal System and Implementation. Ph.D. thesis,
Charles University, Prague.

Benjamin Snyder and Regina Barzilay. 2010. Climb-
ing the tower of Babel: Unsupervised multilingual
learning. In Proceedings of the International Con-
ference on Machine Learning (ICML-10), Haifa, Is-
rael.

Radu Soricut and Franz Och. 2015. Unsupervised mor-
phology induction using word embeddings. In Pro-
ceedings of the 2015 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
1627–1637.

Andrew Trask, David Gilmore, and Matthew Russell.
2015. Modeling order in neural word embeddings at
scale. arXiv preprint arXiv:1506.02338.

Lifu Tu, Kevin Gimpel, and Karen Livescu. 2017.
Learning to embed words in context for syntactic
tasks. arXiv preprint arXiv:1706.02807.

Joe H Ward Jr. 1963. Hierarchical grouping to opti-
mize an objective function. Journal of the American
statistical association, 58(301):236–244.

Nasser Zalmout, Alexander Erdmann, and Nizar
Habash. 2018. Noise-robust morphological dis-
ambiguation for dialectal Arabic. In Proceed-
ings of the 16th Meeting of the North American
Chapter of the Association for Computational Lin-
guistics/Human Language Technologies Conference
(HLT-NAACL18), New Orleans, Louisiana, USA.

Nasser Zalmout and Nizar Habash. 2017. Don’t throw
those morphological analyzers away just yet: Neural
morphological disambiguation for Arabic. In Pro-
ceedings of the 2017 Conference on Empirical Meth-
ods in Natural Language Processing, pages 715–
724.

Inès Zribi, Mariem Ellouze, Lamia Hadrich Belguith,
and Philippe Blache. 2017. Morphological dis-
ambiguation of Tunisian dialect. Journal of King
Saud University-Computer and Information Sci-
ences, 29(2):147–155.

http://is.muni.cz/publication/884893/en
http://is.muni.cz/publication/884893/en

