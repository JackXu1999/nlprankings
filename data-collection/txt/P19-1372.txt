



















































Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3826–3835
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

3826

Are Training Samples Correlated? Learning to Generate Dialogue
Responses with Multiple References

Lisong Qiu1,2, Juntao Li1,2, Wei Bi3, Dongyan Zhao1,2, Rui Yan1,2∗
1Center for Data Science, Peking University, Beijing, China

2Institute of Computer Science and Technology, Peking University, Beijing, China
3Tencent AI Lab, Shenzhen, China

{qiuls,lijuntao,zhaody,ruiyan}@pku.edu.cn
victoriabi@tencent.com

Abstract

Due to its potential applications, open-domain
dialogue generation has become popular and
achieved remarkable progress in recent years,
but sometimes suffers from generic responses.
Previous models are generally trained based
on 1-to-1 mapping from an input query to its
response, which actually ignores the nature
of 1-to-n mapping in dialogue that there may
exist multiple valid responses corresponding
to the same query. In this paper, we pro-
pose to utilize the multiple references by con-
sidering the correlation of different valid re-
sponses and modeling the 1-to-n mapping with
a novel two-step generation architecture. The
first generation phase extracts the common
features of different responses which, com-
bined with distinctive features obtained in the
second phase, can generate multiple diverse
and appropriate responses. Experimental re-
sults show that our proposed model can ef-
fectively improve the quality of response and
outperform existing neural dialogue models on
both automatic and human evaluations.

1 Introduction

In recent years, open-domain dialogue genera-
tion has become a research hotspot in Natural
Language Processing due to its broad applica-
tion prospect, including chatbots, virtual personal
assistants, etc. Though plenty of systems have
been proposed to improve the quality of gen-
erated responses from various aspects such as
topic (Xing et al., 2017), persona modeling (Zhang
et al., 2018b) and emotion controlling (Zhou et al.,
2018b), most of these recent approaches are pri-
marily built upon the sequence-to-sequence archi-
tecture (Cho et al., 2014; Shang et al., 2015) which
suffers from the “safe” response problem (Li et al.,
2016a; Sato et al., 2017). This can be ascribed
to modeling the response generation process as 1-
to-1 mapping, which ignores the nature of 1-to-

∗Corresponding author: Rui Yan (ruiyan@pku.edu.cn)

Figure 1: An illustration of the two-step generation
architecture. Different from the conventional meth-
ods (shown in green color) which model each response
from scratch every time, our method first builds a com-
mon feature of multiple responses and models each re-
sponse based on it afterward.

n mapping of dialogue that multiple possible re-
sponses can correspond to the same query.

To deal with the generic response problem,
various methods have been proposed, including
diversity-promoting objective function (Li et al.,
2016a), enhanced beam search (Shao et al., 2016),
latent dialogue mechanism (Zhou et al., 2017,
2018a), Variational Autoencoders (VAEs) based
models (Zhao et al., 2017; Serban et al., 2017),
etc. However, these methods still view multiple
responses as independent ones and fail to model
multiple responses jointly. Recently, Zhang et al.
(2018a) introduce a maximum likelihood strat-
egy that given an input query, the most likely re-
sponse is approximated rather than all possible re-
sponses, which is further implemented by Rajen-
dran et al. (2018) with reinforcement learning for
task-oriented dialogue. Although capable of gen-
erating the most likely response, these methods
fail to model other possible responses and ignore
the correlation of different responses.

In this paper, we propose a novel response
generation model for open-domain conversation,
which learns to generate multiple diverse re-
sponses with multiple references by considering



3827

the correlation of different responses. Our moti-
vation lies in two aspects: 1) multiple responses
for a query are likely correlated, which can facil-
itate building the dialogue system. 2) it is easier
to model each response based on other responses
than from scratch every time. As shown in Fig-
ure 1, given an input query, different responses
may share some common features e.g. positive at-
titudes or something else, but vary in discourses or
expressions which we refer to as distinct features.
Accordingly, the system can benefit from model-
ing these features respectively rather than learning
each query-response mapping from scratch.

Inspired by this idea, we propose a two-step
dialogue generation architecture as follows. We
jointly view the multiple possible responses to the
same query as a response bag. In the first gen-
eration phase, the common feature of different
valid responses is extracted, serving as a base from
which each specific response in the bag is further
approximated. The system then, in the second
generation phase, learns to model the distinctive
feature of each individual response which, com-
bined with the common feature, can generate mul-
tiple diverse responses simultaneously.

Experimental results show that our method can
outperform existing competitive neural models un-
der both automatic and human evaluation metrics,
which demonstrates the effectiveness of the over-
all approach. We also provide ablation analyses to
validate each component of our model. To sum-
marize, our contributions are threefold:

• We propose to model multiple responses to a
query jointly by considering the correlations
of responses with multi-reference learning.

• We consider the common and distinctive fea-
tures of the response bag and propose a novel
two-step dialogue generation architecture.

• Experiments show that the proposed method
can generate multiple diverse responses and
outperform existing competitive models on
both automatic and human evaluations.

2 Related Work

Along with the flourishing development of neural
networks, the sequence-to-sequence framework
has been widely used for conversation response
generation (Shang et al., 2015; Sordoni et al.,

2015) where the mapping from a query x to a re-
ply y is learned with the negative log likelihood.
However, these models suffer from the “safe” re-
sponse problem. To address this problem, various
methods have been proposed. Li et al. (2016a)
propose a diversity-promoting objective function
to encourage diverse responses during decoding.
Zhou et al. (2017, 2018a) introduce a responding
mechanism between the encoder and decoder to
generate various responses. Xing et al. (2017)
incorporate topic information to generate informa-
tive responses. However, these models suffer from
the deterministic structure when generating multi-
ple diverse responses. Besides, during the train-
ing of these models, response utterances are only
used in the loss function and ignored when for-
ward computing, which can confuse the model for
pursuing multiple objectives simultaneously.

A few works explore to change the determin-
istic structure of sequence-to-sequence models by
introducing stochastic latent variables. VAE is
one of the most popular methods (Bowman et al.,
2016; Zhao et al., 2017; Serban et al., 2017; Cao
and Clark, 2017), where the discourse-level diver-
sity is modeled by a Gaussian distribution. How-
ever, it is observed that in the CVAE with a fixed
Gaussian prior, the learned conditional posteriors
tend to collapse to a single mode, resulting in a
relatively simple scope (Wang et al., 2017). To
tackle this, WAE (Gu et al., 2018) which adopts a
Gaussian mixture prior network with Wasserstein
distance and VAD (Du et al., 2018) which sequen-
tially introduces a series of latent variables to con-
dition each word in the response sequence are pro-
posed. Although these models overcome the deter-
ministic structure of sequence-to-sequence model,
they still ignore the correlation of multiple valid
responses and each case is trained separately.

To consider the multiple responses jointly, the
maximum likelihood strategy is explored. Zhang
et al. (2018a) propose the maximum generated
likelihood criteria which model a query with its
multiple responses as a bag of instances and pro-
poses to optimize the model towards the most
likely answer rather than all possible responses.
Similarly, Rajendran et al. (2018) propose to re-
ward the dialogue system if any valid answer
is produced in the reinforcement learning phase.
Though considering multiple responses jointly, the
maximum likelihood strategy fails to utilize all
the references during training with some cases ig-



3828

Figure 2: The overall architecture of our proposed dialogue system where the two generation steps and testing
process are illustrated. Given an input query x, the model aims to approximate the multiple responses in a bag
{y} simultaneously with the continuous common and distinctive features, i.e., the latent variables c and z obtained
from the two generation phases respectively.

nored. In our approach, we consider multiple re-
sponses jointly and model each specific response
separately by a two-step generation architecture.

3 Approach

In this paper, we propose a novel response gen-
eration model for short-text conversation, which
models multiple valid responses for a given query
jointly. We posit that a dialogue system can ben-
efit from multi-reference learning by considering
the correlation of multiple responses. Figure 2
demonstrates the whole architecture of our model.
We now describe the details as follows.

3.1 Problem Formulation and Model
Overview

Training samples {(x, {y})i}i=Ni=1 consist of each
query x and the set of its valid responses {y},
where N denotes the number of training samples.
For a dialogue generation model, it aims to map
from the input query x to the output response
y ∈ {y}. To achieve this, different from conven-
tional methods which view the multiple responses
as independent ones, we propose to consider the
correlation of multiple responses with a novel two-
step generation architecture, where the response
bag {y} and each response y ∈ {y} are mod-
eled by two separate features which are obtained in
each generation phase respectively. Specifically,
we assume a variable c ∈ Rn representing the
common feature of different responses and an un-
observed latent variable z ∈ Z corresponding to
the distinct feature for each y in the bag. The com-

mon feature c is generated in the first stage given
x and the distinctive feature z is sampled from the
latent space Z in the second stage given the query
x and common feature c. The final responses are
then generated conditioned on both the common
feature c and distinct feature z simultaneously.

3.2 Common Feature of the Response Bag
In the first generation step, we aim to map from the
input query x to the common feature c of the re-
sponse bag {y}. Inspired by multi-instance learn-
ing (Zhou, 2004), we start from the simple intu-
ition that it is much easier for the model to fit mul-
tiple instances from their mid-point than a random
start-point, as illustrated in Figure 1.

To obtain this, we model the common feature
of the response bag as the mid-point of embed-
dings of multiple responses. In practice, we first
encode the input x with a bidirectional gated re-
current units (GRU) (Cho et al., 2014) to obtain an
input representation hx. Then, the common fea-
ture c is computed by a mapping network which
is implemented by a feed-forward neural network
whose trainable parameter is denoted as θ. The
feature c is then fed into the response decoder to
obtain the intermediate response yc which is con-
sidered to approximate all valid responses. Math-
ematically, the objective function is defined as:

Lavg =
1

|{y}|
∑

y∈{y}

log pψ(y|c) (1)

where |{y}| is the cardinality of the response bag
{y} and pψ represents the response decoder.



3829

Figure 3: The sentence embedding function of the dis-
criminator in the first generation phase.

Besides, to measure how well the intermediate
response yc approximates the mid-point response,
we set up an individual discriminator and derive
the mapping function to produce better results. As
to the discriminator, we first project each utter-
ance to an embedding space with fixed dimension-
ality via convolutional neural networks (CNNs)
with different kernels as the process shown in Fig-
ure 3. Then, the cosine similarity of the query
and response embeddings is computed, denoted as
Dθ′(x,y), where θ′ represents trainable parameter
in the discriminator. For the response bag {y}, the
average response embedding is used to compute
the matching score. The objective of intermedi-
ate response yc is then to minimize the difference
between Dθ′(x,yc) and Dθ′(x, {y}):

Ldisc = Ex,{y},yc [Dθ′(x,yc)−Dθ′(x, {y})] (2)

where yc denotes the utterance produced by the
decoder conditioned on the variable c.

To overcome the discrete and non-differentiable
problem, which breaks down gradient propagation
from the discriminator, we adopt a “soft” continu-
ous approximation (Hu et al., 2017):

ŷct ∼ softmax(ot/τ) (3)

where ot is the logit vector as the inputs to the
softmax function at time-step t and the tempera-
ture τ is set to τ → 0 as training proceeds for
increasingly peaked distributions. The whole loss
for the step-one generation is then

Lfirst = Lavg + Ldisc (4)

which is optimized by a minimax game with ad-
versarial training (Goodfellow et al., 2014).

3.3 Response Specific Generation
The second generation phase aims to model each
specific response in a response bag respectively. In

practice, we adopt the CVAE (Sohn et al., 2015;
Yan et al., 2015) architecture, while two promi-
nent modifications remain. Firstly, rather than
modeling each response with the latent variable
z from scratch, our model approximates each re-
sponse based on the bag representation c with only
the distinctive feature of each specific response re-
maining to be captured. Secondly, the prior com-
mon feature c can provide extra information for
the sampling network which is supposed to de-
crease the latent searching space.

Specifically, similar to the CVAE architecture,
the overall objective for our model in the second
generation phase is as below:

Lcvae =Eqφ(z|x,y,c)pθ(c|x)[log pψ(y|c, z)]
−D[qφ(z|x,y, c)||pϕ(z|x, c)]

(5)

where qφ represents the recognition network and
pϕ is the prior network with φ and ϕ as the train-
able parameters; D(·||·) is the regularization term
which measures the distance between the two dis-
tributions. In practice, the recognition networks
are implemented with a feed-forward network that

[
µ

log
(
σ2
)] = Wq

hxhy
c

+ bq (6)
where hx and hy are the utterance representations
of query and response got by GRU respectively,
and the latent variable z ∼ N (µ, σ2I). For the
prior networks, we consider two kinds of imple-
ments. One is the vanilla CVAE model (Zhao
et al., 2017) where the prior pϕ(z|x, c) is modeled
by a another feed-forward network conditioned on
the representations hx and c as follows,[

µ′

log
(
σ′2
)] = Wp [hxc

]
+ bp (7)

and the distance D(·||·) here is measured by the
KL divergence. For the other, we adopt the
WAE model (Gu et al., 2018) in which the prior
pϕ(z|x, c) is modeled by a mixture of Gaussian
distributions GMM(πk, µ′k, σ

′
k
2I)Kk=1, where K is

the number of Gaussian distributions and πk is the
mixture coefficient of the k-th component of the
GMM module as computed:

πk =
exp(ek)∑K
i=1 exp(ei)

(8)



3830

and  ekµ′k
log σ′2k

 = Wp,k [hxc
]

+ bp,k (9)

To sample an instance, Gumble-Softmax re-
parametrization trick (Kusner and Hernández-
Lobato, 2016) is utilized to normalize the coef-
ficients. The distance here is measured by the
Wasserstein distance which is implemented with
an adversarial discriminator (Zhao et al., 2018).

Recap that in the second generation phase the
latent variable z is considered to only capture
the distinctive feature of each specific response.
Hence to distinguish the latent variable z for each
separate response, we further introduce a multi-
reference bag-of-word loss (MBOW) which re-
quires the network to predict the current response
y against the response bag:

Lmbow = Eqφ(z|x,y,c)[log p(ybow|x, z)
+ λ log(1− p({ȳ}bow|x, z))]

(10)

where the probability is computed by a feed-
forward network f as the vanilla bag-of-word
loss (Zhao et al., 2017) does; {ȳ} is the comple-
mentary response bag of y and its probability is
computed as the average probability of responses
in the bag; and λ is a scaling factor accounting
for the difference in magnitude. As it shows, the
MBOW loss penalizes the recognition networks if
other complementary responses can be predicted
from the distinctive variable z. Besides, since the
probability of the complementary term may ap-
proach zero which makes it difficult to optimize,
we actually adopt its lower bound in practice:

log(1− p(ybow|x, z)) = log(1−
|y|∏
t=1

efyt∑|V |
j e

fj
)

≥ log(
|y|∏
t=1

(1− e
fyt∑|V |
j e

fj
))

(11)
where |V | is vocabulary size.

Totally, the whole loss for the step-two genera-
tion is then:

Lsecond = Lcvae + Lmbow (12)

which can be optimized in an end-to-end way.

3.4 Optimization and Testing

Our whole model can be trained in an end-to-end
fashion. To train the model, we first pre-train the
word embedding using Glove ((Pennington et al.,
2014))1. Then modules of the model are jointly
trained by optimizing the lossesLfirst andLsecond
of the two generation phases respectively. To over-
come the vanishing latent variable problem (Wang
et al., 2017) of CVAE, we adopt the KL annealing
strategy (Bowman et al., 2016), where the weight
of the KL term is gradually increased during train-
ing. The other technique employed is the MBOW
loss which is able to sharpen the distribution of
latent variable z for each specific response and al-
leviate the vanishing problem at the same time.

During testing, diverse responses can be ob-
tained by the two generation phases described
above, where the distinctive latent variable z cor-
responding to each specific response is sampled
from the prior probability network. This process
is illustrated in Figure 2. Capable of capturing the
common feature of the response bag, the variable
c is obtained from the mapping network and no in-
termediate utterance is required, which facilitates
reducing the complexity of decoding.

4 Experimental Setup

4.1 Dataset

Focusing on open-domain dialogue, we perform
experiments on a large-scale single-turn conver-
sation dataset Weibo (Shang et al., 2015), where
each input post is generally associated with mul-
tiple response utterances2. Concretely, the Weibo
dataset consists of short-text online chit-chat di-
alogues in Chinese, which is crawled from Sina
Weibo 3. Totally, there are 4,423,160 query-
response pairs for training set and 10000 pairs
for the validation and testing, where there are
around 200k unique query in the training set and
each query used in testing correlates with four re-
sponses respectively. For preprocessing, we fol-
low the conventional settings (Shang et al., 2015).

4.2 Baselines

We compare our model with representative dia-
logue generation approaches as listed below:

1https://nlp.stanford.edu/projects/glove/
2More such multi-reference data is widely available, e.g.

social media like Twitter. But we adopt Weibo in this work
since it is large and publicly available.

3https://www.weibo.com/



3831

Method Multi-BLEU EMBEDDING Intra-Dist Inter-DistBLEU-1 BLEU-2 G A E Dist-1 Dist-2 Dist-1 Dist-2
S2S 21.49 9.498 0.567 0.677 0.415 0.311 0.447 0.027 0.127
S2S+DB 20.20 9.445 0.561 0.682 0.422 0.324 0.457 0.028 0.130
MMS 21.40 9.398 0.569 0.691 0.427 0.561 0.697 0.033 0.158
CVAE 22.71 8.923 0.601 0.730 0.452 0.628 0.801 0.035 0.179
CVAE+BOW 23.12 8.420 0.605 0.741 0.456 0.687 0.873 0.038 0.194
WAE 24.02 9.281 0.611 0.754 0.460 0.734 0.885 0.044 0.196
Ours-First 23.68 9.240 0.619 0.762 0.471 0.725 0.891 0.045 0.199
Ours-Disc 24.22 9.101 0.617 0.754 0.465 0.670 0.863 0.036 0.184
Ours-MBOW 23.88 9.582 0.622 0.778 0.477 0.681 0.877 0.040 0.190
Ours 24.04 9.362 0.625 0.771 0.480 0.699 0.876 0.042 0.190
Ours+GMP 24.20 9.417 0.618 0.769 0.482 0.728 0.889 0.044 0.198

Table 1: Automatic evaluation results of different models where the best results are bold. The G, A and E of
Embedding represent Greedy, Average, Extreme embedding-based metrics, repsectively.

Method Rela. Divt. Red. Overall
Gold 3.90 4.22 3.79 3.97
S2S 3.10 2.77 3.24 3.07
CVAE 2.98 3.12 3.10 3.07
Ours 3.22 3.19 3.23 3.21

Table 2: Human evaluation results of different models.
Rela., Divt. and Red. represent Relevance, Diversity
and Readability, respectively. The Kappa score among
different human evaluators is 0.4412, which indicates
moderate human agreements.

S2S: the vanilla sequence-to-sequence model
with attention mechanism (Bahdanau et al., 2014)
where standard beam search is applied in testing
to generate multiple different responses.

S2S+DB: the vanilla sequence-to-sequence
model with the modified diversity-promoting
beam search method (Li et al., 2016b) where a
fixed diversity rate 0.5 is used.

MMS: the modified multiple responding
mechanisms enhanced dialogue model proposed
by Zhou et al. (2018a) which introduces respond-
ing mechanism embeddings (Zhou et al., 2017)
for diverse response generation.

CVAE: the vanilla CVAE model (Zhao et al.,
2017) with and without BOW (bag-of-word)
loss (CVAE+BOW and CVAE).

WAE: the conditional Wasserstein autoencoder
model for dialogue generation (Gu et al., 2018)
which models the distribution of data by training a
GAN within the latent variable space.

Ours: we explore our model Ours and conduct

various ablation studies: the model with only the
second stage generation (Ours-First), the model
without the discriminator (Ours-Disc) and multi-
reference BOW loss (Ours-MBOW), and the
model with GMM prior networks (Ours+GMP).

4.3 Evaluation Metrics

To comprehensively evaluate the quality of gener-
ated response utterances, we adopt both automatic
and human evaluation metrics:

BLEU: In dialogue generation, BLEU is widely
used in previous studies (Yao et al., 2017; Shang
et al., 2018). Since multiple valid responses ex-
ist in this paper, we adopt multi-reference BLEU
where the evaluated utterance is compared to pro-
vided multiple references simultaneously.

Distinctness: To distinguish safe and common-
place responses, the distinctness score (Li et al.,
2016a) is designed to measure word-level diversity
by counting the ratio of distinctive [1,2]-grams.
In our experiments, we adopt both Intra-Dist:
the distinctness scores of multiple responses for a
given query and Inter-Dist: the distinctness scores
of generated responses of the whole testing set.

Embedding Similarity: Embedding-based
metrics compute the cosine similarity between the
sentence embedding of a ground-truth response
and that of the generated one. There are various
ways to obtain the sentence-level embedding from
the constituent word embeddings. In our experi-
ments, we apply three most commonly used strate-
gies: Greedy matches each word of the reference
with the most similar word in the evaluated sen-
tence; Average uses the average of word embed-



3832

Input 火山喷发瞬间的一些壮观景象。 再过十分钟就进入win8时代，我是系统升级控。
Query These are some magnificent sights at the moment of the

volcanic eruption.
There remain ten minutes before we entering the era of win8. I am
a geek of system updating.

Gold 大自然才是人类的最终boss。 问个白痴问题必须正版才能升级吧？
Nature is the final boss of human. May I ask an idiot problem. Does the update require a license?
真帅，12月份的时候就能亲眼看到了，好开心啊。 不是给平板电脑用的系统吗？
So cool! I am so happy to see it by myself in December. Isn’t this system for PAD?
被惊艳震撼到了。 已经用了一个多月了，不过还是不喜欢8
I am deeply surprised and shocked. I have used it for a month but I still don’t like it 8
震撼了，小小人类仰视造物主的强大。 好久木用电脑了，想念。
Shocked! The imperceptible humanity looks up to the
power of the creator.

Having not used the computer for a long time, I miss it.

CVAE 大半夜的不光是白天。 这是要用手机吗？
It’s midnight, not only daytime. Do you want to use the phone?
一天一天就能看到了。 我是升级了升级版了。
We can see it day after day. I have updated to the upgrade.
天地之间的风景有如此之美。 我还以为是我的电脑。
How could there exist such amazing sights. I thought it was my computer.
火山喷发瞬间的萤火虫。 升级版的机器人。
The glowworm at the moment of volcanic eruption. The upgraded robot.

Ours 好美，这是哪里呀？ 这是什么软件啊，求解。
So amazing! Where is this? I am wondering what software it is.
好壮观啊一定要保存下来。 我觉得微软的ui还不错。
It’s so magnificent that it should be preserved. I think the ui of Microsoft is not bad.
大白天的不能看到。 现在的产品已经不是新产品了。
It can’t be seen during the day. The current product is not the new.
如果有机会亲眼所见过。 这个是什么应用啊。
If you have chance to see it yourself. What application is this.
如此这般这般淼小。 我觉得这样的界面更像windows8。
It is so so imperceptible. I think interface like this looks more like windows8.

Table 3: Case study for the generated responses from the testing set of Weibo, where the Chinese utterances are
translated into English for the sake of readability. For each input query, we show four responses generated by each
method and an additional intermediate utterance (marked with underline) for our model.

dings; andExtreme takes the most extreme value
among all words for each dimension of word em-
beddings in a sentence. Since multiple references
exist, for each utterance to be evaluated, we com-
pute its score with the most similar reference.

Human Evaluation with Case Analysis: As
automatic evaluation metrics lose sight of the over-
all quality of a response (Tao et al., 2018), we also
adopt human evaluation on 100 random samples to
assess the generation quality with three indepen-
dent aspects considered: relevance (whether the
reply is relevant to the query), diversity (whether
the reply narrates with diverse words) and read-
ability (whether the utterance is grammatically
formed). Each property is assessed with a score
from 1 (worst) to 5 (best) by three annotators. The
evaluation is conducted in a blind process with the
utterance belonging unknown to the reviewers.

4.4 Implementation Details

All models are trained with the following hyper-
parameters: both encoder and decoder are set to
one layer with GRU (Cho et al., 2014) cells, where
the hidden state size of GRU is 256; the utter-
ance length is limited to 50; the vocabulary size is
50,000 and the word embedding dimension is 256;
the word embeddings are shared by the encoder

and decoder; all trainable parameters are initial-
ized from a uniform distribution [-0.08, 0.08]; we
employ the Adam (Kingma and Ba, 2014) for opti-
mization with a mini-batch size 128 and initialized
learning rate 0.001; the gradient clipping strategy
is utilized to avoid gradient explosion, where the
gradient clipping value is set to be 5. For the la-
tent variable, we adopt dimensional size 256 and
the component number of the mixture Gaussian
for prior networks in WAE is set to 5. As to the
discriminator, we set the initialized learning rate
as 0.0002 and use 128 different kernels for each
kernel size in {2, 3, 4}. The size of the response
bag is limited to 10 where the instances inside are
randomly sampled for each mini-batch. All the
models are implemented with Pytorch 0.4.1 4.

5 Results and Analysis

5.1 Comparison against Baselines

Table 1 shows our main experimental results,
with baselines shown in the top and our mod-
els at the bottom. The results show that our
model (Ours) outperforms competitive baselines
on various evaluation metrics. The Seq2seq based
models (S2S, S2S-DB and MMS) tend to generate

4https://pytorch.org



3833

fluent utterances and can share some overlapped
words with the references, as the high BLEU-2
scores show. However, the distinctness scores il-
lustrate that these models fail to generate mul-
tiple diverse responses in spite of the diversity-
promoting objective and responding mechanisms
used. We attribute this to that these models fail to
consider multiple references for the same query,
which may confuse the models and lead to a com-
monplace utterance. As to the CVAE and WAE
models, with the latent variable to control the
discourse-level diversity, diverse responses can be
obtained. Compared against these previous meth-
ods, our model can achieve the best or second
best performances on different automatic evalu-
ation metrics where the improvements are most
consistent on BLEU-1 and embedding-based met-
rics, which demonstrates the overall effectiveness
of our proposed architecture.

In order to better study the quality of generated
responses, we also report the human evaluation re-
sults in Table 2. As results show, although there
remains a huge gap between existing methods and
human performance (the Gold), our model gains
promising promotions over previous methods on
generating appropriate responses with diverse ex-
pressions. With both obvious superiority (read-
ability for S2S and diversity for CVAE) and inferi-
ority (diversity for S2S and relevance for CVAE),
the baselines show limited overall performances,
in contrast to which our method can output more
diverse utterances while maintaining the relevance
to the input query and achieve a high overall score.

5.2 Ablation Study

To better understand the effectiveness of each
component in our model, we further conduct the
ablation studies with results shown at the bottom
of Table 1. Above all, to validate the effective-
ness of the common feature, we remove the first
generation stage and get the Ours-First model. As
the results of BLEU and embedding-based metrics
show, the system can benefit from the common
feature for better relevance to the query.

Moreover, pairwise comparisons Ours-Disc vs.
Ours and Ours-MBOW vs. Ours validate the
effects of the discriminator and modified multi-
reference bag-of-word loss (MBOW). As results
show, the discriminator facilitates extracting the
common feature and yields more relevant re-
sponses to the input query afterward. The MBOW

Figure 4: The statistics of distances between the
input query/intermediate utterance and gold refer-
ences/generated responses, where the distance is mea-
sured by the cosine similarity of sentence embeddings.

loss, similar to the effects of BOW loss in the
CVAE, can lead to a more unique latent variable
for each response and improve the final distinct-
ness scores of generated utterances. In the experi-
ments, we also observed the KL vanishing prob-
lem when training our model and we overcame
it with the KL weight annealing strategy and the
MBOW loss described above.

5.3 Case Study and Discussion

Table 3 illustrates two examples of generated
replies to the input query got from the testing set.
Comparing the CVAE and Ours, we can find that
although the CVAE model can generate diverse ut-
terances, its responses tend to be irrelevant to the
query and sometimes not grammatically formed,
e.g. the words “glowworm” and “robot” in the
sentences. In contrast, responses generated by our
model show better quality, achieving both high rel-
evance and diversity. This demonstrates the ability
of the two-step generation architecture. For better
insight into the procedure, we present the inter-
mediately generated utterances which show that
the feature extracted in the first stage can focus
on some common and key aspects of the query
and its possible responses, such as the “amazing”
and “software”. With the distinctive features sam-
pled in the second generation phase, the model fur-
ther revises the response and outputs multiple re-
sponses with diverse contents and expressions.

Recap that the common feature is expected to
capture the correlations of different responses and
serve as the base of a response bag from which dif-
ferent responses are further generated, as shown



3834

in Figure 1. To investigate the actual perfor-
mances achieved by our model, we compute the
distance between the input query/intermediate ut-
terance and gold references/generated responses
and present the results in Figure 4. As shown, in-
termediate utterances obtained in the first genera-
tion phase tend to approximate multiple responses
with similar distances at the same time. Compar-
ing the generated responses and the references, we
find that generated responses show both high rel-
evant and irrelevant ratios, as the values near 0.00
and 1.00 show. This actually agrees well with our
observation that the model may sometimes rely
heavily on or ignore the prior common feature in-
formation. From a further comparison between the
input query and the mid, we also observe that the
intermediate utterance is more similar to final re-
sponses than the input query, which correlates well
with our original intention shown in Figure 1.

6 Conclusion and future work

In this paper, we tackle the one-to-many query-
response mapping problem in open-domain con-
versation and propose a novel two-step generation
architecture with the correlation of multiple valid
responses considered. Jointly viewing the multi-
ple responses as a response bag, the model extracts
the common and distinct features of different re-
sponses in two generation phases respectively to
output multiple diverse responses. Experimental
results illustrate the superior performance of the
proposed model in generating diverse and appro-
priate responses compared to previous represen-
tative approaches. However, the modeling of the
common and distinct features of responses in our
method is currently implicit and coarse-grained.
Directions of future work may be pursuing better-
defined features and easier training strategies.

7 Acknowledgments

We would like to thank the anonymous re-
viewers for their constructive comments. This
work was supported by the National Key Re-
search and Development Program of China (No.
2017YFC0804001), the National Science Foun-
dation of China (NSFC No. 61672058; NSFC
No. 61876196). Rui Yan was sponsored by CCF-
Tencent Open Research Fund and Alibaba Innova-
tive Research (AIR) Fund.

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2014. Neural machine translation by jointly
learning to align and translate. arXiv preprint
arXiv:1409.0473.

Samuel R Bowman, Luke Vilnis, Oriol Vinyals, An-
drew Dai, Rafal Jozefowicz, and Samy Bengio.
2016. Generating sentences from a continuous
space. In Proceedings of The 20th SIGNLL Confer-
ence on Computational Natural Language Learning,
pages 10–21.

Kris Cao and Stephen Clark. 2017. Latent variable di-
alogue models and their diversity. In Proceedings of
the 15th Conference of the European Chapter of the
Association for Computational Linguistics: Volume
2, Short Papers, pages 182–187.

Kyunghyun Cho, Bart Van Merriënboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using rnn encoder-decoder
for statistical machine translation. arXiv preprint
arXiv:1406.1078.

Jiachen Du, Wenjie Li, Yulan He, Ruifeng Xu, Li-
dong Bing, and Xuan Wang. 2018. Variational au-
toregressive decoder for neural response generation.
In Proceedings of the 2018 Conference on Empiri-
cal Methods in Natural Language Processing, pages
3154–3163.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets. In Advances in neural information
processing systems, pages 2672–2680.

Xiaodong Gu, Kyunghyun Cho, Jungwoo Ha, and
Sunghun Kim. 2018. Dialogwae: Multimodal
response generation with conditional wasserstein
auto-encoder. arXiv preprint arXiv:1805.12352.

Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan
Salakhutdinov, and Eric P Xing. 2017. Toward
controlled generation of text. arXiv preprint
arXiv:1703.00955.

Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Matt J Kusner and José Miguel Hernández-Lobato.
2016. Gans for sequences of discrete elements with
the gumbel-softmax distribution. arXiv preprint
arXiv:1611.04051.

Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2016a. A diversity-promoting ob-
jective function for neural conversation models. In
Proceedings of NAACL-HLT, pages 110–119.

Jiwei Li, Will Monroe, and Dan Jurafsky. 2016b. A
simple, fast diverse decoding algorithm for neural
generation. arXiv preprint arXiv:1611.08562.



3835

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP), pages 1532–1543.

Janarthanan Rajendran, Jatin Ganhotra, Satinder Singh,
and Lazaros Polymenakos. 2018. Learning end-
to-end goal-oriented dialog with multiple answers.
In Proceedings of the 2018 Conference on Empiri-
cal Methods in Natural Language Processing, pages
3834–3843.

Shoetsu Sato, Naoki Yoshinaga, Masashi Toyoda, and
Masaru Kitsuregawa. 2017. Modeling situations in
neural chat bots. In Proceedings of ACL 2017, Stu-
dent Research Workshop, pages 120–127.

Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe,
Laurent Charlin, Joelle Pineau, Aaron C Courville,
and Yoshua Bengio. 2017. A hierarchical latent
variable encoder-decoder model for generating di-
alogues. In AAAI, pages 3295–3301.

Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.
Neural responding machine for short-text conversa-
tion. In Proceedings of the 53rd Annual Meeting of
the Association for Computational Linguistics and
the 7th International Joint Conference on Natural
Language Processing (Volume 1: Long Papers), vol-
ume 1, pages 1577–1586.

Mingyue Shang, Zhenxin Fu, Nanyun Peng, Yansong
Feng, Dongyan Zhao, and Rui Yan. 2018. Learning
to converse with noisy data: Generation with cali-
bration. In IJCAI, pages 4338–4344.

Louis Shao, Stephan Gouws, Denny Britz, Anna
Goldie, Brian Strope, and Ray Kurzweil. 2016.
Generating long and diverse responses with neural
conversation models. openreview.

Kihyuk Sohn, Honglak Lee, and Xinchen Yan. 2015.
Learning structured output representation using
deep conditional generative models. In Advances in
neural information processing systems, pages 3483–
3491.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.
A neural network approach to context-sensitive gen-
eration of conversational responses. arXiv preprint
arXiv:1506.06714.

Chongyang Tao, Lili Mou, Dongyan Zhao, and Rui
Yan. 2018. Ruber: An unsupervised method for au-
tomatic evaluation of open-domain dialog systems.
In Thirty-Second AAAI Conference on Artificial In-
telligence.

Liwei Wang, Alexander Schwing, and Svetlana Lazeb-
nik. 2017. Diverse and accurate image description
using a variational auto-encoder with an additive
gaussian encoding space. In Advances in Neural In-
formation Processing Systems, pages 5756–5766.

Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang,
Ming Zhou, and Wei-Ying Ma. 2017. Topic aware
neural response generation. In AAAI, volume 17,
pages 3351–3357.

Xinchen Yan, Jimei Yang, Kihyuk Sohn, and Honglak
Lee. 2015. Attribute2image: Conditional image
generation from visual attributes. arXiv preprint
arXiv:1512.00570.

Lili Yao, Yaoyuan Zhang, Yansong Feng, Dongyan
Zhao, and Rui Yan. 2017. Towards implicit content-
introducing for generative short-text conversation
systems. In Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Process-
ing, pages 2190–2199.

Hainan Zhang, Yanyan Lan, Jiafeng Guo, Jun Xu, and
Xueqi Cheng. 2018a. Tailored sequence to sequence
models to different conversation scenarios. In Pro-
ceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), volume 1, pages 1479–1488.

Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur
Szlam, Douwe Kiela, and Jason Weston. 2018b.
Personalizing dialogue agents: I have a dog, do you
have pets too? arXiv preprint arXiv:1801.07243.

Junbo Zhao, Yoon Kim, Kelly Zhang, Alexander Rush,
and Yann LeCun. 2018. Adversarially regularized
autoencoders. In International Conference on Ma-
chine Learning, pages 5897–5906.

Tiancheng Zhao, Ran Zhao, and Maxine Eskenazi.
2017. Learning discourse-level diversity for neural
dialog models using conditional variational autoen-
coders. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 654–664.

Ganbin Zhou, Ping Luo, Rongyu Cao, Fen Lin,
Bo Chen, and Qing He. 2017. Mechanism-aware
neural machine for dialogue response generation. In
AAAI, pages 3400–3407.

Ganbin Zhou, Ping Luo, Yijun Xiao, Fen Lin, Bo Chen,
and Qing He. 2018a. Elastic responding machine
for dialog generation with dynamically mechanism
selecting. In AAAI Conference on Artificial Intelli-
gence, AAAI.

Hao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan
Zhu, and Bing Liu. 2018b. Emotional chatting ma-
chine: Emotional conversation generation with in-
ternal and external memory. In Thirty-Second AAAI
Conference on Artificial Intelligence.

Zhi-Hua Zhou. 2004. Multi-instance learning: A sur-
vey. Department of Computer Science & Technol-
ogy, Nanjing University, Tech. Rep.


