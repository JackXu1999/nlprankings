



















































Coreference Resolution with Entity Equalization


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 673–677
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

673

Coreference Resolution with Entity Equalization

Ben Kantor
Tel Aviv University

benkantor@mail.tau.ac.il

Amir Globerson
Tel Aviv University

amir.globerson@gmail.com

Abstract

A key challenge in coreference resolution is
to capture properties of entity clusters, and
use those in the resolution process. Here we
provide a simple and effective approach for
achieving this, via an “Entity Equalization”
mechanism. The Equalization approach rep-
resents each mention in a cluster via an ap-
proximation of the sum of all mentions in the
cluster. We show how this can be done in
a fully differentiable end-to-end manner, thus
enabling high-order inferences in the resolu-
tion process. Our approach, which also em-
ploys BERT embeddings, results in new state-
of-the-art results on the CoNLL-2012 corefer-
ence resolution task, improving average F1 by
3.6%.1

1 Introduction

Coreference resolution is the task of grouping
mentions into entities. A key challenge in this task
is that information about an entity is spread across
multiple mentions. Thus, deciding whether to as-
sign a given mention to a candidate entity could
require entity-level information that needs to be
aggregated from all mentions.

Most coreference resolution systems rely on
pairwise scoring of entity mentions (Clark and
Manning, 2016; Lee et al., 2017; Denis and
Baldridge, 2008; Rahman and Ng, 2009; Durrett
et al., 2013; Chang et al., 2013; Wiseman et al.,
2016; Martschat and Strube, 2015). As such they
are prone to missing global entity information.

The problem of entity-level representation (also
referred to as high-order coreference models) has
attracted considerable interest recently, with meth-
ods ranging from imitation learning (Clark and
Manning, 2015) to iterative refinement (Lee et al.,
2018). Specifically, Lee et al. (2018) tackled this

1Our code is publicly available at https://github.
com/kkjawz/coref-ee

problem by iteratively averaging the antecedents
of each mention to create mention representations
that are more “global” (i.e., reflect information
about the entity to which the mention refers).

Here we propose an approach that provides an
entity-level representation in a simple and intuitive
manner, and also facilitates end-to-end optimiza-
tion. Our “Entity Equalization” approach posits
that each entity should be represented via the sum
of its corresponding mention representations. It
is not immediately obvious how to perform this
equalization, which relies on the entity-to-mention
mapping, but we provide a natural smoothed rep-
resentation of this mapping, and demonstrate how
to use it for equalization.

Now that each mention contains information
about all its corresponding entities, we can use a
standard pairwise scoring model, and this model
will be able to use global entity-level information.

Similar to recent coreference models, our ap-
proach uses contextual embeddings as input men-
tion representations. While previous approaches
employed the ELMo model (Lee et al., 2018), we
propose to use BERT embeddings (Devlin et al.,
2018), motivated by the impressive empirical per-
formance of BERT on other tasks. It is challenging
to apply BERT to the coreference resolution set-
ting because BERT is limited to a fixed sequence
length which is shorter than most coreference res-
olution documents. We show that this can be done
by using BERT in a fully convolutional manner.
Our work is the first to use BERT for the task of
coreference resolution, and we demonstrate that
this results in significant improvement over cur-
rent state-of-the-art.

In summary, our contributions are: a. A sim-
ple and intuitive approach for entity-level repre-
sentation via the notion of Entity-Equalization. b.
The first use of BERT embeddings in coreference-
resolution. c. New state-of-the-art performance on

https://github.com/kkjawz/coref-ee
https://github.com/kkjawz/coref-ee


674

the CoNLL-2012 coreference resolution task, im-
proving over previous F1 performance by 3.6%.

2 Background

Following Lee et al. (2017), we cast the corefer-
ence resolution task as finding a set of antecedent
assignments yi for each span i in the document.
The set of possible values for each yi is Y(i) =
{�, 1, . . . , i − 1}, a dummy antecedent � and all
preceding spans. Non-dummy antecedents repre-
sent coreference links between i and yi, whereas �
indicates that the span is either not a mention, or is
a first mention in a newly formed cluster. When-
ever a new cluster is formed it receives a new in-
dex, and every mention with yi 6= � receives the
index of its antecedents. Thus the process results
in clusters of coreferent entities.

2.1 Baseline Model

We briefly describe the baseline model (Lee et al.,
2018) which we will later augment with Entity-
Equalization and BERT features. Let s(i, j) de-
note a pairwise score between two spans i and j.
Next, for each span i define the distribution P (yi)
over antecedents:

P (yi) =
es(i,yi)∑

y∈Y(i) e
s(i,y)

.

The score is a function of the span representations
defined as follows. For each span i let gi ∈ Rd de-
note its corresponding representation vector (see
Lee et al. (2018) for more details about the model
architecture). Lee et al. (2017) computes the an-
tecedent score s(i, j) = fs(gi, gj) as a pairwise
function of the span representations, i.e. not di-
rectly incorporating any information about the en-
tities to which they might belong. Lee et al.
(2018) improved upon this model by “refining” the
span representations as follows. The expected an-
tecedent representation ai of each span i is com-
puted by using the current antecedent distribution
P (yi) as an attention mechanism:

ai =
∑

yi∈Y(i)

P (yi) · gyi (1)

The current span representation gi is then updated
via interpolation with its expected antecedent rep-
resentation ai:

g′i = fi ◦ gi + (1− fi) ◦ ai (2)

where fi = ff (gi,ai) is a learned gate vector.
Thus, the refined representation g′i is an element-
wise weighted average of the current span repre-
sentation and its direct antecedents. Using this
representation the refined antecedent distribution
can be calculated as follows:

P ′(yi) =
es(g

′
i,g

′
yi
)∑

y∈Y(i) e
s(g′i,g

′
y)

3 Entity Equalization

The idea behind the refinement procedure in Lee
et al. (2018) was to create features that are closer
to cluster-level representations and hence more
“global”. This was partially achieved by con-
sidering not only the current span but also its
antecedents. We would like take this idea one
step further and create refined span representations
that contain information about the entire cluster to
which it belongs. One way to achieve this is by
simply representing each mention via the sum of
the mentions currently in its coreference cluster.
Formally, let C(i) be a coreference cluster (as de-
fined by the antecedent distribution P (yi)) such
that i ∈ C(i), and replace Equation 1 with:

ai =
∑
j∈C(i)

gj (3)

As a result each span will now contain informa-
tion about all of its current coreference cluster, ef-
fectively equalizing the representations of differ-
ent spans belonging to the same cluster.

However, note that it is not clear how to train
such a procedure end-to-end because the cluster-
ing process is not differentiable. To overcome this
problem, we use a differentiable relaxation of the
clustering process (Le and Titov, 2017) and use
the resulting soft clustering matrix to create a fully
differentiable cluster representation. We call this
refinement procedure Entity Equalization and pro-
vide a detailed description in the next section.

To illustrate the difference between Entity
Equalization and antecedent averaging, consider
the following example: “[John] went to the park
and [he] got tired. [John] decided to go back
home.” Now assume that the model outputs the
following antecedent distribution P (yi):

John1 he John2
John1 1 0 0

he 1 0 0
John2 1 0 0



675

there is only one coreference cluster induced by
this antecedent matrix, C = {John1, he, John2}.
A cluster representation for John2 would be the
sum of the representations of all three mentions.
However, using antecedent averaging, the repre-
sentation of John2 will be a weighted average of
the representations of John2 and John1, because
only John1 is an antecedent of John2.

3.1 Implementing Equalization
In order to achieve differentiable cluster represen-
tations, we need a differentiable soft-clustering
process. Le and Titov (2017) introduced such a
relaxation given an antecedent distribution, based
on the following observation: in a document con-
taining m mentions there are m potential entities
E1, ..., Em where Ei has mention i as the first
mention. Let Q(i ∈ Ej) be the probability that
mention i corresponds to entity Ej (that is, to the
entity that has j as its first mention). Le and Titov
(2017) showed that this probability can be com-
puted recursively based on the antecedent distri-
bution P (yi) as follows:

Q(i ∈ Ej) =
∑i−1

k=j P (yi = k) ·Q(k ∈ Ej) if j < i
P (yi = �) if j = i
0 if j > i

Note that this is a fully differentiable procedure
that calculates the clustering distribution for each
entity i.

The distribution Q(i ∈ Ej) above leads to a
simple differentiable implementation of the equal-
ization operation in (3), as described next. In order
to use entity representations for equalizing men-
tion representations, we need a representation for
each entityEi at each time step t, so we won’t rep-
resent a mention using mentions not yet encoun-
tered. We denote it by:

e
(t)
i =

t∑
j=1

Q(j ∈ Ei) · gj

Finally, an entity representation for each mention
i is calculated using the entity distribution of men-
tion i and the global entity representations:

ai =

i∑
j=1

Q(i ∈ Ej) · e(i)j

It can be seen that the above ai will indeed lead to
(3) when the distributions P (y) are deterministic.

4 Using BERT Embeddings

Our coreference model relies on input representa-
tions for each input token. Lee et al. (2018) used
the ELMo context-dependent embeddings for this
purpose. Here we propose to use the more recent
BERT embeddings (Devlin et al., 2018) instead,
which have achieved state of the art performance
on many natural language processing tasks. BERT
is a bidirectional contextual language model based
on the Transformer architecture (Vaswani et al.,
2017). Using BERT for coreference resolution
is not trivial: BERT can only run on sequences
of fixed length which is determined in the pre-
training process. In the pre-trained model pub-
lished by Devlin et al. (2018), this limitation is 512
tokens, which is shorter than many of the docu-
ments in the CoNLL-2012 coreference resolution
task. Even without considering the pre-training
limitation, because the attention mechanism grows
as the square of the sequence length, and because
of the large number of parameters of the BERT
model, running it on very large sequences is not
feasible on most machines due to memory con-
straints.

In order to obtain BERT embeddings for se-
quences of unlimited length, we propose to use
BERT in a convolutional mode as follows. Let
D be a fixed window length. We obtain a repre-
sentation for token i by applying BERT to the se-
quence of tokens from D to the left of i to D to
the right of i. We then take the four last layers of
the BERT model for token i and apply a learnable
weighted averaging to those, similar to the process
used in ELMo. The output of the network is taken
as the representation of token i, and replaced the
ELMo representation in the model of Section 3.1.
We use D = 64, since using the maximum size of
D = 256 is computationally intensive, and good
results are already obtained with 64.2

5 Related Work

Several works have addressed the issue of entity-
level representation (Culotta et al., 2007; Wick
et al., 2009; Singh et al., 2011). In Wiseman
et al. (2016) an RNN is used to model each en-
tity. While this allows complex entity representa-
tions, the assignment of a mention to an RNN is a

2We note that BERT uses a special tokenization called
WordPiece (Wu et al., 2016) which can split words to sub-
words. When a word was split to several sub-words, only the
embedding of the first sub-word was taken.



676

MUC B3 CEAFφ4
Prec. Rec. F1 Prec. Rec. F1 Prec. Rec. F1 Avg. F1

Lee et al. (2018) 81.4 79.5 80.4 72.2 69.5 70.8 68.2 67.1 67.6 73.0
+ BERT 83.51 82.8 83.16 74.51 74.14 74.32 71.93 70.6 71.26 76.25

– Second-order 82.61 83.48 83.04 73.56 75.44 74.49 71.6 71.55 71.57 76.37
+ EE (Ours) 82.63 84.14 83.38 73.31 76.17 74.71 72.37 71.14 71.75 76.61

Table 1: Results on the test set of the English CoNLL-2012 shared task. The average F1 of MUC, B3 and CEAFφ4
is the main evaluation metric.

hard decision, and as such cannot be optimized in
an end-to-end manner. Clark and Manning (2015)
use whole-entity representations as obtained from
agglomerative clustering. But again the clustering
operation in non-differentiable, requiring the use
of imitation learning. In Lee et al. (2018), entity
refinement is more restricted, as it is only obtained
from the attention vector at each step. Thus, we
believe that our model is the first to use entity-level
representations that correspond directly to the in-
ferred clusters, and are end-to-end differentiable.

Mention-entity mappings have been used in the
context of optimizing coreference performance
measures (Le and Titov, 2017; Clark and Man-
ning, 2016). Here we show that these mappings
can also be used for the resolution model itself.
We note that we did not try to optimize for coref-
erence measures as in Le and Titov (2017), and
this is likely to further improve results.

6 Experiments

Data for all our experiments is taken from the En-
glish portion of the CoNLL-2012 coreference res-
olution tasks (Pradhan et al., 2012). Our experi-
mental setup is very similar to Lee et al. (2018),
and our code is built on theirs. We did not change
the optimizer or any of the training hyperparam-
eters. The following changes were made to the
model:

• We used BERT word embeddings instead of
ELMo as input to the LSTM (see Section 4).

• We replaced the span representation refine-
ment mechanism with our Entity Equaliza-
tion approach (see Section 3).

7 Results

Following Pradhan et al. (2012), we report preci-
sion, recall and F1 of the MUC, B3 and CEAFφ4
metrics, and average the F1 score of all three met-
rics to get the main evaluation metric used in the

CoNLL-2012 coreference resolution task. We cal-
culated the metrics using the official evaluation
scripts of CoNLL-2012.

Results on the test set are shown in Table 1.
Our baseline is the span-ranking model from
Lee et al. (2018) with ELMo input features and
second-order span representations, which achieves
73.0% Avg. F1. Replacing the ELMo features
with BERT features achieves 76.25% average F1.
Removing the second-order span-representations
while using BERT features achieves 76.37% F1,
achieving higher recall and lower precision on
all evaluation metrics, while somewhat surpris-
ingly being better overall. Replacing second-
order span representations with Entity Equaliza-
tion achieves 76.64% average F1, while also con-
sistently achieving the highest F1 score on all three
evaluation metrics. Our results set a new state of
the art for coreference resolution, improving the
previous state of the art by 3.6% average F1.

8 Conclusion

In this work we presented a new state-of-the-art
coreference resolution system. Key to our ap-
proach is the idea that each mention should con-
tain information about all its coreferring mentions.
Here we implemented this idea by summing all
mention representations within a cluster. In the fu-
ture we plan to further enrich these representations
by considering information from across the docu-
ment. Furthermore, we can consider more struc-
tured representations of entities that reflect entity
attributes and inter-entity relations.

Acknowledgments

This work was supported by a grant from the Israel
Science Foundation.



677

References
Kai-Wei Chang, Rajhans Samdani, and Dan Roth.

2013. A constrained latent variable model for coref-
erence resolution. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing, pages 601–612.

Kevin Clark and Christopher D Manning. 2015. Entity-
centric coreference resolution with model stacking.
In Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers), vol-
ume 1, pages 1405–1415.

Kevin Clark and Christopher D Manning. 2016. Deep
reinforcement learning for mention-ranking coref-
erence models. In Proceedings of the 2016 Con-
ference on Empirical Methods in Natural Language
Processing, pages 2256–2262.

Aron Culotta, Michael Wick, and Andrew McCallum.
2007. First-order probabilistic models for corefer-
ence resolution. In Human Language Technologies
2007: The Conference of the North American Chap-
ter of the Association for Computational Linguistics;
Proceedings of the Main Conference, pages 81–88.

Pascal Denis and Jason Baldridge. 2008. Specialized
models and ranking for coreference resolution. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, pages 660–
669. Association for Computational Linguistics.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. arXiv preprint arXiv:1810.04805.

Greg Durrett, David Hall, and Dan Klein. 2013. De-
centralized entity-level modeling for coreference
resolution. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), volume 1, pages 114–124.

Phong Le and Ivan Titov. 2017. Optimizing differen-
tiable relaxations of coreference evaluation metrics.
In Proceedings of the 21st Conference on Computa-
tional Natural Language Learning (CoNLL 2017),
pages 390–399.

Kenton Lee, Luheng He, Mike Lewis, and Luke Zettle-
moyer. 2017. End-to-end neural coreference reso-
lution. In Proceedings of the 2017 Conference on
Empirical Methods in Natural Language Process-
ing, pages 188–197.

Kenton Lee, Luheng He, and Luke Zettlemoyer. 2018.
Higher-order coreference resolution with coarse-to-
fine inference. In Proceedings of the 2018 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, Volume 2 (Short Papers), vol-
ume 2, pages 687–692.

Sebastian Martschat and Michael Strube. 2015. La-
tent structures for coreference resolution. Transac-
tions of the Association for Computational Linguis-
tics, 3:405–418.

Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. Conll-
2012 shared task: Modeling multilingual unre-
stricted coreference in ontonotes. In Joint Confer-
ence on EMNLP and CoNLL-Shared Task, pages 1–
40. Association for Computational Linguistics.

Altaf Rahman and Vincent Ng. 2009. Supervised mod-
els for coreference resolution. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing: Volume 2-Volume 2, pages
968–977. Association for Computational Linguis-
tics.

Sameer Singh, Amarnag Subramanya, Fernando
Pereira, and Andrew McCallum. 2011. Large-
scale cross-document coreference using distributed
inference and hierarchical models. In Proceed-
ings of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies-Volume 1, pages 793–803. Association
for Computational Linguistics.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems, pages 5998–6008.

Michael Wick, Aron Culotta, Khashayar Rohani-
manesh, and Andrew McCallum. 2009. An entity
based model for coreference resolution. In Proceed-
ings of the 2009 SIAM International Conference on
Data Mining, pages 365–376. SIAM.

Sam Wiseman, Alexander M Rush, and Stuart M
Shieber. 2016. Learning global features for corefer-
ence resolution. arXiv preprint arXiv:1604.03035.

Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V
Le, Mohammad Norouzi, Wolfgang Macherey,
Maxim Krikun, Yuan Cao, Qin Gao, Klaus
Macherey, et al. 2016. Google’s neural ma-
chine translation system: Bridging the gap between
human and machine translation. arXiv preprint
arXiv:1609.08144.


