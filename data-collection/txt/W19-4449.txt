



















































The Unbearable Weight of Generating Artificial Errors for Grammatical Error Correction


Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, pages 478–483
Florence, Italy, August 2, 2019. c©2019 Association for Computational Linguistics

478

The Unbearable Weight of Generating Artificial Errors for Grammatical
Error Correction

Phu Mon Htut∗
Center for Data Science

New York University
pmh330@nyu.edu

Joel Tetreault
Grammarly

joel.tetreault@grammarly.com

Abstract

In recent years, sequence-to-sequence models
have been very effective for end-to-end gram-
matical error correction (GEC). As creating
human-annotated parallel corpus for GEC is
expensive and time-consuming, there has been
work on artificial corpus generation with the
aim of creating sentences that contain realistic
grammatical errors from grammatically cor-
rect sentences. In this paper, we investigate the
impact of using recent neural models for gen-
erating errors to help neural models to correct
errors. We conduct a battery of experiments on
the effect of data size, models, and comparison
with a rule-based approach.

1 Introduction

Grammatical error correction (GEC) is the task of
automatically identifying and correcting the gram-
matical errors in the written text. Recent work
treats GEC as a translation task that use sequence-
to-sequence models (Sutskever et al., 2014; Bah-
danau et al., 2015) to rewrite sentences with gram-
matical errors to grammatically correct sentences.
As with machine translation models, GEC models
benefit largely from the amount of parallel training
data. Since it is expensive and time-consuming to
create annotated parallel corpus for training, there
is research into generating sentences with artificial
errors from grammatically correct sentences with
the goal of simulating human-annotated data in a
cost-effective way (Yuan and Briscoe, 2016; Xie
et al., 2016; Chollampatt and Ng, 2018).

Recent work in artificial error generation (AEG)
is inspired by the back-translation approach of ma-
chine translation systems (Sennrich et al., 2016;
Poncelas et al., 2018). In this framework, an inter-
mediate model is trained to translate correct sen-
tences into errorful sentences. A new parallel cor-

∗Work done during internship at Grammarly

pus is created using the largely available gram-
matically correct sentences and the correspond-
ing synthetic data generated by this intermediate
model. The newly created corpus with the artifi-
cial errors is then used to train a GEC model (Rei
et al., 2017; Xie et al., 2018; Ge et al., 2018).

To date, there is no work that compares how
different base model architectures perform in the
AEG task. In this paper, we investigate how effec-
tive are different model architectures in generating
artificial, parallel data to improve a GEC model.
Specifically, we train four recent neural models
(and one rule-based model (Bryant and Briscoe,
2018)), including two new syntax-based models,
for generating as well as correcting errors. We
analyze which models are effective in the AEG
and correction conditions as well as by data size.
Essentially, we seek to understand how effective
are recent sequence-to-sequence (seq2seq) neural
model as AEG mechanisms “out of the box.”

2 Related Work

Before the adoption of neural models, early ap-
proaches to AEG involved identifying error statis-
tics and patterns in the corpus and applying
them to grammatically correct sentences (Brock-
ett et al., 2006; Rozovskaya and Roth, 2010).
Inspired by the back-translation approach, re-
cent AEG approaches inject errors into grammat-
ically correct input sentences by adopting meth-
ods from neural machine translation (Felice and
Yuan, 2014; Kasewa et al., 2018). Xie et al.
(2018) propose an approach that adds noise to the
beam-search phase of an back-translation based
AEG model to generate more diverse errors. They
use the synthesized parallel data generated by this
method to train a multi-layer convolutional GEC
model and achieve a 5 point F0.5 improvement
on the CoNLL-2014 test data (Ng et al., 2014).



479

Ge et al. (2018) propose a fluency-boosting learn-
ing method that generates less fluent sentences
from correct sentences and pairs them with cor-
rect sentences to create new error-correct sentence
pairs during training. Their GEC model trained
with artificial errors approaches human-level per-
formance on multiple test sets.

3 Approach

3.1 Correction and Generation Tasks

We train our models on the two tasks—error cor-
rection and error generation. In error correction,
the encoder of the sequence-to-sequence model
takes an errorful sentence as input and the decoder
outputs the grammatically correct sentence. The
process is reversed in the error generation task,
where the model takes a correct sentence as input
and produces an errorful sentence as the output of
the decoder.

We investigate four recent neural sequence-to-
sequence models—(i) multi-layer convolutional
model (MLCONV; Chollampatt and Ng, 2018),
(ii) Transformer (Vaswani et al., 2017), (iii)
Parsing-Reading-Predict Networks (PRPN; Shen
et al., 2018), (iv) Ordered Neurons (ON-LSTM;
Shen et al., 2019)—as error correction models as
well as error generation models. The PRPN and
ON-LSTM models are originally designed as re-
current language models that jointly learn to in-
duce latent constituency parse trees. We use the
adaption of PRPN and ON-LSTM models as de-
coders of machine translation systems (UnderRe-
view, 2019): In this setting, a 2-layer LSTM is
used as the encoder of the syntactic seq-to-seq
models, and the PRPN and ON-LSTM are imple-
mented as the decoders with attention (Bahdanau
et al., 2015). We hypothesize that syntax is im-
portant in GEC and explore whether models that
incorporate syntactic bias would help with GEC
task. We provide a brief description of each model
in §3.2 and refer readers to the original work for
more details.

3.2 Models

Multi-layer Convolutional Model We use the
multi-layer convolutional encoder-decoder base
model (MLCONV) of Chollampatt and Ng (2018)
using the publicly available code from the au-
thors.1 As our aim is to only compare the per-

1https://github.com/nusnlp/
mlconvgec2018

formance of different architectures and not to
achieve state-of-the-art performance, we make
few changes to their code. The model of Chol-
lampatt and Ng (2018) produces 12 possible cor-
rect sentences for each input sentences with error.
They also train an N-gram language model as a re-
ranker to score the generated sentences and pick
the corrected sentence with the best score as fi-
nal output. We did not use this re-ranking step
in our model, nor did we perform ensembling or
use the pre-trained embeddings as in the original
work. We do not observe improvement in models
like transformer and PRPN using re-ranking with
an N-gram language model. Additionally, there’s
only a slight improvement in MLCONV using re-
ranking. The reason might be because the N-gram
language model is not very powerful.

Transformer Model We use the publicly avail-
able Fairseq framework which is built using Py-
torch for training the Transformer model. We ap-
ply the same hyper-parameters used for training
the IWSLT’14 German-English translation model
in the experiments of Vaswani et al. (2017).

PRPN Model is a language model that jointly
learns to parse and perform language modeling
(Shen et al., 2018). It uses a recurrent module with
a self-attention gating mechanism and the gate val-
ues are used to construct the constituency tree. We
use the BiLSTM model as the encoder and PRPN
as the decoder of the sequence-to-sequence model.

ON-LSTM Model is follow-up work of PRPN,
which incorporates syntax-based inductive bias to
the LSTM unit by imposing hierarchical update
order on the hidden state neurons (Shen et al.,
2019). ON-LSTM assumes that different nodes of
a constituency trees are represented by the differ-
ent chunks of adjacent neurons in the hidden state,
and introduces a master forget gate and a master
input gate to dynamically allocate the chunks of
hidden state neurons to different nodes. We use a
BiLSTM model as encoder and ON-LSTM model
as decoder.

4 Experiments

4.1 Data
We use the NUS Corpus of Learner English (NU-
CLE; Dahlmeier et al., 2013) and the Cambridge
Learner Corpus (CLC; Nicholls, 2003) as base
data for training both the correction and genera-
tion models. We remove sentence pairs that do

https://github.com/nusnlp/mlconvgec2018
https://github.com/nusnlp/mlconvgec2018


480

not contain errors during preprocessing resulting
in 51,693 sentence pairs from NUCLE and 1.09
million sentence pairs from the CLC . We append
the CLC data to the NUCLE training set (hence-
forth NUCLE-CLC) to use as training data for
both AEG and correction. We use the standard
NUCLE development data as our validation set
and we early-stop the training based on the cross-
entropy loss of the seq-to-seq models for all mod-
els. For the generation of synthetic errorful data,
we use the 2017 subsection of the LDC New York
Times corpus also employed in the error genera-
tion experiments of Xie et al. (2018) which con-
tains around 1 million sentences.2

4.2 Setup

We conduct four experiments in this paper. In
Exp1, we train all the AEG models and interme-
diate GEC models on NUCLE-CLC. We use the
NYT dataset as input to the AEG models to gener-
ate sentences with artificial errors. We then create
new parallel training sets for correction by com-
bining the sentences from CLC and NUCLE with
the errorful sentences generated by each model.
We then train the GEC models using these parallel
datasets.

The three other experiments are variants of the
first. In Exp2 we train all correction models on ar-
tificial errors generated by the top neural AEG sys-
tems and a rule-based system for comparison. In
Exp3, we train the GEC models on NUCLE to an-
alyze models built on real data. Finally, in Exp4,
we train all GEC models on artificial data to de-
termine how well correction models can perform
without any real data.

All our experiments are tested on the CoNLL-
2014 test set and we use the sentence-level F0.5
score from the MaxMatch (M2) scorer (Dahlmeier
and Ng, 2012) for evaluation. All models are im-
plemented using the Fairseq framework.3

4.3 Results

Exp1: Figure 1 shows the performance of GEC
models trained on the base NUCLE-CLC set and
then retraining with various amounts of artifi-
cial data. We first observe that PRPN performs
substantially higher than the rest of the models
when trained only with the base CLC-NUCLE

2https://catalog.ldc.upenn.edu/
LDC2008T19

3https://github.com/pytorch/fairseq

data. However, its performance drops when arti-
ficial data generated by the corresponding PRPN
AEG model is added. As for ON-LSTM, the per-
formance improves slightly when the amount of
added data is less than 100k but the performance
drops drastically otherwise. Conversely, the per-
formance of MLCONV and Transformer improves
with the added artificial data but the improvement
is not linear with the amount of added data.

Figure 1: (Exp1) Models trained on the artificial data
generated by the corresponding AEG model. The X-
axis represents the amount of artificial data added to
NUCLE-CLC during training.

Exp2: Since the performance of MLCONV and
Transformer GEC models improve with the ad-
dition of artificial data generated by correspond-
ing AEG models, we hypothesize that the artifi-
cial error generated by these models are useful. To
test this hypothesis, we train all the GEC mod-
els with various amount of artificial error gener-
ated by MLCONV and Transformer AEG mod-
els. We also compare these AEG models to a rule-
based one inspired by the confusion set genera-
tion method in Bryant and Briscoe (2018). We
subsequently score each sentence with a language
model (GPT-2 (Radford et al., 2018)) in order not
to select the most probable sentence. This method
generates a confusion set for prepositions (set of
prepositions plus an empty element), determiners,
and morphological alternatives (cat → cats).

The results of these experiments are found in
Table 1. Nearly all correction models improve
when using MLCONV or Transformer AEG data
with the biggest performances yielded using the
Transformer model. Interestingly, when using 1M
or 2M samples, performance starts to decline. We
believe that over 1M samples, the noisiness of the
artificial data overwhelms the contributions of the
real data (roughly over 1M samples). The per-
formance of all models drops when trained with

https://catalog.ldc.upenn.edu/LDC2008T19
https://catalog.ldc.upenn.edu/LDC2008T19
https://github.com/pytorch/fairseq


481

GEC Model AEG model NUCLE-CLC 10K 50K 100K 500K 1M 2M

MLCONV MLCONV 35.2 35.1 34.7 34.6 38.9 39.4 34.0
Transformer MLCONV 36.3 43.9 44.1 45.4 44.4 45.5 42.0
PRPN MLCONV 43.6 45.4 42.8 43.2 39.6 38.6 31.7
ON-LSTM MLCONV 36.6 39.8 35.6 38.4 36.9 24.2 20.1

MLCONV Transformer 35.2 36.1 35.2 39.4 36.6 36.6 36.1
Transformer Transformer 36.3 20.1 43.9 42.9 43.7 44.0 41.0
PRPN Transformer 43.6 43.1 40.9 40.6 41.4 29.4 31.7
ON-LSTM Transformer 36.6 39.8 38.2 39.6 24.0 21.3 20.1

MLCONV Rule-based 35.2 6.0 7.8 10.5 13.7 13.9 –
Transformer Rule-based 36.3 13.5 14.4 21.8 14.5 21.6 –
PRPN Rule-based 43.6 2.8 4.9 2.6 3.9 8.9 –
ON-LSTM Rule-based 36.6 4.7 3.9 5.5 4.2 5.3 –

Table 1: (Exp2) Evaluating the impact of MLCONV, Transformer and the rule-based AEG systems. NUCLE-CLC
column represents the F0.5 score of GEC models trained on the base NUCLE-CLC data. 10K, 50K, 100K, 500K,
1M, and 2M represents the amount of artificial data added to the NUCLE-CLC during training.

the errors generated by the rule-based model. It is
interesting to observe that the performance drops
significantly just by adding 10K artificial sen-
tences to the base data.
Exp3: Table 2 shows the performance of the mod-
els trained on NUCLE dataset with additional arti-
ficial data generated by corresponding AEG mod-
els trained on NUCLE-CLC. We can see that the
performance of all models, except ON-LSTM, im-
proves significantly when 1 million artificial sen-
tence pairs are added to the NUCLE training data,
even though the errors in these sentences do not
resemble natural errors. This contrasts with the re-
sult in Figure 1 where the performance of the GEC
models trained with the combination of artificial
error and CLC-NUCLE base data drops. This sug-
gests that artificial data is helpful when the base
data size is relatively small.

Model NUCLE +10K +50K +1M

MLCONV 10.1 12.3 12.9 16.1
Transformer 11.2 28.1 16.9 22.8
PRPN 8.3 6.9 12.5 26.2
ON-LSTM 9.4 11.3 11.8 6.0

Table 2: (Exp3) Using only NUCLE as base train-
ing for correction. The AEG models are trained using
NUCLE-CLC data as in other experiments.

Exp4: The GEC models trained only on artifi-
cial data perform very poorly. The best setups,
Transformer and MLCONV, achieve F0.5 scores
of 12.8 and 12.4 respectively when trained with 2
million sentences generated by the corresponding
AEG model. This outcomes suggests that AEG
data should be paired with some sample of real

data to be effective.

4.4 Manual Evaluation

We performed a manual analysis of the generated
error sentences and found that many of the errors
did not always resemble those produced by hu-
mans. For example, The situation with other types
is not much (better → downward). This shows
that despite the noisiness of the error-generated
data, some models (namely MLCONV and Trans-
former) were robust enough to improve. This also
suggests that we may achieve better improvement
by controlling artificial errors to resemble the er-
rors produced by humans. The performance of
syntax-based models goes down significantly with
the addition of artificial errors, which indicates
that these models may be sensitive to poor artifi-
cial data.

5 Conclusion

We investigated the potential of recent neural ar-
chitectures, as well as rule-based one, to generate
parallel data to improve neural GEC. We found
that the Multi-Layer Convolutional and Trans-
former models tended to produce data that could
improve several models, though too much of it
would begin to dampen performance. The most
substantial improvements could be found when
the size of the real data for training was quite
small. We also found that the syntax-based mod-
els, PRPN and ONLSTM, are very sensitive to the
quality of artificial errors and their performance
drops substantially with the addition of artificial
error data. Our experiments suggest that, unlike in
machine translation, it is not very straightforward



482

to use a simple back-translation approach for GEC
as unrealistic errors produced by back-translation
can hurt the correction performance substantially.

We believe this work shows the promise of us-
ing recent neural methods in an out-of-the-box
framework, though with care. Future work will
focus on ways of improving the quality of the syn-
thetic data. Ideas include leveraging recent de-
velopments in powerful language models or better
controlling for diversity and frequency of specific
error types.

Acknowledgements

We would like to thank the Grammarly Re-
search Team, especially Maria Nadejde, Courtney
Napoles, Dimitris Alikaniotis, Andrey Gryschuck,
Maksym Bezva and Oleksiy Syvokon. We would
also like to thank Sam Bowman, Kyunghyun Cho,
and the three anonymous reviewers for their help-
ful discussion and feedback.

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2015. Neural machine translation by jointly
learning to align and translate. In 3rd Inter-
national Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
Conference Track Proceedings.

Chris Brockett, William B. Dolan, and Michael Ga-
mon. 2006. Correcting ESL errors using phrasal
SMT techniques. In ACL 2006, 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the Association for Computa-
tional Linguistics, Proceedings of the Conference,
Sydney, Australia, 17-21 July 2006.

Christopher Bryant and Ted Briscoe. 2018. Language
model based grammatical error correction without
annotated training data. In BEA@NAACL-HLT.

Shamil Chollampatt and Hwee Tou Ng. 2018. A multi-
layer convolutional encoder-decoder neural network
for grammatical error correction. In Proceedings of
the Thirty-Second AAAI Conference on Artificial In-
telligence.

Daniel Dahlmeier and Hwee Tou Ng. 2012. Bet-
ter evaluation for grammatical error correction. In
Human Language Technologies: Conference of the
North American Chapter of the Association of Com-
putational Linguistics, Proceedings, June 3-8, 2012,
Montréal, Canada, pages 568–572.

Daniel Dahlmeier, Hwee Tou Ng, and Siew Mei Wu.
2013. Building a large annotated corpus of learner
english: The NUS corpus of learner english. In
Proceedings of the Eighth Workshop on Innovative

Use of NLP for Building Educational Applications,
BEA@NAACL-HLT 2013, June 13, 2013, Atlanta,
Georgia, USA, pages 22–31.

Mariano Felice and Zheng Yuan. 2014. Generating ar-
tificial errors for grammatical error correction. In
Proceedings of the 14th Conference of the European
Chapter of the Association for Computational Lin-
guistics, EACL 2014, April 26-30, 2014, Gothen-
burg, Sweden, pages 116–126.

Tao Ge, Furu Wei, and Ming Zhou. 2018. Reaching
human-level performance in automatic grammati-
cal error correction: An empirical study. CoRR,
abs/1807.01270.

Sudhanshu Kasewa, Pontus Stenetorp, and Sebastian
Riedel. 2018. Wronging a right: Generating better
errors to improve grammatical error detection. In
Proceedings of the 2018 Conference on Empirical
Methods in Natural Language Processing, Brussels,
Belgium, October 31 - November 4, 2018, pages
4977–4983.

Hwee Tou Ng, Siew Mei Wu, Ted Briscoe, Christian
Hadiwinoto, Raymond Hendy Susanto, and Christo-
pher Bryant. 2014. The CoNLL-2014 shared task
on grammatical error correction. In Proceedings of
the Eighteenth Conference on Computational Nat-
ural Language Learning: Shared Task, pages 1–
14, Baltimore, Maryland. Association for Compu-
tational Linguistics.

Diane Nicholls. 2003. The cambridge learner corpus -
error coding and analysis for lexicography and elt.
In Proceedings of the Corpus Linguistics 2003 con-
ference.

Alberto Poncelas, Dimitar Shterionov, Andy Way,
Gideon Maillette de Buy Wenniger, and Peyman
Passban. 2018. Investigating backtranslation in neu-
ral machine translation. CoRR, abs/1804.06189.

Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, and Ilya Sutskever. 2018. Language
models are unsupervised multitask learners.

Marek Rei, Mariano Felice, Zheng Yuan, and Ted
Briscoe. 2017. Artificial error generation with
machine translation and syntactic patterns. In
Proceedings of the 12th Workshop on Innovative
Use of NLP for Building Educational Applica-
tions, BEA@EMNLP 2017, Copenhagen, Denmark,
September 8, 2017, pages 287–292.

Alla Rozovskaya and Dan Roth. 2010. Training
paradigms for correcting errors in grammar and us-
age. In Human Language Technologies: Conference
of the North American Chapter of the Association of
Computational Linguistics, Proceedings, June 2-4,
2010, Los Angeles, California, USA, pages 154–162.

Rico Sennrich, Barry Haddow, and Alexandra Birch.
2016. Improving neural machine translation mod-
els with monolingual data. In Proceedings of the

http://arxiv.org/abs/1409.0473
http://arxiv.org/abs/1409.0473
http://aclweb.org/anthology/P06-1032
http://aclweb.org/anthology/P06-1032
http://www.aclweb.org/anthology/N12-1067
http://www.aclweb.org/anthology/N12-1067
http://aclweb.org/anthology/W/W13/W13-1703.pdf
http://aclweb.org/anthology/W/W13/W13-1703.pdf
http://aclweb.org/anthology/E/E14/E14-3013.pdf
http://aclweb.org/anthology/E/E14/E14-3013.pdf
http://arxiv.org/abs/1807.01270
http://arxiv.org/abs/1807.01270
http://arxiv.org/abs/1807.01270
https://aclanthology.info/papers/D18-1541/d18-1541
https://aclanthology.info/papers/D18-1541/d18-1541
http://arxiv.org/abs/1804.06189
http://arxiv.org/abs/1804.06189
https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf
https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf
https://aclanthology.info/papers/W17-5032/w17-5032
https://aclanthology.info/papers/W17-5032/w17-5032
http://www.aclweb.org/anthology/N10-1018
http://www.aclweb.org/anthology/N10-1018
http://www.aclweb.org/anthology/N10-1018
http://aclweb.org/anthology/P/P16/P16-1009.pdf
http://aclweb.org/anthology/P/P16/P16-1009.pdf


483

54th Annual Meeting of the Association for Compu-
tational Linguistics, ACL 2016, August 7-12, 2016,
Berlin, Germany, Volume 1: Long Papers.

Yikang Shen, Zhouhan Lin, Chin wei Huang, and
Aaron Courville. 2018. Neural language modeling
by jointly learning syntax and lexicon. In Interna-
tional Conference on Learning Representations.

Yikang Shen, Shawn Tan, Alessandro Sordoni, and
Aaron Courville. 2019. Ordered Neurons: Integrat-
ing tree structures into recurrent neural networks. In
International Conference on Learning Representa-
tions.

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.
Sequence to sequence learning with neural net-
works. In Advances in Neural Information Process-
ing Systems 27: Annual Conference on Neural In-
formation Processing Systems 2014, December 8-
13 2014, Montreal, Quebec, Canada, pages 3104–
3112.

UnderReview. 2019. Unknown title.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in Neural Information Pro-
cessing Systems 30: Annual Conference on Neural
Information Processing Systems 2017, 4-9 Decem-
ber 2017, Long Beach, CA, USA, pages 6000–6010.

Ziang Xie, Anand Avati, Naveen Arivazhagan, Dan Ju-
rafsky, and Andrew Y. Ng. 2016. Neural language
correction with character-based attention. CoRR,
abs/1603.09727.

Ziang Xie, Guillaume Genthial, Stanley Xie, An-
drew Y. Ng, and Dan Jurafsky. 2018. Noising and
denoising natural language: Diverse backtranslation
for grammar correction. In Proceedings of the 2018
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2018, New
Orleans, Louisiana, USA, June 1-6, 2018, Volume
1 (Long Papers), pages 619–628.

Zheng Yuan and Ted Briscoe. 2016. Grammatical
error correction using neural machine translation.
In NAACL HLT 2016, The 2016 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, San Diego California, USA, June 12-17,
2016, pages 380–386.

https://openreview.net/forum?id=rkgOLb-0W
https://openreview.net/forum?id=rkgOLb-0W
http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks
http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks
http://papers.nips.cc/paper/7181-attention-is-all-you-need
http://papers.nips.cc/paper/7181-attention-is-all-you-need
http://arxiv.org/abs/1603.09727
http://arxiv.org/abs/1603.09727
https://aclanthology.info/papers/N18-1057/n18-1057
https://aclanthology.info/papers/N18-1057/n18-1057
https://aclanthology.info/papers/N18-1057/n18-1057
http://aclweb.org/anthology/N/N16/N16-1042.pdf
http://aclweb.org/anthology/N/N16/N16-1042.pdf

