



















































Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics


Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 678–687
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1063

Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 678–687
Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics

https://doi.org/10.18653/v1/P17-1063

Generating Contrastive Referring Expressions

Martı́n Villalba and Christoph Teichmann and Alexander Koller
Department of Language Science and Technology

Saarland University, Germany
{villalba|cteichmann|koller}@coli.uni-saarland.de

Abstract

The referring expressions (REs) produced
by a natural language generation (NLG)
system can be misunderstood by the
hearer, even when they are semantically
correct. In an interactive setting, the NLG
system can try to recognize such misun-
derstandings and correct them. We present
an algorithm for generating corrective REs
that use contrastive focus (“no, the BLUE
button”) to emphasize the information the
hearer most likely misunderstood. We
show empirically that these contrastive
REs are preferred over REs without con-
trast marking.

1 Introduction

Interactive natural language generation (NLG)
systems face the task of detecting when they have
been misunderstood, and reacting appropriately to
fix the problem. For instance, even when the sys-
tem generated a semantically correct referring ex-
pression (RE), the user may still misunderstand it,
i.e. resolve it to a different object from the one the
system intended. In an interactive setting, such as
a dialogue system or a pedestrian navigation sys-
tem, the system can try to detect such misunder-
standings – e.g. by predicting what the hearer un-
derstood from their behavior (Engonopoulos et al.,
2013) – and to produce further utterances which
resolve the misunderstanding and get the hearer to
identify the intended object after all.

When humans correct their own REs, they rou-
tinely employ contrastive focus (Rooth, 1992;
Krifka, 2008) to clarify the relationship to the orig-
inal RE. Say that we originally described an object
b as “the blue button”, but the hearer approaches a
button b′ which is green, thus providing evidence
that they misunderstood the RE to mean b′. In this

case, we would like to say “no, the BLUE button”,
with the contrastive focus realized by an appropri-
ate pitch accent on “BLUE”. This utterance alerts
the hearer to the fact that they misunderstood the
original RE; it reiterates the information from the
original RE; and it marks the attribute “blue” as
a salient difference between b′ and the object the
original RE was intended to describe.

In this paper, we describe an algorithm for gen-
erating REs with contrastive focus. We start from
the modeling assumption that misunderstandings
arise because the RE rs the system uttered was
corrupted by a noisy channel into an RE ru which
the user “heard” and then resolved correctly; in
the example above, we assume the user literally
heard “the green button”. We compute this (hypo-
thetical) RE ru as the RE which refers to b′ and
has the lowest edit distance from rs. Based on
this, we mark the contrastive words in rs, i.e. we
transform “the blue button” into “the BLUE but-
ton”. We evaluate our system empirically on REs
from the GIVE Challenge (Koller et al., 2010) and
the TUNA Challenge (van der Sluis et al., 2007),
and show that the contrastive REs generated by our
system are preferred over a number of baselines.

The paper is structured as follows. We first re-
view related work in Section 2 and define the prob-
lem of generating contrastive REs in Section 3.
Section 4 sketches the general architecture for RE
generation on which our system is based. In Sec-
tion 5, we present the corruption model and show
how to use it to reconstruct ru. Section 6 de-
scribes how we use this information to generate
contrastive markup in rs, and in Section 7 we eval-
uate our approach.

2 Related Work

The notion of focus has been extensively studied
in the literature on theoretical semantics and prag-

678

https://doi.org/10.18653/v1/P17-1063
https://doi.org/10.18653/v1/P17-1063


matics, see e.g. Krifka (2008) and Rooth (1997)
for overview papers. Krifka follows Rooth (1992)
in taking focus as “indicat(ing) the presence of al-
ternatives that are relevant for the interpretation
of linguistic expressions”; focus then establishes
a contrast between an object and these alterna-
tives. Bornkessel and Schlesewsky (2006) find
that corrective focus can even override syntactic
requirements, on the basis of “its extraordinarily
high communicative saliency”. This literature is
purely theoretical; we offer an algorithm for auto-
matically generating contrastive focus.

In speech, focus is typically marked through
intonation and pitch accents (Levelt, 1993; Pier-
rehumbert and Hirschberg, 1990; Steube, 2001),
while concepts that can be taken for granted are
deaccented and/or deleted. Developing systems
which realize precise pitch contours for focus in
text-to-speech settings is an ongoing research ef-
fort. We therefore realize focus in written lan-
guage in this paper, by capitalizing the focused
word. We also experiment with deletion of back-
ground words.

There is substantial previous work on interac-
tive systems that detect and respond to misun-
derstandings. Misu et al. (2014) present an er-
ror analysis of an in-car dialogue system which
shows that more than half the errors can only be
resolved through further clarification dialogues, as
opposed to better sensors and/or databases; that is,
by improved handling of misunderstandings. En-
gonopoulos et al. (2013) detect misunderstandings
of REs in interactive NLG through the use of a sta-
tistical model. Their model also predicts the object
to which a misunderstood RE was incorrectly re-
solved. Moving from misunderstanding detection
to error correction, Zarrieß and Schlangen (2016)
present an interactive NLG algorithm which is ca-
pable of referring in installments, in that it can
generate multiple REs that are designed to correct
misunderstandings of earlier REs to the same ob-
ject. The interactive NLG system developed by
Akkersdijk et al. (2011) generates both reflective
and anticipative feedback based on what a user
does and sees. Their error detection and correction
strategy distinguishes a fixed set of possible sit-
uations where feedback is necessary, and defines
custom, hard-coded RE generation sub-strategies
for each one. None of these systems generate REs
marked for focus.

We are aware of two items of previous work that

address the generation of contrastive REs directly.
Milosavljevic and Dale (1996) outline strategies
for generating clarificatory comparisons in ency-
clopedic descriptions. Their surface realizer can
generate contrastive REs, but the attributes that
receive contrastive focus have to be specified by
hand. Krahmer and Theune (2002) extend the In-
cremental Algorithm (Dale and Reiter, 1995) so it
can mark attributes as contrastive. This is a fully
automatic algorithm for contrastive REs, but it in-
herits all the limitations of the Incremental Algo-
rithm, such as its reliance on a fixed attribute or-
der. Neither of these two approaches evaluates the
quality of the contrastive REs it generates.

Finally, some work has addressed the issue of
generating texts that realize the discourse relation
contrast. For instance, Howcroft et al. (2013)
show how to choose contrastive discourse connec-
tives (but, while, . . . ) when generating restau-
rant descriptions, thus increasing human ratings
for naturalness. Unlike their work, the research
presented in this paper is not about discourse rela-
tions, but about assigning focus in contrastive REs.

3 Interactive NLG

We start by introducing the problem of generating
corrective REs in an interactive NLG setting. We
use examples from the GIVE Challenge (Koller
et al., 2010) throughout the paper; however, the
algorithm itself is domain-independent.

GIVE is a shared task in which an NLG system
(the instruction giver, IG) must guide a human user
(the instruction follower, IF) through a virtual 3D
environment. The IF needs to open a safe and steal
a trophy by clicking on a number of buttons in the
right order without triggering alarms. The job of
the NLG system is to generate natural-language
instructions which guide the IF to complete this
task successfully.

The generation of REs has a central place in the
GIVE Challenge because the system frequently
needs to identify buttons in the virtual environ-
ment to the IF. Figure 1 shows a screenshot of a
GIVE game in progress; here b1 and b4 are blue
buttons, b2 and b3 are yellow buttons, and w1 is a
window. If the next button the IF needs to press is
b4 – the intended object, os – then one good RE for
b4 would be “the blue button below the window”,
and the system should utter:

(1) Press the blue button below the window.

After uttering this sentence, the system can

679



Figure 1: Example scene from the GIVE Chal-
lenge.

track the IF’s behavior to see whether the IF has
understood the RE correctly. If the wrong but-
ton is pressed, or if a model of IF’s behavior sug-
gests that they are about to press the wrong but-
ton (Engonopoulos et al., 2013), the original RE
has been misunderstood. However, the system still
gets a second chance, since it can utter a corrective
RE, with the goal of identifying b4 to the IF after
all. Examples include simply repeating the origi-
nal RE, or generating a completely new RE from
scratch. The system can also explicitly take into
account which part of the original RE the IF mis-
understood. If it has reason to believe that the IF
resolved the RE to b3, it could say:

(2) No, the BLUE button below the window.

This use of contrastive focus distinguishes the
attributes the IF misunderstood (blue) from those
that they understood correctly (below the win-
dow), and thus makes it easier for the IF to resolve
the misunderstanding. In speech, contrastive focus
would be realized with a pitch accent; we approx-
imate this accent in written language by capitaliz-
ing the focused word. We call an RE that uses con-
trastive focus to highlight the difference between
the misunderstood and the intended object, a con-
trastive RE. The aim of this paper is to present an
algorithm for computing contrastive REs.

4 Generating Referring Expressions

While we make no assumptions on how the orig-
inal RE rs was generated, our algorithm for re-
constructing the corrupted RE ru requires an RE
generation algorithm that can represent all seman-
tically correct REs for a given object compactly in
a chart. Here we sketch the RE generation of En-
gonopoulos and Koller (2014), which satisfies this
requirement.

NPb4,{b4}

Nb4,{b4}

PPb4,{b3,b4}

NPw1,{w1}

Nw1,{w1}

window

Dw1,

the

Pb4,below

below

Nb4,{b1,b4}

Nb4,{b1,b2,b3,b4}

button

ADJb4,{b1,b4}

blue

Db4,

the

Figure 2: Example syntax tree for an RE for b4.

This algorithm assumes a synchronous gram-
mar which relates strings with the sets of objects
they refer to. Strings and their referent sets are
constructed in parallel from lexicon entries and
grammar rules; each grammar rule specifies how
the referent set of the parent is determined from
those of the children. For the scene in Figure 1,
we assume lexicon entries which express, among
other things, that the word “blue” denotes the set
{b1, b4} and the word “below” denotes the relation
{(w1, b1), (w1, b2), (b3, w1), (b4, w1)}. We com-
bine these lexicons entries using rules such as

“N→ button() |button |{b1, b2, b3, b4}”
which generates the string “button” and asso-

ciates it with the set of all buttons or

“N→ N1(N,PP) |w1 • w2 |R1 ∩R2”
which states that a phrase of type noun can be

combined with a prepositional phrase and their de-
notations will be intersected. Using these rules we
can determine that “the window” denotes {w1},
that “below the window” can refer to {b3, b4} and
that “blue button below the window” uniquely
refers to {b4}. The syntax tree in Fig. 2 represents
a complete derivation of an RE for {b4}.

The algorithm of Engonopoulos and Koller
computes a chart which represents the set of all
possible REs for a given set of input objects, such
as {b4}, according to the grammar. This is done
by building a chart containing all derivations of
the grammar which correspond to the desired set.
They represent this chart as a finite tree automa-
ton (Comon et al., 2007). Here we simply write
the chart as a Context-Free Grammar. The strings
produced by this Context-Free Grammar are then
exactly the REs for the intended object. For ex-
ample, the syntax tree in Fig. 2 is generated by the
parse chart for the set {b4}. Its nonterminal sym-
bols consist of three parts: a syntactic category

680



intended
object: os

referring
expression: rs

heard referring
expression: ru

user resolved
object: ou

Contrastive RE

b4 b2

the blue button
below the window

the yellow button
above the window

Instruction
Giver (IG)

Corruption

Instruction
Follower (IF)

Figure 3: The corruption model.

(given by the synchronous grammar), the referent
for which an RE is currently being constructed,
and the set of objects to which the entire subtree
refers. The grammar may include recursion and
therefore allow for an infinite set of possible REs.
If it is weighted, one can use the Viterbi algorithm
to compute the best RE from the chart.

5 Listener Hypotheses and Edit Distance

5.1 Corruption model

Now let us say that the system has generated and
uttered an RE rs with the intention of referring to
the object os, but it has then found that the IF has
misunderstood the RE and resolved it to another
object, ou (see Fig. 3). We assume for the pur-
poses of this paper that such a misunderstanding
arises because rs was corrupted by a noisy chan-
nel when it was transmitted to the IF, and the IF
“heard” a different RE, ru. We further assume that
the IF then resolved ru correctly, i.e. the corrup-
tion in the transmission is the only source of mis-
understandings.

In reality, there are of course many other rea-
sons why the IF might misunderstand rs, such as
lack of attention, discrepancies in the lexicon or
the world model of the IG and IF, and so on. We
make a simplifying assumption in order to make
the misunderstanding explicit at the level of the
RE strings, while still permitting meaningful cor-
rections for a large class of misunderstandings.

An NLG system that builds upon this idea in
order to generate a corrective RE has access to
the values of os, rs and ou; but it needs to in-
fer the most likely corrupted RE ru. To do this,
we model the corruption using the edit operations
used for the familiar Levenshtein edit distance
(Mohri, 2003) over the alphabet Σ: Sa, substitu-
tion of a word with a symbol a ∈ Σ; D, deletion
of a word; Ia, insertion of the symbol a ∈ Σ; or
K, keeping the word. The noisy channel passes

over each word in rs and applies either D, K or
one of the S operations to it. It may also apply I
operations before or after a word. We call any se-
quence s of edit operations that could apply to rs
an edit sequence for rs.

An example for an edit sequence which cor-
rupts rs = “the blue button below the window”
into ru = “the yellow button above the window”
is shown in Figure 4. The same ru could also have
been generated by the edit operation sequence
K Syellow K Sabove KK, and there is generally a
large number of edit sequences that could trans-
form between any two REs. If an edit sequence s
maps x to y, we write apply(s, x) = y.

We can now define a probability distribution
P (s | rs) over edit sequences s that the noisy
channel might apply to the string rs, as follows:

P (s | rs) =
1

Z

∏

si∈s
exp(−c(si)),

where c(si) is a cost for using the edit operation
si. We set c(K) = 0, and for any a in our alpha-
bet we set c(Sa) = c(Ia) = c(D) = C, for some
fixed C > 0. Z is a normalizing constant which is
independent of s and ensures that the probabilities
sum to 1. It is finite for sufficiently high values
of C, because no sequence for rs can ever contain
more K, S and D operations than there are words
in rs, and the total weight of sequences generated
by adding more and more I operations will con-
verge.

Finally, let L be the set of referring expressions
that the IF would resolve to ou, i.e. the set of candi-
dates for ru. Then the most probable edit sequence
for rs which generates an ru ∈ L is given by

s∗ = arg max
s : apply(s,rs)∈L

P (s | rs)

= arg mins
∑

si∈s c(si),

i.e. s∗ is the edit sequence that maps rs to an RE
in L with minimal cost. We will assume that s∗ is
the edit sequence that corrupted rs, i.e. that ru =
apply(s∗, rs).

5.2 Finding the most likely corruption
It remains to compute s∗; we will then show in
Section 6 how it can be used to generate a cor-
rective RE. Attempting to find s∗ by enumeration
is impractical, as the set of edit sequences for a
given rs and ru may be large and the set of pos-
sible ru for a given ou may be infinite. Instead

681



rs the blue button below the window
edit operation sequence K D Iyellow K Sabove K K

ru the yellow button above the window

Figure 4: Example edit sequence for a given corruption.

we will use the algorithm from Section 4 to com-
pute a chart for all the possible REs for ou, rep-
resented as a context-free grammar G whose lan-
guage L = L(G) consists of these REs. We
will then intersect it with a finite-state automa-
ton which keeps track of the edit costs, obtaining
a second context-free grammar G′. These opera-
tions can be performed efficiently, and s∗ can be
read off of the minimum-cost syntax tree of G′.

Edit automaton. The possible edit sequences
for a given rs can be represented compactly in the
form of a weighted finite-state automaton F (rs)
(Mohri, 2003). Each run of the automaton on a
string w corresponds to a specific edit sequence
that transforms rs intow, and the sum of transition
weights of the run is the cost of that edit sequence.
We call F (rs) the edit automaton. It has a state qi
for every position i in rs; the start state is q0 and
the final state is q|rs|. For each i, it has a “keep”
transition from qi to qi+1 that reads the word at
position i with cost 0. In addition, there are tran-
sitions from qi to qi+1 with cost C that read any
symbol in Σ (for substitution) and ones that read
the empty string � (for deletion). Finally, there is a
loop with cost C from each qi to itself and for any
symbol in Σ, implementing insertion.

An example automaton for rs =
“the blue button below the window” is shown
in Figure 5. The transitions are written in the
form 〈word in w : associated cost〉. Note that
every path through the edit transducer corre-
sponds to a specific edit sequence s, and the
sum of the costs along the path corresponds to
− logP (s | rs)− logZ.

Combining G and F (rs). Now we can com-
bine G with F (rs) to obtain G′, by intersecting
them using the Bar-Hillel construction (Bar-Hillel
et al., 1961; Hopcroft and Ullman, 1979). For the
purposes of our presentation we assume that G is
in Chomsky Normal Form, i.e. all rules have the
form A → a, where a is a word, or A → B C,
where both symbols on the right hand side are non-
terminals. The resulting grammar G′ uses non-
terminal symbols of the form Nb,A,〈qi,qk〉, where

b, A are as in Section 4, and qi, qk indicate that the
string derived by this nonterminal was generated
by editing the substring of rs from position i to k.

Let Nb,A → a be a production rule of G with a
word a on the right-hand side; as explained above,
b is the object to which the subtree should refer,
and A is the set of objects to which the subtree
actually might refer. Let t = qi → 〈a:c〉qk be a
transition in F (rs), where q, q′ are states of F (rs)
and c is the edit cost. From these two, we create
a context-free rule Nb,A,〈qi,qk〉 → a with weight c
and add it to G′. If k = i + 1, these rules repre-
sent K and S operations; if k = i, they represent
insertions.

Now let Nb,A → Xb1,A1 Yb2,A2 be a binary rule
in G, and let qi, qj , qk be states of F (rs) with
i ≤ j ≤ k. We then add a rule Nb,A,〈qi,qk〉 →
Xb1,A1,〈qi,qj〉 Yb2,A2,〈qj ,qk〉 to G

′. These rules are
assigned weight 0, as they only combine words ac-
cording to the grammar structure of G and do not
encode any edit operations.

Finally, we deal with deletion. Let Nb,A be a
nonterminal symbol in G and let qh, qi, qj , qk be
states of F (rs) with h ≤ i ≤ j ≤ k. We then
add a rule Nb,A,〈qh,qk〉 → Nb,A,〈qi,qj〉 to G′. This
rule deletes the substrings from positions h to i
and j to k from rs; thus we assign it the cost ((i−
h) + (k − j))C, i.e. the cost of the corresponding
� transitions.

If the start symbol of G is Sb,A, then the start
symbol of G′ is Sb,A,〈q0,q|rs|〉. This construction
intersects the languages of G and F (rs), but be-
cause F (rs) accepts all strings over the alpha-
bet, the languages of G′ and G will be the same
(namely, all REs for ou). However, the weights
in G′ are inherited from F (rs); thus the weight of
each RE in L(G′) is the edit cost from rs.

Example. Fig. 6 shows an example tree
for the G′ we obtain from the automaton
in Fig. 5. We can read the string w =
“the yellow button above the window” off of the
leaves; by construction, this is an RE for ou. Fur-
thermore, we can reconstruct the edit sequence
that maps from rs to w from the rules of G′ that

682



q0start q1 q2 q3 q4 q5 q6
the:0
Σ:C

�:C

Σ:C

blue:0
Σ:C

�:C

Σ:C

button:0

Σ:C

�:C

Σ:C

below:0

Σ:C

�:C

Σ:C

the:0
Σ:C

�:C

Σ:C

window:0

Σ:C
Σ:C

�:C

Σ:C

Figure 5: Edit automaton F (rs) for rs = “the blue button below the window”.

Tree

NPb2,{b2}, 〈q0, q6〉

Nb2,{b2},〈q1,q6〉

PPb2,{b1,b2},〈q3,q6〉

NPw1,{w1},〈q4,q6〉

Nw1,{w1},〈q5,q6〉

window

Dw1, ,〈q4,q5〉

the

Pb2,above,〈q3,q4〉

above

Nb2,{b2,b3},〈q1,q3〉

Nb2,{b2,b3},〈q2,q3〉

Nb2,{b1,b2,b3,b4},〈q2,q3〉

button

ADJb2,{b2,b3},〈q2,q2〉

yellow

Db2, ,〈q0,q1〉

the

s K D Iyellow K Sabove KK

Emphasis No, press the BLUE button BELOW the window

Figure 6: A syntax tree described by G′, together with its associated edit sequence and contrastive RE.

were used to derive w. We can see that “yellow”
was created by an insertion because the two states
of F (rs) in the preterminal symbol just above it
are the same. If the two states are different, then
the word was either substituted (“above”, if the
rule had weight C) or kept (“the”, if the rule had
weight 0). By contrast, unary rules indicate dele-
tions, in that they make “progress” in rs without
adding new words to w.

We can compute the minimal-cost tree ofG′ us-
ing the Viterbi algorithm. Thus, to summarize, we
can calculate s∗ from the intersection of a context-
free grammar G representing the REs to ou with
the automaton F (rs) representing the edit distance
to rs. From this, we obtain ru = apply(s∗, rs).
This is efficient in practice.

6 Generating Contrastive REs

6.1 Contrastive focus

We are now ready to generate a contrastive RE
from rs and s∗. We assign focus to the words
in rs which were changed by the corruption –
that is, the ones to which s∗ applied Substitute or
Delete operations. For instance, the edit sequence
in Fig. 6 deleted “blue” and substituted “below”
with “above”. Thus, we mark these words with
focus, and obtain the contrastive RE “the BLUE
button BELOW the window”. We call this strat-
egy Emphasis, and write rsE for the RE obtained

by applying the Emphasis strategy to the RE rs.

6.2 Shortening
We also investigate a second strategy, which gen-
erates more succinct contrastive REs than the Em-
phasis strategy. Most research on RE genera-
tion (e.g. Dale and Reiter (1995)) has assumed
that hearers should prefer succinct REs, which in
particular do not violate the Maxim of Quantity
(Grice, 1975). When we utter a contrastive RE,
the user has previously heard the RE rs, so some
of the information in rsE is redundant. Thus we
might obtain a more succinct, and possibly better,
RE by dropping such redundant information from
the RE.

For the grammars we consider here, rsE often
combines an NP and a PP, e.g. “[blue button]NP
[below the window]PP ”. If errors occur only in
one of these constituents, then it might be suffi-
cient to generate a contrastive RE using only that
constituent. We call this strategy Shortening and
define it as follows.

If all the words that are emphasized in rsE

are in the NP, the Shortening RE is “the” plus
the NP, with emphasis as in rsE . So if rs is
“the [blue button] [above the window]” and s∗ =
K SyellowKKKK, corresponding to a rsE of
“the [BLUE button] [above the window]”, then the
RE would be “the [BLUE button]”.

If all the emphasis in rsE is in the PP, we use

683



We wanted our player to select this button:

So we told them: press the red button to the right
of the blue button.

But they selected this button instead:

Which correction is better for this scene?
◦ No, press the red BUTTON to the right of

the BLUE BUTTON
◦ No, press the red button to the RIGHT of

the blue button

Figure 7: A sample scene from Experiment 1.

“the one” plus the PP and again capitalize as in
rs

E . So if we have s∗ = KKK SbelowKK,
where rsE is “the [blue button] [ABOVE the win-
dow]”, we obtain “the one [ABOVE the window].”
If there is no PP or if rsE emphasizes words in
both the NP and the PP, then we just use rsE .

7 Evaluation

To test whether our algorithm for contrastive REs
assigns contrastive focus correctly, we evaluated
it against several baselines in crowdsourced pair-
wise comparison overhearer experiments. Like
Buß et al. (2010), we opted for an overhearer ex-
periment to focus our evaluation on the effects of
contrastive feedback, as opposed to the challenges
presented by the navigational and timing aspects
of a fully interactive system.

7.1 Domains and stimuli

We created the stimuli for our experiments from
two different domains. We performed a first ex-
periment with scenes from the GIVE Challenge,
while a second experiment replaced these scenes
with stimuli from the “People” domain of the
TUNA Reference Corpus (van der Sluis et al.,
2007). This corpus consists of photographs of men
annotated with nine attributes, such as whether the

We wanted our player to select the person circled
in green:

So we told them: the light haired old man in a
suit looking straight.

But they selected the person circled in red instead.
Which correction is better for this scene?

◦ No, the light haired old man IN A SUIT
LOOKING STRAIGHT
◦ No, the LIGHT HAIRED OLD man in a

suit looking straight

Figure 8: A sample scene from Experiment 2.

person has a beard, a tie, or is looking straight.
Six of these attributes were included in the cor-
pus to better reflect human RE generation strate-
gies. Many human-generated REs in the corpus
are overspecific, in that they contain attributes that
are not necessary to make the RE semantically
unique.

We chose the GIVE environment in order to test
REs referring both to attributes of an object, i.e.
color, and to its spatial relation to other visible ob-
jects in the scene. The TUNA Corpus was chosen
as a more challenging domain, due to the greater
number of available properties for each object on
a scene.

Each experimental subject was presented with
screenshots containing a marked object and an RE.
Subjects were told that we had previously referred
to the marked object with the given RE, but an
(imaginary) player misunderstood this RE and se-
lected a different object, shown in a second screen-
shot. They were then asked to select which one
of two corrections they considered better, where
“better” was intentionally left unspecific. Figs. 7
and 8 show examples for each domain. The full set
of stimuli is available as supplementary material.

To maintain annotation quality in our crowd-
sourcing setting, we designed test items with a

684



clearly incorrect answer, such as REs referring to
the wrong target or a nonexistent one. These test
items were randomly interspersed with the real
stimuli, and only subjects with a perfect score on
the test items were taken into account. Experimen-
tal subjects were asked to rate up to 12 compar-
isons, shown in groups of 3 scenes at a time, and
were automatically disqualified if they evaluated
any individual scene in less than 10 seconds. The
order in which the pairs of strategies were shown
was randomized, to avoid effects related to the or-
der in which they were presented on screen.

7.2 Experiment 1

Our first experiment tested four strategies against
each other. Each experimental subject was pre-
sented with two screenshots of 3D scenes with a
marked object and an RE (see Fig. 7 for an exam-
ple). Each subject was shown a total of 12 scenes,
selected at random from 16 test scenes. We col-
lected 10 judgments for each possible combina-
tion of GIVE scene and pair of strategies, yielding
a total of 943 judgements from 142 subjects after
removing fake answers.

We compared the Emphasis and Shortening
strategies from Section 6 against two baselines.
The Repeat strategy simply presented rs as a “con-
trastive” RE, without any capitalization. Com-
parisons to Repeat test the hypothesis that sub-
jects prefer explicit contrastive focus. The Ran-
dom strategy randomly capitalized adjectives, ad-
verbs, and/or prepositions that were not capital-
ized by the Emphasis strategy. Comparisons to
Random verify that any preference for Emphasis is
not only due to the presence of contrastive focus,
but also because our method identifies precisely
where that focus should be.

Table 1a shows the results of all pairwise com-
parisons. For each row strategy StratR and each
column strategy StratC , the table value corre-
sponds to
(#StratR pref. over StratC)−(#StratC pref. over StratR)

(# tests between StratR and StratC)

Significance levels are taken from a two-tailed
binomial test over the counts of preferences for
each strategy. We find a significant preference for
the Emphasis strategy over all others, providing
evidence that our algorithm assigns contrastive fo-
cus to the right words in the corrective RE.

While the Shortening strategy is numerically
preferred over both baselines, the difference is
not significant, and it is significantly worse than

the Emphasis strategy. This is surprising, given
our initial assumption that listeners prefer succinct
REs. It is possible that a different strategy for
shortening contrastive REs would work better; this
bears further study.

7.3 Experiment 2
In our second experiment, we paired the Empha-
sis, Repeat, and Random strategies against each
other, this time evaluating each strategy in the
TUNA people domain. Due to its poor perfor-
mance in Experiment 1, which was confirmed in
pilot experiments for Experiment 2, the Shorten-
ing strategy was not included.

The experimental setup for the TUNA domain
used 3x4 grids of pictures of people chosen at
random from the TUNA Challenge, as shown in
Fig. 8. We generated 8 such grids, along with REs
ranging from two to five attributes and requiring
one or two attributes to establish the correct con-
trast. The larger visual size of objects in the the
TUNA scenes allowed us to mark both os and ou
in a single picture without excessive clutter.

The REs for Experiment 2 were designed to
only include attributes from the referred objects,
but no information about its position in relation to
other objects. The benefit is twofold: we avoid
taxing our subjects’ memory with extremely long
REs, and we ensure that the overall length of the
second set of REs is comparable to those in the
previous experiment.

We obtained 240 judgements from 65 subjects
(after removing fake answers). Table 1b shows
the results of all pairwise comparisons. We find
that even in the presence of a larger number of at-
tributes, our algorithm assigns contrastive focus to
the correct words of the RE.

7.4 Discussion
Our experiments confirm that the strategy for com-
puting contrastive REs presented in this paper
works in practice. This validates the corruption
model, which approximates semantic mismatches
between what the speaker said and what the lis-
tener understood as differences at the level of
words in strings. Obviously, this model is still an
approximation, and we will test its limits in future
work.

We find that users generally prefer REs with
an emphasis over simple repetitions. In the more
challenging scenes of the TUNA corpus, users
even have a significant preference of Random over

685



Repeat Random Emphasis Shortening
Repeat – 0.041 -0.570*** -0.141

Random -0.041 – -0.600*** -0.109
Emphasis 0.570*** 0.600*** – 0.376***

Shortening 0.141 0.109 -0.376*** –

(a) Results for Experiment 1

Repeat Random Emphasis
Repeat – -0.425*** -0.575***

Random 0.425*** – -0.425***
Emphasis 0.575*** 0.425*** –

(b) Results for Experiment 2

Table 1: Pairwise comparisons between feedback strategies for experiments 1 and 2. A positive value
shows preference for the row strategy, significant at *** p < 0.001.

Repeat, although this makes no semantic sense.
This preference may be due to the fact that em-
phasizing anything at least publically acknowl-
edges the presence of a misunderstanding that re-
quires correction. It will be interesting to explore
whether this preference holds up in an interac-
tive setting, rather than an overhearer experiment,
where listeners will have to act upon the corrective
REs.

The poor performance of the Shortening strat-
egy is a surprising negative result. We would ex-
pect a shorter RE to always be preferred, follow-
ing the Gricean Maxim of Quantity (Grice, 1975).
This may because our particular Shortening strat-
egy can be improved, or it may be because listen-
ers interpret the shortened REs not with respect to
the original instructions, but rather with respect to
a “refreshed” context (as observed, for instance, in
Gotzner et al. (2016)). In this case the shortened
REs would not be unique with respect to the re-
freshed, wider context.

8 Conclusion

In this paper, we have presented an algorithm for
generating contrastive feedback for a hearer who
has misunderstood a referring expression. Our
technique is based on modeling likely user misun-
derstandings and then attempting to give feedback
that contrasts with the most probable incorrect un-
derstanding. Our experiments show that this tech-
nique accurately predicts which words to mark as
focused in a contrastive RE.

In future work, we will complement the over-
hearer experiment presented here with an end-to-
end evaluation in an interactive NLG setting. This
will allow us to further investigate the quality of
the correction strategies and refine the Shortening
strategy. It will also give us the opportunity to in-
vestigate empirically the limits of the corruption
model. Furthermore, we could use this data to re-
fine the costs c(D), c(Ia) etc. for the edit opera-
tions, possibly assigning different costs to differ-
ent edit operations.

Finally, it would be interesting to combine our
algorithm with a speech synthesis system. In this
way, we will be able to express focus with actual
pitch accents, in contrast to the typographic ap-
proximation we made here.

References
Saskia Akkersdijk, Marin Langenbach, Frieder Loch,

and Mariët Theune. 2011. The thumbs up! twente
system for give 2.5. In The 13th European Workshop
on Natural Language Generation (ENLG 2011).

Yehoshua Bar-Hillel, Micha Perles, and Eli Shamir.
1961. On formal properties of simple phrase struc-
ture grammars. Zeitschrift für Phonetik, Sprachwis-
senschaft und Kommunikationsforschung 14:143–
172.

Ina Bornkessel and Matthias Schlesewsky. 2006. The
role of contrast in the local licensing of scrambling
in german: Evidence from online comprehension.
Journal of Germanic Linguistics 18(01):1–43.

Okko Buß, Timo Baumann, and David Schlangen.
2010. Collaborating on utterances with a spoken di-
alogue system using an isu–based approach to incre-
mental dialogue management. In Proceedings of the
Special Interests Group on Discourse and Dialogue
Conference (SIGdial 2010).

Hubert Comon, Max Dauchet, Rémi Gilleron, Flo-
rent Jacquemard, Denis Lugiez, Sophie Tison, Marc
Tommasi, and Christof Löding. 2007. Tree Au-
tomata techniques and applications. published
online - http://tata.gforge.inria.fr/.
http://tata.gforge.inria.fr/.

Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the Gricean maxims in the gen-
eration of referring expressions. Cognitive Science
19(2):233–263.

Nikos Engonopoulos and Alexander Koller. 2014.
Generating effective referring expressions using
charts. In Proceedings of the INLG and SIGdial
2014 Joint Session.

Nikos Engonopoulos, Martı́n Villalba, Ivan Titov, and
Alexander Koller. 2013. Predicting the resolution
of referring expressions from user behavior. In
Proceedings of the 2013 Conference on Empirical
Methods in Natural Language Processing (EMNLP
2013).

686



Nicole Gotzner, Isabell Wartenburger, and Katharina
Spalek. 2016. The impact of focus particles on the
recognition and rejection of contrastive alternatives.
Language and Cognition 8(1):59–95.

H. Paul Grice. 1975. Logic and conversation. In
P. Cole and J. L. Morgan, editors, Syntax and Seman-
tics: Vol. 3: Speech Acts, Academic Press, pages
41–58.

John Edward Hopcroft and Jeffrey Ullman. 1979. In-
troduction to Automata Theory, Languages, and
Computation. Addison-Wesley.

David Howcroft, Crystal Nakatsu, and Michael White.
2013. Enhancing the expression of contrast in
the SPaRKy restaurant corpus. In Proceedings of
the 14th European Workshop on Natural Language
Generation (ENLG 2013).

Alexander Koller, Kristina Striegnitz, Andrew Gargett,
Donna Byron, Justine Cassell, Robert Dale, Johanna
Moore, and Jon Oberlander. 2010. Report on the
Second NLG Challenge on Generating Instructions
in Virtual Environments (GIVE-2). In Proceedings
of the Sixth International Natural Language Gen-
eration Conference (Special session on Generation
Challenges).

E. Krahmer and M. Theune. 2002. Efficient context-
sensitive generation of referring expressions. In
K. van Deemter and R. Kibble, editors, Information
Sharing: Reference and Presupposition in Language
Generation and Interpretation, Center for the Study
of Language and Information-Lecture Notes, CSLI
Publications, volume 143, pages 223–263.

Manfred Krifka. 2008. Basic notions of information
structure. Acta Linguistica Hungarica 55:243–276.

Willem J.M. Levelt. 1993. Speaking: From Intention
to Articulation. MIT University Press Group.

Maria Milosavljevic and Robert Dale. 1996. Strate-
gies for comparison in encyclopædia descriptions.
In Proceedings of the 8th International Natural Lan-
guage Generation Workshop (INLG 1996).

Teruhisa Misu, Antoine Raux, Rakesh Gupta, and Ian
Lane. 2014. Situated language understanding at 25
miles per hour. In Proceedings of the 15th Annual
Meeting of the Special Interest Group on Discourse
and Dialogue (SIGdial 2014).

Mehryar Mohri. 2003. Edit-distance of weighted au-
tomata: General definitions and algorithms. Inter-
national Journal of Foundations of Computer Sci-
ence 14(6):957–982.

Janet B. Pierrehumbert and Julia Hirschberg. 1990.
The meaning of intonational contours in the inter-
pretation of discourse. In Philip R. Cohen, Jerry
Morgan, and Martha E. Pollack, editors, Intentions
in Communication, MIT University Press Group,
chapter 14.

Mats Rooth. 1992. A theory of focus interpretation.
Natural Language Semantics 1:75–116.

Mats Rooth. 1997. Focus. In Shalom Lappin, editor,
The Handbook of Contemporary Semantic Theory,
Blackwell Publishing, chapter 10, pages 271–298.

Anita Steube. 2001. Correction by contrastive focus.
Theoretical Linguistics 27(2-3):215–250.

Ielka van der Sluis, Albert Gatt, and Kees van Deemter.
2007. Evaluating algorithms for the generation of
referring expressions: Going beyond toy domains.
In Proceedings of the International Conference on
Recent Advances in Natural Language Processing
(RANLP 2007).

Sina Zarrieß and David Schlangen. 2016. Easy Things
First: Installments Improve Referring Expression
Generation for Objects in Photographs. In Proceed-
ings of the 54th Annual Meeting of the Association
for Computational Linguistics (ACL 2016).

687


	Generating Contrastive Referring Expressions

