






















Using Positional Suffix Trees to Perform Agile Tree Kernel Calculation

Gustavo Henrique Paetzold
University of Sheffield / Sheffield, United Kingdom

ghpaetzold1@sheffield.ac.uk

Abstract

Tree kernels have been used as an efficient
solution for many tasks, but are difficult
to calculate. To address this problem, in
this paper we introduce the Positional Suf-
fix Trees: a novel data structure devised to
store tree structures, as well as the MFTK
and EFTK algorithms, which use them to
estimate Subtree and Subspace Tree Ker-
nels. Results show that the Positional Suf-
fix Tree can store large amounts of trees in
a scalable fashion, and that our algorithms
are up to 22 times faster than the state-of-
the-art approach.

1 Introduction

A tree kernel is a type of convolution kernel that
represents as features the substructures that com-
pose a tree. They can be interpreted as a func-
tion K (T1,T2), of which the value is a similar-
ity measure between tree structures T1 and T2.
Recently, tree kernels have become popular, and
shown to be an efficient solution in tasks such
as Question Classification (Moschitti, 2006), Re-
lation Extraction (Zelenko et al., 2003), Named
Entity Recognition (Culotta and Sorensen, 2004),
Syntactic Parsing (Collins and Duffy, 2002), Se-
mantic Role Labeling (Moschitti, 2006), Semantic
Parsing (Moschitti, 2004), Glycan Classification
(Yamanishi et al., 2007) and Plagiarism Detection
(Son et al., 2006).

However efficient, tree kernels can be very
difficult to calculate in a reasonable amount of
time. Calculating K (T1,T2) usually requires many
verifications between node labels and can eas-
ily achieve quadratic complexity. Although algo-
rithms of much lower complexity have been pro-
posed (Moschitti, 2006), their performance can
still be unsatisfactory in solving problems which
involve large datasets.

In this paper, we present the findings of an on-
going work which focuses on proposing faster al-
gorithms for the calculation of tree kernels. Our
strategy uses a time-space tradeoff: we reduce
processing time by querying syntactic patterns
stored in a Positional Suffix Tree (PST), a novel
data structure devised for the storage of trees and
graphs. We introduce the the MFTK and EFTK
algorithms, which use PST’s to calculate Subtree
(ST) and Subspace Tree Kernels (SST). Our ex-
periments show that, while the MFTK algorithm is
over 3.5 times faster than the state-of-the-art algo-
rithm, the EFTK algorithm is over 22 times faster.
We also demonstrate that PST’s grow in log-linear
fashion, scaling well to large tree datasets.

2 Positional Suffix Trees

In order for us to create faster algorithms for the
calculation of tree kernels, we have conceived the
Positional Suffix Tree: an adaptation of the well
known Suffix Tree (Weiner, 1973). Its goal is to
store tree structures, such as syntactic parses, and
allow efficient search for patterns in them. In other
words, it is a tree that stores other trees. To avoid
confusion, throughout the rest of the paper we will
refer to PST nodes as “trie nodes”.

Each trie node of the PST represents a tree node
of a certain label in a given position. In con-
stituency parses, for an example, a trie node could
represent an “NP” (Noun Phrase) node as the left-
most child of an “S” (Sentence) node. A PST trie
node is composed of the following components:

• Label: The identifier of the tree node being
represented, such as “DT”.

• Tree ID Set: A set containing the identi-
fiers of each and every tree added to the PST
which contains the tree node in question.

• Children: A vector of size n, where n is the
the largest number of children parented by

Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 269



the tree node in question. In each position
i of the children vector is stored a hash struc-
ture H that maps the set of tree node labels L
to the trie nodes that represent them. The L
set contains all the labels of child nodes ob-
served in position i parented by the tree node
in question.

As an example, consider the trie node that repre-
sents the “NP” node highlighted in the three parse
trees of Figure 1.

Figure 1: Parse trees with “NP” node

Figure 2 illustrates such trie node.

Figure 2: Valid PST trie node

Differently from standard Suffix Trees, the PST
node labels can be of any hashable type, any node
can have one or more children, and the ordering
of a trie node’s children is not determined by the
alphabetical order of their labels, but rather the po-
sition in which the children nodes appear in each
tree individually.

3 Tree Kernel Modeling

Our algorithms calculate two types of kernels: the
Subtree and the Subspace Tree Kernels. Given two
tree structures, the Subtree Kernel (Vishwanathan
and Smola, 2004) represents the overlap of “sub-
trees” between them, which consist of every non-
leaf node along with all its descendants. The Sub-
space Kernel (Collins and Duffy, 2002), on the
other hand, represents the overlap of “subspace
trees”, which are all subtrees and their general-
ized versions, where some or all of their leaves
can be non-terminals. While the EFTK algorithm
explores those definitions directly, the MFTK al-
gorithm explores the ST/SST model of Moschitti

(2006), in which the kernel value between two
trees is represented as:

K (T1,T2) = ∑
n1∈NT1

∑
n2∈NT2

4(n1,n2) (1)

Where NTi is the set of nodes of tree Ti, and
4(n1,n2) is a function that represents the simi-
larity between nodes n1 and n2, subject to the fol-
lowing rules:

• 4(n1,n2) = 0 if n1 6= n2

• 4(n1,n2) = α if n1 = n2 and both n1 and n2
are leaf nodes.

• Otherwise:

4(n1,n2) = α
nc(n1)

∏
j=1

(
σ +4

(
c jn1 ,c

j
n2

))
(2)

Where α is a decay factor and σ ∈{0,1}. When
σ = 0, K (T1,T2) calculates the ST Kernel, and
when σ = 1, the SST Kernel.

4 Algorithms

4.1 PST Storing Algorithm
The recursive algorithm below adds a node Nt of
a given tree identified by ID in position i of the
children vector of trie node Npst .

Algorithm AddNode(Nt , ID, i,Npst):
1. C = Npst .Children
2. L = Nt .Label
3. if L in C[i]:
4. then N = C[i][L]
5. else N = new PSTNode()
6. N.Label = L
7. C[i][L] = N
8. Add ID in N.TreeIDSet
9. for j in [0,‖Nt .Children‖]:
10. Ct = Nt .Children[ j]
11. AddNode(Ct , ID, j, N)

4.2 The MFTK Algorithm
The MFTK (Much Faster Tree Kernel) algorithm
calculates both ST and SST Kernels depending
on the σ parameter. Unlike state-of-the-art algo-
rithms, it does not calculate K (Ti,Tj) individu-
ally, but rather K (Ti,{T1, ... ,Tn}) directly. It re-
ceives as input a target tree Ti and a PST contain-
ing all subtrees, each with an individual ID, of ev-
ery source tree Tj. It also requires a hash M, which

Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 270



maps the subtrees’ IDs to its respective tree Tj.
The algorithm below creates a valid PST and M
map.

Algorithm CreatePST(Ti,T1, ... ,Tn):
1. PST = new PST()
2. M = new Hash()
3. for i in [1,n]:
4. for c in Ti.Nodes:
5. ID = new ID()
6. AddNode(c, ID, 0, PST .Root)
7. M[ID] = i
8. return PST , M

Given a PST, a map M, α and a
σ ∈ {0,1}, the following algorithm calculates
K (Ti,{T1,T2, ... ,Tn−1,Tn}).

Algorithm Score(PST,M,Ti,{T1, ... ,Tn} ,α,σ ):
1. K = new Hash()
2. for j in [1,n]:
3. K[ j] = 0
4. for c in Ti.Nodes:
5. Ss = MFTK(c, PST .Root, 0, α , σ , nil)
6. for Match in Ss.Keys:
7. S = Ss[Match]
8. K[M[Match]] += S
9. return K

The function MFTK, described in the algorithm
below, uses the PST to estimate kernel values. It
receives a tree node Nt , a trie node Npst , a position
i, parameters α and σ and an auxiliary static hash
Ss. It returns a hash Ss[Nt] which maps a subtree
ID Match to its ST/SST score.

Algorithm MFTK(Nt ,Npst , i,α,σ ,Ss):
1. if Ss is nil:
2. then Ss = new Hash()
3. Ss[Nt] = new Hash()
4. Cpst = Npst .Children[i][Nt .Label]
5. for ID in Cpst .TreeIDSet:
6. Ss[Nt] = α
7. for j in [0,‖Nt .Children‖]:
8. Ntc = Nt .Children[ j]
9. MFTK(Ntc, Cpst , j, α , σ , Ss)
10. Miss = {Ss[Nt].Keys}-{Ss[Ntc].Keys}
11. for ID in Ss[Ntc].Keys:
12. Ss[Nt][ID] *= σ + Ss[Ntc][ID]
13. for ID in Miss:
14. Ss[Nt][ID] *= σ
15. return Result = Ss[Nt]

4.3 The EFTK Algorithm

The EFTK (Even Faster Tree Kernel) algorithm
uses a very unique strategy: instead of using the
model of Moschitti (2006), it calculates the num-
ber of common subtrees between two tree struc-
tures directly. The EFTK can only calculate the ST
Kernel. It employs the same CreatePST and Score
routines described in Section 4.2, but instead of
the MFTK function, it applies the one below.

Algorithm EFTK(Nt ,Npst , i,Ss):
1. Cpst = Npst .Children[i][Nt .Label]
2. if Ss is nil:
3. then Ss = Cpst .TreeIDSet
4. else Ss = Ss∩Cpst .TreeIDSet
5. for j in [0,‖Nt .Children‖]:
6. Ct = Nt .Children[ j]
7. if Ct .Label in Cpst .Children[ j].Keys:
8. then EFTK(Ct , Cpst , j, Ss)
9. else Ss = {}
10. Result = new Hash()
11. for ID in Ss:
12. Result[ID] = 1
13. return Result

5 Experiments

5.1 Performance Comparison

In this experiment, we conduct a performance
comparison between the MFTK and EFTK algo-
rithms, the baseline QTK (Quadratic Tree Kernel)
and the state-of-the-art FTK (Fast Tree Kernel),
both of which were proposed by Moschitti (2006).

We have chosen to estimate the processing time
taken by the algorithms to calculate the kernel val-
ues between the constituency parses produced by
the Stanford Parser (Klein and Manning, 2003) of
500 test and 5452 training questions. The datasets
were devised for the task of Question Classifica-
tion (Li and Roth, 2002). The algorithms were im-
plemented in Python, and ran in a computer with
a quad-core Intel R© Core i7-4500U 1.8GHz and
8Gb of RAM running at 1600MHz. Since the time
taken by both FTK and MFTK to calculate ST and
SST kernels do not vary, we choose to present the
performance results for ST kernel calculation only.
Figure 3 illustrate the results obtained for increas-
ing portions of the training set, and Figure 4 the
average time taken to calculate K (Ti,Ti) for Ti of
different node sizes.

The MFTK algorithm is on average 3.54 times
faster than FTK for different corpus sizes, while

Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 271



Figure 3: Processing time over different portions
of the dataset

Figure 4: Processing time over trees of different
node sizes

the EFTK algorithm is on average 22.15 times
faster. It can also be noticed that, while the pro-
cessing time of EFTK grows almost linearly as the
number of nodes rise, the FTK shows a square-
like behavior, which is also outperformed by the
MFTK algorithm.

5.2 Storage Scalability
In this experiment, we evaluate how well Po-
sitional Suffix Trees scale with respect to large
datasets. To that purpose, we chose to store a
dataset of 200k constituency parses of sentences
taken from Wikipedia and Simple Wikipedia
(Paetzold and Specia, 2013) in a PST, and collect
statistics about its size. The PST was implemented
in Python and the script ran in the same computer
used in the experiment of Section 5.1. Figure 5
shows the number of trie nodes in the PST as the
number of stored trees rise, and Figure 6 illustrates
the average number of new PST trie nodes added
after each tree is stored.

It is noticeable that the curve in Figure 5 shows
a convergence pattern, which is in conformity with
what is observed in Figure 6, where it is shown
that the number of average new nodes tends to
converge to an ever lower amount. Such phenom-
ena provide evidence that the PST can indeed store

Figure 5: Number of trie nodes over the numbers
of trees stored

Figure 6: Average number of new trie nodes over
the number of trees stored

large amounts of tree structures in a scalable fash-
ion, since the more trees are added, the less it
needs to grow to represent them.

6 Conclusions and Future Work

In this paper we have introduced the Positional
Suffix Tree, a data structure designed to store trees
and graphs, and also two algorithms which use
them to estimate Subtree and Subspace Tree Ker-
nel values: the MFTK and the EFTK.

Our experiments revealed that, while the MFTK
algorithm calculates both ST and SST Kernels in
nearly half an order of magnitude faster than state-
of-the-art algorithms, the EFTK algorithm calcu-
lates ST Kernels over an order of magnitude faster.
We have also found that the PST provides a scal-
able storage solution for syntactic parse trees.

In the future we intend to devise algorithms
for other kernels, such as the Partial Tree Kernel
(Moschitti, 2006), and also explore ways to cal-
culate approximate, faster to estimate, versions of
such kernels.

Acknowledgments

I would like to thank the University of Sheffield
for supporting this project.

Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 272



References
Michael Collins and Nigel Duffy. 2002. New rank-

ing algorithms for parsing and tagging: Kernels over
discrete structures, and the voted perceptron. In Pro-
ceedings of the 40th Annual Meeting on Association
for Computational Linguistics, ACL ’02, pages 263–
270, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.

Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings
of the 42nd Meeting of the Association for Compu-
tational Linguistics (ACL’04), Main Volume, pages
423–429, Barcelona, Spain, July.

Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In In Proceedings of the
41st Annual Meeting of the Association for Compu-
tational Linguistics, pages 423–430.

Xin Li and Dan Roth. 2002. Learning question classi-
fiers. In Proceedings of the 19th International Con-
ference on Computational Linguistics - Volume 1,
COLING ’02, pages 1–7, Stroudsburg, PA, USA.
Association for Computational Linguistics.

Alessandro Moschitti. 2004. A study on convolution
kernels for shallow semantic parsing. In Proceed-
ings of the 42Nd Annual Meeting on Association for
Computational Linguistics, ACL ’04, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.

Alessandro Moschitti. 2006. Efficient convolution
kernels for dependency and constituent syntactic
trees. In ECML, pages 318–329, Berlin, Germany,
September. Machine Learning: ECML 2006, 17th
European Conference on Machine Learning, Pro-
ceedings.

Gustavo H. Paetzold and Lucia Specia, 2013. Pro-
ceedings of the 9th Brazilian Symposium in Infor-
mation and Human Language Technology, chapter
Text Simplification as Tree Transduction.

Jeong-Woo Son, Seong-Bae Park, and Se-Young Park.
2006. Program plagiarism detection using parse
tree kernels. In Proceedings of the 9th Pacific Rim
International Conference on Artificial Intelligence,
PRICAI’06, pages 1000–1004, Berlin, Heidelberg.
Springer-Verlag.

S V N Vishwanathan and Alex Smola. 2004. Fast ker-
nels for string and tree matching.

Peter Weiner. 1973. Linear pattern matching algo-
rithms. In Proceedings of the 14th Annual Sym-
posium on Switching and Automata Theory (Swat
1973), SWAT ’73, pages 1–11, Washington, DC,
USA. IEEE Computer Society.

Yoshihiro Yamanishi, Francis Bach, and Jean-Philippe
Vert. 2007. Glycan classification with tree kernels.
Bioinformatics, 23(10):1211–1216.

Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation ex-
traction. Journal of Machine Learning Research,
3:2003.

Proceedings of the 20th Nordic Conference of Computational Linguistics (NODALIDA 2015) 273


