










































Automatic Corpora Construction for Text Classification


International Joint Conference on Natural Language Processing, pages 726–732,
Nagoya, Japan, 14-18 October 2013.

Automatic Corpora Construction for Text Classification

Dandan Wang, Qingcai Chen, Xiaolong Wang, Bingyang Yu
Key Laboratory of Network Oriented Intelligent Computation

Harbin Institute of Technology Shenzhen Graduate School, China
{wangdandanhit, qingcai.chen}@gmail.com

wangxl@insun.hit.edu.cn
bingyang.yu@hotmail.com

Abstract

Since the machines become more and
more intelligent, it is reasonable to expect
the automatic construction of text classi-
fiers by given just the objective categories.
As trade-off solutions, existing researches
usually provide additional information to
the category terms to enhance the perfor-
mance of a classifier. Unique from them,
in this paper, we construct the standard
corpora from the web by just providing
text categories. Since there are million-
s of manually constructed websites, it is
hopeful to find out proper text categoriza-
tion (TC) knowledge. So we directly go to
the web and use the hierarchies implied in
navigation bars to extract and verify TC re-
sources. By addressing the issues of nav-
igation bar recognition and text filtering,
the corpora are constructed for given tex-
t categories and the classifiers are trained
based on them. We conduct our experi-
ments on the large scale of webpages col-
lected from the 500 top English websites
on Alexa. The Open Directory Project
(ODP) is used as testing corpus. Experi-
mental results show that, being compared
with the classifier based on manually la-
beled corpus, the classifier trained on au-
to constructed corpora reaches compara-
ble performance for the categories that are
well covered by the training corpus.

1 Introduction

As one of the key techniques in web information
processing, text classification has been studied for
a long time (Aas and Eikvil, 1999; Wang and
Li, 2011; Yang and Pedersen, 1997). A growing
number of machine learning techniques have been
applied to text classification and some of them

have proven to be successful (Miao and Kamel,
2011; Sebastiani, 2002). In the machine learn-
ing approach, the learning process is an instance
of supervised or semi-supervised learning because
classifier can be built automatically by learning
from adequately pre-labeled training documents
and then classified unseen documents (Feldman
and Sanger, 2007). However, the task of manual-
ly labeling a large amount of documents is time-
consuming and even impractical. Given a gen-
eral classification task, people usually construc-
t training data in two ways. One is augment-
ing a small number of labeled documents with
large amounts of unlabeled ones to guide the learn-
ing model iteratively, so that the new classifier
can label the unlabeled documents (Jiang, 2009;
Nigam et al., 2000). In such studies, the boot-
strapping technique is often used to label the un-
labeled documents and refine the initial classifier
(Gliozzo et al., 2009; Ko and Seo, 2009). The
other is collecting training corpora from the We-
b. Such works use the class name and its asso-
ciated terms to collect training corpora iteratively
(Huang et al., 2005). Cheng (2009) and Day et al.
(2009) firstly sample the Web with a set of given
class names, and then query the keywords manual-
ly populated from each class by search engines for
retrieving quality training documents. Huang et al.
(2004) proposed a LiveClassifier system which al-
so makes use of search engines for automatically
constructing training classifier.

Though reached encouraging performance,
above methods have some limitations in organiz-
ing training corpora. For the first method, al-
though some algorithms just use a small set of
labeled documents, which still require much time
and effort for complicated categories (Chen et al.,
2009); And the second method depends on several
external resources, which greatly limits its flexi-
bility and reliability. For example, manually given
keywords or terms for a class are easily affected by

726



different persons; different search engines may al-
so bring different results with various type of nois-
es contained in search results (Huang et al., 2004).

Inspired by these issues, we design a new
system to automatically acquire training corpora.
Given a class hierarchy, our basic idea is to col-
lect corpora merely based on class names. Firstly,
we crawl the webpages starting with several se-
lected websites and identify the navigation bars of
these websites. Then each navigational item in the
navigational bars is matched with the class names.
The valid subpages from a navigational item are
labeled with the matched class name. After ex-
tracting contents from these subpages, the initial
candidate corpora are constructed. Finally cluster-
ing algorithm is used to remove noises from the
corpora. In latter parts of paper, we denote the au-
tomatic constructed corpora as ACC.

The main contributions of this paper are:
(1) An automatic system for constructing classi-

fication corpora is built. It is a new way to collec-
t large-scale, high quality corpora; moreover, it is
completely adaptive to any kind of class hierarchy;

(2) To improve the ACC quality, text cluster-
ing based automatic noise filtering approaches are
proposed and analyzed;

(3) The proposed system and methods are eval-
uated on large scale standard corpora and encour-
aging results are reached.

The remainder of this paper is organized as fol-
lows. Section 2 described the architecture of the
automatic corpora construction system; Section 3
and 4 present experimental settings and results re-
spectively. The paper is closed with conclusion
and future work in section 5.

2 Automatic Corpora Construction

In this paper, we propose a novel system that
can automatically acquire effective training data
through web mining. The architecture of the sys-
tem is given in Fig 1. It is composed of four mod-
ules: data collection, navigational processing, can-
didate corpora construction and corpora denois-
ing. The data collection module crawls webpages
from the given URL seeds. The navigational pro-
cessing module is to extract the navigational bars
from downloaded web pages, and to make catego-
ry judgments for each navigational item. The can-
didate corpora construction module is to get the
candidate corpora by performing content extrac-
tion for the valid links from the navigational item-

Data Collection

Candidate Corpora ConstructionCorpora Denoising

Navigational Processing

Initial 
Url List

Navigational Bars 
Identification

Navigational 
Items Category 

Judgement

Class 
Hierarchy

Clustering Denoising

Valid Links 
Judgement

Web Page Content 
Extraction

Content 
Filtering

Figure 1: Architecture of the ACC System.

s. The corpora denoising module makes clustering
for all texts in the candidate corpora and removes
the noisy web pages for each category.

2.1 Navigational Bars Processing
Generally, the navigational bars locate in one
block or several blocks of a web page. Thus it
is necessary to split the web page into blocks for
identifying the navigational bars. In this paper, we
use the approach proposed by (Keller and Nuss-
baumer, 2012) for segmentation and simplify it by
three rules as follows.

(1) Remove leaf nodes which are not link nodes;
(2) If the node is the only child of of its parent

node, delete the parent node and directly connect
the node with its ancestor node;

(3) If the node has two children nodes, and the
first child node is the link node, while the other
is not, then delete the node and connect the two
children nodes with its ancestor node.

In latter parts of this paper, the set of blocks af-
ter segmentation is denoted as PageSec.

2.1.1 Navigational Bars Identification
The approaches for navigational bars identifica-
tion can be divided into two categories, i.e., rule-
based and graph-based filtering respectively. In
this paper, we compared two different approach-
es for the navigational bars identification.

Rule-based Identification: Firstly, we conduct
filtering for each block in PageSec. The filtering
conditions include link type, link uniqueness etc.
Then a ranking formula is constructed to calculate
the score for each blocks. The features used in the
formula are listed as follows.

(1) Consistent degree of link depth between
the anchor texts within block: Each anchor text

727



within the block will point to a link. The depth of
a link is represented by its slashes’ number. The
consistent degree of link depth between the anchor
text within block is calculated by formula (1).

Dep (Sec) =

−
n∑
i=1

(P (AcDi) ln (P (AcDi)))

ln (n)
(1)

Where n: The number of anchors with different
depth within the block.
P (AcDi): The proportion of anchors with the ith
anchor depth within the block.

(2) Consistent degree of word number be-
tween the anchor texts within block: General-
ly, the word number of each navigational item is
consistent. The more tidy appearance of the items,
the more likely to belong to the same navigational
bar. The consistent degree of word number be-
tween the anchor texts within block is calculated
in the same way with the consistent degree of link
depth.

(3) The proportion of the remaining anchor
texts within block.

Integrating the three features above, we con-
struct a linear weighted summation formula to
rank for the blocks. Finally, the top-ranking block-
s with score bigger than a threshold are added to
the candidate of the navigational bars.

Graph-based Identification: Firstly, we con-
struct the relationship graph of links and find
the maximum complete subgraph by the Bron-
Kerbosch algorithm. Then we use a discriminant
algorithm to extract the final navigational bars.

(1) Construction of Links Relationship
Graph: Each web page is represented with a n-
ode, if page A has a link pointing to page B,
a directed edge from A to B is generated. We
deleted single directional edges and preserved bi-
directional edges; moreover, the directed graph is
transformed to be undirected for simplification. In
this paper, the Bron-Kerbosch algorithm is used to
get the maximum complete subgraph.

(2) Extraction of Navigational Bars: For ex-
tracting navigational bars, we need to take advan-
tage of maximum complete subgraphs to conduct
filtering on the block structure of the web page.
The pseudo code is listed in algorithm1. In addi-
tion, as the vertex number increases to a value, the
running time of searching for the maximum sub-
graphs becomes unacceptable. Thus we apply an
approximate algorithm to extract the navigational

bars when the vertex number is more than 100.

2.1.2 Navigational Items Category Judgment
After identifying the navigational bars, we need
to match the navigational items with each class of
the given class hierarchy. The cosine similarity in
the vector space model is used for calculating the
matching degree. Moreover, in order to get a bet-
ter result, we apply stemming for the navigation-
al items and word expansion for the class names.
Given a navigational item, we firstly calculate its
similarities with all classes and sort those classes
in descending order of the similarities. If the max-
imum similarity in the rank is unique and greater
than a given threshold, label the navigational item
with the corresponding class. Otherwise, we use
the URL information to make further judgment.

Algorithm1: Navigational bars extraction
Input: Maximum complete subgraph MCSQueue
Block set of homepage PageSec
Output: Candidate navigational bars CandNav
Step1: Label all the elements in MCSQueue with
unprocessed.
Step2: Select an unprocessed subgraph SGraph
from MCSQueue. If all processed, turn to step 4.
Step3: Filter on all the elements in PageSec, re-
move the elements not in SGraph and save the re-
sult in CandNav, turn to step 2.
Step4: Sort all blocks in CandNav from more to
less by the number of elements.
Step5: Traverse CandNav from the beginning and
delete Sec if current block contains all the ele-
ments of block Sec which is at the position behind.
Step6: End

2.2 Candidate Corpora Construction
2.2.1 Valid Links Judgment
A navigational item within the navigational bar
usually points to a hub web page that is mainly
composed of a set of links, which makes it diffi-
cult to extract relevant web pages for a given topic.
In general, the links that point to external websites
are treated as invalid links and can be directly fil-
tered. Since some kind of invalid links, such as the
Login, Sitemap etc, occur many times in the web-
site and the times of category assignment to the
invalid links are significantly more than the valid
links. In this paper, we regard the links with the
times of category assignment more than a thresh-
old as invalid links. Since there are multiple nav-

728



igational paths that can lead to a web page, each
valid link may have multiple category labels and
the voting strategy is used to label the valid link.

2.2.2 Web Page Content Extraction
Extracting content from webpages has been re-
searched for decades and numerous methods have
been proposed. Tim proposes a method to extrac-
t content text from diverse web pages by using
the HTML documents tag ratios (Weninger et al.,
2010). Sun presents Content Extraction via Text
Density (CETD) to extract content and also pro-
poses a method called DensitySum to extract inte-
gral content. Moreover, CETD-DS has shown that
it is an effective and robust content extraction al-
gorithm (Sun et al., 2011). In this paper, we apply
Tim’s tag ratio to extract content.

Tag Ratio: Tim’s tag ratio is the ratio of HTM-
L tags characters and Non-HTML tags characters
at each row of the HTML source code. It can be
described by formula (2) as follows:

TagRatioi =
NonTagCharsi
TagNumi

(2)

Where NonTagCharsi: The number of Non-
HTML tags characters at the ith row.
TagNumi: The number of HTML tags at the ith
row. For the hyperlink tag, multiply it by 2.

Since the comments, scripts and CSS tags do
not contain the text content, we remove them from
the HTML code while calculating the tag ratio.
For the tag ratio, we apply the standard gaussian
approach to make smoothing. Firstly we construc-
t a gaussian kernel (Keerthi and Lin, 2003) with
radius of 1 and variance of 2 by formula (3).

ki =

dσe∑
j=−dσe

e
−j2

2σ2 , 0 ≤ i ≤ 2 dσe (3)

After normalization, we get (4):

k′i =
ki∑2dσe
j=0 kj

, 0 ≤ i ≤ 2 dσe (4)

Then we make the convolution operation with this
filter and tag ratio to get the smoothing tag ratio.

Content Extraction: Most of the methods for
content extraction try to use different threshold s-
election strategies for different features, but the
generalization performance of these algorithms
are still not satisfactory. Therefore, we adopt the
K-means clustering with two-dimensional features

to get the final content. The first dimensional fea-
ture is the smoothing tag ratio, the second one is
the approximate derivative of the tag ratio.

2.3 Corpora Denoising
Ideally, web pages with the same category label
in the candidate corpora belong to the same topic.
However, because of the different website author-
ity and management level, some web pages which
do not belong to the category topic are also classi-
fied into this category. In addition, some irrelevant
web pages are preserved owing to the weakness of
the valid links judgment. These noisy web pages
greatly reduce the quality of the candidate corpo-
ra. Therefore, we apply K-means clustering algo-
rithms to conduct corpora denoising. After clus-
tering, the large clusters are preserved while the
smaller ones are removed as the noises.

3 Experimental Settings

3.1 Databases
Self-collected Data: A universal crawler is im-
plemented for the automatic corpora construction
task. In addition to the general crawler task,
it records the jumping information between web
pages for locating the target web pages and the or-
ders of visiting each page in the crawling process.
The initial seed links of the crawler are collected
from the Alexa1 top 500 websites of each category
on May 26, 2012. After removing the duplicated
websites, there are 5593 ones left. Take them as
the starting links and perform crawling, finally we
crawled a total of 783035 web pages.

ODP (Open Directory Project): ODP is one
of the largest corpora for web page classification.
We download the ODP corpus on April 22, 2012.
There are totally 4066266 web page links in which
2144930 web page links are downloaded.

Dataset Split: In our experiments, both the au-
tomatic constructed data and ODP are randomly
split into three near equal scale of subsets with t-
wo parts for training and the remaining for testing.

3.2 Experimental Settings
Preprocessing: The class hierarchy of ODP
is used for the automatic corpora construction.
Libxml2 is used to parse the web pages into the
DOM trees. For the web pages that cannot be di-
rectly parsed, tidy is applied to correct the syn-
tax mistakes. The Porter algorithm (Jongejan and

1Alexa:http://www.alexa.com/

729



Dalianis, 2009) is used for stemming. Generally,
there are two kind of ways to make word expan-
sion. One is based on WordNet (Fellbaum, 1998)
and the other is to obtain the description words for
categories by search engine or other external re-
sources. In this paper, the description words for
each category come from its secondary classifica-
tion keywords under the ODP class hierachy.

Classification and Clustering: Expected
Cross Entropy is selected for feature selection.
8000 dimensional features are selected out. Lib-
SVM 2 is used for classification where the linear
kernel and default settings are applied. K-means
is used for clustering where K is set to 8.

4 Experimental Results

4.1 Performance of ACC system

Navigational Bars Identification: To evaluate
the performance of navigational bars identifica-
tion, we randomly select five websites from the
initial seed links for human label. The results of
rule-based and graph-based navigational bars i-
dentification are shown in Table 1. Nnb denotes
the number of navigational bars. Anr and Rnr de-
note the accuracy and recall of rule-based identifi-
cation approach. Ang andRng denote the accuracy
and recall of graph-based identification approach.
We can see that both methods reach high accura-
cy and relatively lower recall without significant
difference. The reason is that some external links
are filtered while some navigational bars are com-
posed of items from different domains.

Navigational Items Category Judgment: We
randomly sampled 100 websites for human label
from the initial seeds of the crawler. The perfor-
mance of navigational items category judgment is
demonstrated in Table 2. Since the accuracy of
category judgment is very high, a navigational i-
dentification method with higher recall is selected
to increase the size of the final corpora.

Web Page Content Extraction: We evaluate
the performance of web page content extraction
on seven standard corpora: CleanEval-Eng, NY
Times, Yahoo!, Wikipedia, BBC, Arts Technica
and Chaos. Table 3 shows that the web page con-
tent extraction algorithm performs well on accura-
cy for all the seven corpora, but the recall is not
satisfactory on corpora like Wikipedia and Yahoo!

2Liblinear:http://www.csie.ntu.edu.tw/ cjlin/liblinear/

Website NnbAnr(%)Ang(%)Rnr(%)Rng(%)
CNN 49 65 81.3 53.1 53.1

Yahoo! 41 36.2 52.9 51.2 22.0
EatingWell 81 87.2 78.5 43.6 79.5

Adobe 39 97.5 65.5 36.4 17.8
Cornell 38 100 51.6 65.8 42.1

Table 1: Performance of navigational bars identi-
fication

Category Judgement Accuracy
Arts 31%

Business 100%
Computers 93%

Games 85%
Health 91%
News 88%

Science 100%
Shopping 83%
Society 87%
Sports 98%

Table 2: Category judgment performance of navi-
gational items

Corpora Accuracy Recall F1
CleanEval-Eng 85.91% 75.42% 80.32%

NY Times 84.24% 84.90% 84.57%
Yahoo! 95.40% 66.29% 78.22%

Wikipedia 98.82% 34.82% 51.50%
BBC 93.74% 83.55% 88.35%

Arts Technica 96.23% 92.16% 94.15%
Chaos 86.08% 94.47% 90.08%

Table 3: Performance of web page content extrac-
tion on 7 corpora

Corpora Accuracy: In Table 4, we demon-
strate the performance of ACC on each catego-
ry. Np denotes the number of crawled web pages.
A denotes the accuracy before clustering and Ac
denotes the accuracy after clustering. This table
shows that the macro-average accuracy can reach
68.18%. Furthermore, the applying of simple text
clustering method contributes up to 2.73% accu-
racy performance gains, which demonstrates the
effectiveness of our denoising method.

4.2 Performance of Classification

Size of ACC and ODP: The number of crawled
web pages and left web pages after content extrac-

730



tion in ACC and ODP denoted by Np and N cp re-
spectively are given in Table 5. From this table we
can see that only a little part of crawled web pages
in both data sets contain effective contents. It is
because that most of the web pages in ODP are
the homepages of websites, and many web pages
mainly contain pictures rather than effective con-
tents in ACC.

Classification Results of ACC and ODP: In
Table 6, we show the overall SVM classification
performance of each category on ODP and ACC.
The macro-F1 is approximately 72.3% and 79.8%
respectively. By comparing the classification re-
sults of ODP and ACC on each category, we can
see that the performance of ACC is better than
ODP on accuracy and recall.

Category Np A Ac
Arts 32773 41% 40%

Business 10477 86% 85%
Computers 2752 60% 65%

Games 20280 73% 76%
Health 7875 52% 59%
News 33850 70% 72%

Rigional 2256 70% 74%
Science 2358 71% 70%

Shopping 7820 57% 64%
Society 7381 77% 81%
Sports 14769 63% 64%

Average — 65.45% 68.18%

Table 4: Performance of ACC on each category

Category Np NcpACC ODP ACC ODP
Arts 32773 206887 1327 5043

Business 10477 208069 1167 4641
Computers 2752 95136 55 1487

Games 20280 44800 357 876
Health 7875 52230 252 977
News 33850 7438 1179 376

Science 2358 91841 136 2735
Shopping 7820 71070 103 853
Society 7381 161806 278 4304
Sports 14769 74317 742 1985

Table 5: Size of ACC and ODP for each category

But it is clear that this can not prove ACC is su-
perior to ODP. Finally we train a classifier with all
the automatic constructed corpora and use 1/3 pro-
portion of ODP for testing. The results are shown

Class Accuracy(%) Recall(%) F1(%)ODP ACC ODP ACC ODP ACC
Arts 74.1 71.6 84.2 77.3 78.8 74.3
Busi 60.9 76.7 65.4 81.9 63.1 79.2
Comp 73.6 79.5 68.5 77.2 71.0 78.3
Games 81.1 79.7 85.0 79.1 83.0 79.4
Health 68.7 87.3 65.9 86.3 67.3 86.8
News 84.6 83.6 83.2 78.7 83.9 81.1
Science 74.1 78.9 70.4 83.2 72.2 81.0
Shop 47.2 86.3 39.6 88 43.1 87.1
Society 72.2 82.9 76.1 56.9 74.1 67.5
Sports 86.8 82.7 87.9 84.4 87.3 83.5

Table 6: SVM classification performance of each
category on ODP and ACC

in Table 7. The results show that the classification
performance is relatively poor. The main reason
is that the coverage of ACC is inadequate, which
leads to a big distribution difference between the
training and testing data. The factors that influ-
ence the coverage of corpora include the size of
initial URL seeds, the crawling depth, the recall of
navigational bars etc.

Category Accuracy Recall F1
Arts 63.2% 55.5% 59.1%

Business 34.3% 54.6% 42.1%
Computers 57.7% 61.9% 59.7%

Games 37.4% 77.3% 50.4%
Health 22.4% 81.4% 35.1%
News 21.4% 68.9% 32.7%

Science 40.8% 54.5% 46.7%
Shopping 37.0% 17.4% 23.7%
Society 35.2% 13.5% 13.5%
Sports 53.2% 78.7% 63.5%

Table 7: SVM Cross-Test Result

5 Conclusion

In this paper, we proposed a new automatic ap-
proach which makes use of web resources to con-
struct the corpora. An automatic system for con-
structing classification corpora is built. Experi-
ments conducted on ACC and ODP show that the
automatic corpora construction approach is effec-
tive, although the cross-test result is not satisfacto-
ry. Future research will focus on solving the cov-
erage problem of ACC.

731



Acknowledgment

This work is supported in part by National Natural
Science Foundation of China (No.61173075 and
No.61272383).

References
Alfio Gliozzo, Carlo Strapparava and Ido Dagan. 2009

Improving text categorization bootstrapping via un-
supervised learning. ACM Transactions on Speech
and Language Processing.

Bart Jongejan and Hercules Dalianis. 2009. Automatic
training of lemmatization rules that handle morpho-
logical changes in pre-, in- and suffixes alike. Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint
Conference on Natural Language Processing of the
AFNLP, pp.145–153.

Chen-Ming Hung and Lee-Feng Chien. 1999. Text
classification using web corpora and em algorithms.
The Asia Information Retrieval Symposium, pp.12–
23.

Chien-Chung Huang, Kuan-Ming Lin and Lee-Feng
Chien. 2005. Automatic training corpora acquisi-
tion through web mining. IEEE/WIC/ACM Confer-
ence on Web Intelligence.

Chien-Chung Huang, Shui-Lung Chuang and Lee-
Feng Chien. 2004. Liveclassifier:creating hierar-
chical text classifier through web corpora. ACM
Transactions on Speech and Language Processing.

Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press.

Eric P. Jiang. 2009. Semi-supervised text classifica-
tion using rbf networks. International Development
Association, pp.95–106.

Fabrizio Sebastiani. 2002. Machine learning in auto-
mated text categorization. CM Computing Surveys,
34(1):1–47.

Fei Sun, Dandan Song and Lejian Liao. 2011. Dom
based content extraction via text density. SIGIR,
pp.245–254.

Jiaxun Wang and Chunping Li. 2011. An iterative vot-
ing method based on word density for text classifica-
tion. WIMS.

Kamal Nigam, Andrew Kachites Mccallum, Sebastian
Thrun and Tom mitchell. 2000. Text classification
from labeled and unlabeled documents using em.
Machine Learning, 39(2-3):103–134.

Kjersti Aas and Line Eikvil. 1999. A Survey. Text
Categorization.

Matthias Keller and Martin Nussbaumer. 2012. Men-
uMiner: revealing the information architecture of
large web sites by analyzing maximal cliques. Pro-
ceedings of the 21st international conference com-
panion on World Wide Web, ACM: Lyon, France.

Pu-Jen Cheng. 2009 Web-based unsupervised tex-
t classification.

Ronen Feldman and James Sanger. 2007. Advanced
Approaches in Analyzing Unstructured Data. The
Text Mining Handbook, Cambrige University.

Si Chen, Gongde Guo and Lifei Chen. 2009. Semi-
supervised classification based on clustering ensem-
bles. Artificial Intelligence and Computational In-
telligence.

S. Sathiya Keerthi and Chih-Jen Lin. 2003. Asymptot-
ic behaviours of support vector machines with gaus-
sian kernel. MIT Press, Cambrige University.

Tim Weninger, William H. Hsu and Jiawei Han. 2010.
content extraction via tag ratios. WWW, pp.971–
980.

Wei-Yen Day, Chun-Yi Chi, Ruey-Cheng Chen, Pu-Jen
Cheng and Pei-Sen Liu. 2009. Web mining for un-
supervised classification. pp.53–67.

Yiming Yang and Jan O. Pedersen. 1997. A compar-
ative study on feature selection in text categoriza-
tion. International Conference on Machine Learn-
ing, pp.412–420.

Youngjoong Ko and Jungyun Seo. 2009. Text classi-
fication from unlabeled documents with bootstrap-
ping and feature projection techniques. Information
Processing and Management, 45(1):70–83.

Yun-Qian Miao and Mohamed Kamel. 2011. Pairwise
optimized rocchio algorithm for text categorization.
Pattern Recognition Letters, 33(2):375–382.

732


