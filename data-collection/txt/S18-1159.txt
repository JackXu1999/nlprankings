



















































ELiRF-UPV at SemEval-2018 Task 10: Capturing Discriminative Attributes with Knowledge Graphs and Wikipedia


Proceedings of the 12th International Workshop on Semantic Evaluation (SemEval-2018), pages 968–971
New Orleans, Louisiana, June 5–6, 2018. ©2018 Association for Computational Linguistics

ELiRF-UPV at SemEval-2018 Task 10: Capturing Discriminative
Attributes with Knowledge Graphs and Wikipedia

José-Ángel González, Lluı́s-F. Hurtado, Encarna Segarra, Ferran Pla
Universitat Politècnica de València
Camı́ de Vera sn, 46022, València

{jogonba2|lhurtado|esegarra|fpla}@dsic.upv.es

Abstract

This paper describes the participation of
ELiRF-UPV team at task 10, Capturing Dis-
criminative Attributes, of SemEval-2018. Our
best approach consists of using ConceptNet,
Wikipedia and NumberBatch embeddings in
order to stablish relationships between con-
cepts and attributes. Furthermore, this sys-
tem achieves competitive results in the official
evaluation.

1 Introduction

Capturing Discriminative Attributes, task 10 of
SemEval-2018 (Krebs et al., 2018), proposes
working on semantic difference detection . The
goal of the task is to predict whether a word is a
discriminative attribute between two other words.
This problem is known as semantic difference de-
tection, which is a binary classification task: given
a triple (apple, banana, red), it consists in de-
termining whether it exemplifies a semantic dif-
ference. Regarding semantic difference, it is a
ternary relation between two concepts, for in-
stance, (apple, banana) and a discriminative fea-
ture (red) that characterizes the first concept but
not the other.

As task 10 is related to the semantic relations
among different words, knowledge graphs seems
the most appropriate resources to be used. An
interesting knowledge resource that we used for
this task is ConceptNet. In particular, Concept-
Net (Speer et al., 2016) is a knowledge graph that
connects words and phrases of natural language
using labeled edges. It was designed to repre-
sent some general knowledge involved in natu-
ral language and could be used in combination
with other resources. The combination of Con-
ceptNet with distributed representations such as
Word2Vec (Mikolov et al., 2013) and GloVe (Pen-
nington et al., 2014), is known as NumberBatch

embeddings (Speer et al., 2016).
Regarding the relations specified in Concept-

Net, there are a total of 36 relations such as IsA
(A banana is a dessert), UsedFor (A net is used for
catching fish), or FormOf (“Leaves” is a form of
the word “leaf”), intended to represent a relation-
ship independently of the language or the source
of the terms it connects.

In this work, we propose five knowledge based
systems and one additional machine learning sys-
tem based on Siamese networks. We used Con-
ceptNet in order to determine if each input con-
cept and the input attribute are related through a
relation edge or path. When there is a relation-
ship between the first concept and the attribute and
there is no relationship between the second con-
cept and the attribute, then the answer is 1, other-
wise, the answer is 0. However, there are cases in
which ConceptNet does not provide enough infor-
mation to take a decision. In those cases, we have
implemented a system that seeks the information
in Wikipedia articles by using distances between
NumberBatch embeddings.

2 Resources and Preprocess

As we stated in Section 1, ConceptNet 5 is used
in order to find the relationships among con-
cepts and attributes. ConceptNet 5 is freely avail-
able under the Creative Commons Attribution-
ShareAlike license (CC BY SA 4.0) from http:
//conceptnet.io. Moreover, we use two ad-
ditional resources next to ConceptNet.

On the one hand, in order to use more infor-
mation of each concept we used the Wikipedia
articles. In this way, we get the most related ar-
ticle for each concept, following the recommen-
dation of the Wikipedia disambiguation system.
Wikipedia articles had been preprocessed. First,
we remove non relevant sections such as “See

968



Also”, “References” and “External Links” which
links to other resources. After that, we normalized
tokens like numbers or urls e.g. “678.2”→ “num-
ber” y “https://en.wikipedia.org” → “url” and we
made a tokenization of the articles.

On the other hand, we used distributed repre-
sentations of words, more specifically, we used
NumberBatch embeddings (Speer et al., 2016).

3 System Description

We tested several approaches to address this task,
mostly knowledge-based. Let (c1, c2, at) be a
triple where, c1 and c2 are concepts and at is an at-
tribute. The goal of the task is to define a function
d to decide whether at is a discriminative feature
of c1 (value 1 for d) or not (value 0 for d). That is,
if at characterizes c1 but not c2.

Although the training and the development sets
were not very large, we wanted to test the per-
formance of Machine Learning (ML) approaches
for this task. We selected a siamese neural net-
work (Bromley et al., 1993) because these kind
of systems are suitable for similar tasks such as
knowledge base completion (Yang et al., 2014).
This system works as follow. First, the input to
this network are the NumberBatch embeddings of
c1, c2 and at. From this, a shared Multilayer
Perceptron is applied in order to extract a com-
plex representation of each term, f(c1), f(c2) and
f(at). With these representations, we compute the
differences s1 and s2 where s1 = f(c1)–f(at)
and s2 = f(c2)–f(at) with the aim of establish-
ing relationships between each concept and the at-
tribute. Finally, we concatenate s1 and s2 and we
apply a fully-connected layer with softmax acti-
vation functions to carry out a classification i.e.
dSia = 1 if at is discriminative for c1 and not for
c2 or dSia = 0 otherwise.

The rest of the systems were knowledge-based.
As first knowledge-based approach, we use the re-
lationships between each concept and the attribute
to determine if the attribute is discriminant. To
do this, we use the ConceptNet relations. Note
that, ConceptNet contains both positive (IsA, For-
mOf, DerivedFrom, SimilarTo, ...) and negative
relations (DistinctFrom, NotHasProperty). In our
proposals, we only consider positive edges, that is,
those that denote positive relationships.

We look for positive edges between each con-
cept and the attribute. If an edge between c1 and
at exists but there is not any edge between c2 and

at, we assume that at is discriminant. In other
words, at is discriminant if it is reachable from c1
but not from c2. In this way, the function dCN
that determines if the attribute at is discriminant
for concepts c1 and c2 can be defined as shown in
Equation 1.

dCN =

{
1 : if at ∈ R(c1) ∧ at /∈ R(c2)
0 : otherwise

(1)
where, R(c1) and R(c2) are the sets of reach-

able nodes from c1 and c2 respectively using posi-
tive edges.

The main problem of this proposal is its low
coverage. In many cases, there is no edge be-
tween any of the two concepts and the attribute,
and therefore, it is decided that the attribute is not
discriminant. In order to increase the coverage of
dCN , we extend the set of reachable nodes from
a concept to those nodes reachable from other
concepts closely related to the original concept.
We have considered as related concepts those that
are linked by the FormOf relation in ConceptNet.
Considering the extended sets of reachable nodes,
we can redefine the function dCN of Equation 1 as
shown in Equation 2.

dCN2 =

{
1 : if at ∈ R2(c1) ∧ at /∈ R2(c2)
0 : otherwise

(2)
where R2(c) is the set of nodes reachable from

c or from any concept closely related to c.
Nevertheless, this approach still has cover-

age problems. In order to mitigate this prob-
lem, we proposed two new approaches based on
Wikipedia. The main idea is simple, we search
for the attribute at in the Wikipedia article of con-
cepts c1 and c2 (doc(c1) and doc(c2)) and, we de-
cide if at is discriminant based on the result of this
search. In this way, function dW e can be defined
as shown in Equation 3.

dWe =

{
1 : if at ∈ doc(c1) ∧ at /∈ doc(c2)
0 : otherwise

(3)
Further, we can relax the exact match criterion.

Concretely, if we use NumberBatch distributed
representations of words (h), we can compute sim-
ilarities between at and all the tokens of doc(c1)
and doc(c2) in order to decide which concept is
the closest to at.

969



We define a threshold � to ensure that
there is enough difference between the max-
imum similarity max

w∈doc(c1)
cos(h(w), h(at)) and

max
w∈doc(c2)

cos(h(w), h(at)). Using the develop-

ment set, the value of � was fixed to 0.2. This new
decision function dWt is presented in the Equation
4.

dWt =





1 : if max
w∈doc(c1)

cos(h(w), h(at))

− max
w∈doc(c2)

cos(h(w), h(at)) ≥ �
0 : otherwise

(4)
Finally, in order to explore the joint behavior of

the knowledge-based approaches, we propose the
combination of dCN2 and dWt. When there is a re-
lationship between at and any concept –it does not
matter if it is c1, c2 or both– we decide if at is dis-
criminant using dCN2 . But if there is no relation-
ship in ConceptNet between them, we smooth the
decision using dWt. Thus, we only use dCN2 when
we really have information in ConceptNet. The
definition of this new decision function dCN2+Wt
is shown in Equation 5.

dCN2+Wt =





dCN2 : if at ∈ R2(c1)
∨ at ∈ R2(c2)

dWt : otherwise
(5)

4 Experimental Results

In order to validate the correctness of the proposed
approaches and also to select the one with the best
performance for the competition, we carried out
an evaluation of the approaches using the develop-
ment set provided by the organizers. The results
obtained are shown in Table 4.

d Approach Macro F1
dSia Siamese network 57.07
dCN ConceptNet 58.51
dCN2 ConceptNet 2 61.94
dWe Wiki. exact match 58.46
dWt Wiki. threshold 60.34

dCN2+Wt ConceptNet + Wiki. 68.20

Table 1: Results on the development set.

As can be seen in Table 4, the knowledge-based
systems which use knowledge resources obtain
among 1.31 and 11.13 points of macro F1 more

than the Siamese network which uses only Num-
berBatch embeddings. The approaches that use
only ConceptNet (dCN and dCN2) achieved as
good results as those based on Wikipedia (dWe
and dWt). Note that the coverage of dCN and
dCN2 is very low, 48.71% for dCN and 56.61%
for dCN2 . In cases where there are no links in
ConceptNet –more than fifty percent of the time
for dCN– it is decided that the attribute is not
discriminant. Moreover, the more knowledge in-
corporated into the system, the better results are
obtained. We achieved the best results using the
combination of ConceptNet graph and Wikipedia
articles (dCN2+Wt), achieving 68.20 macro F1.

Regarding the evaluation with the test set, we
used dCN2+Wt as decision function for the Se-
mEval competition. Our system achieved compet-
itive results (69.00 macro F1, 6 points of macro
F1 below the best system that obtains 75.00 macro
F1). Our proposal was ranked in 5th place out of
a total of 26 participating teams. Several results
from the official evaluation are shown in Table 4.

Team Macro F1
Sunnynlp (1/26) 75.00
Esantus (2/26) 73.00
ELiRF-UPV (5/26) 69.00

· · ·
Amrita student (25/26) 49.00
Luminoso (26/26) 49.00

Table 2: Official results

5 Analysis of Results

Once the evaluation is finished, we want to carry
out an analysis of the behavior of our system. Our
goal is to detect in which types of attribute the sys-
tem works worse. This way, we could add specific
knowledge resources to deal with these attributes.

Although we have not completed this analysis,
a group of attributes that caught our attention were
the colors. While the overall error rate of our sys-
tem was about 30%, the error in samples with at-
tributes related to colors was about 50%. More de-
tails about the behavior of our system can be seen
in Table 5.

Therefore, it would be possible to improve the
system behavior by treating the color attributes in
a specific way. For instance, by using image re-
sources, such as ImageNet (Deng et al., 2009), to
compute the color palette of images of each con-
cept and compare it with the color attribute.

970



Attributes Errors Occurences
Black 56 116
Brown 41 56
Yellow 11 46
Red 12 19
Blue 1 3
Color 121 (50.42%) 240
Other 586 (27.90%) 2100
Total 707 2340

Table 3: Error analysis in samples with attributes re-
lated to colors.

6 Conclusions and Future Work

In this work, we proposed a knowledge-based sys-
tem for the discriminative attributes task. This sys-
tem is based on the combination of two knowledge
resources: a knowledge graph with semantic links
such as ConceptNet and a general resource such as
Wikipedia.

With this system, we achieved good results
in the development set, compared to a super-
vised learning approach like siamese neural net-
works. That is, a combination of knowledge-based
approaches produces significative improvements
compared to the supervised approach. Regarding
the evaluation with the test set, we obtained com-
petitive results.

As future work, we propose an extension of our
system based on the addition of more knowledge
resources such DBpedia (Lehmann et al., 2015),
Wordnet (Fellbaum, 1998) or Microsoft Concept
Graph (Wang et al., 2015). Moreover, it could be
interesting to consider the sections of Wikipedia
with links to other resources in order to extract
more information.

Finally, we propose the incorporation of knowl-
edge resources into Deep Learning systems, be-
yond using only distributed representations of
words. This offers us end-to-end systems capa-
ble of learning more complex decision algorithms.
Concretely, the siamese neural networks seems to
be promising for this work due to their good re-
sults in related fields such as knowledge-based
completion (Yang et al., 2014).

7 Acknowledgements

This work has been partially supported by the
Spanish MINECO and FEDER founds under
projects ASLP-MULAN: Audio, Speech and
Language Processing for Multimedia Analytics

(TIN2014-54288-C4-3-R); and AMIC: Affective
Multimedia Analytics with Inclusive and Natural
Communication (TIN2017-85854-C4-2-R). Work
of José-Ángel González is also financed by Uni-
versitat Politècnica de València under grant PAID-
01-17.

References
Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard

Säckinger, and Roopak Shah. 1993. Signature ver-
ification using a ”siamese” time delay neural net-
work. In Proceedings of the 6th International Con-
ference on Neural Information Processing Systems,
NIPS’93, pages 737–744, San Francisco, CA, USA.
Morgan Kaufmann Publishers Inc.

J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-
Fei. 2009. ImageNet: A Large-Scale Hierarchical
Image Database. In CVPR09.

Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. Bradford Books.

Alicia Krebs, Alessandro Lenci, and Denis Paperno.
2018. SemEval-2018 Task 10: Capturing discrim-
inative attributes. In Proceedings of International
Workshop on Semantic Evaluation (SemEval-2018),
New Orleans, LA, USA.

Jens Lehmann, Robert Isele, Max Jakob, Anja
Jentzsch, Dimitris Kontokostas, Pablo N. Mendes,
Sebastian Hellmann, Mohamed Morsey, Patrick van
Kleef, Sören Auer, and Christian Bizer. 2015. DB-
pedia - A Large-scale, Multilingual Knowledge Base
Extracted from Wikipedia. Semantic Web Journal,
6(2):167–195.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed represen-
tations of words and phrases and their composition-
ality. CoRR, abs/1310.4546.

Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global vectors for word
representation. In EMNLP, volume 14, pages 1532–
1543.

Robert Speer, Joshua Chin, and Catherine Havasi.
2016. Conceptnet 5.5: An open multilingual graph
of general knowledge. CoRR, abs/1612.03975.

Zhongyuan Wang, Haixun Wang, Ji-Rong Wen, and
Yanghua Xiao. 2015. An inference approach to ba-
sic level of categorization. In Proceedings of the
24th ACM International on Conference on Informa-
tion and Knowledge Management, CIKM ’15, pages
653–662, New York, NY, USA. ACM.

Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng
Gao, and Li Deng. 2014. Embedding entities and
relations for learning and inference in knowledge
bases. CoRR, abs/1412.6575.

971


