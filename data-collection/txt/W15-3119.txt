



















































Chinese Semantic Role Labeling using High-quality Syntactic Knowledge


Proceedings of the Eighth SIGHAN Workshop on Chinese Language Processing (SIGHAN-8), pages 120–127,
Beijing, China, July 30-31, 2015. c©2015 Association for Computational Linguistics and Asian Federation of Natural Language Processing

Chinese Semantic Role Labeling
using High-quality Syntactic Knowledge

Gongye Jin Daisuke Kawahara Sadao Kurohashi
Graduate School of Informatics, Kyoto University

Yoshida-Honmachi, Sakyo-ku, Kyoto, 606-8501, Japan
jin@nlp.ist.i.kyoto-u.ac.jp {dk,kuro}@i.kyoto-u.ac.jp

Abstract

This paper presents an application of Chi-
nese syntactic knowledge for semantic
role labeling (SRL). Besides basic mor-
phological information, syntactic struc-
tures are crucial in SRL. However, it is
difficult to learn such information from
limited, small-scale, manually annotated
training data. Instead of manually increas-
ing the size of annotated data, we use a
large amount of automatically extracted
syntactic knowledge to improve the per-
formance of SRL.

1 Introduction

Semantic role labeling (SRL) is regarded as a task
that is intermediate between syntactic parsing and
semantic analysis in natural language processing
(NLP). The main goal of SRL is to extract a propo-
sition from a sentence about who does what to
whom, when, where and why. By using semantic
roles, the complex expression of a sentence is then
interpreted as an event and its participants (i.e.,
predicates and arguments such as agent, patient,
locative, temporal and manner). Unlike syntactic
level surface cases (i.e., dependency labels such as
subject and object), semantic roles can be regarded
as a deep case representation for predicates. Be-
cause of its ability to abstract the meaning of a sen-
tence, SRL has been applied to many NLP appli-
cations, including information extraction (Chris-
tensen et al., 2010), question answering (Pizzato
and Mollá, 2008) and machine translation (Liu and
Gildea, 2010).

Semantically annotated corpora, such as
FrameNet (Fillmore et al., 2001) and PropBank
(Kingsbury and Palmer, 2002), make this type of
automatic semantic structure analysis feasible by
using supervised machine learning methods. Au-
tomatic SRL processing has two major drawbacks:

firstly, the scale of the training data is quite limited
and although manually annotated data such as
PropBank is available as training data for learning
semantic role prediction models, it is still hard
to learn lexical preferences due its limited size.
Increasing the size and coverage of this resource
for improving the quality of learned models is
a time consuming task. Secondly, similar to
syntactic analysis such as syntactic dependency
parsing, whose performance is highly dependent
on preceding analysis such as POS tagging,
automatic SRL systems are based on syntactic
structures along with lower level information
including POS tags and lexical information. As
a result, SRL suffers from error propagation
from the lower levels of the whole framework.
Although some studies use automatic analysis of
unlabeled data to enrich the training data to solve
the first problem (Fürstenau and Lapata, 2009),
accumulated errors in such automatic analysis
inevitably causes negative effects. Especially, for
some hard-to-analyze languages such as Chinese,
which is difficult to analyze morphologically, the
performance of SRL is always limited due to the
above two problems.

In this paper, we focus on Chinese SRL and
address the problems mentioned above by using
high-quality knowledge automatically extracted
from a large-scale corpus. Instead of using high
level automatic analyses such as semantic roles,
we use lower level syntactic knowledge because
lower level analyses are less erroneous compared
to higher level analyses. The additional knowl-
edge can provide not only a rich lexicon but also
syntactic information, both of which play crucial
roles in SRL. In order to show that automatically
extracted syntactic knowledge is beneficial, we
use predicate-argument structures and case frames
(which will be introduced in later sections) in our
experiments to validate our claim.

The rest of this paper is organized as follows.

120



Section 2 contains related work. Section 3 de-
scribes the high-quality dependency selection pro-
cess. Section 4.1 presents a detailed description of
our approach, conducted on three languages, along
with the results followed by a discussion in Sec-
tion 4.2. Finally, Section 5 contains our conclu-
sions and future work.

2 Related work

The CoNLL-2009 shared task (Hajič et al., 2009)
features a substantial number of studies on SRL
that used Propbank as one of the resources. These
work can be categorized into two types: joint
learning of syntactic parsing and SRL (Tang et al.,
2009; Morante et al., 2009), which learns a unique
model for syntactic parsing and SRL jointly. This
type of framework has the ability to use SRL infor-
mation in syntactic parsing for improvement, but
has a much larger search space during the joint
model learning. The other type is called SRL-
only task (Zhao et al., 2009; Björkelund et al.,
2009), which uses automatic morphological and
syntactic information as the input in order to judge
which token plays what kind of semantic role. Our
work focuses on the second category of SRL. Our
framework is based on those used by Björkelund
et al. (2009) and Yang and Zong (2014).

There were also several studies using semi-
supervised methods for SRL. One basic idea of
semi-supervised SRL is to automatically annotate
unlabeled data using a simple classifier trained
on original training data (Fürstenau and Lapata,
2009). Since there is a substantial amount of er-
ror propagation in SRL frameworks, the additional
automatic semantic roles are not guaranteed to be
of good quality. Contrary to this approach, we
only rely on syntactic level knowledge which does
not suffer too much from error propagation. Also,
some studies assume that sentences that are syn-
tactically and lexically similar are likely to share
the same frame-semantic structure (Fürstenau and
Lapata, 2009). This allows them to project se-
mantic role information to unlabeled sentences us-
ing alignments. However, computation of these
alignments requires additional information such as
word similarity, whose quality is language depen-
dent. Less sparse features capturing lexical in-
formation of words can be also used for semi-
supervised learning of SRL. Such lexical represen-
tation can be learned from unlabeled data (Bengio
et al., 2003). Deschacht and Moens (2009) used

word similarity learned from unlabeled data as ad-
ditional features for SRL. Word embeddings have
also been used in several NLP tasks including SRL
(Collobert et al., 2011). Instead of using word-
level lexical information, our work uses syntactic
knowledge as syntactic level lexical information.
Zapirain et al. (2009) used selectional preferences
to improve SRL. This study is similar to our ap-
proaches but the quality of selectional preferences
was not concerned at all.

In syntactic level of NLP, rich knowledge such
as predicate-argument structures and case frames
are strong backups for various kinds of tasks.
A case frame, which clarifies relations between
a predicate and its arguments, can support tasks
ranging from fundamental analysis, such as syn-
tactic dependency parsing and word similarity cal-
culation, to multilingual applications, such as ma-
chine translation. Japanese case frames have been
successfully compiled (Kawahara and Kurohashi,
2006), where each argument is represented as its
case marker in Japanese such as ‘ga’, ‘wo’, and
‘ni’. For the case frames of other languages
such as English and Chinese, because there are
no such case markers that can help clarify syntac-
tic structures, instead of using case markers like
in Japanese, syntactic surface cases (i.e., subject,
object, prepositional phrase, etc.) are used for
argument representation (Jin et al., 2014). Case
frames can be automatically acquired using a dif-
ferent method such as Chinese Restaurant Process
(CRP) (Kawahara et al., 2014) for different lan-
guages. In our work, we employ such syntactic
level knowledge, which use surface cases as argu-
ment representation, to help SRL task. We refer to
this kind of knowledge as syntactic knowledge in
this paper.

3 Proposed method for SRL

3.1 SRL task description

In previous studies, SRL pipeline1 can be divided
into three main steps: predicate disambiguation
(PD), argument identification (AI), and argument
classification (AC). In the PD step, the main goal
is to identify the “sense id” of each given pred-
icate. Because the sense id for a certain pred-
icate is meaningless for other predicates, classi-
fiers for PD are trained separately for each pred-

1Predicate identification (PI) was not concerned in this pa-
per because we use the data from CoNLL-2009 shared task,
in which the target predicates are given.

121



feature description
PredWord basic morphologic

and syntactic
information of the
predicate and its
parent

PredPOS
PredDeprel
PredParentWord
PredParentPOS
PredParentWord+POS
ChildWordSet

set feature of the
children of
predicate

ChildPOSSet
ChildDepSet
ChildWord+ChildDepSet
ChildPOS+ChildDepSet

DepSubCat

the concatenation
of the dependency
labels of predicate’s
children

Table 1: Features for PD

icate. We used the part of the feature set pro-
posed by Björkelund et al. (2009) and some ad-
ditional features. Table 1 lists the feature sets used
in the PD step. During the prediction, there will
be some predicates which have not been seen be-
fore in training data. We label the sense of those
unseen predicates using the default sense, which is
‘01’ in our work.

Different from syntactic dependency parsing,
given a predicate in a sentence, each token has
a possibility to hold a semantic relation with the
given predicate. Each token is regarded as an ar-
gument candidate. The AI step is mainly to recog-
nize these semantic arguments from the argument
candidates. In the AC step, which is the last step
in the SRL pipeline, each semantic argument is la-
beled with a semantic role. However, there was
some work in which AI and AC step are executed
jointly by inducing a new label ‘null’, which indi-
cates that the token is not a semantic argument of
the predicate. As far as we know, there is small
amount of debate involving the merging of the AI
step and the AC step, especially on whether such
merging is beneficial or not. The joint method
seems to have an ability to reduce the error prop-
agation from the AI step to the AC step. How-
ever, at the same time, since the training sam-
ples with label ‘null’ will consequently outnumber
other labels, there is still a drawback during learn-
ing. In our work, we apply a separate framework
that carries out the AI and AC step in a pipeline

since it is much more intuitive. We use features
from Björkelund et al. (2009) and Yang and Zong
(2014) along with some new features in AI and AC
step. Table 2 lists the features used in each step, in
which we use the mark † to indicate the proposed
features.

3.2 Syntactic knowledge acquisition

We constructed two types of syntactic knowledge
namely, predicate-argument structures and case
frames.

3.2.1 High-quality predicate-argument
structure extraction

Predicate-argument structures (PAS) have been
basically acquired from syntactic analyses which
varies from phrase chunking to syntactic depen-
dency parsing. For example, English PAS in
surface case was acquired in a large scale using
a chunking-based system (Kawahara and Kuro-
hashi, 2010). Some phenomena in Chinese, such
as omission and complex grammar, make it in-
tractable to automatically extract PAS only using
shallow syntactic analysis, such as chunking. Syn-
tactic dependency parsing is applied for Chinese
PAS extraction. Arguments are represented by
their syntactic dependency labels (i.e., subject, ob-
ject, etc.)

Due to various factors, Chinese syntactic depen-
dency parsing is relatively worse in performance
compared to that of English, Japanese, etc. How-
ever, using an existing treebank, it is possible to
train a classifier to acquire high-quality PAS by
only using highly reliable syntactic dependencies.
As a result, we applied syntactic dependency pars-
ing to large-scale raw corpora and adopted the
high-quality syntactic dependency selection ap-
proach (Jin et al., 2014). Their approach first trains
a base parser using a part of the Chinese treebank
and then applies syntactic dependency parsing on
the raw text of another part of the same treebank.
According to the gold-standard annotations, both
postive and negative samples are then collected to
train a binary classifier, which selects those depen-
dencies more likely to be correct. We also follow
their method for the compilation of high-quality
PAS, which can provide a massive amount of syn-
tactic knowledge.

3.2.2 High-quality case frame compilation
In NLP, at the level of syntax, case frames, com-
piled from PAS, were proposed as strong backups

122



feature AI AC description
PredLemma • • basic morphologic

and syntactic
information of the
predicate

PredPOS • •
PredRel • •
PredLemmaSense • •
Head • •
HeadPOS • •
Pred+HeadWord • •
†PredContextWord-1/-2/+1+2 •

context information
of the predicate

†PredContextPOS-1/-2/+1+2 •
†PredContextRel-1/-2/+1+2 •
ArgWord • • basic morphologic

and syntactic
information of the
argument

ArgPOS • •
ArgDeprel • •

†ArgContextWord-1/-2/+1+2 •
context information
of the argument

†ArgContextPOS-1/-2/+1+2 •
†ArgContextRel-1/-2/+1+2 •
DeprelPath • •

structural
information of the
argument in the
dependency tree

LeftSiblingWord • •
LeftSiblingPOS • •
RightSiblingWord • •
RightSiblingPOS • •
Position • •
LeftMostDepWord • •
LeftMostDepPOS • •
RightMostDepWord • •
RightMostDepPOS • •
IsThePredNearest • binary feature indicating

whether the given predi-
cate is the nearest

VerbChainHasSubj • binary feature indicating
whether there is a depen-
dency label ‘SUBJ’ be-
tween the argument and
the predicate

Table 2: Features for AI and AC († marks stand for the features we proposed)

for various kinds of tasks (Kawahara and Kuro-
hashi, 2006). For each predicate, all the PAS
are clustered into different case frames to reflect
different semantic usages. We show an exam-
ple of case frames for the verb ‘谢’ in Table 3,
which has multiple meanings. ‘谢(1)’ is the case
frame used to represent the sense of ‘withering of
flower’. Similarly, the sense of ‘谢’ which means
‘to thank’, the applicable case frame is ‘谢(2)’.
‘谢(3)’ is the case frame for the sense of ‘curtain
call’. In other words, case frames are knowledge
that solves word sense disambiguation (WSD) by

clustering the PAS. We applied the CRP method
described by Kawahara et al. (2014) for clustering
the high-quality PAS to compile high-quality case
frames.

3.3 Using syntactic knowledge for SRL

The motivation of using large-scale syntactic
knowledge is to complement the syntactic infor-
mation in the limited size of training data. In SRL,
an argument may not contain a direct syntactic re-
lation between a given predicate but still plays a
semantic role of the predicate. However, this kind

123



verb surface case instance with frequency in original corpus
谢(1) nsubj 花儿(flower):14,花(flower):22

ad 都(all):16,也(also):6
谢(2) nsubj 你们(you):1

dobj 您(you):8,我(me):6
ad 怎么(how):8,多(very):1

谢(3) nsubj 大战(battle):1
dobj 幕(curtain):6
ad 圆满(successfully):2,也(also):1,正式(officially):1

...

Table 3: Examples of Chinese case frames

!"(Pudong)

#$(promulgate)

%&(implement)

'((involve)

)*(multiple)

+,(field)

-(of)

./(file)

A1

A1

A0

Figure 1: Example of dependency and semantic
relations. Solid arrows denote syntactic dependen-
cies and dotted arrows denote semantic dependen-
cies.

of argument can actually form a direct syntactic re-
lation between the predicate when we change the
expression of the sentence in other ways. In other
words, this kind of argument may hold a direct
syntactic relation with the predicate in real world
natural languages. This is a frequent phenomenon
in multi-verb sentences. Take the sentence in Fig-
ure 1 as an example.

This sentence can be translated as “promulgated
and implemented files involving multiple fields.”
“文件(file)” is a child of “颁布(promulgate)” in
the dependency tree and labeled as semantic role
“A1” of “颁布(promulgate)”. Even though “文
件(file)” does not have a direct dependency rela-
tion with “实行(implement)”, it is still regarded
as a semantic role “A1” of “实行(implement)”.
Similarly, “文件(file)” has also a semantic role
“A0” of the verb “涉及(involve)” with no direct
dependency relation. However, both direct syntac-
tic dependencies “实行(implement) 文件(files)”
and “文件(file) 涉及(involve)” appear frequently
in real world text. Such patterns in surface cases
captured from large-scale corpora would be im-
portant clues for SRL.

In addition, some special surface cases such as
“BA” and “LB/SB” explicitly indicate accusative
case and nominative case, which for most of the
time is labeled as “A1” and “A0” respectively in
PropBank-style SRL specification. “用/以(use)”
is a preposition that strongly indicates the seman-
tic role “MNR” and “在(at)” is a preposition that
always stands for the semantic role “LOC” or
“TMP”. Therefore, it is promising to use large-
scale syntactic knowledge as an additional re-
source.

We created three kinds of additional feature
sets extracted from the above mentioned syntactic
knowledge for SRL. Firstly, we used large-scale
automatically acquired surface case predicate-
argument structures. For each predicate-argument
pair, we measured their point-wise mutual infor-
mation (PMI). Secondly, we used the frequency
of an argument candidate being a certain syntac-
tic role. Finally, by considering the effect of word
sense ambiguity, for each predicate sense, we cal-
culated the frequency of an argument being a cer-
tain syntactic role of a predicate from the corre-
sponding case frames. For all of the additional fea-
tures, we used binned frequency (i.e., high, middle
and low).

Note that a case frame id and a PropBank sense
id do not correspond to each other. As a result,
a mapping process which aligns case frame id(s)
to PropBank verb sense is needed. For exam-
ple, for the sense ‘谢.01’ of the verb ‘谢’, we
extracted and grouped all the related predicate-
argument structures. Then we calculated the sim-
ilarity between verb sense ‘谢.01’ and each case
frame (i.e., ‘谢(1)’, ‘谢(2)’, etc.) by matching the
corresponding predicate-argument structures that
they are composed of. To determine the similar-
ity between the two groups of predicate-argument

124



w/o selection select 50% select 20%
UAS 0.677 0.824 0.920

Table 4: Precision of selected dependencies under different criteria

method precision recall F1
baseline 81.61% 76.40% 78.92
baseline + syntactic knowledge (100%) 81.41% 76.57% 78.92
baseline + syntactic knowledge (50%) 81.57% 76.59% *79.00
baseline + syntactic knowledge (20%) 81.80% 76.63% **79.14

Table 5: Evaluation results of Chinese SRL. The ** mark and * mark mean that the result is regarded as
significant (with a p value < 0.01 and a p value < 0.05 respectively) using McNemar’s test.

structures, we used the method proposed by Kawa-
hara and Kurohashi (2001). This ensures that each
case frame id is aligned to its most similar verb
sense in PropBank.

4 Experiments

4.1 Experimental settings

For large-scale syntactic knowledge acquisition,
30 million sentences from Chinese Gigaword 5.0
(LDC2011T13)2 were used.

For the high-quality dependency selection ap-
proach in the knowledge construction pipeline, the
Stanford parser was used to apply syntactic depen-
dency parsing on the raw texts from Chinese Gi-
gaword. The training section of Chinese Treebank
7.0 was used to train the dependency parser and
the official development section was used to train
a classifier for high-quality dependency selection.
Judging whether the automatic dependencies are
reliable can be regarded as a binary classification
problem, for which we utilized support vector ma-
chines (SVMs). Specifically, we employed SVM-
Light3 with a linear kernel to select high-quality
dependencies from large-scale automatic depen-
dency parses on the Chinese Gigaword for syntac-
tic knowledge construction. Using official evalu-
tion section of CTB 7.0, we evaluated the quality
of thoses selected dependencies using unlabeled
attachment score (UAS), which calculates the per-
centage of correctly indentified dependency heads.

For SRL, we used the Chinese section of
CoNLL-2009 shared task data for experiments.
Automatically obtained morphological and syn-
tactic information (the columns begin with “P”)

2We only used sentences written in simplified characters
in Chinese Gigaword.

3http://svmlight.joachims.org/

was used. PD and AI, AC step are regarded as
multi-class classification problems. We employed
OPAL4 to solve this problem. We set the options
as follows: polynomial kernel with degree 2; pas-
sive aggressive I learner; 20 iterations. The SRL
system without using additional syntactic knowl-
edge was used as a baseline. To examine the ef-
fect of different quality of syntactic knowledge,
we used different set of PAS which was extracted
under different dependency selection thresholds
(20%, 50%, w/o selection). The official script
provided on the CoNLL-2009 shared task website
was used for evaluation.

4.2 Experimental results

Tabel 4 shows the quality of selected dependencies
using different selection criteria. The precision of
automatic syntactic depdencies increases when we
lower the recall.

Table 5 shows our experimental results using
the syntactic knowledge-based features. Syntactic
knowledge (x%) indicates that the top x% (accord-
ing to the classifier) of the automatically extracted
syntactic knowledge was used. ‘100%’ means that
dependency selection step was not performed.

Our baseline system outperforms as well as the
best system in CoNLL-2009 shared task. As we
can see from the result, using large-scale syntac-
tic knowledge can help improve the performance
of SRL. Syntactic knowledge extracted from au-
tomatic parses without any selection (100%) con-
tains a lot of noise and hence is not beneficial
at all. However, filtering noisy syntactic knowl-
edge leads to an significant improvement in Chi-
nese SRL task. This shows that selecting hiqh-
quality dependencies is an important aspect of

4http://www.tkl.iis.u-tokyo.ac.jp/
˜ynaga/opal/

125



high-quality SRL.

5 Conclusion

In this paper, we have used high-quality syntac-
tic knowledge to improve Chinese SRL. The re-
sult showed that this kind of knowledge has a pos-
itive effect on the SRL performance. The quality
of syntactic knowledge turns out to be an impor-
tant factor in such a semi-supervised learning ap-
proach.

In the future, we plan to make use of other low
level knowledge such as word embeddings (Col-
lobert et al., 2011) or word clusters (Koo et al.,
2008), which can be complementary to our syntac-
tic level knowledge. Since recent SRL approaches
are mostly point-wise, i.e., features are extracted
from pairs of the predicate and an argument can-
didate. We plan to design a higher order system
to capture more global features. Also, reranking
is widely utilized in many SRL systems and we
plan to combine our surface case knowledge with a
reranker, in order to further improve Chinese SRL.
Finally, we plan to experiment on different lan-
guages and compare the effectiveness of syntactic
knowledge for different languages.

References
Yoshua Bengio, Réjean Ducharme, Pascal Vincent, and

Christian Jauvin. 2003. A neural probabilistic lan-
guage model. 3:1137–1155, February.

Anders Björkelund, Love Hafdell, and Pierre Nugues.
2009. Multilingual semantic role labeling. In Pro-
ceedings of the Thirteenth Conference on Computa-
tional Natural Language Learning (CoNLL 2009):
Shared Task, pages 43–48, Boulder, Colorado, June.
Association for Computational Linguistics.

Janara Christensen, Mausam, Stephen Soderland, and
Oren Etzioni. 2010. Semantic role labeling for
open information extraction. In Proceedings of the
NAACL HLT 2010 First International Workshop on
Formalisms and Methodology for Learning by Read-
ing, pages 52–60, Los Angeles, California, June. As-
sociation for Computational Linguistics.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. 12:2493–2537, August.

Koen Deschacht and Marie-Francine Moens. 2009.
Semi-supervised semantic role labeling using the la-
tent words language model. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, pages 21–29, Singapore, Au-
gust. Association for Computational Linguistics.

Charles J. Fillmore, Charles Wooters, and Collin F.
Baker. 2001. Building a large lexical databank
which provides deep semantics. In Benjamin Tsou
and Olivia Kwong, editors, Proceedings of the 15th
Pacific Asia Conference on Language, Information
and Computation, Hong Kong.

Hagen Fürstenau and Mirella Lapata. 2009. Semi-
supervised semantic role labeling. In Proceedings of
the 12th Conference of the European Chapter of the
ACL (EACL 2009), pages 220–228, Athens, Greece,
March. Association for Computational Linguistics.

Jan Hajič, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Antònia Martı́, Lluı́s
Màrquez, Adam Meyers, Joakim Nivre, Sebastian
Padó, Jan Štěpánek, Pavel Straňák, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The conll-
2009 shared task: Syntactic and semantic dependen-
cies in multiple languages. In Proceedings of the
Thirteenth Conference on Computational Natural
Language Learning (CoNLL 2009): Shared Task,
pages 1–18, Boulder, Colorado, June. Association
for Computational Linguistics.

Gongye Jin, Daisuke Kawahara, and Sadao Kurohashi.
2014. A framework for compiling high quality
knowledge resources from raw corpora. In Proceed-
ings of the Ninth International Conference on Lan-
guage Resources and Evaluation (LREC’14), pages
109–114.

Daisuke Kawahara and Sadao Kurohashi. 2001.
Japanese case frame construction by coupling the
verb and its closest case component. In Proceed-
ings of the Human Language Technology Confer-
ence, pages 204–210.

Daisuke Kawahara and Sadao Kurohashi. 2006. A
fully-lexicalized probabilistic model for Japanese
syntactic and case structure analysis. In Proceed-
ings of HLT-NAACL 2006, pages 176–183.

Daisuke Kawahara and Sadao Kurohashi. 2010. Ac-
quiring reliable predicate-argument structures from
raw corpora for case frame compilation. In Proceed-
ings of LREC 2010, pages 1389–1393.

Daisuke Kawahara, Daniel Peterson, Octavian
Popescu, and Martha Palmer. 2014. Inducing
example-based semantic frames from a massive
amount of verb uses. In Proceedings of the 14th
Conference of the European Chapter of the As-
sociation for Computational Linguistics, pages
58–67, Gothenburg, Sweden, April. Association for
Computational Linguistics.

Paul Kingsbury and Martha Palmer. 2002. From tree-
bank to propbank. In Language Resources and Eval-
uation.

Terry Koo, Xavier Carreras, and Michael Collins.
2008. Simple semi-supervised dependency parsing.
In Proceedings of ACL-08: HLT, pages 595–603,
Columbus, Ohio, June. Association for Computa-
tional Linguistics.

126



Ding Liu and Daniel Gildea. 2010. Semantic role fea-
tures for machine translation. In Proceedings of the
23rd International Conference on Computational
Linguistics (Coling 2010), pages 716–724, Beijing,
China, August. Coling 2010 Organizing Committee.

Roser Morante, Vincent Van Asch, and Antal van den
Bosch. 2009. Joint memory-based learning of syn-
tactic and semantic dependencies in multiple lan-
guages. In Proceedings of the Thirteenth Confer-
ence on Computational Natural Language Learning
(CoNLL 2009): Shared Task, pages 25–30, Boulder,
Colorado, June. Association for Computational Lin-
guistics.

Luiz Augusto Pizzato and Diego Mollá. 2008. In-
dexing on semantic roles for question answering.
In Coling 2008: Proceedings of the 2nd workshop
on Information Retrieval for Question Answering,
pages 74–81, Manchester, UK, August. Coling 2008
Organizing Committee.

Buzhou Tang, Lu Li, Xinxin Li, Xuan Wang, and Xi-
aolong Wang. 2009. A joint syntactic and semantic
dependency parsing system based on maximum en-
tropy models. In Proceedings of the Thirteenth Con-
ference on Computational Natural Language Learn-
ing (CoNLL 2009): Shared Task, pages 109–113,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.

Haitong Yang and Chengqing Zong. 2014. Multi-
predicate semantic role labeling. In Proceedings of
the 2014 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 363–
373, Doha, Qatar, October. Association for Compu-
tational Linguistics.

Beñat Zapirain, Eneko Agirre, and Lluı́s Màrquez.
2009. Generalizing over lexical features: Selec-
tional preferences for semantic role classification. In
Proceedings of the ACL-IJCNLP 2009 Conference
Short Papers, pages 73–76, Suntec, Singapore, Au-
gust. Association for Computational Linguistics.

Hai Zhao, Wenliang Chen, Chunyu Kity, and Guodong
Zhou. 2009. Multilingual dependency learning: A
huge feature engineering method to semantic depen-
dency parsing. In Proceedings of the Thirteenth
Conference on Computational Natural Language
Learning (CoNLL 2009): Shared Task, pages 55–60,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.

127


