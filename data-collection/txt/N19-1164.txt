



















































Microblog Hashtag Generation via Encoding Conversation Contexts


Proceedings of NAACL-HLT 2019, pages 1624–1633
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

1624

Microblog Hashtag Generation via Encoding Conversation Contexts

Yue Wang 1∗ Jing Li2† Irwin King1 Michael R. Lyu1 Shuming Shi2
1Department of Computer Science and Engineering

The Chinese University of Hong Kong, HKSAR, China
2Tencent AI Lab, Shenzhen, China

1{yuewang, king, lyu}@cse.cuhk.edu.hk
2{ameliajli,shumingshi}@tencent.com

Abstract

Automatic hashtag annotation plays an im-
portant role in content understanding for mi-
croblog posts. To date, progress made in this
field has been restricted to phrase selection
from limited candidates, or word-level hash-
tag discovery using topic models. Different
from previous work considering hashtags to be
inseparable, our work is the first effort to an-
notate hashtags with a novel sequence gener-
ation framework via viewing the hashtag as a
short sequence of words. Moreover, to address
the data sparsity issue in processing short mi-
croblog posts, we propose to jointly model the
target posts and the conversation contexts initi-
ated by them with bidirectional attention. Ex-
tensive experimental results on two large-scale
datasets, newly collected from English Twit-
ter and Chinese Weibo, show that our model
significantly outperforms state-of-the-art mod-
els based on classification.1 Further studies
demonstrate our ability to effectively generate
rare and even unseen hashtags, which is how-
ever not possible for most existing methods.

1 Introduction

Microblogs have become an essential outlet for in-
dividuals to voice opinions and exchange infor-
mation. Millions of user-generated messages are
produced every day, far outpacing the human be-
ing’s reading and understanding capacity. As a
result, the current decade has witnessed the in-
creasing demand for effectively discovering gist
information from large microblog texts. To iden-
tify the key content of a microblog post, hashtags,
user-generated labels prefixed with a “#” (such
as “#NAACL” and “#DeepLearning”), have been

*This work was mainly done when Yue Wang was an in-
tern at Tencent AI Lab.

†Jing Li is the corresponding author.
1To obtain our datasets, please contact Yue Wang and Jing

Li.

Target post for hashtag generation
This Azarenka woman needs a talking to from the
umpire her weird noises are totes inappropes pro-
fessionally. #AusOpen
Replying messages forming a conversation
[T1] How annoying is she. I just worked out what
she sounds like one of those turbo charged cars
when they change gear or speed.
[T2] On the topic of noises, I was at the Nadal-
Tomic game last night and I loved how quiet
Tomic was compared to Nadal.
[T3] He seems to have a shitload of talent and the
postmatch press conf. He showed a lot of maturity
and he seems nice.
[T4] Tomic has a fantastic tennis brain...

Table 1: A post and its conversation snippet about
“Australian Open” on Twitter. “#AusOpen” is the
human-annotated hashtag for the target post. Words in-
dicative of the hashtag are in blue and italic type.

widely used to reflect keyphrases (Zhang et al.,
2016, 2018) or topics (Yan et al., 2013; Hong et al.,
2012; Li et al., 2016). Hashtags can further ben-
efit downstream applications, such as microblog
search (Efron, 2010; Bansal et al., 2015), summa-
rization (Zhang et al., 2013; Chang et al., 2013),
sentiment analysis (Davidov et al., 2010; Wang
et al., 2011), and so forth. Despite the widespread
use of hashtags, there are a large number of mi-
croblog messages without any user-provided hash-
tags. For example, less than 15% tweets contain
at least one hashtag (Wang et al., 2011; Khabiri
et al., 2012). Consequently, for a multitude of
posts without human-annotated hashtags, there ex-
ists a pressing need for automating the hashtag an-
notation process for them.

Most previous work in this field focuses on ex-
tracting phrases from target posts (Zhang et al.,
2016, 2018) or selecting candidates from a pre-



1625

defined list (Gong and Zhang, 2016; Huang et al.,
2016; Zhang et al., 2017). However, hashtags usu-
ally appear in neither the target posts nor the given
candidate list. The reasons are two folds. For one
thing, microblogs allow large freedom for users to
write whatever hashtags they like. For another,
due to the wide range and rapid change of so-
cial media topics, a vast variety of hashtags can be
daily created, making it impossible to be covered
by a fixed candidate list. Prior research from an-
other line employs topic models to generate topic
words as hashtags (Gong et al., 2015; Zhang et al.,
2016). These methods, ascribed to the limitation
of most topic models, are nevertheless incapable
of producing phrase-level hashtags.

In this paper, we approach hashtag annotation
from a novel sequence generation framework. In
doing so, we enable phrase-level hashtags beyond
the target posts or the given candidates to be cre-
ated. Here, hashtags are first considered as a se-
quence of tokens (e.g., “#DeepLearning” as “deep
learning”). Then, built upon the success of se-
quence to sequence (seq2seq) model on language
generation (Sutskever et al., 2014), we present a
neural seq2seq model to generate hashtags in a
word-by-word manner. To the best of our knowl-
edge, we are the first to deal with hashtag annota-
tion in sequence generation architecture.

In processing microblog posts, one major chal-
lenge we might face is the limited features to be
encoded. It is mostly caused by the data spar-
sity exhibited in short and informal microblog
posts.2 To illustrate such challenge, Table 1 dis-
plays a sample Twitter post tagged with “#Au-
sOpen”, referring to Australian Open tennis tour-
nament. Only given the short post, it is difficult to
understand why it is tagged with “#AusOpen”, not
to mention that neither “aus” nor “open” appear in
the target post. In such a situation, how shall we
generate hashtags for a post with limited words?

To address the data sparsity challenge, we ex-
ploit conversations initiated by the target posts
to enrich their contexts. Our approach is bene-
fited from the nature that most messages in a con-
versation tend to focus on relevant topics. Con-
tent in conversations might hence provide con-
texts facilitating the understanding of the original
post (Chang et al., 2013; Li et al., 2015). The
effects of conversation contexts, useful on topic

2For instance, the eligible length of a post on Twitter or
Weibo is up to 140 characters.

modeling (Li et al., 2016, 2018) and keyphrase
extraction (Zhang et al., 2018), have never been
explored on microblog hashtag generation. To
show why conversation contexts are useful, we
display in Table 1 a conversation snippet formed
by some replies of the sample target post. As can
be seen, key content words in the conversation
(e.g., “Nadal”, “Tomic”, and “tennis”) are useful
to reflect the relevance of the target post to the
hashtag “#AusOpen”, because Nadal and Tomic
are both professional tennis players. Concretely,
our model employs a dual encoder (i.e., two en-
coders), one for the target post and the other for
the conversation context, to capture the represen-
tations from the two sources. Furthermore, to cap-
ture their joint effects, we employ the bidirectional
attention (bi-attention) (Seo et al., 2016) to ex-
plore the interactions between two encoders’ out-
puts. Afterward, an attentive decoder is applied to
generate the word sequence of the hashtag.

In experiments, we construct two large-scale
datasets, one from English platform Twitter and
the other from Chinese Weibo. Experimental re-
sults based on both information retrieval and text
summarization metrics show that our model gen-
erates hashtags closer to human-annotated ones
than all the comparison models. For example, our
model achieves 45.03% ROUGE-1 F1 on Weibo,
compared to 25.34% given by the state-of-the-
art classification-based method. Further compar-
isons with classification-based models show that
our model, in a sequence generation framework,
can better produce rare and even new hashtags.

To summarize, our contributions are three-fold:
•We are the first to approach microblog hashtag

annotation with sequence generation architecture.
• To alleviate data sparsity, we enrich context

for short target posts with their conversations and
employ a bi-attention mechanism for capturing
their interactions.
•Our proposed model outperforms state-of-the-

art models by large margins on two large-scale
datasets, constructed as part of this work.

2 Neural Hashtag Generation Model

In this section, we describe our framework shown
in Figure 1. There are two major modules: a dual
encoder to encode both target posts and their con-
versations with a bi-attention to explore their in-
teractions, and a decoder to generate hashtags.



1626

GRU GRUGRU

Merge Merge Merge

…

bi-att

𝛼𝑑

… …

Hashtag decoder

GRU GRU GRU…

The             Azarenka                  professionally

Post encoder

…

…

GRU GRU GRU…

Conversation encoder

…

…

Merge Merge Merge

…

𝒉𝑝

𝒓𝑐

𝒉𝑐

𝒓𝑝

𝒗𝑝 𝒗𝑐

How               annoy                            brain

<BOS>                          Aus Open

Aus Open                         <EOS>

Init

Figure 1: Our hashtag generation framework with a
dual encoder, including a post encoder and a conversa-
tion encoder, where a bi-attention (bi-att) distills their
salient features, followed by a merge layer to fuse them.
An attentive decoder generates the hashtag sequence.

Input and Output. Formally, given a target post
xp formulated as word sequence 〈xp1, x

p
2, ..., x

p
|xp|〉

and its conversation context xc formulated as word
sequence 〈xc1, xc2, ..., xc|xc|〉, where |x

p| and |xc|
denote the number of words in the input target post
and its conversation, respectively, our goal is to
output a hashtag y represented by a word sequence
〈y1, y2, ..., y|y|〉. For training instances tagged
with multiple gold-standard hashtags, we copy
the instances multiple times, each with one gold-
standard hashtag following Meng et al. (2017). All
the input target posts, their conversations, and the
hashtags share the same vocabulary V .

Dual Encoder. To capture representations from
both target posts and conversation contexts, we de-
sign a dual encoder, composed of a post encoder
and a conversation encoder, each taking the xp and
xc as input, respectively.

For the post encoder, we use a bidirectional
gated recurrent unit (Bi-GRU) (Cho et al., 2014)
to encode the target post xp, where its embed-
dings e(xp) are mapped into hidden states hp =
〈hp1,h

p
2, ...,h

p
|xp|〉. Specifically, h

p
i = [

−→
hpi ;
←−
hpi ] is

the concatenation of forward hidden state
−→
hpi and

backward hidden state
←−
hpi for the i-th token:

−→
hpi = GRU(e(x

p
i ),
−−→
hpi−1), (1)

←−
hpi = GRU(e(x

p
i ),
←−−
hpi+1). (2)

Likewise, the conversation encoder converts con-
versations into hidden states hc via another Bi-
GRU. The dimensions of both hp and hc are d.

Bi-attention. To further distill useful represen-
tations from our two encoders, we employ the
bi-attention to explore the interactions between
the target posts and their conversations. The
adoption of bi-attention is inspired by Seo et al.
(2016), where the bi-attention was applied to ex-
tract query-aware contexts for machine compre-
hension. Our intuition is that the content con-
cerning the key points in target posts might have
their relevant words frequently appearing in their
conversation contexts, and vice versa. In general,
such content can reflect what the target posts fo-
cus on and hence effectively indicate what hash-
tags should be generated. For instance, in Ta-
ble 1, names of tennis players (e.g., “Azarenka”,
“Nadal”, and “Tomic”) are mentioned many times
in both target posts and their conversations, which
reveals why the hashtag is “#AusOpen”.

To this end, we first put a post-aware attention
on the conversation encoder with coefficients:

αcij =
exp(fscore(h

p
i ,h

c
j))∑|xc|

j′=1 exp(fscore(h
p
i ,h

c
j′))

, (3)

where the alignment score function
fscore(h

p
i ,h

c
j) = h

p
iWbi−atth

c
j captures the

similarity of the i-th word in the target post
and the j-th word in its conversation. Here
Wbi−att ∈ Rd×d is a weight matrix to be learned.
Then, we compute a context vector rc conveying
post-aware conversation representations, where
the i-th value is defined as:

rci =

|xc|∑
j=1

αcijh
c
j . (4)

Analogously, a conversation-aware attention on
post encoder is used to capture the conversation-
aware post representations as rp.

Merge Layer. Next, to further fuse representa-
tions distilled by the bi-attention on each encoder,
we design a merge layer, a multilayer perceptron
(MLP) activated by hyperbolic function:

vp = tanh(Wp[h
p; rc] + bp), (5)

vc = tanh(Wc[h
c; rp] + bc), (6)

where Wp,Wc ∈ Rd×2d and bp,bc ∈ Rd are
trainable parameters.

Note that either vp or vc conveys the informa-
tion from both posts and conversations, but with a



1627

different emphasis. Specifically, vp mainly retains
the contexts of posts with the auxiliary informa-
tion from conversations, while vc does the oppo-
site. Finally, vectors vp and vc are concatenated
and fed into the decoder for hashtag generation.

Decoder. Given the representations v = [vp;vc]
produced by our dual encoder with bi-attention,
we apply an attention-based GRU decoder to gen-
erate a word sequence y as the hashtag. The prob-
ability to generate the hashtag conditioned on a
target post and its conversation is defined as:

Pr(y|xp,xc) =
|y|∏
t=1

Pr(yt|y<t,xp,xc), (7)

where y<t refers to (y1, y2, ..., yt−1).
Concretely, when generating the t-th word in

hashtag, the decoder emits a hidden state vector
st ∈ Rd and puts a global attention over v. The
attention aims to exploit indicative representations
from the encoder outputs v and summarizes them
into a context vector ct defined as:

ct =

|xp|+|xc|∑
i=1

αdtivi, (8)

αdti =
exp(gscore(st,vi))∑|xp|+|xc|

i′=1 exp(gscore(st,vi′)
, (9)

where gscore(st,vi) = stWattvi is another align-
ment function (Watt ∈ Rd×d) to measure the sim-
ilarity between st and vi.

Finally, we map the current hidden state st of
the decoder together with the context vector ct to
a word distribution over the vocabulary V via:

Pr(yt|y<t,xp,xc) = softmax(Wv[st; ct]+bv),
(10)

which reflects how likely a word to be the t-th
word in the generated hashtag sequence. Here
Wv ∈ RV×2d and bv ∈ RV are trainable weights.

Learning and Inferring Hashtags. During the
training stage, we apply stochastic gradient de-
scent to minimize the loss function of our entire
framework, which is defined as:

L(Θ) = −
N∑

n=1

log(Pr(yn|xpn,xcn; Θ)). (11)

Here N is the number of training instances and Θ
denotes the set of all the learnable parameters.

Datasets # of Avg len Avg len Avg len # of tags
posts of posts of convs of tags per post

Twitter 44,793 13.27 29.94 1.69 1.14
Weibo 40,171 32.64 70.61 2.70 1.11

Table 2: Statistics of our datasets. Avg len of posts,
convs, tags refer to the average number of words in
posts, conversations, and hashtags, respectively.

Datasets |Tagset| P C P ∪ C
Twitter 4,188 2.72% 5.58% 7.69%
Weibo 5,027 8.29% 6.21% 12.52%

Table 3: Statistics of the hashtags. |Tagset|: the number
of distinct hashtags. P , C, and P ∪C: the percentage of
hashtags appearing in their corresponding posts, con-
versations, and the union set of them, respectively.

In hashtag inference, based on the produced
word distribution at each time step, word selection
is conducted using beam search. In doing so, we
generate a ranking list of output hashtags, where
the top K hashtags serve as our final output.

3 Experiment Setup

Here we describe how we set up our experiments.

Datasets and Statistic Analysis. Two large-
scale experiment datasets are newly collected from
popular microblog platforms: an English Twitter
dataset and a Chinese Weibo dataset. The Twit-
ter dataset was built based on the TREC 2011 mi-
croblog track.3 To recover the conversations, we
used Tweet Search API to fetch “in-reply-to” re-
lations in a recursive way. The Weibo dataset
was collected from January to August 2014 us-
ing Weibo Search API via searching messages
with the trending queries4 as keywords. For gold-
standard hashtags, we take the user-annotated
hashtags, appearing before or after a post, as the
reference.5 The statistics of our datasets are shown
in Table 2. We randomly split both datasets into
three subsets, where 80%, 10%, and 10% of the
data corresponds to training, development, and
test sets, respectively.

To further investigate how challenging our
problem is, we show some statistics of the hash-
tags in Table 3 and the distributions of hashtag
frequency in Figure 2. In Table 3, we observe

3https://trec.nist.gov/data/tweets/
4 http://open.weibo.com/wiki/Trends/
5Hashtags in the middle of a post are not considered here

as they generally act as semantic elements (Zhang et al.,
2016, 2018).

https://trec.nist.gov/data/tweets/
http://open.weibo.com/wiki/Trends/


1628

5 10 15 20 25 30 35 40 45 50
Occurrence count

0.00

0.05

0.10

0.15

0.20
Pr

op
or

tio
n

Twitter
Weibo

Figure 2: Distribution of hashtag frequency. The hor-
izontal axis refers to the occurrence count of hashtags
(shown with maximum 50 and bin 5) and the vertical
axis denotes the data proportion.

the large size of hashtags in both datasets. More-
over, Figure 2 indicates that most hashtags only
appear a few times. Given such a large and im-
balanced hashtag space, hashtag selection from a
candidate list, as many existing methods do, might
not perform well. Table 3 also shows that only
a small proportion of hashtags appearing in their
posts, conversations, and either of them, making
it inappropriate to directly extract words from the
two sources to form hashtags.

Preprocessing. For tokenization and word seg-
mentation, we employed the tweet preprocessing
toolkit released by Baziotis et al. (2017) for Twit-
ter, and the Jieba toolkit6 for Weibo. Then, for
both Twitter and Weibo, we further take the fol-
lowing preprocessing steps: First, single-character
hashtags were filtered out for not being mean-
ingful. Second, generic tags, i.e., links, men-
tions (@username), and numbers, were replaced
with “URL” “MENTION”, and “DIGIT”, respec-
tively. Third, inappropriate replies (e.g., retweet-
only messages) were removed, and the remainder
were chronologically ordered to form a sequence
as conversation contexts. Last, a vocabulary was
maintained with the 30K and 50K most frequent
words, for Twitter and Weibo, respectively.

Comparisons. For experiment comparisons, we
first consider a weak baseline RANDOM that ran-
domly ranks hashtags seen from training data.
Two unsupervised baselines are also considered,
where words are ranked by latent topics induced
with the latent Dirichlet allocation topic model
(henceforth LDA), and by their TF-IDF scores
(henceforth TF-IDF). Here for TF-IDF scores, we
consider the N -gram TF-IDF (N ≤ 5). Besides,
we compare with supervised models below:
• EXTRACTOR: Following Zhang et al. (2018),

we extract phrases from target posts as hashtags

6https://pypi.python.org/pypi/jieba/

via sequence tagging and encode conversations
with memory networks (Sukhbaatar et al., 2015).
• CLASSIFIER: We compare with the state-of-

the-art model based on classification (Gong and
Zhang, 2016), where hashtags are selected from
candidates seen in training data. Here two versions
of their classifier are considered, one only taking a
target post as input (henceforth CLASSIFIER (post
only)) and the other taking the concatenation of a
target post and its conversation as input (hence-
forth CLASSIFIER (post+conv)).
• GENERATOR: A seq2seq generator (hence-

forth SEQ2SEQ) (Sutskever et al., 2014) is applied
to generate hashtags given a target post. We also
consider its variant augmented with copy mech-
anism (Gu et al., 2016) (henceforth SEQ2SEQ-
COPY), which has proven effective in keyphrase
generation (Meng et al., 2017) and also takes the
post as input. The proposed seq2seq with the bi-
attention to encode both the post and its conversa-
tion is denoted as OUR MODEL for simplicity.

Model Settings. We conduct model tunings on
the development set based on grid search, where
the hyper-parameters that give the lowest objec-
tive loss are selected. For the sequence genera-
tion models, the implementations are based on the
OpenNMT framework (Klein et al., 2017). The
word embeddings, with dimension set to 200, are
randomly initialized. For encoders, we employ
two layers of Bi-GRU cells, and for decoders, one
layer of GRU cell is used. The hidden size of all
GRUs is set to 300. In learning, we use the Adam
optimizer (Kingma and Ba, 2014) with the learn-
ing rate initialized to 0.001. We adopt the early-
stop strategy: the learning rate decreases by a de-
cay rate of 0.5 till either it is below 1e−6 or the
validation loss stops decreasing. The norm of gra-
dients is rescaled to 1 if the L2-norm > 1 is ob-
served. The dropout rate is 0.1 and the batch size
is 64. In inference, we set the beam-size to 20 and
the maximum sequence length of a hashtag to 10.

For CLASSIFIER and EXTRACTOR, lacking
publicly available codes, we reimplement the
models using Keras.7 Their results are reproduced
in their original experiment settings. For LDA, we
employ an open source toolkit lda.8

Evaluation Metrics. Popular information re-
trival evaluation metrics F1 scores at K (F1@K)

7https://keras.io/
8https://pypi.org/project/lda/

https://pypi.python.org/pypi/jieba/
https://keras.io/
https://pypi.org/project/lda/


1629

Model Twitter Weibo
F1@1 F1@5 MAP RG-1 RG-4 F1@1 F1@5 MAP RG-1 RG-4

Baselines
RANDOM 0.37 0.63 0.89 0.56 0.16 0.43 0.67 0.97 2.14 1.13
LDA 0.13 0.25 0.35 0.60 - 0.10 0.86 0.94 3.89 -
TF-IDF 0.02 0.02 0.03 0.54 0.14 0.85 0.73 1.30 8.04 4.29
EXTRACTOR 0.44 - - 1.14 0.14 2.53 - - 7.64 5.20
State of the arts
CLASSIFIER (post only) 9.44 6.36 12.71 10.75 4.00 16.92 10.48 22.29 25.34 21.95
CLASSIFIER (post+conv) 8.54 6.28 12.10 10.00 2.47 17.25 11.03 23.11 25.16 22.09
GENERATORS
SEQ2SEQ 10.44 6.73 14.00 10.52 4.08 26.00 14.43 32.74 37.37 32.67
SEQ2SEQ-COPY 10.63 6.87 14.21 12.05 4.36 25.29 14.10 31.63 37.58 32.69
OUR MODEL 12.29* 8.29* 15.94* 13.73* 4.45 31.96* 17.39* 38.79* 45.03* 39.73*

Table 4: Comparison results on Twitter and Weibo datasets (in %). RG-1 and RG-4 refer to ROUGE-1 and
ROUGE-SU4 respectively. The best results in each column are in bold. The “*” after numbers indicates signifi-
cantly better results than all the other models (p < 0.05, paired t-test). Higher values indicate better performance.

and mean average precision (MAP) scores (Man-
ning et al., 2008) are reported. Here, different K
values are tested on F1@K and result in a similar
trend, so only F1@1 and F1@5 are reported. MAP
scores are also computed given the top 5 outputs.
Besides, as we consider a hashtag as a sequence of
words, ROUGE metrics for summarization evalu-
ation (Lin, 2004) are also adopted. Here, we use
ROUGE F1 for the top-ranked hashtag prediction
computed by an open source toolkit pythonrouge,9

with Porter stemmer used for English tweets. For
Weibo posts, scores calculated at the Chinese char-
acter level following Li et al. (2018). We report the
average scores for multiple gold-standard hashtags
on ROUGE evaluation.

4 Experimental Results

In this section, we first report the main compari-
son results in Section 4.1, followed by an in-depth
comparative study between classification and se-
quence generation models in Section 4.2. Further
discussions are then presented to analyze our su-
periority and errors in Section 4.3.

4.1 Main Comparison Results
Table 4 reports the main comparison results. For
CLASSIFIER, their outputs are ranked according to
the logits after a softmax layer. For EXTRAC-
TOR, it is unable to produce ranked hashtags and
thus no results are reported for F1@5 and MAP.
For LDA, as it cannot generate bigram hashtags,
no results are presented for ROUGE-SU4. In gen-
eral, we have the following observations:

9https://github.com/tagucci/
pythonrouge

• Hashtag annotation is more challenging for
Twitter than Weibo. Generally, all models per-
form worse on Twitter measured by different met-
rics. The intrinsic reason is the essential lan-
guage difference between English and Chinese mi-
croblogs. English allows higher freedom in writ-
ing, resulting in more variety in Twitter hash-
tags (e.g., abbreviations are prominent like “aus”
in “#AusOpen”). For statistical reasons, Twitter
hashtags are more likely to be absent in either
posts or conversations (Table 3), and have a more
severe imbalanced distribution (Figure 2).
• Topic models and extractive models are inef-

fective for hashtag annotation. The poor perfor-
mance of all baseline models indicates that hash-
tag annotation is a challenging problem. LDA
sometimes performs even worse than RANDOM
due to its inability to produce phrase-level hash-
tags. For extractive models, both TF-IDF and EX-
TRACTOR fail to achieve good results. It is be-
cause most hashtags are absent in target posts,
as we see in Table 3 that only 2.72% hashtags
on Twitter and 8.29% on Weibo appear in target
posts. This confirms that extractive models, re-
lying on word selection from target posts, cannot
well fit the hashtag annotation scenario. For the
same reason, copy mechanism fails to bring no-
ticeable improvements for the seq2seq generator
on both datasets.
• Sequence generation models outperform

other counterparts. When comparing GENERA-
TORS with other models, we find the former uni-
formly achieve better results, showing the superi-
ority to produce hashtags with sequence genera-
tion framework. Classification models, though as

https://github.com/tagucci/pythonrouge
https://github.com/tagucci/pythonrouge


1630

the state of the art, expose their inferiority as they
select labels from the large and imbalanced hash-
tag space (reflected in Table 3 and Figure 2).
• Conversations are useful for hashtag gen-

eration. Among the sequence generation mod-
els, OUR MODEL achieves the best performance
across all the metrics. The observation indicates
the usefulness of bi-attention in exploiting the
joint effects of target posts and their conversations,
which further helps in identifying indicative fea-
tures from both sources for hashtag generation.
However, interestingly, incorporating conversa-
tions fails to boost the classification performance.
The reason why OUR MODEL better exploits con-
versations than CLASSIFIER (post+conv) might be
that we can attend the indicative features when de-
coding each word in the hashtag, which is however
not possible for classification models (considering
hashtags to be inseparable).

4.2 Classification vs. Generation

From Table 4, we observe that the classifiers out-
perform topic models and extractive models by
a large margin but exhibit generally worse re-
sults than sequence generation models. Here, we
present a thorough study to compare hashtag clas-
sification and generation. Four models are se-
lected for comparison: two classifiers, CLASSI-
FIER (post only) and CLASSIFIER (post+conv),
and two sequence generation models, SEQ2SEQ
and OUR MODEL. Below, we explore how they
perform to predict rare and new hashtags.

Rare Hashtags. According to the hashtag dis-
tributions in Figure 2, we can see a large propor-
tion of hashtags appearing only a few times in
the data. To study how models perform to pre-
dict such hashtags, in Figure 3, we display their
F1@1 scores in inferring hashtags with varying
frequency. The lower F1 score on less frequent
hashtags indicates the difficulty to yield rare hash-
tags. The reason probably comes from the overfit-
ting issue caused by limited data to learn from.

We also observe that sequence generation mod-
els achieve consistently better F1@1 scores on
hashtags with varying sparsity degree, while clas-
sification models suffer from the label sparsity is-
sue and obtain worse results. The better perfor-
mance of the former might result from the word-
by-word generation manner in hashtag generation,
which enables the internal structure of hashtags
(how words form a hashtag) to be exploited.

<10 10~50 50~100 >100
0

5

10

15

20

25

30

F1
 sc

or
e 

(%
)

<10 10~50 50~100 >100
0

10

20

30

40

50

CLASSIFIER (only post) CLASSIFIER (post+conv) SEQ2SEQ Our model

Figure 3: F1@1 on Twitter (the left subfigure) and
Weibo (the right subfigure) in inferring hashtags with
varying frequency. In each subfigure, from left to right
shows the results of CLASSIFIER (post only), CLASSI-
FIER (post+conv), SEQ2SEQ, and OUR MODEL. Gen-
eration models consistently perform better.

New Hashtags. To further explore the extreme
situation where hashtags are absent in the training
set, we experiment to see how models perform in
handling new hashtags. To this end, we addition-
ally collect instances tagged with hashtags absent
in training data and construct an external test set,
with the same size as our original test set. Consid-
ering that classifiers will never predict unseen la-
bels, to ensure comparable performance, we only
adopt summarization metrics here for evaluation
and report ROUGE-1 F1 scores in Table 5.

As can be seen, creating unseen hashtags is a
challenging task, where unsurprisingly, all mod-
els perform poorly on this task. Nevertheless, se-
quence generation models perform much better on
both datasets, e.g., at least 6.5x improvements over
classification models observed on Weibo dataset.
For Twitter dataset, the improvements are not that
large, which confirms again that hashtag annota-
tion on Twitter is more difficult due to the nois-
ier data characteristics. In particular, compared
to SEQ2SEQ, OUR MODEL achieves an additional
performance gain in producing new hashtags by
leveraging conversations with the bi-attention.

Model Twitter Weibo
CLASSIFIER (post only) 1.15 1.65
CLASSIFIER (post+conv) 1.13 1.52
SEQ2SEQ 1.33 10.84
OUR MODEL 1.48 12.55

Table 5: ROUGE-1 F1 scores (%) in producing unseen
hashtags. Best results are in bold.

4.3 Further Discussions on Our Model
To further analyze our model, we conduct a quan-
titative ablation study, a qualitative case study, and
an error analysis. We then discuss them in turn.



1631

Ablation Study. We report the ablation study
results in Table 6 to examine the relative con-
tributions of the target posts and the conversa-
tion contexts. To this end, our model is com-
pared with its five variants below: SEQ2SEQ
(post only), SEQ2SEQ (conv only), and SEQ2SEQ
(post+conv), using standard seq2seq to generate
hashtags from their target posts, conversation con-
texts, and their concatenation, respectively; OUR
MODEL (post-att only) and OUR MODEL (conv-att
only), whose decoder only takes vp and vc defined
in Eq. (5) and Eq. (6), respectively. The results
show that solely encoding target posts is more
effective than modeling the conversations alone,
but exploring their joint effects can further boost
the performance, especially combined with a bi-
attention mechanism over them.

Model Twitter Weibo
SEQ2SEQ (post only) 10.44 26.00
SEQ2SEQ (conv only) 6.27 18.57
SEQ2SEQ (post + conv) 11.24 29.85
OUR MODEL (post-att only) 11.18 28.67
OUR MODEL (conv-att only) 10.61 28.06
OUR MODEL (full) 12.29 31.96

Table 6: F1@1 scores (%) for our variants.

Case Study. We further present a case study on
the target post shown in Table 1, where the top five
outputs of some comparison models are displayed
in Table 7. As can be seen, only our model suc-
cessfully generates “aus open”, the gold standard.
Particularly, it not only ranks the correct answer as
the top prediction, but also outputs other seman-
tically similar hashtags, e.g., sport-related terms
like “bbc football”, “arsenal”, and “murray”. On
the contrary, CLASSIFIER and SEQ2SEQ tend to
yield frequent hashtags, such as “just saying” and
“jan 25”. Baseline models also perform poorly:
LDA produces some common single word, and
TF-IDF extracts phrases in the target post, where
the gold-standard hashtag is however absent.

Model Top five outputs
LDA found; stated; excited; card; apparently
TF-IDF inappropes; umpire; woman need;

azarenka woman; the umpire
CLASSIFIER fail; facebook; just saying; quote; pro

choice
SEQ2SEQ fail; jan 25; yr; eastenders; facebook
OUR
MODEL

aus open ; bbc football ; bbc aus ; ar-
senal ; murray

Table 7: Model outputs for the target post in Table 1.
“aus open” matches the gold-standard hashtag.

To analyze why our model obtains superior re-
sults in this case, we display the heatmap in Fig-
ure 4 to visualize our bi-attention weight matrix
Wbi−att. As we can see, bi-attention can identify
the indicative word “Azarenka” in the target post,
via highlighting its other pertinent words in con-
versations, e.g., “Nadal” and “tennis”. In doing
so, salient words in both the post and its conversa-
tions can be unveiled, facilitating the correct hash-
tag “aus open” to be generated.

Figure 4: Visualization of bi-attention given the input
case in Table 1. The horizontal axis denotes a snippet
of a truncated conversation. The vertical axis shows the
target post. Salient words are highlighted.

Error Analysis. Taking a closer look at our out-
puts, we find that one type of major errors comes
from the unmatched outputs with gold standards,
even as a close guess. For example, our model pre-
dicts “super bowl” for a post tagged with “#steel-
ers”, a team in super bowl. In future work, the
semantic similarity should be considered in hash-
tag evaluation. Another primary type of error is
caused by the non-topic hashtags, such as “#fb”
(indicating the messages forwarded from Face-
book). Such non-topic hashtags cannot reflect any
content information from target posts and should
be distinguished from topic hashtags in the future.

5 Related Work

Our work mainly builds on two streams of pre-
vious work — microblog hashtag annotation and
neural language generation.

We are in the line of microblog hashtag annota-
tion. Some prior work extracts phrases from target
posts with sequence tagging models (Zhang et al.,
2016, 2018). Another popular approach is to ap-
ply classifiers and select hashtags from a candidate
list (Heymann et al., 2008; Weston et al., 2014;
Sedhai and Sun, 2014; Gong and Zhang, 2016;



1632

Huang et al., 2016; Zhang et al., 2017). Unlike
them, we generate hashtags with a language gen-
eration framework, where hashtags in neither the
target posts nor the pre-defined candidate list can
be created. Topic models are also widely applied
to induce topic words as hashtags (Krestel et al.,
2009; Ding et al., 2012; Godin et al., 2013; Gong
et al., 2015; Zhang et al., 2016). However, these
models are usually unable to produce phrase-level
hashtags, which can be achieved by ours via gen-
erating hashtag word sequences with a decoder.

Our work is also closely related to neural
language generation, where the encoder-decoder
framework (Sutskever et al., 2014) acts as a
springboard for many sequence generation mod-
els. In particular, we are inspired by the keyphrase
generation studies for scientific articles (Meng
et al., 2017; Ye and Wang, 2018; Chen et al., 2018,
2019), incorporating word extraction and genera-
tion using a seq2seq model with copy mechanism.
However, our hashtag generation task is inherently
different from theirs. As we can see from Table 4,
it is suboptimal to directly apply keyphrase gener-
ation models on our data. The reason mostly lies
in the informal language style of microblog users
in writing both target posts and their hashtags. To
adapt our model on microblog data, we explore the
effects of conversation contexts on hashtag gener-
ation, which has never been studied in any prior
work before.

6 Conclusion

We have presented a novel framework of hash-
tag generation via jointly modeling of target posts
and conversation contexts. To this end, we have
proposed a neural seq2seq model with bi-attention
over a dual encoder for capturing indicative repre-
sentations from the two sources. Experimental re-
sults on two newly collected datasets have demon-
strated that our proposed model significantly out-
performs existing state-of-the-art models. Further
studies have shown that our model can effectively
generate rare and even unseen hashtags.

Acknowledgements

This work is supported by the Research Grants
Council of the Hong Kong Special Administrative
Region, China (No. CUHK 14208815 and No.
CUHK 14210717 of the General Research Fund).
We thank NAACL reviewers for their insightful
suggestions on various aspects of this work.

References
Piyush Bansal, Somay Jain, and Vasudeva Varma.

2015. Towards semantic retrieval of hashtags in mi-
croblogs. In World Wide Web Conference.

Christos Baziotis, Nikos Pelekis, and Christos Doulk-
eridis. 2017. Datastories at semeval-2017 task 4:
Deep LSTM with attention for message-level and
topic-based sentiment analysis. In North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies.

Yi Chang, Xuanhui Wang, Qiaozhu Mei, and Yan Liu.
2013. Towards twitter context summarization with
user influence models. In International Conference
on Web Search and Data Mining.

Jun Chen, Xiaoming Zhang, Yu Wu, Zhao Yan, and
Zhoujun Li. 2018. Keyphrase generation with corre-
lation constraints. In Empirical Methods in Natural
Language Processing.

Wang Chen, Yifan Gao, Jiani Zhang, Irwin King, and
Michael R. Lyu. 2019. Title-guided encoding for
keyphrase generation. In The Thirty-Fourth AAAI
Conference on Artificial Intelligence.

Kyunghyun Cho, Bart van Merrienboer, Çaglar
Gülçehre, Dzmitry Bahdanau, Fethi Bougares, Hol-
ger Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using RNN encoder-decoder
for statistical machine translation. In Empirical
Methods in Natural Language Processing.

Dmitry Davidov, Oren Tsur, and Ari Rappoport. 2010.
Enhanced sentiment learning using twitter hashtags
and smileys. In International Conference on Com-
putational Linguistics.

Zhuoye Ding, Qi Zhang, and Xuanjing Huang. 2012.
Automatic hashtag recommendation for microblogs
using topic-specific translation model. In Interna-
tional Conference on Computational Linguistics.

Miles Efron. 2010. Hashtag retrieval in a microblog-
ging environment. In Conference on Research and
Development in Information Retrieval.

Fréderic Godin, Viktor Slavkovikj, Wesley De Neve,
Benjamin Schrauwen, and Rik Van de Walle. 2013.
Using topic models for twitter hashtag recommen-
dation. In World Wide Web Conference.

Yeyun Gong, Qi Zhang, and Xuanjing Huang. 2015.
Hashtag recommendation using dirichlet process
mixture models incorporating types of hashtags. In
Empirical Methods in Natural Language Process-
ing.

Yuyun Gong and Qi Zhang. 2016. Hashtag recom-
mendation using attention-based convolutional neu-
ral network. In International Joint Conference on
Artificial Intelligence.



1633

Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O. K.
Li. 2016. Incorporating copying mechanism in
sequence-to-sequence learning. In Association for
Computational Linguistics.

Paul Heymann, Daniel Ramage, and Hector Garcia-
Molina. 2008. Social tag prediction. In Confer-
ence on Research and Development in Information
Retrieval.

Liangjie Hong, Amr Ahmed, Siva Gurumurthy,
Alexander J. Smola, and Kostas Tsioutsiouliklis.
2012. Discovering geographical topics in the twit-
ter stream. In World Wide Web Conference.

Haoran Huang, Qi Zhang, Yeyun Gong, and Xuanjing
Huang. 2016. Hashtag recommendation using end-
to-end memory networks with hierarchical attention.
In International Conference on Computational Lin-
guistics.

Elham Khabiri, James Caverlee, and Krishna Yeswanth
Kamath. 2012. Predicting semantic annotations on
the real-time web. In ACM Conference on Hypertext
and Social Media.

Diederik P. Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. In International
Conference on Learning Representations.

Guillaume Klein, Yoon Kim, Yuntian Deng, Jean
Senellart, and Alexander M. Rush. 2017. Opennmt:
Open-source toolkit for neural machine translation.
In Association for Computational Linguistics.

Ralf Krestel, Peter Fankhauser, and Wolfgang Nejdl.
2009. Latent dirichlet allocation for tag recommen-
dation. In ACM Conference on Recommender Sys-
tems.

Jing Li, Wei Gao, Zhongyu Wei, Baolin Peng, and
Kam-Fai Wong. 2015. Using content-level struc-
tures for summarizing microblog repost trees. In
Empirical Methods in Natural Language Process-
ing.

Jing Li, Ming Liao, Wei Gao, Yulan He, and Kam-
Fai Wong. 2016. Topic extraction from microblog
posts using conversation structures. In Association
for Computational Linguistics.

Jing Li, Yan Song, Zhongyu Wei, and Kam-Fai Wong.
2018. A joint model of conversational discourse
and latent topics on microblogs. Computational Lin-
guistics.

Chin-Yew Lin. 2004. Rouge: A package for automatic
evaluation of summaries. In Text Summarization
Branches Out: Proceedings of the Association for
Computational Linguistics-04 Workshop.

Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Schütze. 2008. Introduction to information
retrieval. Cambridge University Press.

Rui Meng, Sanqiang Zhao, Shuguang Han, Daqing
He, Peter Brusilovsky, and Yu Chi. 2017. Deep
keyphrase generation. In Association for Computa-
tional Linguistics.

Surendra Sedhai and Aixin Sun. 2014. Hashtag rec-
ommendation for hyperlinked tweets. In Confer-
ence on Research and Development in Information
Retrieval.

Min Joon Seo, Aniruddha Kembhavi, Ali Farhadi, and
Hannaneh Hajishirzi. 2016. Bidirectional attention
flow for machine comprehension. In International
Conference on Learning Representations.

Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston,
and Rob Fergus. 2015. End-to-end memory net-
works. In Neural Information Processing Systems.

Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014.
Sequence to sequence learning with neural net-
works. In Neural Information Processing Systems.

Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming Zhou,
and Ming Zhang. 2011. Topic sentiment analysis in
twitter: a graph-based hashtag sentiment classifica-
tion approach. In Conference on Information and
Knowledge Management.

Jason Weston, Sumit Chopra, and Keith Adams. 2014.
#tagspace: Semantic embeddings from hashtags. In
Association for Computational Linguistics.

Xiaohui Yan, Jiafeng Guo, Yanyan Lan, and Xueqi
Cheng. 2013. A biterm topic model for short texts.
In World Wide Web Conference.

Hai Ye and Lu Wang. 2018. Semi-supervised learning
for neural keyphrase generation. In Empirical Meth-
ods in Natural Language Processing.

Qi Zhang, Jiawen Wang, Haoran Huang, Xuanjing
Huang, and Yeyun Gong. 2017. Hashtag recommen-
dation for multimodal microblog using co-attention
network. In International Joint Conference on Arti-
ficial Intelligence.

Qi Zhang, Yang Wang, Yeyun Gong, and Xuanjing
Huang. 2016. Keyphrase extraction using deep re-
current neural networks on twitter. In Empirical
Methods in Natural Language Processing.

Renxian Zhang, Wenjie Li, Dehong Gao, and Ouyang
You. 2013. Automatic twitter topic summarization
with speech acts. IEEE Trans. Audio, Speech & Lan-
guage Processing.

Yingyi Zhang, Jing Li, Yan Song, and Chengzhi
Zhang. 2018. Encoding conversation context for
neural keyphrase extraction from microblog posts.
In North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies.


