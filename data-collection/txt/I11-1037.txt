















































Enhancing the HL-SOT Approach to Sentiment Analysis via a Localized Feature Selection Framework


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 327–335,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

Enhancing the HL-SOT Approach to Sentiment Analysis via a Localized
Feature Selection Framework

Wei Wei
Department of Computer and

Information Science
Norwegian University of Science

and Technology
wwei@idi.ntnu.no

Jon Atle Gulla
Department of Computer and

Information Science
Norwegian University of Science

and Technology
jag@idi.ntnu.no

Abstract

In this paper, we propose a Localized Fea-
ture Selection (LFS) framework tailored to
the HL-SOT approach to sentiment analy-
sis. Within the proposed LFS framework,
each node classifier of the HL-SOT ap-
proach is able to perform classification on
target texts in a locally customized index
term space. Extensive empirical analysis
against a human-labeled data set demon-
strates that with the proposed LFS frame-
work the classification performance of the
HL-SOT approach is enhanced with com-
putational efficiency being greatly gained.
To find the best feature selection algorith-
m that caters to the proposed LFS frame-
work, five classic feature selection algo-
rithms are comparatively studied, which
indicates that the TS, DF, and MI al-
gorithms achieve generally better perfor-
mances than the CHI and IG algorithms.
Among the five studied algorithms, the T-
S algorithm is best to be employed by the
proposed LFS framework.

1 Introduction

With tens and thousands of review texts being gen-
erated online, it becomes increasingly challeng-
ing for an individual to exhaustively collect and
study the online reviews. Therefore, research on
automatic sentiment analysis on review texts has
emerged as a popular topic at the crossroads of in-
formation retrieval and computational linguistics.

Sentiment analysis on product reviews aims at
extracting sentiment information from texts. It in-
cludes two tasks, i.e., labeling a target text1 with

1Each product review to be analyzed is called target text

1) the product’s attributes it mentions (attributes
identification task), and 2) the corresponding sen-
timents mentioned therein (sentiment annotation
task). Recently, Wei and Gulla proposed the HL-
SOT approach (Wei and Gulla, 2010), i.e., Hier-
archical Learning (HL) with Sentiment Ontology
Tree (SOT), that is able to achieve the two tasks
in one hierarchical classification process. In the
HL-SOT approach, each target text is encoded by
a vector in a globally unified d-dimensional index
term space and is respectively labeled by different
nodes2 of SOT in a hierarchical manner. Although
the HL-SOT approach is reported with promising
classification performance on tasks of sentimen-
t analysis, its computational efficiency, especially
as d increases, becomes very low. Furthermore,
as d increases it will have more chance to index
noisy term into the globally unified index term s-
pace so that the classification performance of the
HL-SOT approach might be depressed. Hence,
we argue that if a locally customized index ter-
m space could be constructed for each node re-
spectively, both the computational efficiency and
the classification performance of the HL-SOT ap-
proach would be improved.

In this paper, we propose a Localized Feature
Selection (LFS) framework tailored to the HL-
SOT approach. The rationale of the proposed LFS
framework draws on the following two observa-
tions. Firstly, a feature term that is relevant to a
node is usually irrelevant to nodes which stay at
another branch of SOT. For example, “ergonomic-
s” might be a feature term for the node “design
and usability” (see Fig. 1) but it is irrelevant to
the node “image quality”. Secondly, a feature ter-

in the following of this paper.
2If specified otherwise in the following of this paper the

term “node” refers to the classifier of the node.

327



camera +

camera

design and usability image quality lens camera -

design and usability + weight interface design and usability - image quality + noise resolution image quality - lens + lens -

weight + weight - interface + menu button interface -

menu + menu - button + button -

noise + noise - resolution + resolution -

Figure 1: an example of part of a SOT for digital camera

m might become insignificant for child nodes of
i even if the feature term is significant to i. For
example, for a sentence commenting on a digital
camera like “40D handles noise very well”, terms
such as “noise” and “well” are significant feature
terms for the node “noise”. However, the term
“noise” becomes insignificant for its child nodes
“noise +” and “noise -”, since the hierarchical clas-
sification characteristic of the HL-SOT approach
that a node only processes target texts which are
labeled as true by its parent node ensures that each
target text handled by the nodes “noise +” and
“noise -” is already classified as related to “noise”.

In the proposed LFS framework, the concep-
t of “local hierarchy” is defined and introduced
as delimitation of local scope of nodes. The lo-
calized feature selection process is conducted for
each node within its local scope to generate the
customized index term space for the node. The
proposed LFS framework is empirically analyzed
on a human-labeled data set. The experimental
results show that with the proposed LFS frame-
work the classification performance of the HL-
SOT approach is enhanced and the computation-
al efficiency is significantly improved. To test
which is the best to be employed by the proposed
LFS framework, we further comparatively study
five classic feature selection algorithms respec-
tively based on document frequency (DF) (Man-
ning et al., 2008), mutual information (MI) (Man-
ning et al., 2008; Church and Hanks, 1990), χ2-
statistic (CHI) (Manning et al., 2008), information
gain (IG) (Mitchell, 1997), and term strength (T-
S) (Wilbur and Sirotkin, 1992). The comparative-
ly experimental results suggest that the TS, DF,
and MI algorithms achieve generally better perfor-
mance than the CHI and IG algorithms. Among
the five employed algorithms, the TS algorithm
is the best to be employed by the proposed LFS

framework. This paper makes the following con-
tributions:

• We propose a LFS framework to enhance the
classification performance and improve the
computational efficiency of the HL-SOT ap-
proach;

• We conduct a comparative study on five fea-
ture selection algorithms that can be em-
ployed in the proposed LFS.

The remainder of the paper is organized as fol-
lows. In section 2, we discuss an overview of
related work on sentiment analysis. In section 3,
we review the HL-SOT approach proposed in (Wei
and Gulla, 2010). In section 4, we present the pro-
posed LFS framework. The empirical analysis and
the results are presented in section 5. Finally, we
conclude the paper and discuss the future work in
section 6.

2 Related Work

Research on sentiment analysis was originally per-
formed to extract overall sentiments from target
texts. However, as shown in the experiments
in (Turney, 2002), the whole sentiment of a docu-
ment is not necessarily the sum of its parts. Recent
work has shifted the focus from overall document
sentiment to sentiment analysis based on product
attributes (Hu and Liu, 2004; Popescu and Etzioni,
2005; Ding and Liu, 2007; Liu et al., 2005).

Document overall sentiment analysis is to sum-
marize the overall sentiment in the documen-
t, which relies on two finer levels of sentiment
annotation: word-level sentiment annotation and
phrase-level sentiment annotation. The word-
level sentiment annotation is to utilize the polar-
ity annotation of words in each sentence and sum-
marize the overall sentiment of each sentiment-
bearing word to infer the overall sentiment within

328



the text (Hatzivassiloglou and Wiebe, 2000; An-
dreevskaia and Bergler, 2006; Esuli and Sebas-
tiani, 2005; Esuli and Sebastiani, 2006; Hatzi-
vassiloglou and McKeown, 1997; Kamps et al.,
2004; Devitt and Ahmad, 2007; Yu and Hatzivas-
siloglou, 2003). The phrase-level sentiment anno-
tation focuses sentiment annotation on phrases not
words with concerning that atomic units of expres-
sion is not individual words but rather appraisal
groups (Whitelaw et al., 2005). In (Wilson et al.,
2005), the concepts of prior polarity and contex-
tual polarity were proposed. This paper present-
ed a system that is able to automatically identify
the contextual polarity for a large subset of senti-
ment expressions. In (Turney, 2002), an unsuper-
vised learning algorithm was proposed to classify
reviews as recommended or not recommended by
averaging sentiment annotation of phrases in re-
views that contain adjectives or adverbs. However,
the performances of these approaches are not satis-
factory for sentiment analysis on product reviews,
where sentiment on each attribute of a produc-
t could be so complicated that it is unable to be
expressed by overall document sentiment.

Attributes-based sentiment analysis is to ana-
lyze sentiment based on each attribute of a produc-
t. In (Hu and Liu, 2004), mining product features
was proposed together with sentiment polarity an-
notation for each opinion sentence. In that work,
sentiment analysis was performed at the produc-
t attributes level. In (Liu et al., 2005), a system
with framework for analyzing and comparing con-
sumer opinions of competing products was pro-
posed. The system made users be able to clearly
see the strengths and weaknesses of each produc-
t in the minds of consumers in terms of various
product features. In (Popescu and Etzioni, 2005),
Popescu and Etzioni not only analyzed polarity
of opinions regarding product features but also
ranked opinions based on their strength. In (Liu
et al., 2007), Liu et al. proposed Sentiment-PLSA
that analyzed blog entries and viewed them as a
document generated by a number of hidden sen-
timent factors. These sentiment factors may also
be factors based on product attributes. In (Lu and
Zhai, 2008), Lu et al. proposed a semi-supervised
topic models to solve the problem of opinion inte-
gration based on the topic of a product’s attributes.
The work in (Titov and McDonald, 2008) present-
ed a multi-grain topic model for extracting the rat-
able attributes from product reviews. In (Lu et al.,

2009), the problem of rated attributes summary
was studied with a goal of generating ratings for
major aspects so that a user could gain differen-
t perspectives towards a target entity. In a most
recent research work (Wei and Gulla, 2010), Wei
and Gulla proposed the HL-SOT approach that
sufficiently utilizes the hierarchical relationships
among a product attributes and solves the senti-
ment analysis problem in a hierarchical classifi-
cation process. However, the HL-SOT approach
proposed in (Wei and Gulla, 2010) uses a global-
ly unified index term space to encode target texts
for different nodes which is deemed to limit the
performance of the HL-SOT approach. There-
fore, the LFS framework proposed in this paper
aims at overcoming the weakness of the HL-SOT
approach and consequently improving its perfor-
mance by generating a locally customized index
term space for each node.

3 The HL-SOT Approach Review

In the HL-SOT approach (Wei and Gulla, 2010),
each target text is indexed by a vector x ∈ X , X =
Rd. Weight vectors wi(1 ≤ i ≤ N) define linear-
threshold classifiers of each node i in SOT so that
the target text x is labeled true by node i if x is
labeled true by i’s parent node and wi ·x ≥ θi. The
parameters wi and θi are learned from the training
data set: D = {(r, l)|r ∈ X , l ∈ Y}, where Y
denotes the set of label vectors. In the training
process, when a new instance rt is observed, each
row vector wi,t is updated by a regularized least
squares estimator given by:

wi,t = (I + Si,Q(i,t−1)S
⊤
i,Q(i,t−1) + rtr

⊤
t )

−1

×Si,Q(i,t−1)(li,i1 , li,i2 , ..., li,iQ(i,t−1))
⊤ (1)

where I is a d × d identity matrix, Q(i, t − 1)
denotes the number of times the parent of node i
observes a positive label before observing the in-
stance rt, Si,Q(i,t−1) = [ri1 , ..., riQ(i,t−1) ] is a d ×
Q(i, t−1) matrix whose columns are the instances
ri1 , ..., riQ(i,t−1) , and (li,i1 , li,i2 , ..., li,iQ(i,t−1))

⊤ is
a Q(i, t−1)-dimensional vector of the correspond-
ing labels observed by node i. The Formula 1 re-
stricts that the weight vector wi,t of the classifier i
is only updated on the examples that are positive
for its parent node. Then the label vector ŷrt is
computed for the instance rt, before the real label
vector lrt is observed. Then the current threshold
vector θt is updated by:

θt+1 = θt + ϵ(ŷrt − lrt), (2)

329



where ϵ is a small positive real number that de-
notes a corrective step for the current threshold
vector θt. After the training process for each node
of SOT, each target text is to be labeled by each
node i parameterized by the weight vector wi and
the threshold θi in the hierarchical classification
process.

4 The Localized Feature Selection

In this section, we propose the LFS framework to
generate a locally customized index term space for
each node of SOT respectively. We first discuss
why localized feature selection is needed for the
HL-SOT approach. Then we define the concept
of local hierarchy of SOT to introduce the local
feature selection scope of a node, followed by a
presentation on the local hierarchy based feature
selection process.

4.1 Why Localized Feature Selection for the
HL-SOT

One deficiency of the HL-SOT approach is that it
uses a globally unified index term space to index
target texts, which cannot efficiently encode fea-
ture information required by each local individual
node of SOT. When we look into the detailed clas-
sification process of each node of SOT, we observe
the following two types of phenomena. Firstly,
SOT organizes domain knowledge in a tree like
structure. Within a particular domain knowledge
represented by SOT, nodes that stay in differen-
t branches of SOT represent independent different
attributes in that domain. In this way, feature terms
(e.g., the term “ergonomics”) that are relevant to a
node (e.g., the node “design and usability”) might
be irrelevant to other nodes (e.g., the node “im-
age quality”) that stay at another branches of SOT;
Secondly, the HL-SOT approach labels each tar-
get text in a hierarchical order which ensures that
each target text that comes to be handled by a node
has already been labeled as true by its parent n-
ode. Due to this characteristic, feature terms (e.g.,
the term “noise”) that are significant to a node i
(e.g., the node “noise”) might become a trivial ter-
m for i’s child nodes (e.g., the nodes “noise +” and
“noise -”). Therefore, the purpose of the localized
feature selection is to filter out irrelevant terms that
are insignificant to each individual node and build
a locally customized index term space for the n-
ode so that the performance of the node can be
improved.

4.2 Local Feature Selection Scope for a Node

In order to select locally customized feature terms
for each individual node, we need to define a suit-
able scope, called local feature selection scope3,
within which the feature selection process can be
effectively conducted for the node. Since the HL-
SOT approach is a hierarchical classification pro-
cess, before we introduce the local scope for a n-
ode we first give a formal definition on local hier-
archy of SOT.

Definition 1 [Local Hierarchy] A local hierarchy
∆u of SOT is defined to be formed by all the child
nodes of u in SOT, where the node u must be a
non-leaf node of the SOT.

By the Definition 1, we say all the child nodes of
u are on the same local hierarchy under u which
is denoted by ∆u. For examples, in Fig. 2 nodes
“camera +”, “design and usability”, “image quali-
ty”, “lens”, “camera -” are deemed on the same lo-
cal hierarchy under the node “camera” and nodes
“weight +”, “weight -” are deemed on the same
local hierarchy under the node “weight”, etc. In
the hierarchical labeling process of the HL-SOT
approach, after a target text is labeled as true by a
node i it will go further to the local hierarchy un-
der i and is to be labeled by all nodes on the local
hierarchy ∆i. For a target text the labeling pro-
cesses of nodes on ∆i locally can be considered
as a multi-label classification process where each
node is a local label. Therefore, the measurement
for selecting terms as features should be calculat-
ed among nodes on the same hierarchy. Hence, the
local scope for a node is defined within the local
hierarchy which the node is on.

4.3 Local Hierarchy Based Feature Selection

In the proposed LFS framework, local feature se-
lection for a node i of SOT is performed within the
local scope of the node i. Since nodes on the same
local hierarchy share the same local scope, local
feature selection process for all nodes of SOT is
achieved in local hierarchy based manner. Specif-
ically, for the feature selection process on a local
hierarchy ∆, let c1, c2, ..., cK denote the K nodes
on ∆. Let D denote the training data set for the
HL-SOT approach. Let Dck denote the set of in-
stances in D that contains the label of the node
ck(1 6 k 6 K). Let D∆ denote the training cor-
pus for the local hierarchy ∆ which is the set of

3In this paper, we also call it “local scope” for short.

330



Figure 2: All local hierarchies of the example SOT: the grey nodes sharing the same parent node in
dashed line are called on the same local hierarchy under the parent node

all instances in the training data set D that con-
tain any label of nodes on the local hierarchy ∆:
D∆ =

∪K
k=1 Dck . Let Vck denote the set of all

the vocabularies that appears in Dck . Let sck(w)
denote the term score that measures the suitability
of w as a feature for node ck. Let Fck denote the
set of feature terms selected for ck. Let dck denote
the number of features to be selected in Fck . A lo-
cal feature selection process for nodes on the local
hierarchy ∆ is described in Algorithm 1.

Algorithm 1 Localized Feature Selection Algorithm
DATA INITIALIZATION:

1: for each node ck on ∆ do
2: Establish Dck containing instances being labeled true by ck ;
3: Establish the vocabulary set Vck ;
4: Remove stop words from Vck ;
5: end for
6: Establish the training corpus: D∆ =

∪K
k=1 Dck ;

BEGIN
7: for each node ck on ∆ do
8: for each term w ∈ Vck do

with training corpus D∆ and data instance set Dck :
9: Calculate sck (w) with a specified feature selection algorithm;
10: end for
11: Establish feature space Fck with top dck terms from Vck ;
12: end for

END

In the data initialization phase of the Algorith-
m 1, the data instance set Dck and vocabulary set
Vck for each node on the local hierarchy ∆ as well
as the training corpus D∆ are established. In a lo-
cal feature selection process, a term score sck(w)
for each term w ∈ Vck can be calculated by a spec-
ified feature selection algorithm, taking D∆ as the
training corpus and Dck as the data instance set in
the class ck. The local feature selection process
can employ any specific feature selection algorith-
m to calculate the term scores. After all terms in
Vck are calculated, those terms with top dck scores
are selected to establish the feature space Fck for

the node ck. Since the number of terms in Vck
varies from node to node, in order to produce a ra-
tional dimensionality dck for the established fea-
ture space Fck , we introduce a feature selection
rate, denoted by γ, to control dck for each node ck,
i.e., dck = p|Vck | × γq.

After local feature selection processes for all
the nods of SOT are accomplished, a locally cus-
tomized index term space Fck for each node ck is
established. Each target text will be respectively
indexed by a customized vector xck ∈ Xck(Xck =
Rdck ) when it goes through the hierarchical classi-
fication process of the HL-SOT approach. In next
section, we will present the empirical analysis on
evaluating the proposed LFS framework.

5 Empirical Analysis

In this section, we conduct extensive experiments
to empirically analyze the proposed LFS frame-
work. Our experiments are intended to address
the following questions: (1) can the classifica-
tion performance of the HL-SOT approach be im-
proved with the LFS framework; (2) how much
computational efficiency can be gained for the HL-
SOT to be implemented in the LFS framework; (3)
how are the comparative performances produced
by different feature selection algorithms when em-
ployed in the proposed LFS framework.

5.1 Data Set Preparation

We construct our data set based on the digital
camera review data set used in the HL-SOT ap-
proach (Wei and Gulla, 2010). In total, the con-
structed data set contains 1500 snippets of cus-
tomer reviews on digital cameras, where 35 at-
tributes of a digital camera are mentioned in the

331



review data. We build an ontology structure to or-
ganize the mentioned attributes and label each re-
view text with correspondent attributes as well as
sentiments, which complying the rule that if a re-
view text is assigned with a label of a node then
it is assigned with a label of the parent node. We
randomly divide the labeled data set into five fold-
s so that each fold at least contains one example
instance labeled by each attribute node. To catch
the statistical significance of experimental results,
we perform 5 cross-fold evaluation by using four
folds as training data and the other one fold as test-
ing data. All the experimental results presented in
this section are averaged over 5 runs of each ex-
periment.

5.2 Evaluation Metrics
Since the existing HL-SOT approach is a hierar-
chical classification process, we use the same three
classic loss functions (Wei and Gulla, 2010) for
measuring classification performance. They are
respectively the One-error Loss (O-Loss) function,
the Symmetric Loss (S-Loss) function, and the Hi-
erarchical Loss (H-Loss) function4:

• One-error loss (O-Loss) function is defined as:

LO(ŷ, l) = B(∃i : ŷi ̸= li), (3)

where ŷ is the prediction label vector and l is the true
label vector; B(S) is a boolean function which is 1 if
and only if the statement S is true, otherwise it is 0.

• Symmetric loss (S-Loss) function is defined as:

LS(ŷ, l) =

N∑

i=1

B(ŷi ̸= li), (4)

• Hierarchical loss (H-Loss) function is defined as:

LH(ŷ, l) =
N∑

i=1

B(ŷi ̸= li ∧ ∀j ∈ A(i), ŷj = lj),

(5)
where A denotes a set of nodes that are ancestors of
node i in SOT.

5.3 Performance Comparison
In this section, we conduct experiments to show
performance improvement from the proposed LF-
S framework. The performance considered here
include both classification performance and com-
putational efficiency. We use the existing HL-
SOT approach as a baseline. Since the HL-SOT

4Since the three loss functions are respectively well-
defined by each formula and self-explained by their names,
due to the space limitation, we do not present more explana-
tion.

approach used terms’ document frequencies (D-
F) (Manning et al., 2008) algorithm to select fea-
tures to build the globally unified index term s-
pace, employing the same DF feature selection al-
gorithm we apply the proposed LFS framework on
the HL-SOT approach and call the implemented
method “DF-SOT”. The only difference between
HL-SOT and DF-SOT is the index term space for
each node of SOT, i.e., in the HL-SOT all the n-
odes using the globally unified index term space
while in the DF-SOT each node respectively us-
ing a locally customized index term space. In this
way, the performance difference between the two
methods will indicate the effect of the proposed
LFS framework.

5.3.1 Comparison on Classification
Performance

We conduct experiments to investigate whether the
classification performance of the HL-SOT can be
improved when it is implemented with the LFS
framework. Fig. 3 presents the experimental re-
sults of classification accuracies between HL-SOT
and DF-SOT. In the experiments, the dimension-
ality d of the globally unified index term space of
the HL-SOT approach is set to 270, which is large
enough for the HL-SOT approach to reach its best
performance level. The feature selection rate γ for
the locally customized index term space of the DF-
SOT approach is set to 0.2 and 0.3, which brings
respectively 80% and 70% vocabulary reduction.
The value of the corrective step ϵ is set to varying
from 0.005 to 0.05 with each step of 0.005 so that
each running approach can achieve its best perfor-
mance with a certain value of ϵ. From Fig. 3, we
can observe that when γ = 0.2 the DF-SOT ap-
proach reaches its best performance with 0.6953
(ϵ = 0.02) on O-Loss, 1.5516 (ϵ = 0.045) on
S-Loss, and 1.0578 (ϵ = 0.04) on H-Loss, and
that when γ = 0.3 the DF-SOT approach reach-
es its best performance with 0.6953 (ϵ = 0.015)
on O-Loss, 1.5531 (ϵ = 0.02) on S-Loss, and
1.0547 (ϵ = 0.025) on H-Loss, which outperform-
s the best performance of the HL-SOT approach
on O-Loss 0.6984 (ϵ = 0.025), on S-Loss 1.6188
(ϵ = 0.025), and on H-Loss 1.0969 (ϵ = 0.05).
This indicates that with the proposed LFS frame-
work, compared with the HL-SOT approach, the
DF-SOT approach generally improves the classifi-
cation performance.

332



0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05
0.69

0.7

0.71

0.72

0.73

0.74

0.75

0.76

0.77

0.78

Corrective Step

O
−

L
os

s

 

 

HL−SOT(d=270)

DF−SOT(γ=0.2)
DF−SOT(γ=0.3)

(a) O-Loss

0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05

1.55

1.6

1.65

1.7

1.75

1.8

Corrective Step

S−
L

os
s

 

 
HL−SOT(d=270)
DF−SOT(γ=0.2)
DF−SOT(γ=0.3)

(b) S-Loss

0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05
1.05

1.1

1.15

1.2

1.25

Corrective Step

H
−

L
os

s

 

 
HL−SOT(d=270)
DF−SOT(γ=0.2)
DF−SOT(γ=0.3)

(c) H-Loss

Figure 3: Classification Performance (A Smaller Loss Value Means Better Classification Performance)

5.3.2 Comparison on Computational
Efficiency

We conduct further experiments to analyze com-
putational efficiency gained through the proposed
LFS framework. All the experiments are conduct-
ed on a normal personal computer containing an
Intel Pentium D CPU (2.4 GHz, Dual Core) and
4G memory. Fig. 4 summarizes the computation-
al time consumed by experiment runs respectively
for HL-SOT (d = 270) and DF-SOT (γ = 0.2
and γ = 0.3). From Fig. 4, we can observe
that the HL-SOT approach consumes 15917695
ms to finish an experimental run, although the DF-
SOT approach only takes respectively 2.29% (with
γ = 0.2 ) and 4.91% (with γ = 0.2 ) of computa-
tional time as the existing HL-SOT approach con-
sumes and achieves even better classification per-
formance than the HL-SOT approach (see Fig.3).
This confirms that much computational efficien-
cy can be gained for the HL-SOT approach to be
implemented in the LFS framework while better
classification performance is ensured. Since the
computational complexity of each node classifier
of DF-SOT is the same as HL-SOT, the compu-
tational efficiency gained from the proposed LFS
framework should be attributed to the dimension
reduction of the index term space.

5.4 Comparative Study on Feature Selection
Algorithms

The proposed LFS framework for the HL-SOT ap-
proach can employ various feature selection algo-
rithms to select local features for each individu-
al node. In this section, we conduct intensive ex-
periments to comparatively study five classic fea-
ture selection algorithms employed within the LFS
framework. The five employed feature selection
algorithms are respectively document frequency

Figure 4: Time Consuming (ms)

(DF) (Manning et al., 2008) based feature selec-
tion algorithm, mutual information (MI) (Manning
et al., 2008; Church and Hanks, 1990) based fea-
ture selection algorithm, χ2-statistic (CHI) (Man-
ning et al., 2008) based feature selection algorith-
m, information gain (IG) (Mitchell, 1997) based
feature selection algorithm as well as term strength
(TS) (Wilbur and Sirotkin, 1992) based feature s-
election algorithm5.

In the experiments, the feature selection rate γ
is set to 0.2 and 0.3 respectively. The value of
the corrective step ϵ varies from 0.005 to 0.05
with each step of 0.005. The experimental re-
sults are summarized in Fig. 5. From Fig. 5 it
is observed that DF, MI, and TS feature selec-
tion algorithms achieve generally better perfor-
mances than CHI and IG feature selection algo-
rithms when they are employed in the proposed
LFS framework. Specifically, the TS algorithm is
generally the best among the five employed algo-
rithms while the DF algorithm can also achieve as

5Due to the space limitation, details of the studied feature
selection algorithms are not reviewed here. The mechanism
of each algorithm can be read in the related references.

333



0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05
0.68

0.7

0.72

0.74

0.76

0.78

0.8

0.82

Corrective Step

O
−

L
os

s

 

 

DF−SOT
MI−SOT
CHI−SOT
IG−SOT
TS−SOT

(a) O-Loss (γ = 0.2)

0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05

1.55

1.6

1.65

1.7

1.75

1.8

1.85

1.9

Corrective Step

S−
L

os
s

 

 
DF−SOT
MI−SOT
CHI−SOT
IG−SOT
TS−SOT

(b) S-Loss (γ = 0.2)

0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05

1.05

1.1

1.15

1.2

1.25

1.3

1.35

Corrective Step

H
−

L
os

s

 

 
DF−SOT
MI−SOT
CHI−SOT
IG−SOT
TS−SOT

(c) H-Loss (γ = 0.2)

0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05
0.68

0.7

0.72

0.74

0.76

0.78

0.8

Corrective Step

O
−

L
os

s

 

 

DF−SOT
MI−SOT
CHI−SOT
IG−SOT
TS−SOT

(d) O-Loss (γ = 0.3)

0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05
1.5

1.55

1.6

1.65

1.7

1.75

1.8

Corrective Step

S−
L

os
s

 

 
DF−SOT
MI−SOT
CHI−SOT
IG−SOT
TS−SOT

(e) S-Loss (γ = 0.3)

0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05
1

1.05

1.1

1.15

1.2

1.25

1.3

Corrective Step

H
−

L
os

s

 

 
DF−SOT
MI−SOT
CHI−SOT
IG−SOT
TS−SOT

(f) H-Loss (γ = 0.3)

Figure 5: Comparative Performances on the Employed Feature Selection Algorithms

comparable good performance as the TS algorithm
does. This is due to that both the TS and the DF al-
gorithms favor high frequency terms and vocabu-
laries used in customer reviews on a specific prod-
uct are usually overlapping. When γ = 0.3, it can
be also observed that the MI algorithm achieves
as comparable good performance as the TS algo-
rithm does. This is because, in customer reviews,
although some vocabularies are rarely used they
always occur as significant features in some spe-
cific categories. For example, “ergonomics” is a
rare term but almost always appears in the class of
“design and usability”. Therefore, the MI algorith-
m can also achieve relatively better performance
through favoring rare terms that always co-occur
with specific classes.

6 Conclusions and Future Work

In this paper, we propose a LFS framework tai-
lored to the HL-SOT approach to sentiment analy-
sis. In the proposed LFS framework, significan-
t feature terms of each node can be selected to
construct the locally customized index term space
for the node so that the classification performance
and computational efficiency of the existing HL-
SOT approach are improved. The effectiveness of
the proposed LFS is validated against a human-
labeled data set. Further comparative study on

five employed feature selection algorithms with-
in the proposed LFS framework indicates that the
TS, DF, and MI algorithms achieve generally bet-
ter performance than the CHI and IG algorithms.
Among the five employed algorithms, the TS algo-
rithm is the best to be employed by the proposed
LFS framework.

Although the proposed LFS framework shows
its effectiveness of improving on the HL-SOT ap-
proach, its improvement on the classification per-
formance is not so obvious compared with its
much improvement on computational efficiency.
Due to the limited number of instances in the train-
ing data set, the classification performance stil-
l suffers from the problem that unobserved terms
appear in testing cases. This problem is inherent-
ly raised by the bag-of-word model. A concept-
based indexing scheme that can infer concepts of
unobserved terms might alleviate the problem. We
plan to investigate on this issue in the future work.

Acknowledgments

The authors would like to thank the anony-
mous reviewers for the helpful comments on the
manuscript. This work is funded by the Research
Council of Norway under the VERDIKT research
programme (Project No.: 183337).

334



References
Alina Andreevskaia and Sabine Bergler. 2006. Min-

ing wordnet for a fuzzy sentiment: Sentiment tag
extraction from wordnet glosses. In Proceedings of
11th Conference of the European Chapter of the As-
sociation for Computational Linguistics.

Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicog-
raphy. Computational Linguistics, 16(1):22–29.

Ann Devitt and Khurshid Ahmad. 2007. Sentiment
polarity identification in financial news: A cohesion-
based approach. In Proceedings of 45th Annual
Meeting of the Association for Computational Lin-
guistics.

Xiaowen Ding and Bing Liu. 2007. The utility of lin-
guistic rules in opinion mining. In Proceedings of
the 30th Annual International ACM SIGIR Confer-
ence on Research and development in Information
Retrieval.

Andrea Esuli and Fabrizio Sebastiani. 2005. Deter-
mining the semantic orientation of terms through
gloss classification. In Proceedings of 14th ACM
Conference on Information and Knowledge Man-
agement.

Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
wordnet: A publicly available lexical resource for
opinion mining. In Proceedings of 5th International
Conference on Language Resources and Evaluation.

Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proceedings of 35th Annual Meeting of the
Association for Computational Linguistics.

Vasileios Hatzivassiloglou and Janyce M. Wiebe.
2000. Effects of adjective orientation and grad-
ability on sentence subjectivity. In Proceedings
of 18th International Conference on Computational
Linguistics.

Minqing Hu and Bing Liu. 2004. Mining and sum-
marizing customer reviews. In Proceedings of 10th
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining.

Jaap Kamps, Maarten Marx, R. ort. Mokken, and
Maarten de Rijke. 2004. Using WordNet to mea-
sure semantic orientation of adjectives. In Proceed-
ings of 4th International Conference on Language
Resources and Evaluation.

Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opin-
ions on the web. In Proceedings of 14th Interna-
tional World Wide Web Conference.

Yang Liu, Xiangji Huang, Aijun An, and Xiaohui Yu.
2007. ARSA: a sentiment-aware model for predict-
ing sales performance using blogs. In Proceedings

of the 30th Annual International ACM SIGIR Con-
ference on Research and development in Information
Retrieval.

Yue Lu and Chengxiang Zhai. 2008. Opinion inte-
gration through semi-supervised topic modeling. In
Proceedings of 17th International World Wide Web
Conference.

Yue Lu, ChengXiang Zhai, and Neel Sundaresan.
2009. Rated aspect summarization of short com-
ments. In Proceedings of 18th International World
Wide Web Conference.

Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Schutze, 2008. Introduction to Information
Retrieval, chapter 13, pages 271–278. Cambridge
University Press.

Tom Mitchell. 1997. Machine Learning. McGraw-
Hill.

Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing product features and opinions from reviews. In
Proceedings of Human Language Technology Con-
ference and Empirical Methods in Natural Lan-
guage Processing Conference.

Ivan Titov and Ryan T. McDonald. 2008. Modeling
online reviews with multi-grain topic models. In
Proceedings of 17th International World Wide We-
b Conference.

Peter D. Turney. 2002. Thumbs up or thumbs down?
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of 40th Annual
Meeting of the Association for Computational Lin-
guistics.

Wei Wei and Jon Atle Gulla. 2010. Sentiment learning
on product reviews via sentiment ontology tree. In
Proceedings of 48th Annual Meeting of the Associa-
tion for Computational Linguistics.

Casey Whitelaw, Navendu Garg, and Shlomo Arga-
mon. 2005. Using appraisal taxonomies for senti-
ment analysis. In Proceedings of 14th ACM Confer-
ence on Information and Knowledge Management.

J. W. Wilbur and K. Sirotkin. 1992. The automatic i-
dentification of stop words. Journal of the American
Society for Information Science, 18:45–55.

Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of Hu-
man Language Technology Conference and Empir-
ical Methods in Natural Language Processing Con-
ference.

Hong Yu and Vasileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: Separating facts
from opinions and identifying the polarity of opinion
sentences. In Proceedings of 8th Conference on Em-
pirical Methods in Natural Language Processing.

335


