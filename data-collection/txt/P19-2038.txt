



















































ARHNet - Leveraging Community Interaction for Detection of Religious Hate Speech in Arabic


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 273–280
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

273

ARHNet - Leveraging Community Interaction For Detection Of Religious
Hate Speech In Arabic

Arijit Ghosh Chowdhury∗
Manipal Institute of Technology
arijit10@gmail.com

Aniket Didolkar∗
Manipal Institute of Technology
adidolkar123@gmail.com

Ramit Sawhney
Netaji Subhas Institute of Technology

ramits.co@nsit.net.in

Rajiv Ratn Shah
MIDAS, IIIT-Delhi

rajivratn@iiitd.ac.in

Abstract
The rapid widespread of social media has led
to some undesirable consequences like the
rapid increase of hateful content and offen-
sive language. Religious Hate Speech, in par-
ticular, often leads to unrest and sometimes
aggravates to violence against people on the
basis of their religious affiliations. The rich-
ness of the Arabic morphology and the lim-
ited available resources makes this task espe-
cially challenging. The current state-of-the-
art approaches to detect hate speech in Ara-
bic rely entirely on textual (lexical and seman-
tic) cues. Our proposed methodology con-
tends that leveraging Community-Interaction
can better help us profile hate speech con-
tent on social media. Our proposed ARHNet
(Arabic Religious Hate Speech Net) model in-
corporates both Arabic Word Embeddings and
Social Network Graphs for the detection of re-
ligious hate speech.

1 Introduction

Hate speech was a major tool employed to pro-
mote slavery in Colonial America, to aggravate
tensions in Bosnia and in the rise of the Third Re-
ich. The aim of such speech is to ridicule victims,
to humiliate them and represent their grievances
as less serious (Gelashvili, 2018). The relation-
ship between religion and hate speech is com-
plex and has been central to recent discussions
of hate speech directed at religious people, espe-
cially members of religious minorities (Bonotti,
2017). This makes it important to develop auto-
mated tools to detect messages that use inflamma-
tory sectarian language to promote hatred and vi-
olence against people.

Our work extends on the work done by (Al-
badi et al., 2018) in terms of exploring the mer-

its of introducing community interaction as a fea-
ture in the detection of religious hate speech in
Arabic. Most previous work in the area of hate
speech detection has targeted mainly English con-
tent (Davidson et al., 2017) (Djuric et al., 2015)
(Badjatiya et al., 2017). Author profiling using
community graphs has been explored by (Mishra
et al., 2018) for abuse detection on Twitter. We
propose a novel Cyber Hate Detection approach
using multiple twitter graphs and traditional word
embeddings.

Social network graphs are increasingly being
used as a powerful tool for NLP applications
(Mahata et al., 2018; Shah et al., 2016b), lead-
ing to substantial improvement in performance for
tasks like text categorization, sentiment analysis,
and author attribute identification ((Hovy, 2015);
(Yang and Eisenstein, 2015); (Yang et al., 2016).
The idea of using this type of information is best
explained by the concept of homophily, i.e., the
phenomenon that people, both in real life as well
as on the Internet, tend to associate more with
those who appear similar. Here, similarity can be
defined based on various parameters like location,
age, language, etc. The basic idea behind leverag-
ing community interaction is that if we have infor-
mation about members of a community defined by
some similarity measure, then we can infer infor-
mation about a person based on which community
they belong to. For our study, knowing that mem-
bers of a particular community are prone to prolif-
erating religious hate speech content, and know-
ing that the user is connected to this community,
we can use this information beyond linguistic cues
and more accurately predict the use of hateful/non-
hateful language. Our work seeks to address two
main questions:



274

• Is one community more prone to spreading
hateful content than the other?

• Can such information be effectively lever-
aged to improve the performance of the cur-
rent state of the art in the detection of re-
ligious hate speech within Arabic speaking
users?

In this paper, we do an in-depth analysis of how
adding community features may enhance the per-
formance of classification models that detect reli-
gious hate speech in Arabic.

2 Related Work

Hate speech research has been conducted exten-
sively for the English language. Amongst the
first ones to apply supervised learning to the task
of hate speech detection were (Yin and Davison,
2009) who used a linear SVM classifier to iden-
tify posts containing harassment based on local,
contextual and sentiment-based (e.g., presence of
expletives) features. Their best results were with
all of these features combined. Notably, (Waseem
and Hovy, 2016) created a dataset for detection of
Hate Speech on Twitter. They noted that character
n-grams are better predictive features than word
n-grams for recognizing racist and sexist tweets.
Their n-gram-based classification model was out-
performed using Gradient Boosted Decision Trees
classifier trained on word embeddings learned us-
ing LSTMs (Waseem and Hovy, 2016). There
has been limited literature on the problem of Hate
Speech detection on Arabic social media. (Magdy
et al., 2015) trained an SVM classifier to predict
whether a user is more likely to be an ISIS sup-
porter or opposer based on features of the users
tweets.

Social Network graphs have been leveraged in
several ways for a variety of purposes in NLP.
Given the graph representing the social network,
such methods create low-dimensional representa-
tions for each node, which are optimized to predict
the nodes close to it in the network. Among those
that implement this idea are (Yang et al., 2016),
who used representations derived from a social
graph to achieve better performance in entity link-
ing tasks, and Chen and Ku (Yang and Eisenstein,
2015), who used them for stance classification. A
considerable amount of literature has also been de-
voted to sentiment analysis with representations
built from demographic factors ((Yang and Eisen-

stein, 2015); (Chen and Ku, 2016)). Other tasks
that have benefited from social representations are
sarcasm detection (Amir et al., 2016) and political
opinion prediction (Tlmcel and Leon, 2017).

To our knowledge, so far there has been no sub-
stantial research on using social network graphs as
features to analyze and categorize tweets in Ara-
bic. Our work proposes a novel architecture that
builds on the current state of the art and improves
its performance using community graph features.

3 Data

We conduct our experiments with the dataset pro-
vided by (Albadi et al., 2018). The authors col-
lected the tweets referring to different religious
groups and labeled them using crowdsourced
workers. In November 2017, using Twitters search
API 2, the authors collected 6000 Arabic tweets,
1000 for each of the six religious groups. They
used this collection of tweets as their training
dataset. Due to the unavailability of a hate lex-
icon and to ensure unbiased data collection pro-
cess; they included in their query only impartial
terms that refer to a religion name or the people
practicing that religion. In January 2018, they col-
lected another set of 600 tweets, 100 for each of
the six religious groups, for their testing dataset.
After an inter-annotator agreement of 81% , 2526
tweets were labeled as Hate.

The dataset was released as a list of 5570 tweet
IDs along with their corresponding annotations.
Using the python Twarc library, we could only re-
trieve 3950 of the tweets since some of them have
now been deleted or their visibility limited. Of
the ones retrieved, 1,685 (42.6%) are labelled as
hate, and the remaining 2,265 (57.4%) as Non-
Hate; this distribution follows the original dataset
very closely (45.1%, 54.9%).

3.1 Preprocessing

We followed some of the Arabic-specific normal-
ization steps proposed in (Albadi et al., 2018)
along with some other Twitter-specific preprocess-
ing techniques.

• Normalization of Hamza with alef seat to
bare alef.

• Normalization of dotless yeh (alef maksura)
to yeh.

• Normalization of teh marbuta to heh.



275

Hate
Õæ


jm.

Ì'@ Xñ
�
¯ð Ñë 	áK


	
YË@ éK
Y«AÓ úÎ«ð

	
àA¢J


�
Ë@ ZA

	
JK.


@ Ñë 	áK


	
YË@ XñîD
Ë @ úÎ« é<Ë @

�
é
	
JªË ZA

�
KC

�
JË @ ÐñJ
Ë @

TuesdayMorning curse of god on the jews who are the sons of the satan and on their helpers
who are the fuel of hell

ÑêªJ.
�
�K


	áÓð
	á�


�
®

	
¯A

	
JÖÏ @

�
éªJ


�
Ë@ 	áÓ

	
P


B@ Qê£ ÑêÊË @

Oh god purify the land from the rawafid hypocrite Shia and those who follow them
ø



PA
	
JË @ð XñîD
Ë @ é

	
JªË A

	
®
�
JJ


	
¯ 	áªÊK
 é<Ë @

God cursed Vittafa cursed Jews and Christians
é
�
®J


�
®k ÕÂ

�
JK. ðQªË AJ.

�
K ZA«YËAK. ø


XñîD
Ë @ É
�
J
�
¯ ÈðAm�'
ð hCËAK. ÕÎ

ÖÏ @ è A
	

g@ É
�
J
�
®K
 ÕÎ

ÖÏ @ éÖÏ


ñÓ

Muslim Muslim kills his Muslim brother and tries to kill the Jew by praying to the Arabs

Table 1: Examples for Hate Speech.

Non-Hate
�
éK. PA

	
ªÖÏ @ Â XñîD
Ë @

�
èQ» @

	
X 	á«

�



KA

�
Kð ÕÎ

�
�
�
K H. Q

	
ªÖÏ @

	
­J


�
P


@

�
é


ñÓ

The Moroccan Archives Foundation receives documents on the memory of Moroccan Jews
éJ


�
JË @ ú




	
¯ (Qå

�
J. Ë @ É¿ ú



Î«

	
àñÊ

	


	
®ÖÏ @) XñîD
Ë @ ú



Î« é

�
JË 	Q

	
K @ AÒ» ø



ñÊË@ð 	áÖÏ @ È 	Q

	
K @ é<ËAK


God sent down the Manna and the Salafi as it sent down on the Jews (the favored of all human
beings) in Hell

 AK. QËAK. Â ÉJ.
�
®ÖÏ @ �
Ò

	
mÌ'@

�
éK. PA

	
ªÖÏ @ XñîD
Ë @

�
èQ» @

	
X 	á«

�



KA

�
Kð ÕÎ

�
�
�
K H. Q

	
ªÖÏ @

	
­J


�
P


@

�
é


ñÓ

Morocco’s Shiv receives documents on the memory of Moroccan Jews next Thursday in Rabat
éJ


	
K A

	
�B@ ÐQ

�
�m�

	
' Yª

	
K ÕË �. é

	
JK
AîD XñîE


	á�
jJ
Ó
	á�
ÒÊÓ ÐX@ XBð@ A

	
JÊ¿

We are all Adam’s children, Muslims, Christian Jews, Zionists, but we no longer respect hu-
manity

Table 2: Examples for Non-Hate Speech.

• Normalizing links, user mentions, and num-
bers to somelink, someuser, and somenum-
ber, respectively.

• Normalizing hashtags by deleting under-
scores and the # symbol.

• Removing diacritics (the harakat), tatweel
(stretching character), punctuations, emojis,
non-Arabic characters, and one-letter words.

• Repeated characters were removed if the rep-
etition was of count three or more.

• We used the list of 356 stopwords created by
(Albadi et al., 2018). This list did not have
negation words as they usually represent im-
portant sentiments.

• Stemming: We used the ISRI Arabic Stem-
mer provided by NLTK to handle inflected
words and reduce them to a common reduced
form.

4 Methodology

4.1 Community and Social Interaction
Network

To leverage information about community inter-
action, we create an undirected unlabeled social
network graph wherein nodes are the authors and
edges are the connections between them.

We use two social network graphs in our study :

• Follower Graph : This is an unweighted
undirected graph G with nodes v represent-
ing authors, with edges e such that for each
e ∈ E, there exists u, v ∈ the set of authors
such that u follows v or vice versa.

• Retweet Graph : This is an unweighted
undirected graph G with nodes v represent-
ing authors, with edges e such that for each
e ∈ E, there exists u, v ∈ the set of authors
such that u has retweeted v or vice versa.



276

From these social network graphs, we ob-
tain a vector representation, i.e., an embedding
that we refer to as an Interaction, for each au-
thor using the Node2Vec framework (Grover and
Leskovec, 2016). Node2Vec uses a skip-gram
model (Mikolov et al., 2013) on a graph to cre-
ate a representation for each of its nodes based on
their positions and their neighbors. Given a graph
with nodes V = v1, v2, ..., vn, Node2Vec seeks to
maximize the following log probability:∑

v∈V LogPr(Ns(v)|v)
where Ns(v)denotes the network neighborhood
of node v generated through sampling strategy
s. The framework can learn low-dimensional em-
beddings for nodes in the graph. These embed-
dings can emphasize either their structural role or
the local community they are a part of. This de-
pends on the sampling strategies used to generate
the neighborhood: if breadth-first sampling (BFS)
is adopted, the model focuses on the immediate
neighbors of a node; when depth-first sampling
(DFS) is used, the model explores farther regions
in the network, which results in embeddings that
encode more information about structural role of a
particular node . The balance between these two
ways of sampling the neighbors is directly con-
trolled by two node2vec parameters, namely p and
q. The default value for these is 1, which ensures
a node representation that gives equal weight to
both structural and community-oriented informa-
tion. In our work, we use the default value for
both p and q. Additionally, since Node2Vec does
not produce embeddings for single users without
a community, these have been mapped to a single
zero embedding. The dimensions of these embed-
dings were 64.

Figure 1 shows an example of a community.
The nodes represent users and the edges represent
an Interaction between them.

4.2 Classification
For every tweet ti ∈ D, in the dataset, a binary
valued value variable yi is used, which can either
be 0 or 1. The value 0 indicates that the text be-
longs to the Non-Hate category while 1 indicates
Hate Speech.

The following steps are executed for every tweet
ti ∈ D :

1. Word Embeddings. All the words in our
vocabulary are encoded to form 600-
dimensional word embeddings obtained

Figure 1: A community interaction snippet from
gretweet

Figure 2: The ARHNet Architecture

by concatenating Twitter-CBOW 300-
dimensional embedding with our trained
embedding.

2. Sentence Representation. This is obtained
by passing the word embeddings through the
corresponding deep learning model.

3. Node Embeddings. The node embedding for
the author of ti is concatenated with the sen-
tence representation to get the final represen-
tation.

4. Dense Layer. The final representation is
passed through a dense layer which outputs



277

Architecture Accuracy Precision Recall F1 AUROC
AraHate-LR 0.75 0.72 0.74 0.73 0.82
AraHate-SVM 0.75 0.72 0.72 0.72 0.81
AraHate-GRU 0.77 0.65 0.89 0.75 0.84
GRU + self-attention 0.78 0.71 0.78 0.74 0.83
GRU + CNN 0.79 0.69 0.86 0.77 0.86
LSTM 0.76 0.65 0.86 0.74 0.82
LSTM + self-attention 0.78 0.68 0.82 0.75 0.86
LSTM + CNN 0.80 0.71 0.83 0.77 0.86
Bidirectional GRU 0.79 0.70 0.85 0.77 0.85
Bidirectional GRU + self-attention 0.80 0.74 0.80 0.77 0.87
Bidirectional GRU + CNN 0.79 0.71 0.81 0.76 0.85
Bidirectional LSTM 0.80 0.73 0.79 0.76 0.86
Bidirectional LSTM + self-attention 0.77 0.66 0.86 0.75 0.87
Bidirectional LSTM + CNN 0.81 0.74 0.81 0.77 0.86

Table 3: Performance of various deep learning models.

Architecture Accuracy Precision Recall F1 AUROC
GRU + NODE2VEC 0.79 0.74 0.76 0.75 0.85
GRU + self-attention + NODE2VEC 0.78 0.67 0.87 0.75 0.84
GRU + CNN + NODE2VEC 0.80 0.68 0.87 0.77 0.85
LSTM + NODE2VEC 0.75 0.63 0.86 0.73 0.81
LSTM + self-attention + NODE2VEC 0.78 0.70 0.79 0.74 0.84
LSTM + CNN + NODE2VEC (ARHNet) 0.79 0.69 0.89 0.78 0.86
Bi-GRU + NODE2VEC 0.79 0.67 0.86 0.75 0.85
Bi-GRU + self-attention + NODE2VEC 0.79 0.70 0.82 0.76 0.86
Bi-GRU + CNN + NODE2VEC 0.81 0.72 0.84 0.77 0.86
Bi-LSTM + NODE2VEC 0.80 0.73 0.81 0.77 0.86
Bi-LSTM + self-attention + NODE2VEC 0.78 0.68 0.82 0.75 0.85
Bi-LSTM + CNN + NODE2VEC 0.80 0.73 0.81 0.77 0.86

Table 4: Performance of various deep learning models with community features.

a score that is converted to a probability dis-
tribution using a sigmoid activation.

4.3 Baselines

An extensive comparison with state-of-the-art
generic and specific models the case for our pro-
posed methodology. To make a fair compari-
son between all the methodologies, the experi-
ments are conducted concerning the baselines in
(Albadi et al., 2018) have used a simple GRU
model as their best performing model. Their
GRU model uses 240 hidden features. They have
also compared results with Logistic Regression
and Support Vector Machine Models. The Lo-
gistic regression classifier was trained using char-
acter n-gram features (n =1-4) with L2 regular-
ization. The SVM classifier was also trained us-

ing character n-gram features (n = 1-4) with lin-
ear kernel and L2 regularization, similar to (Al-
badi et al., 2018). For the GRU model, they have
used the Twitter-CBOW 300-dimensional embed-
ding model(Soliman et al., 2017) for obtaining
word embeddings. The output of the embedding
layer was fed into a dropout layer with probabil-
ity 0.5. They used batches of size 32 and Adam
as their optimizer. We refer the models trained by
(Albadi et al., 2018) as the AraHate baselines. We
conduct our experiments with LSTM (Liu et al.,
2016) and CNN-LSTM (Zhou et al., 2015) mod-
els. LSTMs can capture long term dependencies
better than RNNs and GRUs, and a CNN-LSTM
network utilizes the ability of a CNN to extract
higher-level phrase representations, which are fed
into an LSTM. We did not increase the complexity



278

of the baselines beyond this to not risk overfitting
on a small dataset.

4.4 Models and Hyperparameters

First, we prepared the vocabulary by assigning
integer indexes to unique words in our dataset.
Tweets were then converted into sequences of in-
teger indexes. These sequences were padded with
zeros so that the tweets in each batch have the
same length during training. They were then fed
into an embedding layer which maps word in-
dexes to word embeddings. We trained our word
embeddings using GenSim 1. We also used the
Twitter-CBOW 300-dimension embedding model
provided by AraVec (Soliman et al., 2017) which
contains over 331k word vectors that have been
trained on about 67M Arabic tweets. We concate-
nated our own trained embeddings with the Ar-
aVec embeddings to obtain 600-dimensional em-
beddings Similar to (Albadi et al., 2018), The out-
put of the embedding layer was fed into a dropout
layer with a rate of 0.5 to prevent overfitting.

For both LSTM and GRU, the word embed-
dings were passed to both unidirectional and bidi-
rectional LSTM with 240 features each. In the
GRU-CNN/LSTM-CNN models, we used 2 Con-
volutional Layers with a Kernel Size of 3 and Relu
Activation in the middle. We obtained the final
representation by taking the maximum along the
temporal dimension. For self-attention, the output
of the GRU/LSTM was passed to a self-attention
layer. For the self-attention models, we used 240
features.

We compared each of these models with their
counterparts obtained by concatenating Node2Vec
embeddings to the representations obtained by the
above deep learning models. The final represen-
tation was then passed into a Sigmoid Layer. We
performed training in batches of size 32, and we
used Adam as our optimizer for all experiments.

5 Results And Discussion

In our experiments, we have beaten the scores
of (Albadi et al., 2018) in all 5 metrics. We
obtained a highest f1-score of 0.78 as com-
pared to 0.77 in (Albadi et al., 2018). This is
achieved in our LSTM + CNN + CISNet model.
The ARHNet model outperforms baselines in
terms of Recall, F1 and AUROC metrics while

1radimrehurek.com/gensim/models/word2vec.html

GRU-NODE2VEC demonstrates the highest pre-
cision, and the Bi-GRU-CNN-NODE2VEC model
achieves the highest accuracy. Our methodol-
ogy effectively improves upon the current state of
the art and is successful in demonstration of how
community interaction can be leveraged to tackle
downstream NLP tasks like detection of religious
hate speech. Albadi et al. (2018) reached an 0.81
agreement score between annotators. Our method-
ology, therefore, matches human performance in
terms of unambiguously categorizing texts that
contain religious hate speech from texts that don’t.

To summarize, our approach highlights the va-
lidity of using Community Interaction Graphs as
features of classification in Arabic. Despite hav-
ing a sparse representation of users, our proposed
methodology has shown improvements on Accu-
racy and F1 over previously state of the art models
on a reduced dataset.

6 Conclusion

In this paper, we explored the effectiveness of
community-interaction information about authors
for the purpose of categorizing religious hate
speech in the Arabic Twittersphere and build upon
existing work in the linguistic aspects of social
media (Shah et al., 2016c,a; Mahata et al., 2015).
Working with a dataset of 3950 tweets annotated
for Hate and Non-Hate, we first comprehensively
replicated three established and currently best-
performing hate speech detection methods based
on character n-grams and GRUs as our baselines.
We then constructed a graph of all the authors of
tweets in our dataset and extracted community-
based information in the form of dense low-
dimensional embeddings for each of them using
Node2Vec. We showed that the inclusion of com-
munity graph embeddings significantly improves
system performance over the baselines and ad-
vances the state of the art in this task. Users prone
to proliferate hate do tend to form social groups
online, and this stresses the importance of utilizing
community-based information for automatic reli-
gious hate speech detection.

References

N. Albadi, M. Kurdi, and S. Mishra. 2018. Are they
our brothers? analysis and detection of religious
hate speech in the arabic twittersphere. In 2018
IEEE/ACM International Conference on Advances

https://doi.org/10.1109/ASONAM.2018.8508247
https://doi.org/10.1109/ASONAM.2018.8508247
https://doi.org/10.1109/ASONAM.2018.8508247


279

in Social Networks Analysis and Mining (ASONAM),
pages 69–76.

Silvio Amir, Byron C. Wallace, Hao Lyu, Paula Car-
valho, and Mário J. Silva. 2016. Modelling context
with user embeddings for sarcasm detection in social
media. CoRR, abs/1607.00976.

Pinkesh Badjatiya, Shashank Gupta, Manish Gupta,
and Vasudeva Varma. 2017. Deep learning for hate
speech detection in tweets. CoRR, abs/1706.00188.

Matteo Bonotti. 2017. Religion, hate speech and non-
domination. Ethnicities, 17:259–274.

Wei-Fan Chen and Lun-Wei Ku. 2016. UTCNN: a
deep learning model of stance classification on so-
cial media text. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics: Technical Papers, pages 1635–1645,
Osaka, Japan. The COLING 2016 Organizing Com-
mittee.

Thomas Davidson, Dana Warmsley, Michael W. Macy,
and Ingmar Weber. 2017. Automated hate speech
detection and the problem of offensive language.
CoRR, abs/1703.04009.

Nemanja Djuric, Jing Zhou, Robin Morris, Mihajlo Gr-
bovic, Vladan Radosavljevic, and Narayan Bhamidi-
pati. 2015. Hate speech detection with comment
embeddings. In Proceedings of the 24th Interna-
tional Conference on World Wide Web, WWW ’15
Companion, pages 29–30, New York, NY, USA.
ACM.

Teona Gelashvili. 2018. Hate speech on social media:
Implications of private regulation and governance
gaps. Student Paper.

Aditya Grover and Jure Leskovec. 2016. node2vec:
Scalable feature learning for networks. CoRR,
abs/1607.00653.

Dirk Hovy. 2015. Demographic factors improve clas-
sification performance. In Proceedings of the 53rd
Annual Meeting of the Association for Computa-
tional Linguistics and the 7th International Joint
Conference on Natural Language Processing (Vol-
ume 1: Long Papers), pages 752–762, Beijing,
China. Association for Computational Linguistics.

Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2016.
Recurrent neural network for text classification with
multi-task learning. CoRR, abs/1605.05101.

Walid Magdy, Kareem Darwish, and Ingmar We-
ber. 2015. #failedrevolutions: Using twitter to
study the antecedents of ISIS support. CoRR,
abs/1503.02401.

Debanjan Mahata, Jasper Friedrichs, Rajiv Ratn Shah,
and Jing Jiang. 2018. Detecting personal intake of
medicine from twitter. IEEE Intelligent Systems,
33(4):87–95.

Debanjan Mahata, John R Talburt, and Vivek Kumar
Singh. 2015. From chirps to whistles: discover-
ing event-specific informative content from twitter.
In Proceedings of the ACM web science conference,
page 17. ACM.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed represen-
tations of words and phrases and their composition-
ality. CoRR, abs/1310.4546.

Pushkar Mishra, Marco Del Tredici, Helen Yan-
nakoudakis, and Ekaterina Shutova. 2018. Author
profiling for abuse detection. In COLING.

Rajiv Ratn Shah, Anupam Samanta, Deepak Gupta,
Yi Yu, Suhua Tang, and Roger Zimmermann. 2016a.
Prompt: Personalized user tag recommendation for
social media photos leveraging personal and social
contexts. In 2016 IEEE International Symposium
on Multimedia (ISM), pages 486–492. IEEE.

Rajiv Ratn Shah, Yi Yu, Suhua Tang, Shin’ichi Satoh,
Akshay Verma, and Roger Zimmermann. 2016b.
Concept-level multimodal ranking of flickr photo
tags via recall based weighting. In Proceedings
of the 2016 ACM Workshop on Multimedia COM-
MONS, pages 19–26. ACM.

Rajiv Ratn Shah, Yi Yu, Akshay Verma, Suhua Tang,
Anwar Dilawar Shaikh, and Roger Zimmermann.
2016c. Leveraging multimodal information for
event summarization and concept-level sentiment
analysis. Knowledge-Based Systems, 108:102–109.

Abu Bakr Soliman, Kareem Eissa, and Samhaa R. El-
Beltagy. 2017. Aravec: A set of arabic word embed-
ding models for use in arabic nlp. Procedia Com-
puter Science, 117:256 – 265. Arabic Computa-
tional Linguistics.

C. Tlmcel and F. Leon. 2017. Predicting political opin-
ions in social networks with user embeddings. In
2017 13th IEEE International Conference on In-
telligent Computer Communication and Processing
(ICCP), pages 213–219.

Zeerak Waseem and Dirk Hovy. 2016. Hateful sym-
bols or hateful people? predictive features for hate
speech detection on twitter. In Proceedings of the
NAACL Student Research Workshop, pages 88–93,
San Diego, California. Association for Computa-
tional Linguistics.

Yi Yang, Ming-Wei Chang, and Jacob Eisenstein.
2016. Toward socially-infused information extrac-
tion: Embedding authors, mentions, and entities.
CoRR, abs/1609.08084.

Yi Yang and Jacob Eisenstein. 2015. Putting
things in context: Community-specific embed-
ding projections for sentiment analysis. CoRR,
abs/1511.06052.

Dawei Yin and Brian D. Davison. 2009. Detection of
harassment on web 2.0.

http://arxiv.org/abs/1607.00976
http://arxiv.org/abs/1607.00976
http://arxiv.org/abs/1607.00976
http://arxiv.org/abs/1706.00188
http://arxiv.org/abs/1706.00188
https://doi.org/10.1177/1468796817692626
https://doi.org/10.1177/1468796817692626
https://www.aclweb.org/anthology/C16-1154
https://www.aclweb.org/anthology/C16-1154
https://www.aclweb.org/anthology/C16-1154
http://arxiv.org/abs/1703.04009
http://arxiv.org/abs/1703.04009
https://doi.org/10.1145/2740908.2742760
https://doi.org/10.1145/2740908.2742760
http://arxiv.org/abs/1607.00653
http://arxiv.org/abs/1607.00653
https://doi.org/10.3115/v1/P15-1073
https://doi.org/10.3115/v1/P15-1073
http://arxiv.org/abs/1605.05101
http://arxiv.org/abs/1605.05101
http://arxiv.org/abs/1503.02401
http://arxiv.org/abs/1503.02401
http://arxiv.org/abs/1310.4546
http://arxiv.org/abs/1310.4546
http://arxiv.org/abs/1310.4546
https://doi.org/https://doi.org/10.1016/j.procs.2017.10.117
https://doi.org/https://doi.org/10.1016/j.procs.2017.10.117
https://doi.org/10.1109/ICCP.2017.8117006
https://doi.org/10.1109/ICCP.2017.8117006
https://doi.org/10.18653/v1/N16-2013
https://doi.org/10.18653/v1/N16-2013
https://doi.org/10.18653/v1/N16-2013
http://arxiv.org/abs/1609.08084
http://arxiv.org/abs/1609.08084
http://arxiv.org/abs/1511.06052
http://arxiv.org/abs/1511.06052
http://arxiv.org/abs/1511.06052


280

Chunting Zhou, Chonglin Sun, Zhiyuan Liu, and Fran-
cis C. M. Lau. 2015. A C-LSTM neural network for
text classification. CoRR, abs/1511.08630.

http://arxiv.org/abs/1511.08630
http://arxiv.org/abs/1511.08630

