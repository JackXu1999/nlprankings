



















































Jiuge: A Human-Machine Collaborative Chinese Classical Poetry Generation System


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 25–30
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

25

Jiuge: A Human-Machine Collaborative Chinese Classical Poetry
Generation System

Zhipeng Guo1∗ , Xiaoyuan Yi1∗, Maosong Sun1† ,
Wenhao Li1, Cheng Yang1, Jiannan Liang1, Huimin Chen1, Yuhui Zhang1, Ruoyu Li2
1Department of Computer Science and Technology, Tsinghua University, Beijing, China

Institute for Artificial Intelligence, Tsinghua University, Beijing, China
State Key Lab on Intelligent Technology and Systems, Tsinghua University, Beijing, China

26ESTATES PTE LTD, Singapore

Abstract

Research on the automatic generation of po-
etry, the treasure of human culture, has lasted
for decades. Most existing systems, however,
are merely model-oriented, which input some
user-specified keywords and directly complete
the generation process in one pass, with lit-
tle user participation. We believe that the
machine, being a collaborator or an assistant,
should not replace human beings in poetic cre-
ation. Therefore, we proposed Jiuge, a human-
machine collaborative Chinese classical po-
etry generation system. Unlike previous sys-
tems, Jiuge allows users to revise the unsatis-
fied parts of a generated poem draft repeatedly.
According to the revision, the poem will be dy-
namically updated and regenerated. After the
revision and modification procedure, the user
can write a satisfying poem together with Ji-
uge system collaboratively. Besides, Jiuge can
accept multi-modal inputs, such as keywords,
plain text or images. By exposing the options
of poetry genres, styles and revision modes, Ji-
uge, acting as a professional assistant, allows
constant and active participation of users in
poetic creation.

1 Introduction

Language is one of the most important forms of
human intelligence, among different genres, po-
etry is a beautiful, poetic and artistic genre which
expresses one’s emotions and ideas with relatively
fewer words. Across various countries, nationali-
ties, and cultures, poetry is always fascinating, im-
pacting profoundly on the development of human
civilization.

Recently, researchers have worked on automatic
poetry generation. Meanwhile, neural networks
have proven to be powerful on this task (Zhang
and Lapata, 2014; Wang et al., 2016; Yan, 2016;

∗ indicates equal contribution
† Corresponding author: M.Sun(sms@tsinghua.edu.cn)

Zhang et al., 2017; Yi et al., 2017). Besides the
research value of exploring human writing mech-
anism and computer creativity, these models and
systems could also benefit electronic entertain-
ment, advertisement, and poetry education.

However, the recently released Chinese poetry
generation systems are mainly model-oriented,
which take some user inputs and directly complete
the generation in one pass, resulting in poor user
participation. Moreover, these systems generate
poetry in fewer styles and genres, and provide lim-
ited options for users. For example, the Daoxi-
angju system1 requires the user to determine the
rhyme, which creates a barrier for beginners. The
Oude system2 simplifies the user’s choices and
only allows the input of a few options and genres.
The Microsoft Quatrain3 provides limited candi-
dates of a theme and each line, but it only supports
the generation of quatrains.

Due to the lack of user participation, the above
systems are mainly designed for entertainment.
We argue that the leading role in literary creation
should not be a machine, or at least not only a ma-
chine, because it is difficult for machines to handle
the complex expressions of one’s emotion and the
use of images in poetic creation.

Rather than completely replace humans, a better
way is to utilize the system to assist human cre-
ation. The human-machine collaboration mech-
anism in Jiuge system can not only improve the
emotions and semantics of generated poems but
also guide and teach beginners to understand the
poetic creation process.

In summary, the contributions of our Jiuge sys-
tem are as follows:

• Multi-modal input. Jiuge can accept multi-
1http://www.poeming.com/web/
2https://crl.ptopenlab.com:8800/poem/index
3http://duilian.msra.cn/jueju/



26

Keywords:

Plain Text:

Picture:

plane, blue sky

There is a plane in the blue sky.

Extract

Expand

Transform

Genre: Quatrain, Acrostic, Iambic

Style: Standard, Sadness about seasons, …

Input Preprocessing Module

Working Memory Model

Genere Control

Unsupervised Style Control

Main Framework

Acrostic Poetry Generation 

Generation Model 

Pattern Checking

Re-Ranking

Postprocessing Model 

Automatic Reference Recommendation

Collaborative Revision Module

Revision Modes

Static/Local Dynamic/Global Dynamic

Final Poetry

The swan goose is flying outside 
the clouds.

The heavy mist almost make the 

ferry invisible.

The vast road has extended to 
thousands of miles away.

It's so remote that it seems like it 

reaches the sky.

Keywords: fly, blue sky, swan goose, vast  

Figure 1: The architecture of Jiuge system.

modal input such as keywords, plain text, and
even images. For modern concepts in the in-
put, Jiuge utilizes a knowledge graph to map
them into relevant keywords in classical Chi-
nese poetry.

• Various styles and genres. Unlike previous
systems, Jiuge provides more than twenty op-
tions of genre and ten options of style, and
can generate more diverse poems.

• Human-machine collaboration. Jiuge sup-
ports human-machine collaborative and inter-
active generation. The user can revise the un-
satisfied parts of a generated poem. In terms
of the revision, Jiuge will dynamically update
and re-generate the poem. During this pro-
cess, Jiuge also offers candidate words and
human-authored poetry as references for be-
ginners.

2 Architecture

2.1 Overview

We show the overall architecture of Jiuge system
in Fig. 1, which mainly consists of four modules:
1) input preprocessing, 2) generation, 3) postpro-
cessing and 4) collaborative revision. Given the
user-specified genre, style, and inputs (keywords,
plain text or images), the preprocessing module
extracts several keywords from the inputs and then
conducts keyword expansion to introduce richer
information. Jiuge also transforms the words in
modern concepts, which are incompatible with
classical Chinese poetry (written in ancient Chi-
nese language), such as refrigerator and airplane,
to appropriate relevant ones, e.g., airplane → fly.
With these preprocessed keywords, the generation
module generates a poem draft. The postprocess-
ing module re-ranks the candidates of each line

and removes the ones that do not conform to struc-
tural and phonological requirements. At last, the
collaborative revision module interacts with the
user and dynamically updates the draft for several
times according to the user’s revision, to collabo-
ratively create a satisfying poem.

We detail each module in the following parts.

2.2 Input Preprocessing Module
Keyword Extraction. Jiuge allows multi-modal
input to meet the needs of generating poetry ac-
cording to keywords, tweets or photos.

For plain text, we first use THULAC4 (Li and
Sun, 2009) to conduct Chinese word segmentation
and compute the importance r(w) of each wordw:

r(w)=[α∗ti(w)+(1−α)∗tr(w)], (1)

where ti(w) and tr(w) are the TF-IDF (Term
Frequency-Inverse Document Frequency) value
and TextRank (Mihalcea and Tarau, 2004) score
calculated with the whole poetry corpus respec-
tively. α is a hyper-parameter to balance the
weights of ti(w) and tr(w). Afterwards, we se-
lect top K words with the highest scores.

For each image, we use the Aliyun image recog-
nition tool5, which gives the names of five rec-
ognized objects with corresponding probability
s(w). Then we select top K words with the high-
est s(w) · r(w).

Keyword Mapping. The extracted or recog-
nized keywords could be some modern concepts,
such as airplane and refrigerator. Since these
words never occur in the classical poetry corpus,
the generation module will take them as a UNK
symbol and generate totally irrelevant poems.

To address this problem, we build a Poetry
Knowledge Graph (PKG) from Wikipedia data,

4http://thulac.thunlp.org/
5https://ai.aliyun.com/image



27

PKG

! = 0.33

! = 0.13 ! = 0.08

(fly)

(airplane)

(wind) (wing)

(a)

PWCG

!"#$% = 25.3

!"#$% = 27.1 !"#$% = 20.7

(egret)

(swan goose)

(fly)

(butterfly)

(b)

Figure 2: (a) A sampled subgraph of PKG. (b) A sam-
pled subgraph of PWCG.

which contains 616, 360 entities and 5, 102, 192
relations. 40, 276 of these entities occur in our po-
etry corpus. Before keywords extension and selec-
tion, we first use PKG to map the modern concepts
to its most relevant entities in poetry, to guarantee
both quality and relevance of generated poems.

For a modern concept word wi, we score its
each neighbor word wj by:

g(wj)= tfwiki(wj |wi) · log(
N

1+df(wj)
) · arctan(p(wj)

τ
),

(2)

where tfwiki(wj |wi) is the term frequency of wj
in the Wikipedia article of wi, df(wj) is the num-
ber of Wikipedia articles containing wj , N is the
number of Wikipedia articles, and p(wj) is the
word frequency counted in all articles. We give an
example of mapping the modern word “airplane”
in Fig. 2(a).

Keyword Extension. The generation module
can handle multi-keywords input. More keywords
could lead to richer contents and emotions in gen-
erated poems. Therefore, if the number of ex-
tracted keywords is less than K, we further con-
duct keywords extension. To this end, we build
a Poetry Word Co-occurrence Graph (PWCG) as
shown in Fig. 2 (b). This graph indicates the co-
occurrence of two words in the same poem. The
weight of the edge between two words is calcu-
lated according to the Pointwise Mutual Informa-
tion (PMI) as follows:

PMI(wi, wj) = log
p(wi, wj)

p(wi) ∗ p(wj)
, (3)

where p(wi) and p(wi, wj) are the word frequency
and co-occurrence frequency in poetry corpus. For
a given word w, we get all its adjacent words wk
in PWCG and select those with higher values of
log p(wk) ∗ PMI(w,wk) + β ∗ r(wk) where β is
a hyperparameter.

2.3 Generation Module
As shown in Fig. 3, the core component of the
generation module is our proposed working mem-

Figure 3: The simplified structure of the working mem-
ory model, which mainly comprise an encoder, a de-
coder and there memory components. xi is the i-th line
and xi,j is the j-word in the i-th line. Please refer to (Yi
et al., 2018b) for more details.

ory model (Yi et al., 2018b), which takes at most
K preprocessed keywords as input. The encoder
maps each word or line into vector representa-
tions, and the decoder generates each line word-
by-word. The topic memory stores keywords ex-
plicitly and independently, which can learn a flex-
ible order and form of keywords expression. The
history memory and local memory are dynami-
cally read and written to improve the context co-
herence of generated poems.

Genere Control. Chinese classical poetry in-
volves various genres, and each genre strictly de-
fines the structural and phonological pattern of a
poem, such as the length of each line, the tone
of each word, and the number of lines. We use
our designed genre embedding (Yi et al., 2018b)
to disentangle the semantic content and the genre
pattern. The genre embedding indicates the line
length, word tone, and rhyme, which is fed to the
decoder. By this way, we can train one model with
all genres of poems and control the genre of gen-
erated poems by specifying a pattern.

Training patterns are automatically extracted
from the corpus. For generating, we make the
genre as a user option. However, the selection of
rhyme may be difficult for users without relevant
literature knowledge. Therefore, we train a classi-
fier (implemented with a feedforward neural net-
work) to predict an appropriate rhyme in terms of
the keywords.

Unsupervised Style Control. Besides genres,
there are also diverse styles in Chinese poetry such
as battlefield, romantic, pastoral, etc. For certain
contents or topics, creating different styles of po-
etry is one main user requirement. Since the la-
belled data is quite rare and expensive, we use



28

our proposed style disentanglement model (Yang
et al., 2018) to achieve unsupervised style control.
This method disentangles the style space into M
different sub-spaces by maximizing the mutual in-
formation between the style distribution and the
generated poetry distribution.

It is noteworthy that this method is transparent
to model structures which can be applied to any
generation model. In this stage, we employ it for
the generation of Chinese quatrain poetry (Jueju),
which will be extended to more genres in the fu-
ture. We set the number of styles M = 10. Af-
ter training, we manually annotate each style with
some descriptive phrases, such as sorrow during
drinking and rural scenes, to indicate the theme of
the corresponding style. The style selection is also
set as a user option.

Acrostic Poetry Generation In Chinese po-
etry, there is another special genre called acros-
tic poetry. Given a sequence of words seq =
(x0,0, x1,0, · · · , xn,0), which could be someone’s
name or a blessing sentence, the author is re-
quired to create a poem using each word xi,0 as
the first word of each line xi and the created poem
should also conform to the genre pattern and con-
vey proper semantic meanings.

The input for this genre is the sequence seq.
As our generation module takes keywords as in-
put, we first use pre-trained word2vec embeddings
(Mikolov et al., 2013) to get K keywords related
to seq according to the cosine distance of each
keyword and the words in seq. Then we directly
feed each xi,0 into the decoder at the first step.

To alleviate the disfluency caused by this
constraint, we generate the second word with
the conditional probability: pgen(xi,1|xi,0) =
pdec(xi,1|xi,0)+ δ ∗plm(xi,1|xi,0), where pdec and
plm are probability distributions of the decoder
and a neural language model respectively.

If the length of the input sequence is less than
n (the number of lines in a poem), we also use the
language model to extend it to n words.

2.4 Postprocessing Module

Jiuge takes a line-to-line generation schema and
generates each line with beam search (beam
size=B). As a result, we can get B candidates for
each line. We design a postprocessing module to
automatically check and re-rank these candidates,
and then select the best one, which is used for the
generation of subsequent lines in a poem.

Pattern Checking. The genre embedding intro-
duced in Sec. 2.3 cannot guarantee that generated
poems perfectly adhere to required patterns. Thus,
we further remove the invalid candidates accord-
ing to the specified length, rhythm, and rhyme.

Re-Ranking. Our preliminary experiments
show that the best candidate may not be ranked as
the top 1 because the training objective is Maxi-
mum Likelihood Estimation (MLE), which tends
to give the generic and meaningless candidates
lower costs (Yi et al., 2018a). To automatically
select the best candidate, we adopt the automatic
rewarders we proposed in (Yi et al., 2018a), in-
cluding a fluency rewarder, a context coherence
rewarder, and a meaningfulness rewarder. Then
the candidate with the highest weighted-average
rewards given by them will be selected.

2.5 Collaborative Revision Module
We call the poem generated by the generation
module in one pass the draft, since the user may
revise it for several times to collaboratively cre-
ate a satisfying poem together with the machine.
We implement such collaboration with a revision
module.

Revision Modes. Define a n-line poem draft
as X = (x1, x2, · · · , xn), and each line contain-
ing li words as xi = (xi,1, xi,2, ..., xi,li). At ev-
ery turn, the user can revise one word in the draft.
Then the revision module returns the revision in-
formation to the generation module which updates
the draft according to the revised word. We imple-
ment three revision modes in terms of the updating
way: static, local dynamic, and global dynamic.

• Static updating mode. The revision is re-
quired to meet the phonological pattern of the
draft and the draft will not be updated except
the revised word. The rhythm and rhyme in-
formation is given to the user together with
the generated draft and the invalid revision
will be alerted. During the beam search pro-
cess, we also store top 10 candidate words in
each position as recommendations.

• Local dynamic updating mode. If the
user revises word xi,j , then Jiuge will
re-generate the succeeding subsequence,
xi,j+1, · · · , xi,li , in the i-th line by feeding
the revised word to the decoder for the re-
vised position.

• Global dynamic updating mode.



29

If the user revises word xi,j , Jiuge
will re-generate all succeeding words,
xi,j+1, · · · , xi,li , · · · , xn,ln . In terms of the
revision position, e.g., the rhymed positions,
a new phonological pattern may be adopted.

Thanks to this collaborative revision-updating pro-
cess, the user can choose a mode and gradually re-
vise the draft until she/he feels satisfied.

Automatic Reference Recommendation. For
poetry writing beginners or these lacking profes-
sional knowledge, it is hard to revise the draft ap-
propriately. To aid in the revision process, we
implement an automatic recommendation compo-
nent. This component searches several human-
authored poems, which are semantically similar
to the generated draft, for the user as references.
Then the user could decide how to make revision
with these references.

In detail, define a n-line human-created poem as
Y = (y1, · · · , yn) and a relevance scoring func-
tion as rel(xi, yi) to give the relevance of two
lines. Then we return N poems with the highest
relevance score rs(X,Y ), calculated as:

rs(X,Y )=

n∑
i=1

rel(xi, yi) + γ ∗ I(Y ∈ Dmaster), (4)

where Dmaster is a poetry set of masterpieces, I
is the indicator function, and the hyper-parameter
γ is specified to balance the quality and relevance
of searched poems. For more details of the rele-
vance scoring function, we refer the reader to our
previous work (Liang et al., 2018).

3 Demonstration

We implement a webpage version of Jiuge6 which
allows users to create diverse poems and share
with the others conveniently. The initial page pro-
vides some basic options: multi-modal input and
the selection of genre and style, as shown in Fig. 4.

Jiuge is easy to use. After selecting the in-
put mode and providing corresponding content,
the user can further choose a favourite genre and
style7. As shown in Fig. 5 (a), the user inputs two
keywords, desert and cavalry, and chooses to gen-
erate a quatrain with the normal style. Then the
user clicks the “Generate Poetry” button. After a
few seconds, the system returns the processed key-
words and a poem draft.

6Our system is available at https://jiuge.
thunlp.cn/ .

7Temporarily only the Jueju genre supports multiple
styles.

Figure 4: The initial page of Jiuge System.

In order to help the user collaboratively revise
the generated poem, Jiuge provides some high-
quality human-authored poems which are seman-
tically similar to the generated one, as the refer-
ences. The user can click the button to change
the references. At this time, the user can select
an unsatisfying word to be revised in the draft
and then Jiuge will give some recommended re-
vision candidates. Besides these candidates, other
choices are also allowed. After selecting the revi-
sion mode introduced in Sec. 2.5, Jiuge will update
or re-generate the draft according to the revised
word. Through several turns of collaborative revi-
sion, the user and Jiuge work together to create a
satisfying poem, as in Fig. 5 (b)8.

In addition, Jiuge also supports picture sharing.
By clicking the “Share Poetry” button, Jiuge will
print the created poem on a beautiful picture so
that the user can share it with others.

4 Conclusion and Future Work

We demonstrate Jiuge, a human-machine collab-
orative Chinese classical poetry generation sys-
tem. Our system accepts multi-modal input and
allows deep user participation in the choice of var-
ious styles and genres, as well as in collaborative
revision. With an easy-to-use web interface, the
user can collaboratively create a satisfying poem
together with the system. Instead of being a simple
entertainment software, Jiuge takes a step towards
professional AI assistant for poetic education.

We collect a large number of human usage
records from the interface, laying the foundation
for enhancing the collaborative creation method
in the future. We will also continue to integrate

8The poems in Fig.5 are manually translated for better
demonstration. In practice, we utilize a neural translation
model to conduct automatic translation.

https://jiuge.thunlp.cn/
https://jiuge.thunlp.cn/


30

(a) (b)

Figure 5: The collaborative creation page: an example of revision. (a) The poem draft generated in one pass. (b)
The poem after four turns of revision and updating.

more styles and extend the collaborative creation
to more genres.

5 Acknowledgements

We would like to thank Cunchao Tu, Yunqiu Shao
and anonymous reviewers for their insightful com-
ments. It is supported by Natural Science Foun-
dation of China (NSFC) Grant 61532001 and the
NExT++ project, the National Research Founda-
tion, Prime Ministers Office, Singapore under its
IRC@Singapore Funding Initiative.

References
Zhongguo Li and Maosong Sun. 2009. Punctuation as

implicit annotations for chinese word segmentation.
computational linguistics. Computational Linguis-
tics, 35(4):505–512,.

Jiannan Liang, Maosong Sun, Xiaoyuan Yi, Cheng
Yang, Huimin Chen, and Zhenghao Liu. 2018. Neu-
ral network-based jiju poetry generation. In Pro-
ceedings of the Seventeenth China National Con-
ference on Computational Linguistics, Changsha,
China.

Rada Mihalcea and Paul Tarau. 2004. Textrank: Bring-
ing order into text. In Proceedings of the 2004 Con-
ference on Empirical Methods in Natural Language
Processing.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.

Zhe Wang, Wei He, Hua Wu nad Haiyang Wu, Wei
Li, Haifeng Wang, and Enhong Chen. 2016. Chi-
nese poetry generation with planning based neu-
ral network. In Proceedings of COLING 2016,
the 26th International Conference on Computational
Linguistics:Technical Papers, pages 1051–1060, Os-
aka, Japan.

Rui Yan. 2016. i,poet:automatic poetry composition
through recurrent neural networks with iterative pol-
ishing schema. In Proceedings of the Twenty-Fifth
International Joint Conference on Artificial Intelli-
gence, pages 2238–2244, New York, USA.

Cheng Yang, Maosong Sun, Xiaoyuan Yi, and Wenhao
Li. 2018. Stylistic chinese poetry generation via un-
supervised style disentanglement. In Proceedings of
the 2018 Conference on Empirical Methods in Nat-
ural Language Processing, pages 3960–3969, Brus-
sels, Belgium.

Xiaoyuan Yi, Ruoyu Li, and Maosong Sun. 2017. Gen-
erating chinese plassical poems with rnn encoder-
decoder. In Proceedings of the Sixteenth Chinese
Computational Linguistics, pages 211–223, Nan-
jing, China.

Xiaoyuan Yi, Maosong Sun, Ruoyu Li, and Wenhao
Li. 2018a. Automatic poetry generation with mu-
tual reinforcement learning. In Proceedings of the
2018 Conference on Empirical Methods in Natural
Language Processing, pages 3143–3153, Brussels,
Belgium.

Xiaoyuan Yi, Maosong Sun, Ruoyu Li, and Zong-
han Yang. 2018b. Chinese poetry generation with
a working memory mode. In Proceedings of the
Twenty-Seventh International Joint Conference on
Artificial Intelligence, pages 4553–4559, Stock-
holm, Sweden.

Jiyuan Zhang, Yang Feng, Dong Wang, Yang Wang,
Andrew Abel, Shiyue Zhang, and Andi Zhang.
2017. Flexible and creative chinese poetry gener-
ation using neural memory. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics, pages 1364–1373. Association
for Computational Linguistics.

Xingxing Zhang and Mirella Lapata. 2014. Chinese
poetry generation with recurrent neural networks.
In Proceedings of the 2014 Conference on Empiri-
cal Methods in Natural Language Processing, pages
670–680, Doha, Qatar.


