



















































Fact Discovery from Knowledge Base via Facet Decomposition


Proceedings of NAACL-HLT 2019, pages 2892–2901
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

2892

Fact Discovery from Knowledge Base via Facet Decomposition

Zihao Fu1, Yankai Lin2, Zhiyuan Liu2∗, Wai Lam1
1 Department of Systems Engineering and Engineering Management

The Chinese University of Hong Kong, Hong Kong
2 Department of Computer Science and Technology,

State Key Lab on Intelligent Technology and Systems,
National Lab for Information Science and Technology, Tsinghua University, Beijing, China

Abstract

During the past few decades, knowledge bases
(KBs) have experienced rapid growth. Never-
theless, most KBs still suffer from serious in-
completion. Researchers proposed many tasks
such as knowledge base completion and re-
lation prediction to help build the representa-
tion of KBs. However, there are some issues
unsettled towards enriching the KBs. Knowl-
edge base completion and relation prediction
assume that we know two elements of the fact
triples and we are going to predict the miss-
ing one. This assumption is too restricted in
practice and prevents it from discovering new
facts directly. To address this issue, we pro-
pose a new task, namely, fact discovery from
knowledge base. This task only requires that
we know the head entity and the goal is to
discover facts associated with the head en-
tity. To tackle this new problem, we propose
a novel framework that decomposes the dis-
covery problem into several facet discovery
components. We also propose a novel auto-
encoder based facet component to estimate
some facets of the fact. Besides, we propose a
feedback learning component to share the in-
formation between each facet. We evaluate our
framework using a benchmark dataset and the
experimental results show that our framework
achieves promising results. We also conduct
extensive analysis of our framework in discov-
ering different kinds of facts. The source code
of this paper can be obtained from https:
//github.com/thunlp/FFD.

1 Introduction

Recent years have witnessed the emergence
and growth of many large-scale knowledge
bases (KBs) such as Freebase (Bollacker et al.,
2008), DBpedia (Lehmann et al., 2015), YAGO
(Suchanek et al., 2007) and Wikidata (Vrandečić

∗ Corresponding author: Zhiyuan Liu (li-
uzy@tsinghua.edu.cn).

Serena 
Williams

BirthPlace

Best 
Female Tennis 
Player Award

AwardReceived

Serena 
Williams

BirthPlace

Best 
Female Tennis 
Player Award

AwardReceived

Gender Nationality

Tennis Player

ProfessionLanguage

USAFemale

English

SaginawSaginaw

Figure 1: In the FDKB task, only the head entity is
given. The relation and tail entity should be discovered
simultaneously given the head entity.

and Krötzsch, 2014) to store facts of the real
world. Most KBs typically organize the complex
structured information about facts in the form of
triples (head entity, relation, tail entity), e.g.,
(Bill Gates, CEOof, Microsoft Inc.). These KBs
have been widely used in many AI and NLP tasks
such as text analysis (Berant et al., 2013), question
answering (Bordes et al., 2014a), and information
retrieval (Hoffmann et al., 2011).

The construction of these KBs is always an on-
going process due to the endless growth of real-
world facts. Hence, many tasks such as knowl-
edge base completion (KBC) and relation predic-
tion (RP) are proposed to enrich KBs.

The KBC task usually assumes that one entity
and the relation r are given, and another entity is
missing and required to be predicted. In general,
we wish to predict the missing entity in (h, r, ?)
or (?, r, t), where h and t denote a head and tail
entity respectively. Similarly, the RP task pre-
dicts the missing relation given the head and tail
entities and their evidence sentences, i.e. filling
(h, ?, t). Nevertheless, the assumption of knowing
two parts of the triple is too strong and is usually
restricted in practice.

In many cases, we only know the entity of in-

https://github.com/thunlp/FFD
https://github.com/thunlp/FFD


2893

terest, and are required to predict both its attribu-
tive relations and the corresponding entities. As
shown in Figure 1, the task is to predict the fact
triples when given only the head entity, i.e. filling
(h, ?, ?). Since any entity can serve as the head
entity for identifying its possible fact triples, this
task should be more practical for real-world set-
tings. This task is non-trivial since less informa-
tion is provided for prediction. We name the task
as Fact Discovery from Knowledge Base (FDKB).

Some existing methods such as knowledge base
representation (KBR) can be applied to tackle the
FDKB task with simple modifications. KBR mod-
els typically embed the semantics of both enti-
ties and relations into low-dimensional semantic
space, i.e., embeddings. For example, TransE
(Bordes et al., 2013) learns low-dimensional and
real-valued embeddings for both entities and rela-
tions by regarding the relation of each triple fact
as a translation from its head entity to the tail en-
tity. TransE can thus compute the valid score for
each triple by measuring how well the relation can
play a translation between the head and tail enti-
ties. Many methods have been proposed to extend
TransE to deal with various characteristics of KBs
(Ji et al., 2015, 2016; He et al., 2015; Lin et al.,
2015a).

To solve the FDKB task using KBR, one fea-
sible way is to exhaustively calculate the scores
of all (r, t) combinations for the given head en-
tity h. Afterwards, the highly-scored facts are re-
turned as results. However, this idea has some
drawbacks: (1) It takes all relations to calculate
ranking scores for each head entity, ignoring the
nature of the head entity. The combination of all
possible relations and tail entities will lead to huge
amount of computations. (2) A large set of candi-
date triples immerses the correct triples into a lot
of noisy triples. Although the probability of in-
valid facts getting a high score is small, with the
large size of the candidate set, the total number of
invalid facts with high score is non-negligible.

To address the above issues, we propose a
new framework named as fact facet decomposi-
tion (FFD). The framework follows human being’s
common practice to identify unknown facts: One
typically firstly investigates which relation that a
head may have, and then predicts the tail entity
based on the predicted relation. This procedure
actually utilizes information from several perspec-
tives. Similarly, FFD decomposes fact discovery

into several facets, i.e., head-relation facet, tail-
relation facet, and tail inference facet, and model
each facet respectively. The candidate fact is con-
sidered to be correct when all of the facets are
trustworthy. We propose a novel auto-encoder
based entity-relation component to discover the re-
latedness between entities and relations. Besides,
we also propose a feedback learning component to
share the information between each facet.

We have conducted extensive experiments using
a benchmark dataset to show that our framework
achieves promising results. We also conduct an
extensive analysis of the framework in discovering
different kinds of facts. The contributions of this
paper can be summarized as follows: (1) We intro-
duce a new task of fact discovery from knowledge
base, which is more practical. (2) We propose a
new framework based on the facet decomposition
which achieves promising results.

2 Related Work

In recent years, many tasks (Wang et al., 2017)
have been proposed to help represent and enrich
KBs. Tasks such as knowledge base completion
(KBC) (Bordes et al., 2013; Wang et al., 2014;
Ji et al., 2015, 2016; Wang et al., 2017) and rela-
tion prediction (RP) (Mintz et al., 2009; Lin et al.,
2015a; Xie et al., 2016) are widely studied and
many models are proposed to improve the perfor-
mance on these tasks. However, the intention of
these tasks is to test the performance of models
in representing KBs and thus they cannot be used
directly to discover new facts of KBs. Moreover,
our FDKB task is not a simple combination of the
KBC and RP task since both of these two tasks re-
quire to know two of the triples while we assume
we only know the head entity.

A common approach to solving these tasks is
to build a knowledge base representation (KBR)
model with different kinds of representations.
Typically, one element of the triples is unknown.
Then, all entities are iterated on the unknown el-
ement and the scores of all combinations of the
triples are calculated and then sorted.

Many works focusing on KBR attempt to
encode both entities and relations into a low-
dimensional semantic space. KBR models can
be divided into two major categories, namely
translation-based models and semantic matching
models (Wang et al., 2017).

Translation-based models such as TransE (Bor-



2894

des et al., 2013) achieves promising perfor-
mance in KBC with good computational effi-
ciency. TransE regards the relation in a triple as
a translation between the embedding of head and
tail entities. It means that TransE enforces that the
head entity vector plus the relation vector approx-
imates the tail entity vector to obtain entity and re-
lation embeddings. However, TransE suffers from
problems when dealing with 1-to-N, N-to-1 and
N-to-N relations. To address this issue, TransH
(Wang et al., 2014) enables an entity to have dis-
tinct embeddings when involving in different rela-
tions. TransR (Lin et al., 2015b) models entities
in entity space and uses transform matrices to map
entities into different relation spaces when involv-
ing different relations. Then it performs transla-
tions in relation spaces. In addition, many other
KBR models have also been proposed to deal with
various characteristics of KBs, such as TransD (Ji
et al., 2015), KG2E (He et al., 2015), PTransE (Lin
et al., 2015a), TranSparse (Ji et al., 2016).

Semantic matching models such as RESCAL
(Nickel et al., 2011), DistMult(Yang et al., 2014),
Complex (Trouillon et al., 2016), HolE (Nickel
et al., 2016) and ANALOGY (Liu et al., 2017)
model the score of triples by the semantic simi-
larity. RESCAL simply models the score as a bi-
linear projection of head and tail entities. The bi-
linear projection is defined with a matrix for each
relation. However, the huge amount of parameters
makes the model prone to overfitting. To allevi-
ate the issue of huge parameter space, DistMult is
proposed to restrict the relation matrix to be diag-
onal. However, DistMult cannot handle the asym-
metric relations. To tackle this problem, Com-
plex is proposed assuming that the embeddings of
entities and relations lie in the space of complex
numbers. This model can handle the asymmet-
ric relations. Later, Analogy is proposed by im-
posing restrictions on the matrix rather than build-
ing the matrix with vector. It achieves the state-
of-the-art performance. Besides, (Bordes et al.,
2011; Socher et al., 2013; Chen et al., 2013; Bor-
des et al., 2014b; Dong et al., 2014; Liu et al.,
2016) conduct the semantic matching with neural
networks. An energy function is used to jointly
embed relations and entities.

3 Problem Formulation

We denote E as the set of all entities in KBs, R is
the set containing all relations. |E| and |R| stand

for the size of each set respectively. A fact is a
triple (h, r, t) in which h, t ∈ E and r ∈ R. T is
the set of all true facts.

When a head entity set H is given, a new fact
set is to be discovered based on these head enti-
ties. The discovered fact set is denoted as Td =
{(h, r, t)|h ∈ H}. Our goal is to find a fact set Td
that maximize the number of correct discovered
facts:

max
Td
|Td ∩ T |

s.t. |Td| = K,
(1)

in which K is a user-specified size.

4 Methodology

4.1 Fact Facet Decomposition Framework
Problem (1) is intractable since the set T is un-
known. We tackle this problem by estimating a
fact confidence score function c(h, r, t) for each
fact in Td and maximize the total score. The prob-
lem is then formulated as:

max
Td

∑
(h,r,t)∈Td

c(h, r, t)

s.t. |Td| = K.
(2)

To integrate the information from various facets
of the fact, our framework, known as Fact Facet
Decomposition (FFD) framework, decomposes
the fact discovery problem into several facet-
oriented detection tasks. A fact is likely to be cor-
rect if all facets provide supportive evidence. The
facets are as follows:

1. Head-relation facet: A fact is likely true, if
the head entity has a high probability of con-
taining the relation. This is denoted as fh(r);

2. Tail-relation facet: A fact is likely true, if the
tail entity has a high probability of containing
the relation. This is denoted as ft(r);

3. Tail inference facet: A fact is likely true, if
the score of the tail entity is high with respect
to the given head and relation. This is de-
noted as fh,r(t).

Therefore, the facet confidence score can be ex-
pressed as:

c(h, r, t) = λ1fh(r) + λ2ft(r) + λ3fh,r(t), (3)

where λ1, λ2, λ3 are weight parameters. The head-
relation facet and the tail-relation facet can be both



2895

KBs

Train Predict

L(ye, ỹe) p̂(r|e)

ỹe ỹe

y0e

ye

x x

e, r1, t1 e, r2, t2 e, r3, t3 e, r4, t4 e, r5, t5

Figure 2: The structure of the entity-relation compo-
nent.

modeled with an entity-relation facet component.
The tail inference facet can be modeled by a KBR
component.

4.1.1 Entity-relation Facet Component
The entity-relation component estimates the prob-
ability of a relation given an entity. The structure
is shown in Figure 2. It is modeled as the log of
the estimated conditional probability:

fe(r) = log p̂(r|e), (4)

where e = h or t. p̂(r|e) aims at measuring the
probability of a relation that this entity may have.
In order to estimate this probability, the existing
relations of a head or tail entity is used to infer
other related relations. For example, if a head en-
tity has an existing fact in which the relation is
“BirthPlace”, we may infer that this head entity
may be a person and some relations such as “Gen-
der”, “Language” may have a high probability of
association with this head entity. Therefore, the
problem is transformed into a problem that esti-
mates the relatedness between relations. To in-
fer the probability of each relation based on exist-
ing relations, we employ a denoising auto-encoder
(Vincent et al., 2008) which can recover almost the
same representation for partially destroyed inputs.
Firstly, facts related to an entity is extracted from
the KBs. Then, this entity is encoded by the exist-
ing relations. Let ye ∈ R|R| be the 0-1 representa-
tion of relations that e has. yei indicates whether
the entity e has the relation i or not. During the

training phase, non-zero elements in ye is ran-
domly set to zero and the auto-encoder is trained
to recover the corrupted elements. The corrupted
vector is denoted as y′e.

Formally, our structure encoder first maps the
corrupted one-hot vector y′e to a hidden represen-
tation x ∈ Rd1 of the entity through a fully con-
nected layer:

x = tanh(Wfy
′
e + bf ), (5)

where Wf ∈ Rd1×|R| is the translation matrix
and bf ∈ Rd1 is the bias vector. x is the vector
representation of the entities in a hidden semantic
space. In this space, similar entities are close to
each other while entities of different types are far
from each other. If some relations are missing, the
fully connected layer will also map the entity into
a nearby position.

Afterwards, x is used to recover the probability
distribution for all relations through a fully con-
nected layer and a sigmoid layer:

ỹe = sigmoid(Wgx + bg), (6)

where Wg ∈ R|R|×d1 and bg ∈ R|R| is the weight
matrix and bias vector of the reverse mapping re-
spectively. ỹe is the recovered probability distri-
bution of each relation (therefore, the sum of each
element in ỹe does not necessarily equal to 1).
This layer will map the entity representation in
the semantic space into a probability vector over
all relations. Since similar entities are located in
the adjacent area, they are likely to have a simi-
lar relation probability. Therefore, the probability
of missing relations will also be high though the
relations are unknown.

We use the original one-hot representation of
the relations and the recovered relation probabil-
ity to calculate a loss function:

L(ye, ỹe) = −
|E|∑
e=1

|R|∑
i=1

{yei log(ỹei) +

(1− yei) log(1− ỹei)}. (7)

The loss function forces the output ỹei to be con-
sistent with yei which makes it capable to dis-
cover all related relations from known relations.
It can be optimized with an Adam (Kingma and
Ba, 2015) based optimizer.

When predicting new facts, the one-hot repre-
sentation ye is sent into the auto-encoder directly



2896

instead of using the corrupted representation. The
result ỹe is the estimated probability of each rela-
tion, i.e.

p̂(r = i|e) = ỹei. (8)
This probability will be high if relation i is closely
related to the existing relations of the entity e.

4.1.2 Tail Inference Facet Component
We use a KBR component to model the tail infer-
ence facet fh,r(t). Three KBR models are investi-
gated namely DistMult, Complex, and Analogy.

The DistMult model defines the score function
as fr(h, t) = hT diag(r)t, in which h, r, t are vec-
tor representation of the head, relation and tail re-
spectively. The learning objective is to maximize
the margin between true facts and false facts. It
can decrease the score of the wrong facts and in-
crease the the score of the true facts at the same
time.

The Complex model employs complex number
as the KBR embedding. Therefore, the score func-
tion is defined as fr(h, t) = Re(hT diag(r)t̄), in
which h, r, t are complex vectors and t̄ stands for
the conjugate of t.

The Analogy model does not restrict the rela-
tion matrix to be diagonal. Therefore, the score
function is fr(h, t) = hTMrt, in which Mr is
the matrix corresponding to the relation r. Since
many relations satisfy normality and commutativ-
ity requirements, the constraints can thus be set
as WrW Tr = W

T
r Wr,∀r ∈ R and WrWr′ =

Wr′Wr,∀r, r′ ∈ R. Solving such a problem
is equivalent to optimizing the same objective
function with the matrix constrained to almost-
diagonal matrices(Liu et al., 2017).

After the score function is calculated, the tail in-
ference facet fh,r(t) is modeled by a softmax func-
tion:

fh,r(t) = log p̂(t|h, r) = log
efr(h,t)∑

t′∈E e
fr(h,t′)

.

(9)
It should be noted that the normalizing step is only
conducted on the tail entities since the head and
relation are the input of the model. We only use
these three models due to the limited space. Other
models can be embedded into our framework eas-
ily in the same way.

4.2 Fact Discovery Algorithm
As mentioned above, we need to calculate fh(r),
ft(r) and fh,r(t). fh(r) and ft(r) are computed

by the entity-relation component while fh,r(t) is
computed by the tail inference component. Recall
that a fact is likely to be true when all the facets ex-
hibit strong support. In other words, we can prune
away the fact if one of the facets is low and stop
calculating other facets. Based on this strategy, we
design two additional constraints on Problem (2).
Therefore, this method can be viewed as a shrink
of the constraint space of the optimization prob-
lem. The new problem can be expressed as:

max
Td

∑
(h,r,t)∈Td

{λ1fh(r) + λ2ft(r) + λ3fh,r(t)}

s.t. h ∈ H; |Td| = K
fh(r) > τh;

∑
r

1(fh(r) > τh) = nh

ft(r) > τt;
∑
r

1(ft(r) > τt) = nt,

(10)
where 1A(x) is an indicator function. 1A(x) = 1
if x ∈ A and 1A(x) = 0 otherwise. nh and nt are
the user-specified parameters indicating top-nh or
top-nt relations are considered. λ1, λ2 and λ3 are
fixed hyperparameters.

Problem (10) is actually a mixed integer linear
programming problem. We start to solve this prob-
lem from the constraints. Since ft(r) is indepen-
dent of the givenH, it can be preprocessed and can
be reused for other queries. When a head entity h
is given, we firstly calculate fh(r) and get top-nh
relations ranked by fh(r). Then, for each relation,
ft(r) is used to get the top-nt entities. Afterwards,
the tail inference facet fh,r(t) will be calculated
for all remaining relations and entities and top-nf
triples will be cached. Finally, top-K̄ facts ranked
by the facet confidence score c(h, r, t) is returned
as the new facts discovered for the entity h, where
K̄ = K/|H| stands for the average fact number
for each head entity.

4.3 Feedback Learning

The three facets depict the characteristics of the
KBs from different perspectives. For example,
the head-relation facet indicates which relation the
head entity may have. The tail-relation facet can
be interpreted in a similar manner. We propose a
feedback learning (FL) component for the facets to
share the information in different perspective with
each other. FL feeds the predicted facts back to the
training set to enhance the training procedure and
iterates predicting and training several times. In



2897

the iteration, the information from different per-
spectives is shared with each facet via the newly
added facts.

Specifically, after predicting the top-nh facts for
each head entity, we select top-nfb (nfb < nh)
most probable facts according to the score of each
triple and then feed them into the existing knowl-
edge base for re-training the FFD model. We re-
peat the above updating operation several rounds.

5 Experiment

5.1 Dataset

We evaluate our framework by re-splitting a
widely used dataset FB15k (Bordes et al., 2013),
which is sampled from Freebase. It contains
1, 345 relations and 14, 951 entities. In FB15k,
some of the testing set’s head entities do not ap-
pear in the training set as head. To evaluate our
framework, we construct the new dataset. We
re-split FB15k into training (Ttrain), validation
(Tvalid) and testing (Ttest) set, and make sure that
there is no overlap between the three sets. For all
head entities in H, a relation ratio R% is used
to assign the facts into training and testing set.
R% relations of a head entity are in the train-
ing set while the other 1 − R% are in the test-
ing set. In order to evaluate the task, we require
that the head entities in H is the same as the test-
ing head entity and is a subset of the training head
set, i.e. H = {h|(h, r, t) ∈ Ttest,∃r, t ∈ E} ⊂
{h|(h, r, t) ∈ Ttrain,∃r, t ∈ E}. We set R = 50.
After the splitting, the training, testing and vali-
dation set size is 509, 339, 41, 861 and 41, 013 re-
spectively.

5.2 Comparison Models

To demonstrate the effectiveness of our frame-
work, we provide several strong comparison mod-
els that can be used in solving this task.

5.2.1 Matrix Factorization Models (SVD and
NMF)

MF models firstly count the frequency of all
relation-tail pairs. Some low-frequency relation-
tail pairs are ignored to save computational time.
Afterwards, we build a (head, relation-tail) co-
occurrence matrix MC ∈ R|E|×p, in which p is
the size of the relation-tail pair set. Each element
MCij in the matrix represents whether the head en-
tity i has the relation-tail pair j or not. Then, the
matrix will be decomposed by the product of two

matrices, i.e.

MC ≈WH, (11)

in which W ∈ R|E|×k, H ∈ Rk×p. k is the hid-
den category number of the head and relation-tail
pairs. The decomposition can be achieved in sev-
eral ways with different assumptions. Two kinds
of matrix decomposition models are used namely
SVD (Halko et al., 2011) and NMF (Lee and Se-
ung, 1999).

In the prediction stage, a new matrix is con-
structed by M ′C = WH . For each row in
M ′C , we record top-K̄ relation-tail pairs and their
scores. The MF models always suffer from the
sparsity problem since a lot of relation-tail pairs
are ignored.

5.2.2 KBR+ Models (DistMult+, Complex+
and Analogy+)

The most straightforward method of estimating
the fact confidence score c(h, r, t) is to use KBR
model directly to evaluate each triples’ score. We
exhaustively score all possible combinations of re-
lations and tails and use the highly-scored facts to
make up the set Td. We select some state-of-the-
art models including DistMult (Yang et al., 2014),
Complex (Trouillon et al., 2016) and Analogy (Liu
et al., 2017). We denote them as DistMult+, Com-
plex+ and Analogy+.

After a KBR model learns a score function
fr(h, t), the probability of each (r, t) pair with re-
spect to a given head entity can be estimated by a
softmax function:

p̂(r, t|h) = e
fr(h,t)∑

r′∈R
∑

t′∈E e
fr′ (h,t

′)
. (12)

Afterwards, the score of each fact is sorted and
top-K̄ relation-tail pairs for a head entity are re-
garded as the predicted results.

5.3 Experimental Setup
There are 2,000 head entities in the testing set.
Therefore, we predict the corresponding relation
and tail entity with respect to these 2,000 head en-
tities. In MF models, only relation-tail pairs that
occur more than 3 times in the training set are con-
sidered (24,615 pairs in total). For each head en-
tity, we set K̄ = 50. In KBR+, we also set K̄ =
50. For our framework, we set nh = nt = 30,
nf = 10, K̄ = 50, λ1 = 1.0, λ2 = 1.0, λ3 = 0.5.
The auto-encoder iterates for 1,000 epochs and the



2898

learning rate for Adam is 0.005. For the feedback
learning component, we set nfb = 20, 000. With
this setting, each model returns 100,000 facts.

We use four evaluation metrics, including pre-
cision, recall MAP, and F1 in relation prediction.
Precision is defined as the ratio of the true positive
candidates’ count over the number of all the re-
trieved candidates’ count. Recall is defined as the
ratio of the true positive candidates’ count over all
the positive facts’ count in the testing set. MAP
(Manning et al., 2008) is a common evaluation
method in information retrieval tasks. F1 is de-
fined as the harmonic mean of the precision and
recall.

5.4 Experimental Results
The experimental result is shown in Table 1. From
the experiment result, we observe that:

Method MAP precision recall F1
SVD 0.0873 0.0897 0.2143 0.1265
NMF 0.0827 0.0857 0.2048 0.1209

DistMult+ 0.1086 0.1068 0.2552 0.1506
Complex+ 0.2384 0.1608 0.3842 0.2267
Analogy+ 0.2367 0.1606 0.3837 0.2265

FFD
(DistMult) 0.2486 0.1939 0.4633 0.2734

FFD
(Complex) 0.2723 0.1991 0.4758 0.2808

FFD (Analogy) 0.2769 0.2001 0.4779 0.2821
FFD (Analogy)

w/o FL 0.2308 0.1978 0.4725 0.2788

Table 1: Results of our framework and comparison
models.

1. FFD based model outperforms other mod-
els in all metrics. It illustrates the advan-
tage of our decomposition design. Moreover,
in FFD, using Analogy to predict c(h, r, t)
outperforms Complex. One reason is that
the discovery algorithm harness the relatively
large parameter space of Analogy and avoids
some occasionally emerging wrong facts;

2. The relation of the head entity can be cor-
rectly predicted. This is because, in train-
ing, we remove some relations and the auto-
encoder is trained to learn to recover the
missing relations based on the remaining re-
lations.

3. The MF based models (i.e. SVD and NMF)
perform not as good as KBR+ models and
FFD. The reason is partially due to the spar-
sity problem in MF models. A lot of relation-

100 101 102 103
Average head per tail (hpt)

0.00

0.25

0.50

0.75

1.00

Pr
ec

isi
on

SVD Analogy+ FFD(Analogy)

100 101 102
Average tail per head (tph)

Figure 3: Precision on each relation. Deep color stand
for the number of fact is large.

tail pairs have not been used as the feature
and thus cannot be predicted;

4. Different from the traditional KBC task,
Complex performs slightly better than Anal-
ogy. One reason is that Analogy’s constraint
is looser than Complex. Therefore, it may
easily predict wrong facts due to error propa-
gation;

5. The ablation experiment shows that the feed-
back learning can improve the performance
effectively.

To illustrate the capability of handling different
kinds of relations, we plot the accuracy with re-
spect to different kinds of relations. We use heads
per tail (hpt) and tails per head (tph) index to rep-
resent the difficulty of each relation. If the rela-
tion’s index is high, it means that each head of the
relation may have more tails or vice versa. These
relations are more difficult to predict. This is the
similar problem of 1-N, N-1 and N-N relation in
KBC task. The plot is shown in Figure 3. From
the figure, we can observe that:

1. FFD can be adapted to all kinds of relations
with different hpt and tph;

2. MF, KBR+, FFD models can handle relations
with relatively high hpt but fail with high tph.
This is because our goal is to predict relation
and tail based on the head. Therefore, the
choice may be harder to make with high tph;

3. As the hpt grows, the precision of SVD
model also grows. The reason is that as
hpt grows, the sparsity problem is alleviated.
Therefore, the performance of SVD grows.

5.5 Sparsity Investigation
The MF model suffers from the sparsity problem
since a lot of relation-pair does not appear in the



2899

training set. We examine the training set and ob-
serve that 97.46% relation-tail pairs does not ap-
pear and 0.34% relation-tail pairs appear for only
one time. These pairs can hardly provide any in-
formation for the MF models either.

Relation Ratio train test valid
10% 451,214

41,861 41,013
20% 462,395
30% 475,841
40% 491,498
50% 509,339

Table 2: Statistics of dataset with different relation ra-
tio.

To test whether our framework is capable of
dealing with the data sparsity problem. We re-
move training facts which contains head entities
in H according to a specific ratio. We decrease
the relation ratio R% from 50% to 10% to ex-
plore the effectiveness of our framework in dis-
covering new facts. The dataset statistics is shown
in Table 2. We apply FFD (Analogy) on each
dataset. As shown in Table 3, precision, F1 and
recall decrease since the data becomes more and
more sparse. MAP increase slightly since it is av-
eraged on all extracted facts. When the extracted
facts number decreases, some facts rank at the tail
with low scores are excluded.

Relation Ratio MAP precision recall F1
50% 0.2101 0.1851 0.4421 0.2609
40% 0.2099 0.1768 0.4224 0.2493
30% 0.2167 0.1686 0.4029 0.2378
20% 0.2236 0.1623 0.3878 0.2289
10% 0.2497 0.1534 0.3664 0.2162

Table 3: Result of dataset in different relation ratio.

5.6 Case Study
We provide a case study to demonstrate the char-
acteristics of different models and show that our
FFD can utilize more information. We choose the
head entity “Stanford Law School” (Freebase ID:
/m/021s9n). The predicted facts of SVD, Anal-
ogy+ and FFD (Analogy) are shown in Table 4.
From the table, we can observe that:

1. FFD (Analogy) can predict facts such as
(“Located In”, “Stanford”) and (“Mail Ad-
dress City”, “Stanford”) while other methods
fail to. It implies that this model can predict
some relation with multiple possible tails;

2. Analogy+ outperforms SVD in general while
fails to exceed FFD (Analogy). The reason is

Relation Tail
In
RT
pair SVD

Ana-
log+

FFD
(Anal-
ogy)

Located In USA
√ √ √

Located In California
√ √ √

Located In Stanford
√

Educational
Institution

Stanford Law
School

√ √

Graduates
Degree Law Degree

√ √ √ √

Graduates
Degree Juris Doctor

√ √ √ √

Mail Address
State California

√ √ √

Mail Address
City Stanford

√

Parent
Institution

Stanford
University

√ √

Tuition
Measurement US Dollar

√ √ √

Webpage
Category WebPage

√ √ √

Table 4: Predicted facts by SVD, FFD+ and FFD
(Analogy). “

√
” stands for whether the prediction is

correct.

that it fails to predict some general facts like
(“Located In”, “USA”) or (“Tuition Measure-
ment”, “US Dollar”). This may due to the
high scores given to some wrong facts;

3. The SVD model can only predict those facts
whose relation and tail belong to the selected
relation-tail pairs while Analogy+ and FFD
(Analogy) can predict more facts;

4. SVD model prefers to predict some basic
facts such as “Located In” and “Tuition Mea-
surement”. This is because those relations
appear a lot of times in the training set and
have limited possible tail entities. Therefore,
it is easy for SVD model to make such pre-
diction.

6 Conclusions and Future Work

In this paper, we introduce a new task of fact dis-
covery from knowledge base, which is quite im-
portant for enriching KBs. It is challenging due to
the limited information available about the given
entities for prediction. We propose an effective
framework for this task. Experimental results on
real-world datasets show that our model can effec-
tively predict new relational facts. We also demon-
strate that the feedback learning approach is use-
ful for alleviating the issue of data sparsity for the
head entities with few facts.



2900

Facts discovery from knowledge base is essen-
tial for enriching KBs in the real world. De-
spite the fact that our work shows some promis-
ing results, there still remains some challenges:
(1) There exists much more internal information
such as relational paths and external information
such as text, figures and videos on the web, which
can be used to further improve the performance.
(2) The feedback learning approach in this paper
is to simply utilize those confident predicted rela-
tional facts to enhance the model. Reinforcement
learning may help us dynamically select those in-
formative and confident relational facts.

Acknowledgments

The work described in this paper is partially sup-
ported by grants from the Research Grant Coun-
cil of the Hong Kong Special Administrative Re-
gion, China (Project Codes: 14203414) and the
Direct Grant of the Faculty of Engineering, CUHK
(Project Code: 4055093). Liu and Lin are sup-
ported by the National Key Research and Develop-
ment Program of China (No. 2018YFB1004503)
and the National Natural Science Foundation of
China (NSFC No. 61572273, 61661146007).

References
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy

Liang. 2013. Semantic parsing on freebase from
question-answer pairs. In Proceedings of EMNLP,
pages 1533–1544.

Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a collab-
oratively created graph database for structuring hu-
man knowledge. In Proceedings of SIGMOD, pages
1247–1250.

Antoine Bordes, Sumit Chopra, and Jason Weston.
2014a. Question answering with subgraph embed-
dings. In Proceedings of EMNLP, pages 615–620.

Antoine Bordes, Xavier Glorot, Jason Weston, and
Yoshua Bengio. 2014b. A semantic matching en-
ergy function for learning with multi-relational data.
Machine Learning, 94(2):233–259.

Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In Proceedings of NIPS, pages
2787–2795.

Antoine Bordes, Jason Weston, Ronan Collobert,
Yoshua Bengio, et al. 2011. Learning structured
embeddings of knowledge bases. In Proceedings of
AAAI, pages 301–306.

Danqi Chen, Richard Socher, Christopher D Manning,
and Andrew Y Ng. 2013. Learning new facts from
knowledge bases with neural tensor networks and
semantic word vectors. In Proceedings of ICLR.

Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko
Horn, Ni Lao, Kevin Murphy, Thomas Strohmann,
Shaohua Sun, and Wei Zhang. 2014. Knowledge
vault: A web-scale approach to probabilistic knowl-
edge fusion. In Proceedings of SIGKDD, pages
601–610.

Nathan Halko, Per-Gunnar Martinsson, and Joel A
Tropp. 2011. Finding structure with random-
ness: Probabilistic algorithms for constructing ap-
proximate matrix decompositions. SIAM review,
53(2):217–288.

Shizhu He, Kang Liu, Guoliang Ji, and Jun Zhao. 2015.
Learning to represent knowledge graphs with gaus-
sian embedding. In Proceedings of CIKM, pages
623–632.

Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S Weld. 2011. Knowledge-
based weak supervision for information extraction
of overlapping relations. In Proceedings of ACL,
pages 541–550.

Guoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and
Jun Zhao. 2015. Knowledge graph embedding via
dynamic mapping matrix. In Proceedings of ACL,
pages 687–696.

Guoliang Ji, Kang Liu, Shizhu He, and Jun Zhao. 2016.
Knowledge graph completion with adaptive sparse
transfer matrix. In Proceedings of AAAI, pages 985–
991.

Diederik P Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceedings
of ICLR.

Daniel D Lee and H Sebastian Seung. 1999. Learning
the parts of objects by non-negative matrix factor-
ization. Nature, 401(6755):788.

Jens Lehmann, Robert Isele, Max Jakob, Anja
Jentzsch, Dimitris Kontokostas, Pablo N Mendes,
Sebastian Hellmann, Mohamed Morsey, Patrick van
Kleef, Sören Auer, et al. 2015. Dbpedia–a large-
scale, multilingual knowledge base extracted from
wikipedia. Semantic Web, 6(2):167–195.

Yankai Lin, Zhiyuan Liu, Huanbo Luan, Maosong Sun,
Siwei Rao, and Song Liu. 2015a. Modeling rela-
tion paths for representation learning of knowledge
bases. In Proceedings of EMNLP, pages 705–714.

Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and
Xuan Zhu. 2015b. Learning entity and relation em-
beddings for knowledge graph completion. In Pro-
ceedings of AAAI, pages 2181–2187.

Hanxiao Liu, Yuexin Wu, and Yiming Yang. 2017.
Analogical inference for multi-relational embed-
dings. In ICML, pages 2168–2178.



2901

Quan Liu, Hui Jiang, Andrew Evdokimov, Zhen-Hua
Ling, Xiaodan Zhu, Si Wei, and Yu Hu. 2016. Prob-
abilistic reasoning via deep learning: Neural associ-
ation models. arXiv preprint arXiv:1603.07704.

Christopher D Manning, Prabhakar Raghavan, Hinrich
Schütze, et al. 2008. Introduction to information re-
trieval, volume 1. Cambridge university press Cam-
bridge.

Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extrac-
tion without labeled data. In Proceedings of ACL-
IJCNLP, pages 1003–1011.

Maximilian Nickel, Lorenzo Rosasco, and Tomaso
Poggio. 2016. Holographic embeddings of knowl-
edge graphs. In Proceedings of AAAI, pages 1955–
1961.

Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2011. A three-way model for collective
learning on multi-relational data. In Proceedings of
ICML, pages 809–816.

Richard Socher, Danqi Chen, Christopher D Manning,
and Andrew Ng. 2013. Reasoning with neural ten-
sor networks for knowledge base completion. In
Proceedings of NIPS, pages 926–934.

Fabian M Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowl-
edge. In Proceedings of WWW, pages 697–706.
ACM.

Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric
Gaussier, and Guillaume Bouchard. 2016. Complex
embeddings for simple link prediction. In proceed-
ings of ICML, pages 2071–2080.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and
Pierre-Antoine Manzagol. 2008. Extracting and
composing robust features with denoising autoen-
coders. In Proceedings of ICML, pages 1096–1103.

Denny Vrandečić and Markus Krötzsch. 2014. Wiki-
data: a free collaborative knowledgebase. Commu-
nications of the ACM, 57(10):78–85.

Quan Wang, Zhendong Mao, Bin Wang, and Li Guo.
2017. Knowledge graph embedding: A survey
of approaches and applications. IEEE TKDE,
29(12):2724–2743.

Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. 2014. Knowledge graph embedding by trans-
lating on hyperplanes. In Proceedings of AAAI,
pages 1112–1119.

Ruobing Xie, Zhiyuan Liu, Jia Jia, Huanbo Luan, and
Maosong Sun. 2016. Representation learning of
knowledge graphs with entity descriptions. In Pro-
ceedings of AAAI, pages 2659–2665.

Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng
Gao, and Li Deng. 2014. Embedding entities and
relations for learning and inference in knowledge
bases. arXiv preprint arXiv:1412.6575.


