



















































Stop Word Lists in Free Open-source Software Packages


Proceedings of Workshop for NLP Open Source Software, pages 7–12
Melbourne, Australia, July 20, 2018. c©2018 Association for Computational Linguistics

7

Stop Word Lists in Free Open-source Software Packages

Joel Nothman
Sydney Informatics Hub

University of Sydney
joel.nothman@gmail.com

Hanmin Qin
Peking University

qinhanmin2005@sina.com

Roman Yurchak
Symerio

rth.yurchak@gmail.com

Abstract

Open-source software (OSS) packages
for natural language processing often in-
clude stop word lists. Users may apply
them without awareness of their surprising
omissions (e.g. hasn’t but not hadn’t) and
inclusions (e.g. computer), or their incom-
patibility with particular tokenizers. Mo-
tivated by issues raised about the Scikit-
learn stop list, we investigate variation
among and consistency within 52 popular
English-language stop lists, and propose
strategies for mitigating these issues.

1 Introduction

Open-source software (OSS) resources tend to be-
come de-facto standards by virtue of their avail-
ability and popular use. Resources include tok-
enization rules and stop word lists, whose precise
definitions are essential for reproducible and in-
terpretable models. These resources can be se-
lected somewhat arbitrarily by OSS contributors,
such that their popularity within the community
may not be a reflection of their quality, universal-
ity or suitability for a particular task. Users may
then be surprised by behaviors such as the word
computer being eliminated from their text analy-
sis due to its inclusion in a popular stop list.

This paper brings to the community’s attention
some issues recently identified in the Scikit-learn
stop list. Despite is popular use, the current Scikit-
learn maintainers cannot justify the use of this par-
ticular list, and are unaware of how it was con-
structed. This spurs us to investigate variation
among and consistency within popular English-
language stop lists provided in several popular lan-
guage processing, retrieval and machine learning
libraries. We then make recommendations for im-
proving stop list provision in OSS.

2 Background

Stop words are presumed to be not informative as
to the meaning of documents, and hence are de-
fined by being unusually frequent, or by not being
“content words”. Saif et al. (2014) lists several
methods for constructing a stop word list, includ-
ing: manual construction; words with high docu-
ment frequency or total term frequency in a corpus;
or by comparing term frequency statistics from a
sample of documents with those in a larger col-
lection.1 In practice, Manning et al. (2008) in-
dicate that statistical approaches tend not to be
used alone, but are combined with manual filter-
ing. This paper notes ways in which statistical
construction of stop lists may have introduced re-
grettable errors.

Stop lists have been generated for other lan-
guages, such as Chinese (Zou et al., 2006),
Thai (Daowadung and Chen, 2012) and
Farsi (Sadeghi and Vegas, 2014), using uses
similar frequency threshold approaches, are
susceptible to the same issues discussed here.

Most prior work focuses on assessing or im-
proving the effectiveness of stop word lists, such
as Schofield et al.’s (2017) recent critique of stop
lists in topic modeling. Our work instead exam-
ines what is available and widely used.

3 Case Study: Scikit-learn

Having become aware of issues with the Scikit-
learn (Pedregosa et al., 2011) stop list,2 we be-
gin by studying it. Scikit-learn provides out-of-
the-box feature extraction tools which convert a
collection of text documents to a matrix of token
counts, optionally removing n-grams containing

1They also investigate using supervised feature selection
techniques, but the supervised learning context is inapplica-
ble here.

2As at version 0.19.1



8

given stop words. Being a popular library for ma-
chine learning, many of its users take a naive ap-
proach to language processing, and are unlikely to
take a nuanced approach to stop word removal.

History While users are able to provide their
own stop list, Scikit-learn provides an English-
language list since July 2010. The list was initially
disabled by default since the contributing author
claimed that it did not improve accuracy for text
classification (see commit 41b0562). In Novem-
ber 2010, another contributor argued to enable the
list by default, saying that stop word removal is a
reasonable default behavior (commit 41128af).
The developers disabled the list by default again
in March 2012 (commit a510d17).

The list was copied from the Glasgow Informa-
tion Retrieval Group,3 but it was unattributed until
January 2012 (commit d4c4c6f). The list was
altered in 2011 to remove the content word com-
puter (commit cdf7df9), and in 2015 to correct
the word fify to fifty (commit 3e4ebac).

This history gives a sense of how a stop word
list may be selected and provided without great
awareness of its content: its provenance was ini-
tially disregarded; and some words were eventu-
ally deemed inappropriate.

Critique Currently, the list in Scikit-learn has
several issues. Firstly, the list is incompatible
with the tokenizer provided along with it. It in-
cludes words discarded by the default tokenizer,
i.e., words less than 2 chars (e.g. i), and some
abbreviated forms which will be split by the tok-
enizer (e.g. hasnt). What’s more, it excludes encl-
itics generated by the tokenizer (e.g. ve of we’ve).
In April 2017, a maintainer proposed to add ve to
the list.4 Contributors argued this would break re-
producibility across software versions, and the is-
sue remains unresolved.

Secondly, there are some controversial words in
the list, such as system and cry. These words are
considered to be informative and are seldom in-
cluded in other stop lists. In March 2018, a user
requested the removal of system and has gained
approval from the community.5

Another issue is that the list has some surpris-

3http://ir.dcs.gla.ac.uk/resources/
linguistic_utils/stop_words

4https://github.com/scikit-learn/
scikit-learn/issues/8687

5https://github.com/scikit-learn/
scikit-learn/issues/10735

1970 1980 1990 2000 2010

Snowball

Glasgow IR

rank.nl
(Google)

scikit-learn

MySql
(InnoDB)

MySql
(MyIsam)SMART

NLTK

CoreNLP

Lucene / Solr

Stone, et al spaCy

gensim

postgres

Figure 1: Family tree of popular stop word lists.

ing omissions. Compared to extensions of the
Glasgow IR list from Stone et al. (2010) used by
spaCy (Honnibal and Montani, 2017) and gen-
sim (Řehůřek and Sojka, 2010), the list in Scikit-
learn includes modal has, but lacks does; includes
intensifier very but excludes really; and includes
light verb get but excludes make.

The Glasgow IR list appears to have been con-
structed from corpus statistics, although typo-
graphic errors like fify suggest manual editing.
However, we have not found any documentation
about how the Glasgow IR list was constructed.
Hence we know little about how to generate com-
parable lists for other languages or domains.

In the remainder of this paper, we consider how
similar issues apply to other open-source stop lists.

4 Datasets

We conduct our experiments on Igor Brigadir’s
collection of English-language stop word lists.6

We exclude 1 empty list, 2 lists which contain n-
grams (n > 1) and 1 list which is intended to aug-
ment other lists (i.e. LEMUR’s forumstop). Fi-
nally, we get 52 lists extracted from various search
engines, libraries, and articles. The size of the lists
varies (see the right part of Figure 2), from 24
words in the EBSCOhost medical databases list,
to 988 words in the ATIRE search engine list.

5 Stop List Families

Through digging into project history, we construct
a family tree of some popular stop lists (Figure 1)
to show how popular OSS packages adopt or adapt
existing lists. Solid lines in the figure correspond
to inclusion without major modification, while
dashed lines correspond to a more loose adapta-
tion. For instance, the Glasgow IR list used by
Scikit-learn was extended with 18 more words by

6https://github.com/igorbrigadir/
stopwords/tree/21fb2ef

https://github.com/scikit-learn/scikit-learn/commit/41b0562
https://github.com/scikit-learn/scikit-learn/commit/41128af
https://github.com/scikit-learn/scikit-learn/commit/a510d17
https://github.com/scikit-learn/scikit-learn/commit/d4c4c6f
https://github.com/scikit-learn/scikit-learn/commit/cdf7df9
https://github.com/scikit-learn/scikit-learn/commit/3e4ebac
http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words
http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words
https://github.com/scikit-learn/scikit-learn/issues/8687
https://github.com/scikit-learn/scikit-learn/issues/8687
https://github.com/scikit-learn/scikit-learn/issues/10735
https://github.com/scikit-learn/scikit-learn/issues/10735
https://github.com/igorbrigadir/stopwords/tree/21fb2ef
https://github.com/igorbrigadir/stopwords/tree/21fb2ef


9

Stone et al. (2010), and this list was adopted by
OSS packages gensim and spaCy in turn.

A more data driven approach identifies similar-
ities among stop lists by clustering them with the
Jaccard distance metric (JD(A,B) := 1− |A∩B||A∪B|
where A and B are sets of stop words). In
Figure 2, we have plotted the same data with a
heatmap of word inclusion in order of descending
document frequency in the NYT section of Giga-
word 5.0 (Parker et al., 2011). Here we take the
maximum frequency under three tokenizers from
Lucene, Scikit-learn and spaCy. Each of them
has different approaches to enclitics (e.g. hasn’t is
treated as hasn’t in Lucene; hasn in Scikit-learn
and has n’t in spaCy).

Looking at the heatmap, we see that stop words
are largely concentrated around high document
frequency. Some high frequency words are ab-
sent from many stop lists because most stop lists
assume particular tokenization strategies (See Sec-
tion 6.2). However, beyond the extremely frequent
words, even the shortest lists vary widely in which
words they then include. Some stop lists include
many relatively low-frequency words. This is
most noticeable for large lists like TERRIER and
ATIRE-Puurula. TERRIER goes to pains to in-
clude synthesized inflectional variants, even con-
cerninger, and archaic forms, like couldst.

Through the clusermap, we find some lists with
very high within-cluster similarity (JD < 0.2):
Ranks.nl old Google list and MySQL/InnoDB list;
PostgreSQL list and NLTK list; Weka list, MAL-
LET list, MySQL-MyISAM list, SMART list and
ROUGE list; Glasgow IR list, Scikit-learn list and
spaCy/Gensim list. Beyond these simple clusters,
some lists appear to have surprisingly high over-
lap (usually asymmetric): Stanford CoreNLP list
appears to be an extension of Snowball’s original
list; ATIRE-Puurula appears to be an extension of
the Ranks.nl Large list.

6 Common Issues for Stop Word Lists

In section 3, we find several issues in the stop word
list from Scikit-learn. In this section, we explore
how these problems manifest in other lists.

6.1 Controversial Words

We consider words which appear in less than 10%
of lists to be controversial.7 After excluding words

7Some false negatives will result from the shared origins
of lists detailed in the previous section, but we find very simi-

which do not begin with English characters, we get
2066 distinct stop words in the 52 lists. Among
these words, 1396 (67.6%) words only appear in
less than 10% of lists, and 807 (39.1%) words only
appear in 1 list (see the bars at the top of Figure 2),
indicating that controversial words cover a large
proportion. On the contrary, only 64 (3.1%) words
are accepted by more than 80% lists. Among the
52 lists, 45 have controversial words.

We further investigate the document frequency
of these controversial words using Google Books
Ngrams (Michel et al., 2011). Figure 3 shows the
document frequency distribution. Note: We scale
document frequency of controversial words by the
max document frequency among all the words.
Although peaked on rare words, some words are
frequent (e.g. general, great, time), indicating that
the problem is not trivial.

6.2 Tokenization and Stop Lists

Popular software libraries apply different tok-
enization rules, particularly with respect to word-
internal punctuation. By comparing how different
stop lists handle the word doesn’t in Figure 4, we
see several approaches: most lists stop doesn’t. A
few stop doesn or doesnt, but none stop both of
these. Two stop doesn’t as well as doesnt, which
may help them be robust to different choices of
tokenizer, or may be designed to handle informal
text where apostrophes may be elided.

However, we find tools providing lists that are
inconsistent with their tokenizers. While most lists
stop not, Penn Treebank-style tokenizers – pro-
vided by CoreNLP, spaCy, NLTK and other NLP-
oriented packages – also generate the token n’t.
Of our dataset, n’t is only stopped by CoreNLP.8

Weka and Scikit-learn both have default tokeniz-
ers which delimit tokens at punctuation including
’, yet neither stops words like doesn.

We find similar results when repeating this anal-
ysis on other negated models (e.g. hasn’t, haven’t,
wouldn’t), showing that stop lists are often tuned
to particular tokenizers, albeit not always the
default tokenizer provided by the corresponding
package. More generally, we have not found any
OSS package which documents how tokenization
relates to the choice of stop list.

lar results if we remove near-duplicate lists (Jaccard distance
< 0.2) from our experiments.

8We are aware that spaCy, in commit f708d74, recently
amended its list to improve consistency with its tokenizer,
adding n’t among other Penn Treebank contraction tokens.

https://github.com/explosion/spaCy/commit/f708d7443b42ddd8c04aca029722859d594ceba7


10

0.00.20.40.6
Jaccard distance

,
yo

u
se

e
pa

st
ca

n'
t

pr
ob

le
m

id
ea

go
ne

w
ro

ng
op

en
ed

ch
ec

k
st

ud
ie

s
no

v 85
lu

nc
h

re
su

lte
d

ba
ck

s
se

c
w

ow
fif

te
en

pa
rte

d
as

id
es

fu
rth

er
ed th

u
ar

en
t

fo
re

s
m

au
ge

r
m

ys
e

ov
er

al
le

st
in

w
ar

de
r ¹

Words in descending Gigaword frequency

0

50

# 
lis

ts

0 500 1000
# words

t101_minimal
okapi_cacm_expanded

terrier
reuters_wos

okapi_sample
okapi_sample_expanded

onix
galago_rmstop

indri
voyant_taporware

taporware
scikitlearn

glasgow_stop_words
spacy_gensim

atire_ncbi
choi_2000naacl

zettair
tonybsk_1
rouge_155

smart
mysql_myisam

mallet
weka

ranksnl_large
tonybsk_6

atire_puurula
gate_keyphrase

cook1988_function_words
nltk

postgresql
corenlp_acronym

snowball_expanded
ranksnl_default

snowball_original
corenlp_stopwords

99webtools
textfixer

sphinx_astellar
vw_lda

lingpipe
okapi_cacm

lexisnexis
bow_short

ovid
mysql_innodb

ranksnl_oldgoogle
lucene_elastisearch
corenlp_hardcoded

ebscohost_medline_cinahl
okapiframework

sphinx_500
datasciencedojo

Figure 2: Word inclusion in clustered English stop word lists. Words are ordered by descending docu-
ment frequency. The dendrogram on the left indicates minimum Jaccard distance between stop list pairs
when merged. The bars on the right show the number of words in each list, and the bars on the top
indicate the number of lists each word is found in.

Figure 3: Document frequency distribution of con-
troversial words

6.3 Incompleteness

Stop lists generated exclusively from corpus statis-
tics are bound to omit some inflectional forms
of an included word, as well as related lexemes,
such as less frequent members of a functional syn-
tactic class. In particular, stop word list con-
struction prefers frequency criteria over contex-
tual indicators of a word’s function, despite Har-
ris’s (1954) well-established theory that similar
words (e.g. function words, light verbs, negated
modals) should appear in similar contexts.

To continue the example of negated modals, we
find inconsistencies in the inclusion of have and its
variants, summarized in Figure 5. Weka includes
has, but omits its negated forms, despite including
not. Conversely, Okapi includes doesnt, but omits



11

Figure 4: Number of stop lists that include variants
of doesn’t and their combinations.

Figure 5: Number of stop lists that include variants
of have and their combinations.

does. Several lists include has, hasnt, have and
had, but omits havent and hadnt. Several lists that
include has and have forms omit had forms. These
inclusions and omissions seem arbitrary.

Some negated modals like shan’t and mustn’t
are absent more often than other modals (e.g.
doesn’t, hasn’t), which may be an unsurprising ar-
tifact of their frequency, or may be an ostensive
omission because they are more marked.

TERRIER list (Ounis et al., 2005) appears to
have generated inflectional variants, to the extent
of including concerninger. This generally seems
an advisable path towards improved consistency.

7 Improving Stop List Provision in OSS

Based on the analysis above, we propose strategies
for better provision of stop lists in OSS:

Documentation Stop lists should be docu-
mented with their assumptions about tokenization
and other limitations (e.g. genre). Documentation
should also include information on provenance
and how the list was built.

Dynamic Adaptation Stop lists can be adapted
dynamically to match the NLP pipeline. For ex-
ample, stop lists can be adjusted according to the
tokenizer chosen by the user (e.g. through apply-
ing the tokenizer to the stop list); a word which is
an inflectional variant of a stop word could also be
removed

Quality Control The community should de-
velop tools for identifying controversial terms in
stop lists (e.g. words that are frequent in one
corpus but infrequent in another), and to assist
in assessing or mitigating incompleteness issues.
For instance, future work could evaluate whether
the nearest neighborhood of stop words in vector
space can be used to identify incompleteness.

Tools for Automatic Generation A major limi-
tation of published stop lists is their inapplicability
to new domains and languages. We thus advocate
language independent tools to assist in generating
new lists, which could incorporate the quality con-
trol tools above.

8 Conclusion

Stop word lists are a simple but useful tool for
managing noise, with ubiquitous support in natu-
ral language processing software. We have found
that popular stop lists, which users often apply
blindly, may suffer from surprising omissions and
inclusions, or their incompatibility with particular
tokenizers. Many of these issues may derive from
generating stop lists using corpus statistics. We
hence recommend better documentation, dynami-
cally adapting stop lists during preprocessing, as
well as creating tools for stop list quality control
and automatically generating stop lists.

Acknowledgments

We thank Igor Brigadir for collecting and provid-
ing English-language stop word lists along with
their provenance. We also thank Scikit-learn con-
tributors for bringing these issues to our attention.



12

References

P. Daowadung and Y. H. Chen. 2012. Stop word in
readability assessment of thai text. In Proceedings
of 2012 IEEE 12th International Conference on Ad-
vanced Learning Technologies, pages 497–499.

Zelig Harris. 1954. Distributional structure. Word,
10(23):146–162.

Matthew Honnibal and Ines Montani. 2017. spaCy 2:
Natural language understanding with bloom embed-
dings, convolutional neural networks and incremen-
tal parsing. To appear.

Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Schütze. 2008. Introduction to Information
Retrieval. Cambridge University Press.

Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser
Aiden, Adrian Veres, Matthew K. Gray, Joseph P.
Pickett, Dale Hoiberg, Dan Clancy, Peter Norvig,
Jon Orwant, Steven Pinker, Martin A. Nowak, and
Erez Lieberman Aiden. 2011. Quantitative analysis
of culture using millions of digitized books. Sci-
ence, 331(6014):176–182.

Iadh Ounis, Gianni Amati, Vassilis Plachouras, Ben
He, Craig Macdonald, and Douglas Johnson. 2005.
Terrier information retrieval platform. In Proceed-
ings of the 27th European Conference on Advances
in Information Retrieval Research, pages 517–519.

Robert Parker, David Graff, Junbo Kong, Ke Chen, and
Kazuaki Maeda. 2011. English Gigaword fifth edi-
tion LDC2011T07. Linguistic Data Consortium.

Fabian Pedregosa, Gaël Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, Jake Vanderplas, Alexan-
dre Passos, David Cournapeau, Matthieu Brucher,
Matthieu Perrot, and Édouard Duchesnay. 2011.
Scikit-learn: Machine learning in Python. Journal
of Machine Learning Research, 12:2825–2830.

Radim Řehůřek and Petr Sojka. 2010. Software Frame-
work for Topic Modelling with Large Corpora. In
Proceedings of the LREC 2010 Workshop on New
Challenges for NLP Frameworks, pages 45–50, Val-
letta, Malta. ELRA.

Mohammad Sadeghi and Jess Vegas. 2014. Automatic
identification of light stop words for persian infor-
mation retrieval systems. Journal of Information
Science, 40(4):476–487.

Hassan Saif, Miriam Fernández, Yulan He, and Harith
Alani. 2014. On stopwords, filtering and data spar-
sity for sentiment analysis of Twitter. In Pro-
ceedings of the Ninth International Conference on
Language Resources and Evaluation. Proceedings.,
pages 810–817.

Alexandra Schofield, Måns Magnusson, and David
Mimno. 2017. Pulling out the stops: Rethinking
stopword removal for topic models. In Proceedings
of the 15th Conference of the European Chapter of
the Association for Computational Linguistics: Vol-
ume 2, Short Papers, pages 432–436.

Benjamin Stone, Simon Dennis, and Peter J. Kwantes.
2010. Comparing methods for single paragraph
similarity analysis. Topics in Cognitive Science,
3(1):92–122.

Feng Zou, Fu Lee Wang, Xiaotie Deng, Song Han, and
Lu Sheng Wang. 2006. Automatic construction of
chinese stop word list. In Proceedings of the 5th
WSEAS International Conference on Applied Com-
puter Science.

https://pdfs.semanticscholar.org/7f08/e7fef287e838dde5ecbc27a66b4175fb5cc0.pdf
https://pdfs.semanticscholar.org/7f08/e7fef287e838dde5ecbc27a66b4175fb5cc0.pdf
http://www.tandfonline.com/doi/pdf/10.1080/00437956.1954.11659520
https://nlp.stanford.edu/IR-book/
https://nlp.stanford.edu/IR-book/
https://doi.org/10.1126/science.1199644
https://doi.org/10.1126/science.1199644
https://doi.org/10.1007/978-3-540-31865-1_37
https://catalog.ldc.upenn.edu/ldc2011t07
https://catalog.ldc.upenn.edu/ldc2011t07
http://dl.acm.org/citation.cfm?id=1953048.2078195
http://is.muni.cz/publication/884893/en
http://is.muni.cz/publication/884893/en
https://doi.org/10.1177/0165551514530655
https://doi.org/10.1177/0165551514530655
https://doi.org/10.1177/0165551514530655
http://oro.open.ac.uk/40666/
http://oro.open.ac.uk/40666/
http://aclweb.org/anthology/E17-2069
http://aclweb.org/anthology/E17-2069
https://doi.org/10.1111/j.1756-8765.2010.01108.x
https://doi.org/10.1111/j.1756-8765.2010.01108.x
http://www.wseas.us/e-library/conferences/2006hangzhou/papers/531-205.pdf
http://www.wseas.us/e-library/conferences/2006hangzhou/papers/531-205.pdf

