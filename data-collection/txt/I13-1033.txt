










































Multimodal Comparable Corpora as Resources for Extracting Parallel Data: Parallel Phrases Extraction


International Joint Conference on Natural Language Processing, pages 286–292,
Nagoya, Japan, 14-18 October 2013.

Multimodal Comparable Corpora as Resources for Extracting Parallel
Data: Parallel Phrases Extraction

Haithem Afli, Loı̈c Barrault and Holger Schwenk
Université du Maine,

Avenue Olivier Messiaen F-72085 - LE MANS, France
FirstName.LastName@lium.univ-lemans.fr

Abstract

Discovering parallel data in comparable
corpora is a promising approach for over-
coming the lack of parallel texts in statis-
tical machine translation and other NLP
applications. In this paper we propose an
alternative to comparable corpora of texts
as resources for extracting parallel data:
a multimodal comparable corpus of audio
and texts. We present a novel method to
detect parallel phrases from such corpora
based on splitting comparable sentences
into fragments, called phrases. The au-
dio is transcribed by an automatic speech
recognition system, split into fragments
and translated with a baseline statistical
machine translation system. We then use
information retrieval in a large text corpus
in the target language, split also into frag-
ments, and extract parallel phrases. We
compared our method with parallel sen-
tences extraction techniques. We evaluate
the quality of the extracted data on an En-
glish to French translation task and show
significant improvements over a state-of-
the-art baseline.

1 Introduction

The development of a statistical machine trans-
lation (SMT) system requires one or more paral-
lel corpora called bitexts for training the transla-
tion model and monolingual data to build the tar-
get language model. Unfortunately, parallel texts
are a limited resource and they are often not avail-
able for some specific domains and language pairs.
That is why, recently, there has been a huge in-
terest in the automatic creation of parallel data.
Since comparable corpora exist in large quantities
and are much more easily available (Munteanu and
Marcu, 2005), the ability to exploit them is highly

beneficial in order to overcome the lack of parallel
data. The ability to detect these parallel data en-
ables the automatic creation of large parallel cor-
pora.

Most of existing studies dealing with compara-
ble corpora look for parallel data at the sentence
level (Zhao and Vogel, 2002; Utiyama and Isa-
hara, 2003; Munteanu and Marcu, 2005; Abdul-
Rauf and Schwenk, 2011). However, the de-
gree of parallelism can vary considerably, from
noisy parallel texts, to quasi parallel texts (Fung
and Cheung, 2004). Corpora from the last cate-
gory contain none or few good parallel sentence
pairs. However, there could have parallel phrases
in comparable sentences that can prove to be help-
ful for SMT (Munteanu and Marcu, 2006). As an
example, consider Figure 1, which presents two
news articles with their video from the English and
French editions of the Euronews website1. The ar-
ticles report on the same event with different sen-
tences that contain some parallel translations at the
phrase level. These two documents contain in par-
ticular no exact sentence pairs, so techniques for
extracting parallel sentences will not give good re-
sults. We need a method to extract parallel phrases
which exist at the sub-sentential level.

For some languages, text comparable corpora
may not cover all topics in some specific domains
and languages. This is because potential sources
of comparable corpora are mainly derived from
multilingual news reporting agencies like AFP,
Xinhua, Al-Jazeera, BBC etc, or multilingual en-
cyclopedias like Wikipedia, Encarta etc. What we
need is exploring other sources like audio to gener-
ate parallel data for such domains that can improve
the performance of an SMT system.

In this paper, we present a method for detecting
and extracting parallel data from multimodal cor-
pora. Our method consists in extracting parallel

1www.euronews.com/

286



 Comparable audio

 Comparable texts

 Manual      Transcription
 Manual Transcription

Figure 1: Example of multimodal comparable cor-
pora from the Euronews website.

 Audio (en)

 Text (fr)

Figure 2: Example of multimodal comparable cor-
pora from the TED website.

phrases.

2 Extracting parallel data

2.1 Basic Idea

Figure 2 shows an example of multimodal compa-
rable data coming from the TED website 2. We
have an audio source of a talk in English and its
text translation in French. We think that we can
extract parallel data from this corpora, at the sen-
tence and the sub-sentential level.

In this work we seek to adapt and to improve
machine translation systems that suffer from re-
source deficiency by automatically extracting par-
allel data in specific domains.

2http://www.ted.com/

Audio L1

Sentences L1

Translations L2

Phrases 
L2

ASR

SMT

IR

Texts L2

Multimodal
Comparable

Corpora

Parallel 
Data

Filter

Phrases L1

Split

Phrases L2

Split

Figure 3: Principle of the parallel phrase extrac-
tion system from multimodal comparable corpora.

2.2 System Architecture

The basic system architecture is described in Fig-
ure 3. We can distinguish three steps: auto-
matic speech recognition (ASR), statistical ma-
chine translation (SMT) and information retrieval
(IR). The ASR system accepts audio data in the
source language L1 and generates an automatic
transcription. This transcription is then split into
phrases and translated by a baseline SMT system
into language L2. Then, we use these translations
as queries for an IR system to retrieve most sim-
ilar phrases in the texts in L2, which were previ-
ouslt split into phrases. The transcribed phrases in
L1 and the IR result in L2 form the final parallel
data. We hope that the errors made by the ASR
and SMT systems will not impact too severely the
extraction process.

Our technique is similar to that of (Munteanu
and Marcu, 2006), but we bypass the need of the
Log-Likelihood-Ratio lexicon by using a baseline
SMT system and the TER measure (Snover et al.,
2006) for filtering. We also report an extension of
the work of (Afli et al., 2012) by splitting tran-
scribed sentences and the text parts of the mul-
timodal corpus into phrases with length between
two to ten tokens. We extract from each sentence
on the corpus all combinations of two to ten se-
quential words.

287



2.3 Baseline systems

Our ASR system is a five-pass system based on the
open-source CMU Sphinx toolkit 3(version 3 and
4), similar to the LIUM’08 French ASR system
described in (Deléglise et al., 2009). The acous-
tic models are trained in the same manner, except
that a multi-layer perceptron (MLP) is added us-
ing the bottle-neck feature extraction as described
in (Grézl and Fousek, 2008). Table 2.3 shows the
performances of the ASR system on the develop-
ment and test corpora.

Corpus % WER
Development 19.2
Test 17.4

Table 1: Performance of the ASR system on de-
velopment and test data.

Our SMT system is a phrase-based system
(Koehn et al., 2003) based on the Moses SMT
toolkit (Koehn et al., 2007). The standard four-
teen feature functions are used, namely phrase and
lexical translation probabilities in both directions,
seven features for the lexicalized distortion model,
a word and a phrase penalty and a target language
model. It is constructed as follows. First, word
alignments in both directions are calculated. We
used the multi-threaded version of the GIZA++
tool (Gao and Vogel, 2008). Phrases and lexical
reorderings are extracted using the default settings
of the Moses toolkit. The parameters of our sys-
tem were tuned on a development corpus, using
the MERT tool (Och, 2003).

We use the Lemur IR toolkit (Ogilvie and
Callan, 2001) for the phrases extraction proce-
dure. We first index all the French text (after split-
ting it into segments) into a database using Indri
Index. This feature enable us to index our text
documents in such a way we can use the trans-
lated phrases as queries to run information re-
trieval in the database, with the specialized Indri
Query Language. By these means we can retrieve
the best matching phrases from the French side of
the comparable corpus.

For each candidate phrases pair, we need to de-
cide whether the two phrases are mutual transla-
tions. For this, we calculate the TER between
them using the tool described in (Servan and

3Carnegie Mellon University:
http://cmusphinx.sourceforge.net/

Schwenk, 2011),4 i.e. between automatic trans-
lation, and the phrases selected by IR.

3 Experiments

In our experiments, we compare our phrase ex-
traction method (which we call PhrExtract) with
the sentence extraction method (SentExtract) of
(Afli et al., 2012). We use the extracted dataset by
both methods as additional SMT training data, and
measure the quality of the parallel data by its im-
pact on the performance of the SMT system. Thus,
the final extracated parallel data is injected into the
baseline system. The various SMT systems are
evaluated using the BLEU score (Papineni et al.,
2002). We conducted experiments on an English
to French machine translation task. All the text
data is automatically split into phrases of two to
ten tokens.

3.1 Data description

Our multimodal comparable corpus consists of
spoken talks in English (audio) and written texts
in French. The goal of the TED task is to trans-
late public lectures from English into French. The
TED corpus totals about 118 hours of speech.
We call the English transcriptions of the audio
part TEDasr witch is split into phrases (called
TEDasr split). A detailed description of the TED
task can be found in (Rousseau et al., 2011).

The development corpus DevTED consists of 19
talks and represents a total of 4 hours and 13 min-
utes of speech transcribed at the sentence level.
The language model is trained with the SRI LM
toolkit (Stolcke, 2002), on all the available French
data without the TED data. The baseline system is
trained with version 7 of the News-Commentary
(nc7) and Europarl (eparl7) corpus.5 The indexed
data consist of the French text part of the TED cor-
pus which contains translations of the English part
of the corpus. We call it TEDbi. It is split into
phrases (called TEDbi split). Tables 2 and 3 sum-
marize the characteristics of the different corpora
used in our experiments.

3.2 Experimental results

We first apply sentence extraction on the TED cor-
pus with a method similar to (Afli et al., 2012). We
then apply phrase extraction on the same data split

4http://sourceforge.net/projects/
tercpp/

5http://www.statmt.org/europarl/

288



bitexts # tokens in-domain ?
nc7 3.7M no

eparl7 56.4M no
DevTED 36k yes

Table 2: MT training and development data.

Data # tokens in-domain ?
TEDasr 1.8M yes
TEDbi 1.9M yes

TEDbi split 80.4M yes
TEDasr split 82.7M yes

Table 3: Comparable data used for the extraction
experiments.

as described in 2.2. Then, both methods are com-
pared.

As mentioned in section 2.3, the TER score is
used as a metric for filtering the result of IR. We
keep only the sentences or phrases which have a
TER score below a certain threshold determined
empirically. Thus, we filter the selected sen-
tences or phrases in each condition with different
TER thresholds ranging from 0 to 100 by steps of
10. The extracted parallel data are added to our
generic training data in order to adapt the baseline
system. Table 4 presents the BLEU score obtained
for these different experimental conditions.

Our baseline SMT system, trained with generic
bitexts achieves a BLEU score of 22.93. We can
see that our new method of phrase extraction sig-
nificantly improve the baseline system more than
sentences extraction method until the TER thresh-
old of 80 is reached: the BLEU score increases
from 22.93 to 23.70 with the best system of our
proposed method and from 22.93 to 23.40 with the
best system using the classical method of sentence
extraction.

The results show that the choice of the appro-
priate TER threshold depends on the method. We
can see that for PhrExtract the best threshold is
60 when the best one is 80 for SentExtract. This
last one is also an important point in the general
evaluation of the two methods. In fact, we can
see on Figure 4 that from this point our proposed
method gives less performing results than SentEx-
tract method.

This suggest to apply combination of the two
methods. This corresponds to injecting the ex-
tracted phrases and sentences into the training

data. The combination method is called CombEx-
tract. Figure 4 presents the comparison of the dif-
ferent experimental conditions in term of BLEU
score for each TER threshold. We can see that ex-
cept for threshold 30, the curve of the combination
follows in general the same trajectory of the curve
of PhrExtract. These results show that SentExtract
has no big impact in combination with the PhrEx-
tract method and the best threshold when using
PhrExtract is at 60.

 22

 22.5

 23

 23.5

 24

 0  20  40  60  80  100

BL
EU

 sc
or

e

TER threshold

PhrExtract
SentExtract

CombExtract
Baseline

Figure 4: Performance of PhrExtract, SentExtract
and their combination in term of BLEU score for
each TER threshold.

This is because of the big difference on the
quantity of data between the two methods as we
can see in Table 4. The benefit of our method
is that it can generates more quantities of paral-
lel data than the sentence extraction method for
each TER threshold, and this difference of quanti-
ties improves results of MT system until the TER
threshold of 80 is reached. However, we can see
in Table 4 that the quality of only 39.35k (TER
80) extracted by SentExtract can have exactly the
same impact of 25.3M extracted by our new tech-
nique. That is why we intend to investigate in the
filtering module of our system.

4 Related Work

Research on exploiting comparable corpora goes
back to more than 15 years ago (Fung and Yee,
1998; Koehn and Knight, 2000; Vogel, 2003;
Gaussier et al., 2004; Li and Gaussier, 2010). A
lot of studies on data acquisition from compara-
ble corpora for machine translation have been re-
ported (Su and Babych, 2012; Hewavitharana and
Vogel, 2011; Riesa and Marcu, 2012).

To the best of our knowledge (Munteanu and

289



TER BLEU score BLEU score # tokens (fr) # tokens (fr)
SentExtract PhrExtract SentExtract PhrExtract

0 22.86 23.39 55 1.06M
10 22.97 23.35 313 1.4M
20 23.06 23.53 1.7k 2.5M
30 22.95 23.39 6.9k 4.3M
40 22.92 23.45 23.5k 7.02M
50 23.26 23.54 62.4k 11.4M
60 23.10 23.70 13.82k 13.8M
70 23.29 23.41 25.15k 18.04M
80 23.40 23.40 39.35k 25.3M
90 23.39 23.18 57.54k 35.9M
100 23.34 23.26 83.60k 45.3M

Baseline 22.93 - 60.1M -

Table 4: Number of tokens extracted and BLEU scores on DevTED obtained with PhrExtract and Sen-
tExtract methods for each TER threshold.

Marcu, 2006) was the first attempt to extract paral-
lel sub-sentential fragments (phrases), from com-
parable corpora. They used a method based on a
Log-Likelihood-Ratio lexicon and a smoothing fil-
ter. They showed the effectiveness of their method
to improve an SMT system from a collection of
a comparable sentences. The weakness of their
method is that they filter source and target frag-
ments separately, which cannot guarantee that the
extracted fragments are a good translations of each
other. (Hewavitharana and Vogel, 2011) show a
good result with their method based on on a pair-
wise correlation calculation which suppose that
the source fragment has been detected.

The second type of approach in extracting paral-
lel phrases is the alignment-based approach (Quirk
et al., 2007; Riesa and Marcu, 2012). These meth-
ods are promising, but since the proposed method
in (Quirk et al., 2007) do not improve significantly
MT performance and model in (Riesa and Marcu,
2012) is designed for parallel data, it’s hard to say
that this approach is actually effective for compa-
rable data.

This work is similar to the work by (Afli et al.,
2012) where the extraction is done at the phrase
level instead of the sentence level. Our methodol-
ogy is the first effort aimed at detecting translated
phrases on a multimodal corpora.

Since our method can extract parallel phrases
from a multimodal corpus, it greatly expands the
range of corpora which can be usefully exploited.

5 Conclusion

We have presented a fully automatic method for
extracting parallel phrases from multimodal com-
parable corpora, i.e. the source side is available
as audio stream and the target side as text. We
used a framework to extract parallel data witch
combine an automatic speech recognition system,
a statistical machine translation system and infor-
mation retrieval system. We showed by experi-
ments conducted on English-French data, that par-
allel phrases extracted with this method improves
significantly SMT performance. Our approach can
be improved in several aspects. The automatic
splitting is very simple; more advanced phrases
generation might work better, and eliminate re-
dundancy. Trying other method on filtering can
also improve the precision of the method.

6 Acknowledgments

This work has been partially funded by the French
Government under the project DEPART.

References
S. Abdul-Rauf and H. Schwenk. 2011. Parallel sen-

tence generation from comparable corpora for im-
proved smt. Machine Translation.

H. Afli, L. Barrault, and H. Schwenk. 2012. Paral-
lel texts extraction from multimodal comparable cor-
pora. In JapTAL, volume 7614 of Lecture Notes in
Computer Science, pages 40–51. Springer.

P. Deléglise, Y. Estève, S. Meignier, and T. Merlin.
2009. Improvements to the LIUM french ASR sys-

290



tem based on CMU Sphinx: what helps to signifi-
cantly reduce the word error rate? In Interspeech
2009, Brighton (United Kingdom), 6-10 september.

P. Fung and P. Cheung. 2004. Multi-level bootstrap-
ping for extracting parallel sentences from a quasi-
comparable corpus. In Proceedings of the 20th in-
ternational conference on Computational Linguis-
tics, COLING ’04.

P. Fung and L. Y. Yee. 1998. An ir approach for
translating new words from nonparallel, compara-
ble texts. In Proceedings of the 17th international
conference on Computational linguistics - Volume 1,
COLING ’98, pages 414–420.

Q. Gao and S. Vogel. 2008. Parallel implementa-
tions of word alignment tool. In Software Engineer-
ing, Testing, and Quality Assurance for Natural Lan-
guage Processing, SETQA-NLP ’08, pages 49–57.

E. Gaussier, J.-M. Renders, I. Matveeva, C. Goutte, and
H. Déjean. 2004. A geometric view on bilingual
lexicon extraction from comparable corpora. In Pro-
ceedings of the 42nd Annual Meeting on Association
for Computational Linguistics, ACL ’04.

F. Grézl and P. Fousek. 2008. Optimizing bottle-neck
features for LVCSR. In 2008 IEEE International
Conference on Acoustics, Speech, and Signal Pro-
cessing, pages 4729–4732. IEEE Signal Processing
Society.

S. Hewavitharana and S. Vogel. 2011. Extracting par-
allel phrases from comparable data. In Proceedings
of the 4th Workshop on Building and Using Compa-
rable Corpora: Comparable Corpora and the Web,
BUCC ’11, pages 61–68.

P. Koehn and K. Knight. 2000. Estimating word trans-
lation probabilities from unrelated monolingual cor-
pora using the em algorithm. In Proceedings of the
Seventeenth National Conference on Artificial Intel-
ligence and Twelfth Conference on Innovative Ap-
plications of Artificial Intelligence, pages 711–715.
AAAI Press.

P. Koehn, Franz J. Och, and D. Marcu. 2003. Sta-
tistical phrase-based translation. In Proceedings of
the 2003 Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology - Volume 1, NAACL
’03, pages 48–54.

P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: open source toolkit
for statistical machine translation. In Proceedings
of the 45th Annual Meeting of the ACL on Interac-
tive Poster and Demonstration Sessions, ACL ’07,
pages 177–180.

B. Li and E. Gaussier. 2010. Improving corpus com-
parability for bilingual lexicon extraction from com-
parable corpora. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics,
COLING ’10, pages 644–652.

D. S. Munteanu and D. Marcu. 2005. Improv-
ing Machine Translation Performance by Exploiting
Non-Parallel Corpora. Computational Linguistics,
31(4):477–504.

D. S. Munteanu and D. Marcu. 2006. Extracting
parallel sub-sentential fragments from non-parallel
corpora. In Proceedings of the 21st International
Conference on Computational Linguistics and the
44th annual meeting of the Association for Compu-
tational Linguistics, ACL-44, pages 81–88.

Franz J. Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, ACL ’03, pages 160–
167, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.

P. Ogilvie and J. Callan. 2001. Experiments using
the lemur toolkit. Procedding of the Trenth Text Re-
trieval Conference (TREC-10).

K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of the 40th Annual Meet-
ing on Association for Computational Linguistics,
ACL ’02, pages 311–318.

Q. Quirk, R. Udupa, and A. Menezes. 2007. Gener-
ative models of noisy translations with applications
to parallel fragment extraction. In In Proceedings of
MT Summit XI, European Association for Machine
Translation.

J. Riesa and D. Marcu. 2012. Automatic parallel frag-
ment extraction from noisy data. In Proceedings of
the 2012 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, NAACL HLT ’12,
pages 538–542.

A. Rousseau, F. Bougares, P. Deléglise, H. Schwenk,
and Y. Estève. 2011. LIUM’s systems for the
IWSLT 2011 speech translation tasks. International
Workshop on Spoken Language Translation 2011.

C. Servan and H. Schwenk. 2011. Optimising multiple
metrics with mert. The Prague Bulletin of Mathe-
matical Linguistics (PBML).

S. Snover, B. Dorr, R. Schwartz, M. Micciulla, and
J. Makhoul. 2006. A study of translation edit rate
with targeted human annotation. Proceedings of As-
sociation for Machine Translation in the Americas,
pages 223–231.

A. Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In International Confer-
ence on Spoken Language Processing, pages 257–
286, November.

291



F. Su and B. Babych. 2012. Measuring comparabil-
ity of documents in non-parallel corpora for effi-
cient extraction of (semi-)parallel translation equiv-
alents. In Proceedings of the Joint Workshop on
Exploiting Synergies between Information Retrieval
and Machine Translation (ESIRMT) and Hybrid Ap-
proaches to Machine Translation (HyTra), EACL
2012, pages 10–19. Association for Computational
Linguistics.

M. Utiyama and H. Isahara. 2003. Reliable measures
for aligning japanese-english news articles and sen-
tences. In Proceedings of the 41st Annual Meeting
on Association for Computational Linguistics - Vol-
ume 1, ACL ’03, pages 72–79.

S. Vogel. 2003. Using noisy bilingual data for sta-
tistical machine translation. In Proceedings of the
tenth conference on European chapter of the Asso-
ciation for Computational Linguistics - Volume 2,
EACL ’03, pages 175–178.

B. Zhao and S. Vogel. 2002. Adaptive parallel sen-
tences mining from web bilingual news collection.
In Proceedings of the 2002 IEEE International Con-
ference on Data Mining, ICDM ’02, Washington,
DC, USA. IEEE Computer Society.

292


