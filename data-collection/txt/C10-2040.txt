347

Coling 2010: Poster Volume, pages 347–355,

Beijing, August 2010

Verbs are where all the action lies: Experiences of Shallow Parsing of a

Morphologically Rich Language

Harshada Gune

Mugdha Bapat
Department of Computer Science and Engineering,

Mitesh M. Khapra

Indian Institute of Technology Bombay

Pushpak Bhattacharyya

{harshadag,mbapat,miteshk,pb}@cse.iitb.ac.in

Abstract

Verb sufﬁxes and verb complexes of mor-
phologically rich languages carry a lot of
information. We show that this infor-
mation if harnessed for the task of shal-
low parsing can lead to dramatic improve-
ments in accuracy for a morphologically
rich language- Marathi1. The crux of the
approach is to use a powerful morpholog-
ical analyzer backed by a high coverage
lexicon to generate rich features for a CRF
based sequence classiﬁer. Accuracy ﬁg-
ures of 94% for Part of Speech Tagging
and 97% for Chunking using a modestly
sized corpus (20K words) vindicate our
claim that for morphologically rich lan-
guages linguistic insight can obviate the
need for large amount of annotated cor-
pora.

Introduction

1
Shallow parsing which involves Part-of-Speech
(POS) tagging and Chunking is a fundamental
task of Natural Language Processing (NLP). It is
natural to view each of these sub-tasks as a se-
quence labeling task of assigning POS/chunk la-
bels to a given word sequence. For languages like
English where annotated corpora are available in
abundance these tasks can be performed with very
high accuracy using data-driven machine learning
techniques. Languages of the world show differ-
ent levels of readiness with respect to such anno-
tated resources and hence not all languages may
1Marathi is the ofﬁcial language of Maharashtra, a state in
Western India. The language has close to 20 million speakers
in the world.

provide a conducive platform for machine learn-
ing techniques.

In this scenario, morphologically rich lan-
guages from the Indian subcontinent present a
very interesting case. While these languages do
not enjoy the resource abundance of English, their
linguistic richness can be used to offset this re-
source deﬁcit. Speciﬁcally, in such languages, the
sufﬁxes carry a lot of information about the cate-
gory of a word which can be harnessed for shal-
low parsing. This is especially true in the case of
verbs where sufﬁxes like Z(cid:3) {ne}, ZAr(cid:3) {naare} 2
clearly indicate the category of the word. Further,
the structure of verb groups in such languages is
relatively rigid and can be used to reduce the am-
biguity between main verbs and auxiliary verbs.

In the current work, we aim to reduce the data
requirement of machine learning techniques by
appropriate feature engineering based on the char-
acteristics of the language. Speciﬁcally, we tar-
get Marathi- a morphologically rich language-
and show that a powerful morphological analyzer
backed by a high coverage lexicon and a simple
but accurate Verb Group Identiﬁer (VGI) can go a
long way in improving the accuracy of a state of
the art sequence classiﬁer. Further, we show that
harnessing such features is the only way by which
one can hope to build a high-accuracy classiﬁer
for such languages, and that simply throwing in a
large amount of annotated corpora does not serve
the purpose. Hence it makes more sense to invest
time and money in developing good morphologi-
cal analyzers for such languages than investing in
annotation. Accuracy ﬁgures of 94% for Part of

2These are the sufﬁxes which derive inﬁnitive and gerund

verb forms respectively.

348

Speech Tagging and 97% for Chunking using a
modestly sized corpus (20K words) vindicate our
claim that for morphologically rich languages lin-
guistic knowledge plays a very important role in
shallow parsing of these languages.

2 Related Work

Many POS taggers have been built for English
employing machine learning techniques ranging
from Decision Trees (Black et al., 1992) to Graph-
ical Models (Brants, 2000; Brill, 1995; Ratna-
parkhi, 1996; Lafferty et al., 2001). Even hy-
brid taggers such as CLAWS (Garside and Smith,
1997) which combine stochastic and rule based
approaches have been developed. However, most
of these techniques do not focus on harnessing the
morphology; instead they rely on the abundance
of data which is not a very suitable proposition
for some of the resource deprived languages of the
Indian sub-continent.

Morphological processing based taggers using
a combination of hand-crafted rules and anno-
tated corpora have been tried for Turkish (Oﬂazer
and Kuru¨oz, 1994), Arabic (Tlili-Guiassa, 2006),
Hungarian (Megyesi, 1999) and Modern Greek
(Giorgos et al., 1999). The work on Hindi POS
tagging (Singh et al., 2006) comes closest to our
approach which showed that using a detailed lin-
guistic analysis of morphosyntactic phenomena,
followed by leveraging sufﬁx information and ac-
curate verb group identiﬁcation can help to build
a high-accuracy (93-94%) part of speech tagger
for Hindi. However, to the best of our knowledge,
there is no POS tagger and Chunker available for
Marathi and ours is the ﬁrst attempt at building
one.

3 Motivating Examples

To explain the importance of sufﬁx information
for shallow parsing we present two motivating ex-
amples. First, consider the following Marathi sen-
tence,
hA r-tA don gAvA\nA joXZArA aAh(cid:3).
haa rasta don gavaannaa jodaNaaraa VM aahe.
this road two villages connecting is
this is the road connecting VM two villages.

The word joXZArA {jodaNaaraa} (connecting)
in the above sentence is a verb and can be cat-
egorized as such by simply looking at the sufﬁx
ZArA {Naaraa} as this sufﬁx does not appear with
any other POS category. When sufﬁx informa-
tion is used as a feature a statistical POS tagger
is able to identify the correct POS tag of joXZArA
{jodaNaaraa} even when it does not appear in the
training data. Hence, using sufﬁx information en-
sures that a classiﬁer is able to learn meaningful
patterns even in the absence of large training data.
Next, we consider two examples for chunking.

uDaNyaachaa B-VGNN3

• VGNN (Gerund Verb Chunk)
mAZsAn(cid:3) uX(cid:23)yAcA (cid:254)y(cid:215) k(cid:3)lA.
maaNasaane
prayatna kelaa.
man ﬂy try do
man tried ﬂying B-VGNN.
• VGINF (Inﬁnitival Verb Chunk)
(yAn(cid:3) cAlAylA s(cid:0) zvAt k(cid:3)lF.
tyaane chaalaayalaa B-VGNF suruvaata
kelii.
he walk start did
he started to walk B-VGINF.

Here, we are dealing with the case of two speciﬁc
verb chunks, viz., VGNN (gerund verb chunk) and
VGINF (inﬁnitival verb chunk). A chunk having
a gerund always gets annotated as VGNN and a
chunk having an inﬁnitival verb always gets anno-
tated as VGINF. Thus, the correct identiﬁcation of
these verb chunks boils down to the correct iden-
tiﬁcation of gerunds and inﬁnitival verb forms in
the sentence which in turn depend on the careful
analysis of sufﬁx information. For example, in
Marathi, the attachment of the verbal sufﬁx “(cid:23)y-
AcA” {Nyaachaa} to a verb root always results in
a gerund. Similarly, the attachment of the verbal
sufﬁx “ylA” {yalaa} to a verb root always results
in an inﬁnitival verb form. The use of such sufﬁx
information as features can thus lead to better gen-
eralization for handling unseen words and thereby
reduce the need for additional training data. For
instance, in the ﬁrst sentence, even when the word
“uX(cid:23)yAcA” {uDaNyaachaa} does not appear in
3Note that for all our experiments we used BI scheme for

chunking as opposed to the BIO scheme

349

the training data, a classiﬁer which uses sufﬁx in-
formation is able to label it correctly based on its
experience of previous words having sufﬁx “(cid:23)y-
AcA” {Nyaachaa} whereas a classiﬁer which does
not use sufﬁx information fails to classify it cor-
rectly.

4 Morphological Structure of Marathi
Marathi nouns inﬂect for number and case. They
may undergo derivation on the attachment of post-
positions. In the oblique case, ﬁrst a stem is ob-
tained from the root by applying the rules of in-
ﬂection. Then a postposition is attached to the
stem. Postpositions (including case markers and
the derivational sufﬁxes) play a very important
role in Marathi morphology due to the complex
morphotactics.

Marathi adjectives can be classiﬁed into two
categories: ones that do not inﬂect and others that
inﬂect for gender, number and case where such an
inﬂection agrees with the gender and number of
the noun modiﬁed by them.

The verbs inﬂect for gender, number and
person of the subject and the direct object in a
sentence. They also inﬂect for tense and aspect
of the action as well as mood of the speaker in
an illocutionary act. They may even undergo
derivation to derive the nouns, adjectives or
postpositions. Verbal morphology in Marathi
is based on Aakhyaata theory for inﬂection and
Krudanta theory for derivation which are two
types of verb sufﬁxes (Damale, 1970).

Aakhyaata Theory: Aakhyaata refers to tense,
aspect and mood. Aakhyaata form is realized
through an aakhyaata sufﬁx which is a closing
sufﬁx attached to verb root. For example, bslA
{basalaa} (sat) comes from basa + laa. There are
8 types of aakhyaatas named after the phonemic
shape of the aakhyaata sufﬁx. Associated with ev-
ery aakhyaata are various aakhyaata-arthas which
indicate the features: tense, aspect and mood. An
aakhyaata may or may not agree with gender.
Krudanta Theory: Krudanta sufﬁxes are at-
tached to the end of verbs to form non-inﬁnitive
For example, DAvAylA (DAv +
verb forms.
aAylA) {dhaavaayalaa} (to run). There are 8
types of krudantas deﬁned in Marathi.

5 Design of Marathi Shallow Parser
Figure 1 and 2 show the overall architectures of
Marathi POS tagger and chunker. The proposed
system contains 3 important components. First,
a morphological analyzer which provides ambi-
guity schemes and sufﬁx information for gener-
ating a rich set of features. Ambiguity Scheme
refers to the list of possible POS categories a word
can take. This can add valuable information to a
sequence classiﬁer by restricting the set of pos-
sible POS categories for a word. For example,
the word jAt {jaat} meaning caste or go(caste-
noun, go- VM/VAUX) can appear as a noun or a
main verb or an auxiliary verb. Hence it falls in
the ambiguity scheme <NN-VM-VAUX>. This
information is stored in a lexicon. These features
are then fed to a CRF based engine which cou-
ples them with other elementary features (previ-
ous/next words and bigram tags) for training a se-
quence labeler. Finally, in the case of POS tagger,
we use a Verb Group Identiﬁer (VGI) which acts
as an error correcting module for correcting the
output of the CRF based sequence labeler. Each
of these components is described in detail in the
following sub-sections.

5.1 Morphological Analyzer
The formation of polymorphemic words leads
to complexities which need to be handled dur-
ing the analysis process. For example, consider
the steps involved in the formation of the word
d(cid:3)vAsmorQyAn(cid:3) {devasamorchyane} (the one in
front of the God + ERGATIVE).

devaasamora = (deva → devaa)

+ samora

devaasamorachaa = ( devaasamora → devaasamora)

+ chaa

devaasamorachyaane = (devaasamorachaa → devaasamorachyaa)

+ ne

In theory, the process can continue recursively for
the attachment of any number of sufﬁxes. How-
ever, in practice, we have observed that a word in
Marathi contains at most 4 sufﬁxes.

FSMs prove to be elegant and computationally
for analyzing polymorphemic

tools

efﬁcient

350

Figure 1: Architecture of POS Tagger

words. However, the recursive process of word
formation in Marathi involves inﬂection at the
time of attachment of every new sufﬁx. The FSM
needs to be modiﬁed to handle this. However,
during the i-th recursion only (i-1)-th morpheme
changes its form which can be handled by suit-
ably modifying the FSM. The formation of word
d(cid:3)vAsmorQyAn(cid:3) {devaasamorachyaane} can be
viewed as:

devaasamora = (deva → devaa)

+ samora

devaasamorachaa = ( deva → devaa)

+ ( samora → samora)
+ chaa

devaasamorachyaane = (deva → devaa)

+ (samora → samora)
+ (chaa → chyaa)
+ ne

In general,
Polymorphemic word = (inf lected morpheme1)
+ (inf lected morpheme2) + ...

Now, we can create an FSM which is aware of
these inﬂected forms of morphemes in addition to
the actual morphemes to handle the above recur-
sive process of word formation. These inﬂected
forms are generated using the paradigm-based4
system written in Java and then fed to the FSM
implemented using SFST5.

4A paradigm identiﬁes the uninﬂected form of words

which share similar inﬂectional patterns.

5http://www.ims.uni-stuttgart.de/projekte/gramotron

Our lexicon contains 16448 nouns categorized
into 76 paradigms, 8516 adjectives classiﬁed
as inﬂecting and non-inﬂecting adjectives, 1160
verbs classiﬁed into 22 classes.
It contains 142
postpositions, 80 aakhyaata and 8 krudanta suf-
ﬁxes.

5.2 CRF
Conditional Random Fields (Lafferty et al., 2001)
are undirected graphical models used for labeling
sequential data. Under this model, the conditional
probability distribution of a tag given the observed
word sequence is given by,

PT
Z(X) · e

1

PK

t=1

k=1 λkfk(Yt−1,Yt,X,t)

(1)

P (Y |X; λ) =

where,

X = source word

Y = target word

T = length of sentence

K = number of f eatures
λk = f eature weight

Z(X) = normalization constant

We used CRF++6, an open source implementa-
tion of CRF, for training and further decoding the
tag sequence. We used the following features for
training the sequence labeler (here, wi is the i-th
word, ti is the i-th pos tag and ci is the i-th chunk
tag).
/SOFTWARE/SFST.html

6http://crfpp.sourceforge.net/

351

Figure 2: Architecture of Chunker

Features used for POS tagger training
Consider position of interest = i

• ti ti−1 and wj such that i − 3 < j < i + 3
• ti ti−1 and sufﬁx information of wi
• ti ti−1 and ambiguity scheme of wi

Here, the ﬁrst features are weak features which
depend only on the previous/next words and bi-
gram tags. The next two are rich morphological
features which make use of the output of the
morphological analyzer.

Features used for Chunker training
Consider position of interest = i

• ci ci−1 and tj, wj such that i− 3 < j < i + 3
• ci ci−1 and sufﬁx information of wi

where ci, ci−1 ∈ {B, I}. Here again, the ﬁrst set
of features are weak features and the second set
of features are rich morphological features.

5.3 Verb Group Identiﬁcation (VGI)
In Marathi, certain auxiliaries like ast(cid:3) {asate}
(be), aAh(cid:3) {aahe} (is) etc.. can also act as main
verbs in certain contexts. This ambiguity between
VM (main verbs) and VAUX (auxiliary verbs) can
lead to a large number of errors in POS tagging
if not handled correctly. However, the relatively
rigid structure of Marathi VG coupled with dis-
tinct sufﬁx-afﬁnity of auxiliary verbs allows us to
capture this ambiguity well using the following
simple regular expression:

MainVerbRoot (KrudantaSufﬁx AuxVerbRoot)*

AakhyaataSufﬁx

The above regular expression imposes some re-
striction on the occurrence of certain auxiliary
verbs after speciﬁc krudanta sufﬁxes. This restric-
tion is captured with the help of a rule ﬁle contain-
ing krudanta sufﬁx-auxiliary verb pairs. A sample
entry from this ﬁle is

Un , kAY [oon, kaaDh]

the auxiliary verb kAY
which suggests that
{kaaDh} can appear after the sufﬁx Un {oon}.
We created a rule ﬁle containing around 350 such
valid krudanta sufﬁx-auxiliary verb pairs.

An important point which needs to be high-
lighted here is that a simple left to right scan ig-
noring sufﬁx information and marking the ﬁrst
verb constituent as main verb and every other
constituent as auxiliary verb does not work for
Marathi. For example, consider the following
verb sequence,

(yAlA ucl(cid:1) n aAZAv(cid:3) lAgl(cid:3).
tyaalaa uchaluun aaNaave laagale

He carry bring need

It was needed to carry and bring him.

Here, a simple left to right scan of the verb se-
quence ignoring the sufﬁx information would im-
ply that ucl(cid:1) n is a VM whereas aAZAv(cid:3) and
lAgl(cid:3) are VAUX. However, this is not the case
and can be identiﬁed correctly by considering the
sufﬁx afﬁnity of auxiliary verbs. Speciﬁcally, in
this case, the verb root aAZ cannot take the role
of an auxiliary verb when it appears after the kru-
danta sufﬁx Un. This suggests that the verb

352

aAZAv(cid:3) does not belong to the same verb group
as ucl(cid:1) n and hence is not a VAUX. This shows
sufﬁx and regular expression help in disambiguat-
ing VM-VAUX which is a challenge in all POS
taggers.

6 Experimental Setup
We used documents from the TOURISM and
NEWS domain for all our experiments 7. These
documents were hand annotated by two Marathi
lexicographers. The total size of the corpus was
kept large (106273 POS tagged words and 63033
chunks) to study the impact of the size of training
data versus the amount of linguistic information
used. The statistics about each POS tag and chunk
tag are summarized in Table 1 and Table 2.

Frequency
POS
in Corpus
Tag
51047
NN
578
NST
PRP
8770
DEM 3241
VM
17716
VAUX 6295
7311
JJ
RB
1060
97
UT
PSP
69

Frequency
POS
in Corpus
Tag
359
RP
CC
3735
QW 630
QF
1928
2787
QC
QO
277
INTF 158
INJ
22
RDP
39
NEG 154

Table 1: POS Tags in Training Data

Frequency
Chunk
in Corpus
Tag
40254
NP
VGF
7425
VGNN 1105
782
RBP
CCP
4796

Frequency
in Corpus
2680
3553

Chunk
Tag
JJP
VGNF
VGINF 58
BLK
NEGP

2337
43

Table 2: Chunk Tags in Training Data

7 Results
We report results in four different settings:
Weak Features (WF): Here we use the basic

7The data can be found at www.cﬁlt.iitb.ac.in/

CRF classiﬁer with elementary word features (i.e.,
words appearing in a context window of 3) and bi-
gram tag features and POS tags in case of chunker.
Weak Morphological Features (Weak-MF): In
addition to the elementary features we use sub-
strings of length 1 to 7 appearing at the end of the
word as feature. The idea here is that such sub-
strings taken from the end of the word can provide
a good approximation of the actual sufﬁx of the
word. Such substrings thus provide a statistical
approximation of the sufﬁxes in the absence of a
full ﬂedged morphological analyzer. This should
not be confused with weak features which mean
tags and word.
Rich Morphological Features (Rich-MF): In
addition to the elementary features we use the am-
biguity schemes and sufﬁx information provided
by the morphological analyzer.
Reach Morphological Features + Verb Group
Identiﬁcation (Rich-MF+VGI): This setting is
applicable only for POS tagging where we apply
an error correcting VGI module to correct the out-
put of the feature rich CRF tagger.

In each case we ﬁrst divided the data into four
folds (75% for training and 25% for testing).
Next, we varied the training data in increments of
10K and calculated the accuracy of each of the
above models. The x-axis represents the size of
the training data and the y-axis represents the pre-
cision of the tagger/chunker. Figure 3 plots the
average precision of the POS tagger across all cat-
egories using WF, Weak-MF, Rich-MF and Rich-
MF VGI for varying sizes of the training data.
Figure 6 plots the average precision of the chun-
ker across all categories using WF, Weak-MF and
Rich-MF. Next, to show that the impact of mor-
phological analysis is felt more for verbs than
other POS categories we plot the accuracies of
verb pos tags (Figure 4) and verb chunk tags (Fig-
ure 7) using WF, Weak-MF, Rich-MF and Rich-
MF VGI for varying sizes of the training data.

8 Discussions
We made the following interesting observations
from the above graphs and tables.
1.
Importance of linguistic knowledge: Fig-
ure 3 shows that using a large amount of anno-
tated corpus (91k), the best accuracy one can hope

353

Figure 3: Average Accuracy of all POS Tags
(Note: The graphs for Rich-MF and Rich-MF+VGI coincide)

Figure 6: Average Accuracy of all Chunk Tags

Figure 4: Average Accuracy of Verb POS Tags
(Note: The graphs for Rich-MF and Rich-MF+VGI almost coincide)

Figure 7: Average Accuracy of Verb Chunks

Figure 5: Average Accuracy of Non Verb POS Tags

Figure 8: Average Accuracy of Non Verb Chunks
(Note: All the graphs coincide.)

y
c
a
r
u
c
c
A
%

 

 100

 90

 80

 70

 60

 50

Accuracy v/s Data Size

WF
Weak-MF
Rich-MF
Rich-MF + VGI

 10000 20000 30000 40000 50000 60000 70000 80000 90000

No. of Words in Training Data

 100

 98

 96

 94

 92

 90

 88

 86

y
c
a
r
u
c
c
A
%

 

 10000

Accuracy v/s Data Size

WF
Weak-MF
Rich-MF

 30000

 20000
No. of Words in Training Data

 40000

 50000

 60000

y
c
a
r
u
c
c
A
%

 

 100

 90

 80

 70

 60

 50

 40

 30

Accuracy v/s Data Size

WF
Weak-MF
Rich-MF
Rich-MF + VGI

 10000 20000 30000 40000 50000 60000 70000 80000 90000

No. of Words in Training Data

y
c
a
r
u
c
c
A
%

 

 100

 95

 90

 85

 80

 75

 10000

Accuracy v/s Data Size

WF
Weak-MF
Rich-MF

 30000

 20000
No. of Words in Training Data

 40000

 50000

 60000

y
c
a
r
u
c
c
A
%

 

 100

 90

 80

 70

 60

 50

Accuracy v/s Data Size

WF
Weak-MF
Rich-MF

 10000 20000 30000 40000 50000 60000 70000 80000 90000

No. of Words in Training Data

y
c
a
r
u
c
c
A
%

 

 100

 95

 90

 85

 80

 75

 10000

Accuracy v/s Data Size

WF
Weak-MF
Rich-MF

 30000

 20000
No. of Words in Training Data

 40000

 50000

 60000

354

for is around 85% if morphological information is
not harnessed i.e., if only weak features are used.
Adding more data will deﬁnitely not be of much
use as the curve is already close to saturation. On
the other hand, if morphological information is
completely harnessed using a rich morphological
analyzer then an accuracy as high as 94% can be
obtained by using data as small as 20k words. Fig-
ure 6 tells a similar story. In the absence of mor-
phological features a large amount of annotated
corpus (62k words) is needed to reach an accu-
racy of 96%, whereas if sufﬁx information is used
then the same accuracy can be reached using a
much smaller training corpus (20k words). This
clearly shows that while dealing with morpholog-
ically rich languages, time and effort should be
invested in building powerful morphological ana-
lyzer.
2. Weak morphological features vs rich mor-
phological analyzer: Figure 3 shows that in the
case of POS tagging using just weak morpholog-
ical features gives much better results than the
baseline (i.e. using only weak features). How-
ever, it does not do as well as the rich features
especially when the training size is small, thereby
suggesting that an approximation of the morpho-
logical sufﬁxes may not work for a language hav-
ing rich and diverse morphology. On the other
hand, in the case of chunking, the weak morpho-
logical features do marginally better than the rich
morphological features suggesting that for a rela-
tively easier task (chunking as compared to POS
tagging) even a simple approximation of the ac-
tual sufﬁxes may deliver the goods.
3. Speciﬁc case of verbs: Figure 4 shows that in
case of POS tagging using sufﬁxes as features re-
sults in a signiﬁcant increase in accuracy of verbs.
Speciﬁcally accuracy increases from 62% to 95%
using a very small amount of annotated corpus
(20K words). Comparing this with ﬁgure 5 we see
that while using morphological information deﬁ-
nitely helps other POS categories, the impact is
not as high as that felt for verbs. Figures 7 and
8 for chunking show a similar pattern i.e., the ac-
curacy of verb chunks is affected more by mor-
phology as compared to other chunk tags. These
ﬁgures support our claim that “verbs is where all
the action lies” and they indeed need special treat-

VM
17078

VM
VAUX 257

VAUX
347
6025

Table 3: Confusion matrix for VM-VAUX using
Rich-MF

ment in terms of morphological analysis.
4. Effect of VGI: Figures 3 and 4 show that
the VGI module does not lead to any improve-
ment in the overall accuracy. A detailed analysis
showed that this is mainly because there was not
much VM-VAUX ambiguity left after applying
CRF model containing rich morphological fea-
tures. To further illustrate our point we present the
confusion matrix (see Table 3 ) for verb tags for
a POS tagger using Rich-MF. Table 3 shows that
there were only 347 VM tags which got wrongly
tagged as VAUX and 257 VAUX tags which got
wrongly tagged as VM. Thus the rich morpholog-
ical features were able to take care of most VM-
VAUX ambiguities in the data. However we feel
that if the data contains several VM-VAUX ambi-
guities such as the one illustrated in the example
in Section 5.3 then the VGI module would come
in play and help to boost the performance by re-
solving such ambiguities.

9 Conclusion
We presented here our work on shallow parsing of
a morphologically rich language- Marathi. Our re-
sults show that while dealing with such languages
one cannot ignore the importance of harnessing
morphological features. This is especially true for
verbs where improvements upto 50% in accuracy
can be obtained by adroit handling of sufﬁxes and
accurate verb group identiﬁcation. An important
conclusion that can be drawn from our work is
that while dealing with morphologically rich lan-
guages it makes sense to invest time and money
in developing powerful morphological analyzers
than placing all the bets on annotating data.

References
Black, Ezra, Fred Jelinek, John Lafferty, Robert Mer-
cer, and Salim Roukos. 1992. Decision tree mod-
els applied to the labeling of text with parts-of-

355

speech. In HLT ’91: Proceedings of the workshop
on Speech and Natural Language, pages 117–121,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.

Brants, Thorsten. 2000. TnT - A Statistical Part-
of-Speech Tagger.
In 6th Applied Natural Lan-
guage Processing (ANLP ’00), April 29 - May 4,
pages 224–231. Association for Computational Lin-
gusitics.

Brill, Eric. 1995. Transformation-Based Error-Driven
Learning and Natural Language Processing: A Case
Study in Part-of-Speech Tagging. Computational
Linguistics, 21(4):543–565.

Damale, M K. 1970. Shastriya Marathi Vyaakarana.

Pune Deshmukh and Company.

Garside, Roger and Nicholas Smith. 1997. A Hybrid
Grammatical Tagger: CLAWS. In Garside, Roger,
Geoffrey Leech, and Tony McEnery, editors, Cor-
pus Annotation, pages 102–121. Longman, London.

Giorgos, Orphanos, Kalles Dimitris, Papagelis Thana-
sis, and Christodoulakis Dimitris. 1999. Decision
Trees and NLP: A case study in POS Tagging.

Lafferty, John, Andrew McCallum, and F. Pereira.
2001. Conditional Random Fields: Probabilis-
tic Models for Segmenting and Labeling Sequence
Data. In Proc. 18th International Conf. on Machine
Learning, pages 282–289. Morgan Kaufmann, San
Francisco, CA.

Megyesi, Beta. 1999. Improving Brill’s POS Tagger

For An Agglutinative Language, 02.

Oﬂazer, Kemal and Ilker Kuru¨oz. 1994. Tagging and
Morphological Disambiguation of Turkish Text. In
ANLP, pages 144–149.

Ratnaparkhi, Adwait. 1996. A Maximum Entropy
Model for Part-of-Speech Tagging.
In Brill, Eric
and Kenneth Church, editors, Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 133–142. Association for
Computational Linguistics, Somerset, New Jersey.

Singh, Smriti, Kuhoo Gupta, Manish Shrivastava, and
Pushpak Bhattacharyya.
2006. Morphological
Richness Offsets Resource Demand - Experiences
in Constructing a POS Tagger for Hindi.
In Pro-
ceedings of ACL-2006.

Tlili-Guiassa, Yamina. 2006. Hybrid Method for Tag-
ging Arabic Text. Journal of Computer Science 2,
3:245–248.

