















































Jointly Extracting Japanese Predicate-Argument Relation with Markov Logic


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1125–1133,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

Jointly Extracting Japanese Predicate-Argument Relation
with Markov Logic

Katsumasa Yoshikawa, Masayuki Asahara and Yuji Matsumoto

Graduate School of Information Science,

Nara Institute of Science and Technology

8916-5, Takayama-cho, Ikoma, Nara 630-0192, Japan

{katsumasa-y,masayu-a,matsu}@is.naist.jp

Abstract

This paper describes a new Markov Logic

approach for Japanese Predicate-Argument

(PA) relation extraction. Most previous

work built separated classifiers correspond-

ing to each case role and independently

identified the PA relations, neglecting de-

pendencies (constraints) between two or

more PA relations. We propose a method

which collectively extracts PA relations by

optimizing all argument candidates in a

sentence. Our method can jointly consider

dependency between multiple PA relations

and find the most probable combination of

predicates and their arguments in a sen-

tence. In addition, our model involves new

constraints to avoid considering inappro-

priate candidates for arguments and iden-

tify correct PA relations effectively. Com-

pared to the state-of-the-art, our method

achieves competitive results without large-

scale data.

1 Introduction

Predicate-argument (PA) relation extraction is

one of the challenging problems in Natural Lan-

guage Processing. The analysis extracts seman-

tic information such as “who did what to whom”,

which is often useful to various applications like

information extraction, document summarization,

and machine translation.

Predicate-argument relation extraction is of-

ten called semantic role labeling. In English,

it has been researched on large corpora such

as FrameNet (Fillmore et al., 2001) and Prop-

Bank (Palmer et al., 2005). CoNLL Shared Task

2008 (Surdeanu et al., 2008) is a representative

work of semantic role labeling based on these cor-

pora. Japanese PA relation extraction is a kind

of semantic role labeling but an argument is often

called case. A typical example of Japanese PA re-

Figure 1: Example of Predicate-Argument Struc-

ture

lation is shown in Figure 1. In this example, “��
� (went)” is a predicate and there are two argu-
ments for the predicate, that is, a nominative case

role (ga) is “� (He)” and a dative case role (ni) is
“��� (library)”.

In Japanese, Taira et al. (2008) and Imamura et

al. (2009) tackled PA relation extraction on NAIST

Text Corpus (Iida et al., 2007). They created

three separated models corresponding to each of

the case; ga (Nominative), wo (Accusative), and ni

(Dative).

Even though some English semantic role labeler

apply global models, most of them solve problems

on a per-predicate basis (Toutanova et al., 2008;

Watanabe et al., 2010). In this work, we propose

an approach to Japanese PA relation extraction on

a per-sentence basis and utilize important depen-

dencies between one PA relation and another in the

same sentence. In order to use such dependencies

as global constraints, we apply a Markov Logic ap-

proach to Japanese PA relation extraction. In recent

years, in English semantic role labeling, a Markov

Logic model has achieved one of the state-of-the-

art results (Meza-Ruiz and Riedel, 2009a). With

global constraints between multiple PA relations,

a Markov Logic model can avoid inconsistencies

between several PA relations and improve perfor-

mance of extraction.

In addition, we introduce new global constraints

to effectively delete inappropriate argument can-

didates which are unrelated to PA relations. We

consider that extraction of PA relations and dele-

1125



Figure 2: Difference in Methods

tion of the other phrases are two sides of the same

coin. We jointly perform such extraction and dele-

tion with Markov Logic.

Through our experiments, we report the effec-

tiveness of the Markov Logic approach to Japanese

PA relation extraction in detail. We show that

our model with global constraints outperforms the

model without them. Comparison with previ-

ous work shows that our Markov Logic approach

achieves competitive results without selectional

preference features obtained from large-scale un-

labelled data. In qualitative analysis, we find that

our global model resolves some difficult cases such

as PA relations in relative clauses.

The remainder of this paper is organized as fol-

lows: Section 2 describes related work; Section

3 introduces Markov Logic; Section 4 explains

our proposed Markov Logic Network; Section 5

presents and discusses the experimental setting and

the results; and in Section 6 we conclude and

present ideas for future research.

2 Related Work

In Japanese, PA annotated corpora such as Ky-

oto Text Corpus (KTC) (Kawahara et al., 2002) and

NAIST Text Corpus (NTC) (Iida et al., 2007) have

been developed and utilized. 1 CoNLL Shared Task

2009 (Hajič et al., 2009) included Japanese PA re-

lation extraction on the data from KTC.

The data we used in this work is from NTC. NTC

is based on the same text as KTC, which contains

38,384 sentences from 2,929 news articles. 2 The

annotation in NTC has the three case roles: “ga

(Nominative)”, “wo (Accusative)”, and “ni (Da-

tive)”. The predicate-argument annotation in NTC

is based on deep cases and is more difficult to ana-

1KTC is annotated with surface cases and NTC is anno-
tated with deep cases

2These articles are from a Japanese newspaper, “Mainichi
Shinbun”

lyze than the surface case annotations which KTC

employs. Note that KTC includes morphological

information, base phrase segmentation, and syntac-

tic dependency structure. We can merge these an-

notation from KTC and deep case annotation from

NTC.

There are two main previous work with NTC.

First, Taira et al. (2008) researched extraction of

PA relations by SVM classifiers and decision lists.

Their approach focused on not only verbal predi-

cates but also nominal predicates. Secondly, Ima-

mura et al. (2009) combined a Maximum Entropy

model with a language model learned from large-

scale corpora and achieved the state-of-the-art re-

sults.

Both Taira et al. and Imamura et al. created an

independent model for each of the cases ga, wo,

and ni (the left box in Figure 2). So, their models

neglect the dependencies between cases. For exam-

ple, the method in previous work produces “NP2”

for both ga and ni cases. Though it is unlikely that

the same noun phrase occupies two argument posi-

tions of a predicate, it is possible with their models.

However, our Markov Logic approach creates a

joint model for the three cases and finds the most

probable assignments taking into consideration the

dependency between them. As a result, our model

can prevent such an unlikely result (See the right

box in Figure 2).

Moreover, in contrast to Imamura’s work, our

method does not exploit large-scale corpora. They

depended on their language model derived from

large-scale corpora to decide the selectional prefer-

ence between a predicate and an argument. On the

other hand, we handle the problem by global op-

timization per-sentence without using large-scale

corpora.

In the CoNLL Shared Task 2009 (Hajič et al.,

2009), a competition of multilingual semantic role

labeling was held and Japanese was one of the

target languages. In the shared task, Meza-Ruiz

and Riedel (2009b) proposed a joint approach with

Markov Logic. They also reported their Markov

Logic approach for English semantic role labeling

in detail (Meza-Ruiz and Riedel, 2009a). Their

method divided the problem into four subtasks:

predicate identification, argument identification,

sense disambiguation, and role labeling. The sub-

tasks are solved jointly. 3 We adapt their model to

3Note, in the CoNLL 2009 Shared Task, predicate identifi-
cation is not necessary. So, they used the CoNLL 2008 Shared
Task data in their work.

1126



Japanese PA relation extraction on NTC. In order

to compare with Taira et al. (2008) and Imamura et

al. (2009), we perform only argument identification

and role labeling.

About joint models of semantic role labeling

without using Markov Logic, there are various pre-

vious work on CoNLL Shared Task Data. For ex-

ample, Toutanova et al. (2008) and Watanabe et

al. (2010) proposed joint models on the data of

CoNLL Shared Task 2005 and 2009, respectively.

While their models solve the problem on a per-

predicate basis, our Markov Logic model solves it

on a per-sentence basis. An optimization on a per-

sentence basis is necessary and desirable for PA re-

lation extraction on NTC since NTC has deep case

annotations without case-frame dictionaries corre-

sponding to them.

3 Markov Logic

It has long been clear that local classification

alone cannot adequately solve all prediction prob-

lems we encounter in practice. This observa-

tion motivated a field within machine learning,

often referred to as Statistical Relational Learn-

ing (SRL), which focuses on the incorporation

of global correlations that hold between statistical

variables (Getoor and Taskar, 2007).

One particular SRL framework that has recently

gained momentum as a platform for global learn-

ing and inference in AI is Markov Logic (Richard-

son and Domingos, 2006), a combination of first-

order logic and Markov Networks. It can be under-

stood as a formalism that extends first-order logic

to allow formulae that can be violated with some

penalty. From an alternative point of view, it is an

expressive template language that uses first order

logic formulae to instantiate Markov Networks of

repetitive structure. In the field of NLP, the Markov

Logic approach has been applied to various tasks

such as entity resolution (Singla and Domingos,

2006)�information extraction (Poon and Domin-
gos, 2007), and coreference resolution (Poon and

Domingos, 2008), among others.

From a wide range of SRL languages we chose

Markov Logic because it supports discriminative

training (as opposed to generative SRL languages

such as PRM (Koller, 1999)). Moreover, sev-

eral Markov Logic software libraries exist and are

freely available (as opposed to other discrimina-

tive frameworks such as Relational Markov Net-

works (Taskar et al., 2002)).

A Markov Logic Network (MLN) M is a set of

pairs (φ,w) where φ is a first order formula and w

is a real number (the formula’s weight). It defines a

probability distribution over sets of ground atoms,

or so-called possible worlds, as follows:

p (y) =
1

Z
exp




�

(φ,w)∈M

w
�

c∈Cφ

f
φ
c (y)


 (1)

Here each c is a binding of free variables in φ to

constants in our domain. Each f
φ
c is a binary fea-

ture function that returns 1 if in the possible world

y the ground formula we get by replacing the free

variables in φ with the constants in c is true, and

0 otherwise. Cφ is the set of all bindings for the

free variables in φ. Z is a normalization constant.

Note that this distribution corresponds to a Markov

Network (the so-called Ground Markov Network)

where nodes represent ground atoms and factors

represent ground formulae.

Designing formulae is only one part of the game.

In practice, we also need to choose a training

regime (in order to learn the weights of the formu-

lae we added to the MLN) and a search/inference

method that picks the most likely set of ground

atoms (PA relations in our case) given our trained

MLN and a set of observations. However, imple-

mentations of these methods are often already pro-

vided in existing Markov Logic interpreters such as

Alchemy 4 and Markov thebeast. 5

4 Proposed Markov Logic Network

This section describes our Markov Logic model

for Japanese PA relation extraction. We will

describe our proposed Markov Logic Network

(MLN) in detail. First, let us define logical pred-

icates for our MLN. The three hidden predicates

are listed in Table 1.

predicate definition

isArg(i) Bunsetsu i is an argument

delete(i) Bunsetsu i is deleted

role(i, j, r) Bunsetsu i has an argument j

with role r

Table 1: Hidden Predicates

Note that Japanese dependency parsing is based

on bunsetsu units, which are similar in concept to

English base phrases. In order to exploit informa-

tion parsed in this way, we handle all logical pred-

icates by bunsetsu phrases (not tokens).

The hidden predicates model the decisions we

4http://alchemy.cs.washington.edu/
5http://code.google.com/p/thebeast/

1127



logical predicate description example

word(i,w) Bunsetsu i has word form w ��� (went),� (he)
stem(i, s) Bunsetsu i has stem s �� (go)
pos(i, p) Bunsetsu i has POS tag p (coarse-grained) �� (noun)
dpos(i, p) Bunsetsu i has POS tag p (fine-grained) ��-�� (noun-general)
ne(i, n) Bunsetsu i has named entity tag n (from NE tagger) PERSON�LOCATION
kana(i, k) Bunsetsu i has kana (Romanization) k itta, kare

isPred(i) Bunsetsu i is a predicate True or False

numeric(i) Bunsetsu i has a number character True or False

de f inite(i) Bunsetsu i contains the article corresponding to

DEFINITE “the”, such as “sore” or “sono”

True or False

demonstrative(i) Bunsetsu i contains the article corresponding to

DEMONSTRATIVE “this” or “that”, such as

“kono” or “ano”

True or False

particle(i) Bunsetsu has a particle such as “wa”,“ga”,“wo”,

“ni”

True or False

goiCate(i, g) Bunsetsu i has lexical category tag g in Nihongo

Goi Taikei (Ikehara et al., 1997)

���� (sport),�� (female)

goiMatch(i, j) Bunsetsu phrases i and j satisfy the selectional

restriction of Nihongo Goi Taikei

True or False

dep(i, j, d) Dependency label between i and j is d True or False

path(i, j, l) Syntactic path between i and j is l ↑↓ (sibling), ↑↑ (ancestor)

Table 2: Observed Predicates

need to make: whether a bunsetsu phrase i is an

argument of some predicate (argument identifica-

tion); whether a bunsetsu phrase i is deleted (phrase

deletion); whether a bunsetsu phrase j is an argu-

ment of the predicate i with semantic role r (role

labeling).

Here the first two types of decision can be mod-

eled through unary logical predicates isArg(a) and

delete(i), while the other type can be represented

by a ternary logical predicate role(p, a, r). Because

we do not know their information at test time, we

call them hidden.

Our Markov Logic approach is based on English

semantic role labeling with Markov Logic as pro-

posed by Meza-Ruiz and Riedel (2009a). As men-

tioned earlier, they divided the problem into four

subtasks and defined five hidden predicates (is-

Predicate, isArgument, hasRole, role, and sense).

In order to be comparable with the previous work

in Japanese PA relation extraction (Taira et al.,

2008; Imamura et al., 2009), we deal with only ar-

gument identification and role labeling in our re-

search. Therefore, we define only the three hidden

predicates in Table 1.

In addition to the hidden predicates, we define

observed logical predicates representing informa-

tion at test time. For example, in our case we

could introduce a predicate word(i,w) which indi-

cates that a phrase i has the word form w. We list

the all observed predicates in Table 2.

With our predicates defined, we can now go on

to incorporate our intuition about the task using

weighted first-order logic formulae. In the follow-

ing we will explain the formulae of our proposed

MLN. Sections 4.1 and 4.2 describe our local and

global formulae for isArg and role, respectively.

Section 4.3 mentions the formulae for deletion.

4.1 Local Formulae

We say that a formula is local if its groundings

relate any number of observed ground predicates to

exactly one hidden ground predicate. Local formu-

lae are defined with some observed predicates from

Table 2 and a hidden predicate from Table 1.

The local formulae for isArg and delete capture

the relation of the bunsetsu phrases with their lex-

ical and syntactic properties (simple phrase prop-

erty). The formula describing a local property of

word form is

word(a,+w)⇒ isArg(a) (2)

which implies that a bunsetsu a is an argument with

a weight that depends on the word form. Note, the

+ notation indicates that the MLN contains one in-

1128



Type Formula Description

hard isArg(a)⇒ ∃p.∃r.role(p, a, r) Every argument must relate to at least one predicate

hard role(p, a, r)⇒ isArg(a) If a plays the role r for p, then a has to be an argument

hard role(p, a, r1) ∧ r1 � r2 ⇒ ¬role(p, a, r2) There is exact one case role between a predicate and an ar-
gument

Table 3: Global Formulae for isArg and role

stance of the rule, with a separate weight, for each

assignment of the variables with a plus sign.

The local formulae for role represent proper-

ties between two bunsetsu phrases (linked phrases

property). For example, the following formula

ne(a,+n) ∧ dep(p, a,+d)

⇒ role(p, a,+r) (3)

denotes a local property of named entity and syn-

tactic dependency.

As in Formula (3), some observed predicates

(goiMatch, dep, and path) in Table 2 construct for-

mulae using other observed predicates in this table.

First-order logical formulae such as Formulae

(2) and (3) become the feature templates of MLN.

Each template produces several instantiations. An

example of a template instantiation based on Figure

1 is

ne(1, PERSON) ∧ dep(4, 1, “D”)

⇒ role(4, 1, ga) (4)

which is a typical expansion from Formula (3).

4.2 Global Formulae

The intuition behind the previous formulae can

also be captured using a local classifier. However,

Markov Logic also allows us to say more:

isArg (a)⇒ ∃p.∃r.role(p, a, r) (5)

In this formula, we made a statement about more

global properties of a PA relation extraction that

cannot be captured with local classifiers. This for-

mula ensures the consistency between predicate

and argument, that is, arguments belong to at least

one predicate. This type of rule forms the core idea

of our global model.

Global formulae involve two or more atoms of

hidden predicates and enable us to jointly deal with

argument identification, phrase deletion, and role

labeling. With global formulae, our MLN consid-

ers not only a single decision at a time but also han-

dles several decisions, simultaneously. Our global

formulae for argument identification and role label-

ing are shown in Table 3.

All the formulae in Table 3 are hard con-

straints which enforce consistency between the hid-

den predicates. In MLN, formulae of hard con-

straint are defined as special formulae with infinite

weights. A possible world which violates hard con-

straints is never chosen as a correct answer. For

example, Formula (5) is such a global formula.

Another formula ensuring the consistency between

role and isArg is

role(p, a, r)⇒ isArg (a) (6)

which indicates “If a phrase a plays the role r for

p, then a must be an argument”.

The last global formula

role(p, a, r1) ∧ r1 � r2 ⇒ ¬role(p, a, r2) (7)

implies that there is only one case role between a

predicate p and an argument a. Formula (7) enables

us to prevent the contradiction shown in Figure 2.

4.3 Deletion Formulae

Let us explain formulae for deletion in this sec-

tion, independently. The main idea of our deletion

is to delete bunsetsu phrases which are unrelated

to PA relations and to help extract correct argu-

ments. Extraction of correct arguments and dele-

tion of non-arguments are two sides of the same

idea. An example is shown in Figure 3. We have a

main verb “��� (went)” as a predicate and there
are five argument candidates for it. We want to

extract correct arguments, “�� (He)” for ga-case
and “��� (library)” for ni-case among the five
candidates. Here, if we can remove an instrumental

case, “������� (by mother’s new car)”, ex-
tracting the correct arguments becomes much eas-

ier.

Notably, our significant contribution is doing

this deletion processes with extraction of PA re-

lations, simultaneously. Deleting too many bun-

setsu phrases often hurts the recall because it often

deletes correct arguments. We call this phenomena

over-deletion. Performing extraction and deletion

by one joint model prevents over-deletion and im-

proves the performance of PA relation extraction.

Deletion formulae are also divided into local and

global. However, local formulae implement the

same properties for isArg we mentioned in Section

4.1. As an exception, a characteristic local formula

1129



Figure 3: Example of PA Relation with Instrumental Case

is

dep(i, j,+d) ∧ isPred( j)⇒ ¬delete(i). (8)

which implies the PA relations with syntactic de-

pendencies are not deleted. It implements the fact

that PA relations often have syntactic dependency

relations. Actually, we can find that dependency

relations are dominant in Table 5 and Formula (8)

contributes to improve performance.

However, the local formulae address the deletion

of a single bunsetsu phrase and we cannot expect

a large improvement by adding delete. The main

contributions of delete come from the global dele-

tion formulae.

The global formulae for delete have three hard

and one soft constraints. We show the global for-

mulae in Table 4. The first three formulae in this

table show the hard constraints which ensure the

consistency between delete and the other two hid-

den predicates (isArg and role). The most impor-

tant formula of them is

delete(i)⇒ ¬isArg(i) (9)

which implies that the deleted phrase does not be-

come an argument.

The last formula in Table 4 is defined as a soft

constraint:

word(h,+w) ∧ pos(h,+p) ∧ dep(h,m,+d)

∧delete(h)⇒ delete(m) (10)

which denotes “if a head phrase h is removed, then

the child phrases m should be deleted”. This for-

mula does not always hold but the remaining un-

certainty with regard to this formula is captured

by a weight trained from corpora. This constraint

implements the important deletion concept as we

mentioned earlier.

Considering the example in Figure 3, Formula

(10) is grounded as,

word(4, “��”) ∧ pos(4,NOUN+PARTICLE)

∧dep(4, 2, “D”) ∧ delete(4)⇒ delete(2) (11)

which implies that “if ‘�� (by car)’ is removed,
‘�� (mother’s)’ should be also removed”. Figure
4 shows the dependency parsed tree extracted from

Figure 4: Deletion of Instrumental Case

the sentence in Figure 3. The subtree under “��
(by car)” should be deleted by Formula (11).

Note that Japanese dependency parsing usually

targets only unlabeled parsing. Almost all labels

are “D”. 6 Therefore, we exploit the word and

pos of head bunsetsu phrases as a substitution. In

Japanese, word form and POS implicitly give us in-

formation similar to dependency labels. However,

if we exploit our method in English, labeled infor-

mation such as probj or amod should be helpful to

train proper weights for Formula (10).

5 Experimental Results

5.1 Experimental Setup

Our experimental setting is based on previous

work (Taira et al., 2008; Imamura et al., 2009)

which was performed on NAIST Text Corpus.

Let us summarize our used data and tools. The

data used, NAIST Text Corpus version 1.4β, has

news articles and editorials. As training examples,

we use articles published from January 1st to Jan-

uary 11th and editorials from January to August.

As development data, we use articles published on

January 12th and 13th and editorials in September.

For evaluation, we use articles dated January 14th

to 17th and editorials dated October to December.

This way to split the data is same as Taira et al.

(2008). We show the statistics of the evaluation

data in Table 5.

As seen in this table, “ga-case” is dominant.

PA relations which have syntactic dependency re-

6We sometimes have “P”, “A”, and “I” labels but it is not
enough to model our deletion idea.

1130



Type Formula Description

hard isArg(a)⇒ ¬delete(a) If a is an argument then it is not deleted.

hard delete(i)⇒ ¬isArg(i) If a bunsetsu i is deleted then it is not an argument.

hard role(p, a, r)⇒ ¬delete(p) ∧ ¬delete(a) If a is an argument of p with the role r then neither p
nor a is deleted.

soft word(h,+w)∧pos(h,+p)∧dep(h,m,+d)∧

delete(h)⇒ delete(m)

If a head phrase h is deleted with word w and POS p
then a child phrase m is deleted.

Table 4: Global Deletion Formulae

ga wo ni

Dep. 13,086 5,192 3,645

Zero-Intra 4,556 376 231

Total 17,642 5,568 3,876

Table 5: Statistics in Evaluation Data

lations (Dep.) are much more common than

intra-sentential zero-anaphoric PA relations (Zero-

Intra). However, in Japanese, we often find

zero-anaphoric PA relations called case ellipsis.

More detailed descriptions of PA relation types

are shown in (Iida et al., 2006). Note that we

target only PA relations which occur in a sen-

tence (intra-sentential PA relations). The joint

approach using Markov Logic is computationally

hard even if it targets only intra-sentential PA rela-

tions. Therefore, extraction of inter-sentential PA

relations which are crossing sentence boundaries is

intractable. Moreover, our approach finds the most

optimized PA assignments in a whole sentence. To

keep consistency in a sentence, we delete the sen-

tences which have inter-sentential PA relations.

For extracting features, we exploit the annota-

tion of Kyoto Text Corpus as the POS and the syn-

tactic dependency of bunsetsu phrases. We per-

form named entity tagging using CaboCha version

0.53. 7 Based on Taira’s work, we introduce se-

lectional restriction features from a Japanese The-

saurus, Nihongo Goi Taikei (Ikehara et al., 1997).

Learning and inference algorithms for our joint

model are provided by Markov thebeast, a Markov

Logic engine tailored for NLP applications.

5.2 Results

First, let us show the comparison between the

models with/without global constraints in Table 6.

Global is the model with global constraints and Lo-

cal is without them. Note that the local and global

formulae of deletion are also included in Local and

Global, respectively. Table 6 shows Precision (P),

Recall (R), and F1-value (F) of each hidden pred-

icate. We can find that Global yielded clear im-

7http:/code.google.com/p/cabocha/

Local Global

P R F P R F

isArg 79.2 71.4 75.1 94.6 84.2 89.1

delete 86.6 90.4 88.4 94.3 97.9 96.1

role 86.3 72.5 78.8 85.5 77.7 81.4

Table 6: Local vs Global

provements for all hidden predicates. These im-

provements are statistically significant. 8 These re-

sults suggest that the three target subtasks (argu-

ment identification, phrase deletion, and role label-

ing) can cooperate with each other. For PA relation

extraction (role), the recall was mainly improved

(the value in bold type).

We perform a simple analysis of hidden predi-

cate removal. For each hidden predicate, a model

was trained with that predicate removed and all

other predicates retained. For PA relation extrac-

tion (role), Table 7 shows the model performance

with removal of the isArg and delete predicates.

The removal of delete drops the model perfor-

mance larger than that of isArg. While the removal

of isArg drops the precision and saves the recall,

the removal of delete is the other way around.

Next, we evaluate the results of PA relation ex-

traction (role) by each case, “ga (Nominative)”,

“wo (Accusative)”, and “ni (Dative)” in Table 8.

All scores in the table are F1-value. Our Global

model is more advantageous in “Zero-Intra” than

Local model. Especially, in ga-case of Zero-Intra

the score jumped from 42.1pt to 54.1pt (+12pt).

Again, with global constraints, our global model

finds the most probable state in the sentence. It

is often difficult to extract Zero-Intra PA relations

with only local features because syntactic depen-

dencies between them are weak. Therefore, our

global constraints contribute to find correct assign-

ments of PA relations and we got a large improve-

ment in Zero-Intra.

Let us compare our results with the state-of-the-

art (Taira et al., 2008; Imamura et al., 2009). In

Table 8, we show the best scores in bold types for

8ρ < 0.01, McNemar’s test 2-tailed

1131



Local Global [Taira, 2008] [Imamura, 2009]

ga wo ni ga wo ni ga wo ni ga wo ni

Dep. 85.7 91.2 79.5 88.8 91.3 79.7 75.6 88.2 89.5 87.0 93.9 80.8

Zero-Intra 42.1 7.3 0.0 54.1 10.3 0.0 30.2 11.4 3.7 50.0 30.8 0.0

Table 8: Comparison to the State-of-the-Art (F1)

Predicate Removed P R F

No removal (Global) 85.5 77.7 81.4

-isArg 84.8 77.9 81.2

-delete 85.3 76.8 80.8

-isArg-delete (Local) 86.3 72.5 78.8

Table 7: Effect of Hidden Predicate Removal

each case. For ga-case, our model, Global, out-

performed the others. On the other hand, for wo-

case and ni-case, our results were relatively lower

than them. Because our approach deals with the

all three cases by one joint model and ga-case is

dominant in the data, it extracts more numbers of

ga-case than the others. However, ga-case is often

the most important for PA relation extraction and

sometimes called indispensable case. Our method

can extract such important information better than

previous work. Although our model did not exploit

large-scale corpora, our results are competitive to

the results of Imamura et al. (2009).

Error Analysis

(this)
��
1

(reason)
��
2
�
(Gray Wolf)
����

3

(revival in the US)
����

4
(plan)

���
5

(FWS)
��������

6

(in Canada)
����

7

(capture)

����
8

(wild)
���

9

(twelve wolves)
����

10

(transport by air)

��
11

�

(Form this reason, FWS which plans to revive Gray
Wolf in the US captured twelve wolves in Canada and
transported them by air.)

In the above sentence, we have three predicates

(gray boxed) and three arguments (underlined).

The relations between predicates and arguments

are complex with relative clause and often cause

misunderstandings.

About this sentence, our Local model output:
�
role(5, 6, ga), role(5, 4,wo), role(8, 6, ga),

role(11, 2, ga), role(11, 10,wo)
�

It did not output wo-case of “���� (cap-
ture)”. Because we do not have case-frame dictio-

nary in NTC, our models did not know that “��
��” usually requires wo-case (Accusative).
Another error is underlined that ga-case of “��

(transport by air)” is identified as “�� (reason)”,
because “��” is only a phrase dependent on “�
�”.
On the other hand, Global improved the errors as
�
role(5, 6, ga), role(5, 4,wo), role(8, 6, ga),

role(8, 10,wo), role(11, 6, ga), role(11, 10,wo)
�
.

By global optimization in a sentence, our Global

model overcame the lack of semantic features and

successfully identified “����” as wo-case of “
����”. This PA relation is in a relative clause
and often hard to identify. Though Abekawa and

Okumura (2005) resolved Japanese PA relations in

relative clauses by exploiting large-scale corpora,

our Markov Logic approach handles this problem

by global optimization. Moreover, in global model,
�
delete(1), delete(2), delete(7)

�
are also output and

“��” and “��” did not become argument can-
didates. As a result, “��������” was cor-
rectly selected as a ga-case of “��”.

6 Conclusion

In this paper, we proposed a new Markov Logic

approach for Japanese predicate-argument (PA) re-

lation extraction. Our model exploited global con-

straints between multiple PA relations and intro-

duced phrase deletion. Our global constraints suc-

cessfully improved the performance of PA relation

extraction. In comparison to the state-of-the-art,

our approach achieved competitive results with no

large-scale data.

As future work, we will introduce utilizing fea-

tures derived from large-scale data following Ima-

mura’s work. Selectional preference features from

large-scale corpora are expected to improve the

performance for extracting wo-case and ni-case.

We will also investigate the state-of-the-art tech-

nique of sentence compression in related to our

deletion approach. It might be interesting to eval-

uate our approach in sentence compression tasks.

Adding sentence compression might make the PA

relation extractor more efficient and allow us to ex-

tract inter-sentential PA relations, too.

1132



References

Takeshi Abekawa and Manabu Okumura. 2005. Corpus-
based analysis of japanese relative clause constructions. In
Proceedings of 2nd International Joint Conference on Nat-
ural Language Processing (IJCNLP), pages 46–57, Jeju Is-
land, Korea.

Charles J. Fillmore, Charles Wooters, and Collin F. Baker.
2001. Building a large lexical databank which pro-
vides deep semantics. In Proceedings of the Pacific
Asian Conference on Language, Information and Compu-
tation(PACLIC), Hong Kong.

Lise Getoor and Ben Taskar, 2007. Introduction to Statistical
Relational Learning, chapter 12, pages 339–371. The MIT
Press, Cambridge Massachusetts 02142.

Jan Hajič, Massimiliano Ciaramita, Richard Johansson,
Daisuke Kawahara, Maria Antònia Martı́, Lluı́s Màrquez,
Adam Meyers, Joakim Nivre, Sebastian Padó, Jan
Štěpánek, Pavel Straňák, Mihai Surdeanu, Nianwen Xue,
and Yi Zhang. 2009. The conll-2009 shared task: Syn-
tactic and semantic dependencies in multiple languages.
In Proceedings of the Thirteenth Conference on Computa-
tional Natural Language Learning (CoNLL 2009): Shared

Task, pages 1–18, Boulder, Colorado, June. Association for
Computational Linguistics.

Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2006. Ex-
ploiting syntactic patterns as clues in zero-anaphora resolu-
tion. In Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual meet-

ing of the Association for Computational Linguistics, ACL-
44, pages 625–632, Stroudsburg, PA, USA. Association for
Computational Linguistics.

Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji Mat-
sumoto. 2007. Annotating a japanese text corpus with
predicate-argument and coreference relations. In Proceed-
ings of the Linguistic Annotation Workshop, LAW ’07,
pages 132–139, Stroudsburg, PA, USA. Association for
Computational Linguistics.

Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio
Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi
Ooyama, and Yoshihiko Hayashi. 1997. Nihongo Goi
Taikei, A Japanese Lexicon. Iwanami Shoten, Tokyo.

Kenji Imamura, Kuniko Saito, and Tomoko Izumi. 2009. Dis-
criminative approach to predicate-argument structure anal-
ysis with zero-anaphora resolution. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the ACL

and the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP (ACL-IJCNLP), Confer-
ence Short Papers, pages 85–88, Suntec, Singapore, Au-
gust. Association for Computational Linguistics.

Daisuke Kawahara, Sadao Kurohashi, and Koichi Hashida.
2002. Construction of japanese relevance-tagged corpus
(in japanese). In the 8th Annual Meeting of the Association
for Natural Language Processing, pages 495–498.

Daphne Koller, 1999. Probabilistic Relational Models, pages
3–13. Springer, Berlin/Heidelberg, Germany.

Ivan Meza-Ruiz and Sebastian Riedel. 2009a. Jointly identi-
fying predicates, arguments and senses using markov logic.
In Proceedings of Human Language Technologies: The
2009 Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages 155–
163, Boulder, CO, USA, June. Association for Computa-
tional Linguistics.

Ivan Meza-Ruiz and Sebastian Riedel. 2009b. Multilingual
semantic role labelling with markov logic. In Proceed-
ings of the Thirteenth Conference on Computational Natu-
ral Language Learning (CoNLL 2009): Shared Task, pages
85–90, Boulder, Colorado, June. Association for Computa-
tional Linguistics.

Martha Palmer, Paul Kingsbury, and Daniel Gildea. 2005.
The proposition bank: An annotated corpus of semantic
roles. Computational Linguistics, 31.

Hoifung Poon and Pedro Domingos. 2007. Joint infer-
ence in information extraction. In Proceedings of the
Twenty-Second National Conference on Artificial Intelli-
gence, pages 913–918, Vancouver, Canada. AAAI Press.

Hoifung Poon and Pedro Domingos. 2008. Joint unsuper-
vised coreference resolution with Markov Logic. In Pro-
ceedings of the 2008 Conference on Empirical Methods in
Natural Language Processing, pages 650–659, Honolulu,
Hawaii, October. Association for Computational Linguis-
tics.

Matthew Richardson and Pedro Domingos. 2006. Markov
logic networks. Machine Learning, 62(1-2):107–136.

Parag Singla and Pedro Domingos. 2006. Entity resolution
with markov logic. In Proceedings of the Sixth Interna-
tional Conference on Data Mining (ICDM), pages 572–
582, Washington, DC, USA. IEEE Computer Society.

Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluı́s
Màrquez, and Joakim Nivre. 2008. The conll 2008 shared
task on joint parsing of syntactic and semantic dependen-
cies. In CoNLL 2008: Proceedings of the Twelfth Confer-
ence on Computational Natural Language Learning, pages
159–177, Manchester, England, August. Coling 2008 Or-
ganizing Committee.

Hirotoshi Taira, Sanae Fujita, and Masaaki Nagata. 2008. A
japanese predicate argument structure analysis using deci-
sion lists. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP), pages
523–532, Honolulu, HI, USA. Association for Computa-
tional Linguistics.

Ben Taskar, Abbeel Pieter, and Daphne Koller. 2002. Dis-
criminative probabilistic models for relational data. In Pro-
ceedings of the 18th Annual Conference on Uncertainty in

Artificial Intelligence (UAI-02), pages 485–492, San Fran-
cisco, CA. Morgan Kaufmann.

Kristina Toutanova, Aria Haghighi, and Christopher D. Man-
ning. 2008. A global joint model for semantic role label-
ing. Computational Linguistics, 34:161–191, June.

Yotaro Watanabe, Masayuki Asahara, and Yuji Matsumoto.
2010. A structured model for joint learning of argument
roles and predicate senses. In Proceedings of the ACL 2010
Conference Short Papers, pages 98–102, Uppsala, Sweden,
July. Association for Computational Linguistics.

1133


