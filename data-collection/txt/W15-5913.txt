



















































Proceedings of the...


D S Sharma, R Sangal and E Sherly. Proc. of the 12th Intl. Conference on Natural Language Processing, pages 89–94,
Trivandrum, India. December 2015. c©2015 NLP Association of India (NLPAI)

An unsupervised EM method to infer time variation in sense probabilities

Martin Emms
Dept of Computer Science

Trinity College, Dublin
Ireland

martin.emms@cs.tcd.ie

Arun Jayapal
Dept of Computer Science

Trinity College, Dublin
Ireland

jayapala@cs.tcd.ie

Abstract

The inventory of senses for a given word
changes over time – tweet has gained the
‘Twitter post’ sense only relatively re-
cently and this paper addresses the prob-
lem of the computational detection of
such change. We propose a generative
model which conditions context words on
a target expression’s sense and conditions
the sense choice on the time of writing.
We develop an EM algorithm to estimate
the parameters from raw time-stamped n-
gram data with no sense annotation. We
are able to demonstrate the inference of
parameters which plausibly reflect the ob-
jective dynamics of sense use frequencies,
in particular the emergence of a new sense.

1 Introduction

Many words are ambiguous so that a simple count
of a word frequency is really a sum of several
word-sense frequencies. It is also the case that
over time the inventory of senses possessed by a
word changes and there must be a point in time
where a given sense first came into use: the ‘Twit-
ter post’ sense of tweet is an example of a rela-
tively recent new arrival. Fig 1 summarises the

1955 1970 20001985

C0

Figure 1: Word frequency (solid line) and sense
frequencies (dashed lines).

situation abstractly, with the solid black-line a plot
of simple word frequency over time (as might eas-
ily be produced the Google n-gram viewer), and

the dashed lines a hypothetical decomposition into
two senses, with one of the senses first emerging
around 1970. Essentially the aim of the paper is to
propose a method which can carry out this kind of
decomposition and then use it to detect the time of
emergence of a novel sense: we have marked this
point C0 in the sense plot.

As lexical information is central to so many
NLP tasks, means to automatically identify
changes to the required information could be use-
ful. For example, if an SMT system trained from
aligned corpora from particular times is to be ap-
plied to text from different times it could be of use
to know whether there have been sense changes,
perhaps identifying which occurrences can be an-
ticipated to be poorly translated. Overlooking this
is perhaps what underlies the following case of
poor translation fron English to Tamil via Google
translate:

aRX qBi? *H�`�- ?Qr2p2`- ?Bb #`Qr +H2�`2/- �M/ ?2 r�b ;�v �;�BM U7`QK õbQMb
�M/ HQp2`bö #v .X>X G�r`2M+2 RNjR,V

hRX �)"(�(� ��)\@� �$�Q SV$@ ��G ?�O@� �G[@ �$B
�*<O@ ��)�9.�B7/��("B

GRX EB­`­- ­vBM mK- �p�`�im Tm`mp�K �F�` ` �TT�*mK- K�` ` mK �p�` Kh *mK
Ô`BM �++�`FF�Bv­�`

The English original, S1, comes from 1931, at
which time gay simply meant ‘happy’. In recent
decades it has overwhelmingly gained the sense
‘homosexual’. T1 and L1 are the Tamil translation
and its transliteration where the word is translated
as ōrin

¯
accērkkaiyāl.ar, which has the ‘homosex-

ual’ sense.
We will propose a relatively simple probabilis-

tic model which conditions words in a target’s con-
text on that target’s sense and conditions senses
on times, which incorporates an independence as-
sumption that the context words are independent
of time given the target’s sense. We use the Google
n-gram data set (Michel et al., 2011) which pro-
vides time-stamped data but no sense informa-
tion and develop an EM algorithm to estimate

89



the model’s parameters in an unsupervised fashion
from this data. We will show that the algorithm
is able to provide an accurate date of sense emer-
gence (true positives), and also to detect the ab-
sence of sense emergence when appropriate (true
negatives). We make some points also concerning
the difficulties in the evaluation of such a sense-
emergence system.

2 A model with time-dependent senses

It is intuitive that the distribution of words in the
context of given target word is not independent
of the sense of that target and this leads to ap-
proaches to unsupervised word-sense disambigua-
tion which seek to model that dependency (Man-
ning and Schütze, 2003). These approaches also
include a prior on the different senses. We essen-
tially generalise this by having a succession of pri-
ors, one for each time period.

To make this more precise, assume a data item
d represents a particular occurrence of a target ex-
pression T , and let ~W be the sequence of words in
a window around T and let Y be its time-stamp.
Suppose there are k different senses of T , mod-
eled with a discrete variable S. A complete data
item is to be thought of as providing values for
Y , S and ~W ; raw data will be incomplete con-
cerning S, the sense. p(Y, S, ~W ) may factorised
as p(Y )p(S|Y )p( ~W |S, Y ) without loss of gener-
ality. We then make some independence assump-
tions: (i) that conditioned on S the words ~W are
independent of Y , so p( ~W |S, Y ) = p( ~W |S) and
(ii) that conditioned on S the words are indepen-
dent of each other, so p( ~W |S) = ∏i(p( ~Wi|S).
This gives equation (1):

p(Y, S, ~W ) = p(Y )×p(S|Y )×
∏

i

p(Wi|S) (1)

The term p(S|Y ) directly models the fact that a
sense’s likelihood can vary over time, possibly
having zero probability on some early range of
times and thus representing the non-availability of
that sense of target T at those times. Assumption
(i) reflects a plausible idea that given a concept be-
ing conveyed, the expected accompanying vocab-
ulary is at least substantially time-independent. It
also drastically reduces the number of parameters
to be estimated. The parameters of the model in
(1) have to be estimated from data in which the
values of the sense variable S are not given. We
tackle this unsupervised estimation problem via

an EM procedure (Dempster et al., 1977), though
Gibbs sampling could be an alternative. We iterate
between an E and an M step, as follows1:

(E) for each data item d and each possible value
s of S, determine the conditional probability
of S = s given Y d and ~W d, under current
parameters – call this γd(s).

(M) use the γd(s) valus to derive new estimates
of parameters via the update formulae

P (S = s|Y = y) =
∑

d:Y d=y[γ
d(s)]∑

d:Y d=y[1]

P (w|S = s) =
∑

d(γ
d(s)×#(w, ~W d))

∑
d(γ

d(s)× length( ~W d))

2.1 Evaluation possibilities
As others have noted, the evaluation of the inferred
sense dynamics produced by such a system is a
challenge: large-scale, sense-labelled, diachronic
corpora to serve as a gold-standard do not exist
(Cook et al., 2014). So without doing large scale
manual annotation, the full detail of the inferred
sense dynamics cannot be straightforwardly eval-
uated.

However, concerning just the times of sense
emergence (the point C0 in Fig.1) the prospects
are somewhat better. First of all, for recent lex-
ical innovations, native speakers are often confi-
dent that they can judge that it is indeed recent
(see section 4). A speaker’s intuition that a sense
emerged recently could serve as prima facie ev-
idence against a system verdict outcome which
finds no such recent emergence.

In pursuit of more objectivity and to consider
innovations that are less recent, it is natural to con-
sider dictionaries. For a given form/meaning pair-
ing, an historically oriented dictionary (eg. the
Oxford English Dictionary (OED)) will strive to
include the very earliest citation that has been dis-
covered – call this Dc0. We will use D

c
0 as a

lower bound on the true emergence date C0, which
seems reasonable. The results section 3 will show
a couple of examples wherre Dc0 is considerably
earlier than C0, the time at which which the use
steadily starts to grow in use. Form/meaning pair-
ings also make it into dictionaries at some partic-
ular time, so close inspection of a succession of
dictionaries, though labour intensive, can give a

1P (Y ) is not estimated can be easily shown not to be
needed for the other estimates.

90



date of its first inclusion – call this Di0. Some
researchers have attempted this (see section 4),
though in what follows we will not.

There is a further option to establish an emer-
gence date for a novel sense of a target T . If
there are words which it is intuitive to expect in
the vicinity of T in the novel sense, and not in
other senses, then one would expect the probabil-
ity of seeing these words in T ’s context to start
to climb at a particular time. For example, mouse
has come to have a sense referring to a computer
pointing device, in which usage it is intuitive to
expect words like click, button, pointer and drag
in it’s context. For any word w and target T let
us define trackT (w) to be the sequence of its per-
year probabilities of occurrence in the context of
T . If when trackmouse(w) is plotted for the above
words, they all show a sharp increase at the same
time point, this is good evidence that this is the
emergence time of the novel sense. In the results
section 3 we will use such ‘tracks’-based dates as
a target against which to compare any apparent in-
flection point of an inferred P (S|Y ) parameter –
the righthand plot in Figure 2(a) is an example.

3 Experiments

The experiments reported here use the Google 5-
gram dataset (Michel et al., 2011). This is a data
set released by Google giving per-year counts of
5-grams in their digitized books holdings. From
the entire 5-gram data-set it is possible to pull for
a given target word T , a corpus of time-stamped 5-
grams (with counts) containing T . As a diachronic
corpus this data set has size and time range ad-
vantages. For example, prior work (Emms, 2013;
Emms and Jayapal, 2014) used text snippets from
search results obtained using Google’s date spe-
cific search facility, giving a time range of 1990-
2013 and about 100 examples per year. The 5-
gram data reaches far further back with a far larger
amount of data per year (see Table 1). For example
for the target mouse there is on average over 15000
5-gram entries featuring it per year. Its largest
seeming disadvantage is that each 5-gram for a tar-
get gives a context of no more than 4 words.

Each line of the Google 5-gram data gives a
year-specific count for the particular 5-gram. The
EM presentation in section 2 assumed data items
represented single target occurrences. In using the
5-gram data we effectively treat each 5-gram data
entry as representing n separate tokens of T con-

tributing to no other 5-gram counts: the data set
makes it impossible to know to what extent any
original token of T has contributed to several dif-
ferent 5-gram counts. This involves changing the
M step to

P (S = s|Y = y) =
∑

d:Y d=y
[γd(s)×nd]∑

d:Y d=y
[nd]

P (w|S = s) =
∑

d(γ
d(s)×nd×#(w, ~W d))∑

d(γ
d(s)×nd×length( ~W d))

Concerning initialisation, for an experiment on
a target T having a corpus of occurrences corp, we
initialise P (w|S) to (1− λ)Pcorp + λPran, where
Pcorp are the word probabilities in corp, Pran is a
random word distribution and λ is a mixing pro-
portion, here set to 10−5. Also initially the per-
year sense distributions P (S|Y ) values are set to
the same as each other. These start values thus
are very far from representing the senses as being
drastically different to each other or having any
time variation at all.

Two sets of targets where chosen, a first set
{strike, mouse, boot, compile, surf } of words
known to exhibit sense emergence and a second
set { ostensible, present } of words where there is
not an expectation of an emergent sense. The two
sets together give both positive and negative tests
for the algorithm. Table 1 lists these words and
for the first set gives an indication of the emer-
gent senses. The next two columns give two kinds
of reference dating information for the emergence
of these senses. The ‘OED-first’ column gives
the first citation date according to the OED, a
lower bound for any inferred emergence date. The
‘tracks date’ gives an emergence date that is ap-
parent from the ’tracks’ plots for words that are
intuitively associated with the emergent sense (see
section 2.1). The final ‘EM date’ column is the
emergence date inferred when the EM algorithm
was run.

Figure 2(a-d) depicts various aspects of the out-
comes on some of the test items. The leftmost plot
in (a-c) shows the EM-inferred P (S|Y ) parame-
ters for different targets T , and the rightmost plot
shows some tracksT (w) plots (see section 2.1),
for some words thought especially associated with
the novel sensse – these track the probabilities of
these words in the n-grams for the target and are
the basis for the ‘tracks date’ column in Table 1.

mouse Figure 2(a): the algorithm was run for 3
sense variants on data from 1950 to 2010, and in
the lefthand plot the blue line, for P (S = 1|Y ),

91



Target Years Lines New sense OED-first tracks date EM date within 10%
mouse 1950-2008 910k computer pointing devince 1965 1983 1982 yes
surf 1950-2008 183k exploring internet 1992 1994 1993 yes
boot 1920-2008 1286k computer start up 1980 1980 1983 yes
compile 1950-2008 689k transform to machine code 1952 1966 1966 yes
strike 1800-2008 5053k industrial action 1810 1880 1866 yes
ostensible 1800-2008 130k NA – – none –
present 1850-2008 56333k NA – – none –

Table 1: The test items, their new senses and dating information – see text for explanation of columns

shows an emergent sense, departing from near
zero first around 1983. The righthand plot ‘tracks’
plots also show a sharp increase around 1983.

We wrote an inflection function which applied
to an inferred P (S|Y ) parameter returns the date,
if any, at which the sense probability starts to de-
part from, and continues to climb from, zero and
the ‘EM date’ column of Table 1 gives the in-
flection points obtained on a particular inferred
P (S|Y ) parameter for each test item. For mouse,
the EM-based emergence date is later than the
OED first citation date, and very close to the
tracks-based date. This illustrates why simply tak-
ing the OED first citation date as a gold stan-
dard would be a mistake. The OED first cita-
tion comes from a research paper in 1965, but the
mouse computer peripheral only became popular
considerably later and it is not unexpected that the
date at which this use of the term mouse departed
and continued to climb from zero is substantially
later. For all the test items, the ‘within 10%’ col-
umn indicates the agreement between the EM- and
tracks-based dates.

Also in Fig. 2(a-c), the box below shows for
the apparently emerging sense S, the top 30 words
when ranked according to the ratio of P (w|S) to
Pcorp(w) (call this gist(S)). For the mouse case,
gist(S = 1) seems mostly consistent with the
‘pointing device’ sense.

surf Figure 2(b). EM was run on data from 1950
to 2010, for 5 senses. In the lefthand plot the green
line, for P (S = 3|Y ), is an emergent sense, ap-
pearing to depart from near zero first around 1993.
The ‘tracks’ plots to the right seem to increase
around around 1994. The OED first citation date
of 1992 is consistent with both. The ‘gist’ words
for S = 3 also seem mostly consistent the ‘inter-
net exploration’ sense.

strike Figure 2(c): EM was run on data from 1800
to 2008, for 3 senses, a far longer time span than
the preceding cases. In the left-hand plot, the

blue line, for P (S = 1|Y ), is an emergent sense,
appearing to depart from near zero first around
1865. The tracks plot for words intuitively asso-
ciated with the industrial action sense indicate an
increase from around 1880. Both of these are con-
sistent with the OED first citation date of 1820.
The ‘gist’ words for S = 1 seem consistent with
S = 1 representing the ‘industrial action’ sense.
For space reasons, the boot and compile outcomes
are not shown in Fig.2, but analogous outcomes
were obtained, summarised in Table 1.

ostensible and present Figure 2(d) shows the plots
of the inferred P (S|Y ) distributions. Neither
shows an emerging sense, in line with expecta-
tions.

The number of senses sought in the EM runs
for the different target items varied somewhat (be-
tween 3 and 5). This is somewhat to be expected
as the extent of ambiguity probably varies for the
different target items and in some cases where an
emergence was less clear with n senses, it became
clearer with n+ 1 senses.

The procedure was implemented in C++. To ob-
tain the code or data see www.scss.tcd.ie/
Martin.Emms/SenseDynamics. As an indi-
cation of exection time, for a data-set of approxi-
mately 900k lines a single EM iteration takes 8.01
seconds.

4 Prior Work

In this section we review some related work
on novel sense detection. Wijaya and Yeniterzi
(2011) did make some analyses on the Google n-
gram data in relation to indicators of sense change,
seeking to apply ideas from LDA (Blei et al.,
2003). It is not however a concrete proposal for
novel sense detection and to suit the LDA perspec-
tive they artificially concatenate a year’s worth of
n-grams to create a single document.

In a number of papers (Lau et al., 2012; Cook
et al., 2013; Cook et al., 2014) have applied a

92



(a) mouse (inferred P (S|Y ) and observed P (w|mouse))

1950 1970 1990 2010

0.
0

0.
4

0.
8

Year

S
en

se
 P

ro
p

sense 1

1950 1970 1990 2010

0.
00

0
0.

01
0

0.
02

0

Year
w

or
d 

pr
ob

s clickbuttonpointerdrag

gist(sense 1) button, pointer, left, right, release, over, move, down,
drag, your, hold, on, then, Release, to, you, cursor, when, click-
ing, position, Move, the, press, changes, Click, use, while, When,
moving, moves

(b) surf (inferred P (S|Y ) and observed P (w|surf))

1950 1970 1990 2010

0.
0

0.
4

0.
8

Year

S
en

se
 P

ro
p sense 3

1950 1970 1990 20100
.0

00
0

0.
00

06
0.

00
12

Year

w
or

d 
pr

ob
s netmailinternetweb

gist(sense 3) END , Internet, ., Net, Web, net, ”, or, web, Wide,
World, ’, for, mail, and, turf, ?, while, internet, ,, time, L, games,
your, looking, -, go, e, beach, information

(c) strike (inferred P (S|Y ) and observed P (w|strike))

1800 1900 2000

0.
0

0.
4

0.
8

Year

S
en

se
 P

ro
p

sense 1

1800 1900 2000

0.
0

0.
2

0.
4

0.
6

0.
8

Year

w
or

d 
pr

ob
s

union
coal
miners

gist(sense 1) general, -, went, START , The, hunger, ’, was, slip,
workers, of, price, by, called, miners, during, on, no, R, day, go,
coal, had, in, after, been, call, were, emptive, capability

(d) ostensible and present

1800 1900 2000

0.
0

0.
4

0.
8

Year

S
en

se
 P

ro
p

sense 1
sense 2

1850 1900 1950 2000

0.
0

0.
4

0.
8

Year

S
en

se
 P

ro
p

sense 1sense 2sense 3

Figure 2: For (a-c), lefthand plot shows EM-inferred values for P (S|Y ), with the sense number S of an
apparent emergent sense labelled; the righthand plot show probability ‘tracks’ for some words intuitively
associated with the emergent sense (see text for further details). gist(S) in the boxes is the top-30 as
ranked by P (w|S)/Pcorp(w); (d) shows inferred P (S|Y ) for items with no sense emergence
pre-existing word sense induction (WSI) system
to novel sense detection. They draw on ideas from
LDA, treating each context of n words as gener-
ated from n topics, and define a target’s sense to
be the most frequent topic amongst the context
words. A striking difference to our model is that
their model essentially has no parameters refer-
ring to time. They therefore take time-stamped
data and pool it to train a time-unaware system,
then assign target expressions their most probable
sense, and finally inspect the pattern of assigned
senses and the time stamps. As data, rather than a
real year-by-year diachronic corpus, they worked
with data representing two time periods, T1 and
T2. Presumbaly in the ideal case, if a sense S truly
emerged between T1 and T2 it should assign sense
S only to items from T2. Their approach to eval-
uation uses dictionary inclusion dates (ie., Di0 see
section 2.1), so refers to senses which came to be
included in dictionaries between the investigated
time periods. Relative to a set of distractor ex-
pressions not thought to exhibit sense emergence

their system has some success in distinguishing
between true cases and the distractors in so far as
when items are ranked by the ratio p2 : p1 of their
inferred sense frequencies in the periods T2 and
T1, the neologisms tend to be more highly ranked
than the distractors.

Mitra et al. (2014) have also presented work on
sense emergence. Their data set is a dependency-
parsed version of the Google 5-grams, whose
time-line they divide into eras containing equal
amounts of data. They do not propose a prob-
abilistic model but instead have a distance-based
clustering system. On each era’s data they per-
form a clustering of occurrences, and then propose
ways to relate the clusters for era T1, {sT11 , . . . sT1m }
to the clusters of a later era T2, {sT21 , . . . sT2n }: if
a T2 cluster, sT2i , relates to no T1 cluster, this is
counted as evidence of the emergence of a sense
between T1 and T2. For evaluation purposes they
considered the inferred emergences between the
eras 1909-1953 and 2002-2005, verifying not by
reference to dictionaries but by reference to the in-

93



tuitions of one of the authors. Some of the exam-
ples given in the paper (eg. organ-related use of
donation) seem plausible, others are noted as true
emergences though the OED would suggest other-
wise (eg. an assailant sense of thug).

5 Conclusions

We have proposed a relatively simple generative
model, one which assumes that given the target’s
sense, the context words are independent of time
– the P (w|S) parameter – and that for each time,
there is a prior for each sense – the P (S|Y ) pa-
rameter. Together this models the way the context
words for a given target do vary over time, through
the sum

∑
S[p(S|Y )p( ~W |S)]. We have proposed

an EM procedure for the estimation of the parame-
ters of such a model and how this can be applied to
Google n-gram data, which gives counts for time-
stamped n-grams, and we have shown that intu-
itive values for the P (S|Y ) parameters can be ob-
tained.

The approach is in several respects simpler than
some related work discussed in section 4. To em-
phasize this further, the algorithm used raw rather
than lemmatized words and used a data-set with
no syntactic annotation. It also lacks any inher-
ent constraint to keep P (S|Y1) and P (S|Y2) close
when Y1 and Y2 are close and its striking that the
inferred P (S|Y ) come out as relatively smooth
functions of time. Nonetheless a direction of fu-
ture work could be to consider modeling such a
smoothness constraint.

Section 4 mentioned the LDA-based model of
(Lau et al., 2012; Cook et al., 2013; Cook et
al., 2014) and it would certainly be of interest to
seek to apply their algorithms to the data we have
considered and conversely, our algorithms to their
data. Also the work of Mitra et al. (2014) sug-
gests a line of development in which we adapt our
approach to first estimate separate models on data
belonging to eras and then similarly attempt to re-
late the obtained collections of word distributions.

Acknowledgments

This research is supported by Science Foun-
dation Ireland through the CNGL Programme
(Grant 12/CE/I2267) in the ADAPT Centre
(www.adaptcentre.ie) at Trinity College Dublin.

References
David M. Blei, Andrew Y. Ng, and Michael I. Jor-

dan. 2003. Latent dirichlet allocation. In Jour-
nal of Machine Learning Research, volume 3, pages
993–1022,, March.

Paul Cook, Jey Han Lau, Michael Rundell, Diana Mc-
Carthy, , and Timothy Baldwin. 2013. A lexico-
graphic appraisal of an automatic approach for de-
tecting new word senses. In Proceedings of eLex
2013.

Paul Cook, Jey Han Lau, Diana McCarthy, and Tim-
othy Baldwin. 2014. Novel word-sense identifica-
tion. In Proceedings of COLING 2014, the 25th In-
ternational Conference on Computational Linguis-
tics, page 1624–1635. ACL, August.

A.P. Dempster, N.M. Laird, and D.B. Rubin. 1977.
Maximum likelihood from incomplete data via the
em algorithm. J. Royal Statistical Society, B 39:1–
38.

Martin Emms and Arun Jayapal. 2014. Detect-
ing change and emergence for multiword expres-
sions. In Proceedings of the 10th Workshop on Mul-
tiword Expressions (MWE), pages 89–93, Gothen-
burg, Sweden. Association for Computational Lin-
guistics.

Martin Emms. 2013. Dynamic EM in neologism evo-
lution. In Hujun Yin, Ke Tang, Yang Gao, Frank
Klawonn, Minho Lee, Thomas Weise, Bin Li, and
Xin Yao, editors, Proceedings of IDEAL 2013, vol-
ume 8206 of Lecture Notes in Computer Science,
pages 286–293. Springer.

Jey Han Lau, Paul Cook, Diana McCarthy, David New-
man, and Timothy Baldwin. 2012. Word sense in-
duction for novel sense detection. In Proceedings of
the 13th Conference of the European Chapter of the
Association for Computational Linguistics (EACL
2012), pages 591–601, Avignon, France, April.

Christopher Manning and Hinrich Schütze, 2003.
Foundations of Statistical Language Processing,
chapter Word Sense Disambiguation, pages 229–
264. MIT Press, 6 edition.

Jean-Baptiste Michel, Yuan Kui Shen, Aviva Presser
Aiden, Adrian Veres, Matthew K. Gray, The
Google Books Team, Joseph P. Pickett, Dale
Hoiberg, Dan Clancy, Peter Norvig, Jon Orwant,
Steven Pinker, Martin A. Nowak, and Erez Lieber-
man Aiden. 2011. Quantitative analysis of cul-
ture using millions of digitized books. Science,
331(6014):176–182.

Sunny Mitra, Ritwik Mitra, Martin Riedl, Chris Bie-
mann, Animesh Mukherjee, and Pawan Goyal.
2014. That’s sick dude!: Automatic identification
of word sense change across different timescales.
In Proceedings of the 52nd Annual Meeting of
the Association for Computational Linguistics, page
1020–1029. Association for Computational Linguis-
tics, June.

Derry Tanti Wijaya and Reyyan Yeniterzi. 2011. Un-
derstanding semantic change of words over cen-
turies. In Proceedings of the 2011 International
Workshop on DETecting and Exploiting Cultural di-
versiTy on the Social Web, DETECT ’11, pages 35–
40, New York, NY, USA. ACM.

94


