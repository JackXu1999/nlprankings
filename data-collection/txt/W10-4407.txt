




































Unavoidable Ill-nestedness in Natural Language and  
the Adequacy of Tree Local-MCTAG Induced Dependency Structures   

 
 

Joan Chen-Main* and Aravind K. Joshi*+ 
*Institute for Research in Cognitive Science, and +Department of Computer and Information Science 

3401 Walnut Street, Suite 400A 

University of Pennsylvania 

Philadelphia, PA 19104-6228, USA 
{chenmain, joshi}@seas.upenn.edu 

 

 

 

 

 

Abstract 

Within generative approaches to grammar, char-

acterizing the complexity of natural language 

has traditionally been couched in terms of formal 

language theory. Recently, Kuhlmann (2007) 

and collaborators have shown how derivations of 

generative grammars can be alternately repre-

sented as dependency graphs. The properties of 

such structures provide a new perspective of 

grammar formalisms and different metric of 

complexity. The question of complexity of natu-

ral language can be recast in dependency struc-

ture terms. Ill-nested structures have been as-

signed to some examples in the literature (Bos-

ton et al, 2009, Maier and Lichte, 2009), but the 

availability of well-nested alternatives prevents 

the use of these examples to claim that ill-

nestedness is an unavoidable linguistic reality. 

This paper claims that two examples, one Ger-

man and one Czech, are unavoidably ill-nested, 

indicating that ill-nestedness is indeed unavoid-

able in natural language. We conclude that for-

malisms that generate only well-nested struc-

tures, such as TAGs, are not quite powerful 

enough. However, the tree-local multi-

component extension to TAG does generate ill-

nested structures, providing just the appropriate 

amount of complexity in dependency structure 

terms for characterizing natural language. 

1 Introduction 

Within generative approaches to human grammar, 

characterizing the complexity of natural language 

has traditionally been couched in terms of formal 

language theory. For some time, it appeared that 

the weak generative capacity of context free 

grammars might be adequate for capturing natural 

language. After the linguistic patterns reported by 

Shieber (1985) and Culy (1985) indicated that this 

was not so, Joshi (1985) proposed that a grammar 

that adequately described natural languages should 

have four particular properties, dubbing the class 

of such grammars as mildly context-sensitive. A 

number of independently developed grammar for-

malisms not only had these properties but turned 

out to be weakly equivalent (Joshi et al., 1991). 

Recently, Kuhlmann (2007) and collaborators 

have connected the generative grammar approach 

with the dependency grammar approach, where 

linguistic analysis is based on word-to-word rela-

tionships. In particular, two properties that are 

naturally defined over dependency structures, gap 
degree (a measure of discontinuity) and well- vs. 
ill-nestedness (whether interleaving substructures 
are permitted) carve out classes of structures that 

are systematically related to the derivations of gen-

erative grammars. For example, derivations in 

CFGs correspond to well-nested, gap degree zero 

dependency structures while derivations in lexical-

ized Tree Adjoining Grammars (LTAGs) corre-

spond to well-nested, gap degree ≤ 1 dependency 
structures (Bodirsky et al., 2005). 

These properties of associated dependency 

structures provide a new perspective of generative 

grammars and a different metric of complexity. 

The question of the complexity of natural language 

can be recast in dependency structure terms. It 

Dependency Structures and Unavoidable Ill-nestedness

53



turns out that more than 99.5% of the structures in 

both the Prague Dependency Treebank (PDT) (Ha-

jič et al., 2001) and Danish Dependency Treebank 
(DDT) (Kromann. 2003) are well-nested and gap 

degree ≤ 1 (Kuhlmann and Nivre, 2006). However, 
it is not obvious what to conclude regarding the 

gap degree and ill/well-nestedness of natural lan-

guage from the small number of remaining data. 

While ill-nested structures have been assigned to 

some examples in the literature (Boston et al, 2009, 

Maier and Lichte, 2009), a closer look at these ex-

amples shows that reasonable alternative analyses 

result in structures that are no longer ill-nested. 

Specifically, when the auxiliary is assumed to be a 

dependent of the main verb instead of vice versa, 

the examples become well-nested. This precludes 

us from using these examples to make the kind of 

strong claim we would like to: that ill-nestedness is 

an unavoidable linguistic reality. Our first contri-

bution is the articulation of two empirically verifi-

able questions of theoretical interest: Does natural 

language include structures that are unavoidably 

ill-nested and/or gap degree > 1?  Our second con-

tribution is the submission of two examples, a 

German construction that involves both extraposi-

tion and a split quantifier, and a Czech compara-

tive, which we claim are unavoidably ill-nested. 

Based on these, we conclude that ill-nestedness is 

indeed unavoidable in natural language and gram-

mars that generate only well-nested structures 

(such as LTAG) are not quite powerful enough. 

Unlike LTAG, its Tree Local Multi-component 

extension (TL-MCTAG) does have the capacity to 

induce structures that are ill-nested (Kuhlmann and 

Möhl, 2006) and also to accommodate the two ex-

amples we present. This aligns well with what we 

know about TAG and TL-MCTAG in traditional 

terms: Although TL-MCTAGs are weakly equiva-

lent to TAGs, they are more powerful than TAGs 

in terms of strong generative capacity, i.e., they 

permit the derivation of structures not derivable in 

TAGs, and thus have been argued to be a necessary 

extension to TAGs on linguistic grounds. 

The paper is structured as follows. Section 2 re-

views the notions of gap degree and well-/ill-

nestedness. Section 3 uses LTAG to illustrate how 

a derivation of a generative grammar can be alter-

nately represented as a dependency graph and re-

views how the class of LTAG derivations corre-

sponds to the class of well-nested and gap degree ≤ 
1 dependency structures. Section 4 turns to linguis-

tic data. We show how plausible alternate reanaly-

ses can lead to well-nestedness for some previous 

examples, and discuss the two examples for which 

we argue that ill-nestedness is unavoidable. Sec-

tion 5 shows how an analysis for our German ex-

ample is available in the TL-MCTAG extension, 

which permits derivations associated with ill-

nested dependency structures. Section 6 compares 

and contrasts dependency structures induced by 

TAGs with those induced by Combinatorial Cate-

gorial Grammars (Koller and Kuhlmann, 2009) 

and Minimalist Grammars (Boston et al, 2009). 

Section 7 summarizes and concludes the paper. 

2 Discontinuity in Dependency Structures 

The dependency structures we refer to in this paper 

are 3-tuples: a set of nodes, a dominance relation, 

and a (total) precedence relation. Dominance is 

encoded via a directed edge and precedence is en-

coded via left to right position on the page.  Here, 

we review two measures of discontinuity defined 

on dependency structures. Expanded explanation 

can be found in (Kuhlmann and Nivre, 2006). 

 

 

 

 
 

Figure 1. An example dependency structure 

2.1 Gap Degree 

It will be useful to first define the term projection.   
Definition: The projection of a node x is the set of 
nodes dominated by x (including x). 

Definition: A gap is a discontinuity with respect to 
precedence in the projection of a node in the de-

pendency structure.  (E.g. in Figure (1), the node c 
is the gap preventing b and d from forming a con-
tiguous interval.) 

Definition: The gap degree of a node is the num-
ber of gaps in its projection. 

Definition: The gap degree of a dependency struc-
ture is the max among the gap degrees of its nodes.  

2.2 Well-/Ill-nestedness 

Definition: If the roots of two subtrees in the de-
pendency structure are not in a dominance relation, 

then the trees are disjoint. 
Definition: If nodes x1, x2 belong to tree X, nodes 
y1, y2 belong to tree Y, precedence orders these 

a b c d e

Joan Chen-Main, Aravind K. Joshi

54



nodes: x1 > y1 > x2 > y2, and X and Y are disjoint, 
then trees X and Y interleave. (E.g, in Figure (1), b 
and d belong to the subtree rooted in b, while c and 
e belong to the subtree rooted in c.  These two sub-
trees are disjoint. Since the nodes are ordered b > c 
> d > e, the two trees interleave.) 

A dependency graph with interleaving subtrees 

is ill-nested, as in (1).  A dependency graph with 
no interleaving is well-nested, (e.g Fig. (2d)). 

3 LTAG Derivations as Dependency 
Structures  

The LTAG induced dependency structures detailed 

by Bodirsky et al. (2005) provide an example of 

how a derivation of a generative grammar can be 

translated into a dependency graph, retaining in-

formation from both the derivation itself and its 

final phrase structure. We illustrate using a deriva-

tion based on the cross-serial dependencies seen in 

Dutch subordinate clauses, shown in Figure 2. (2a) 

shows a set of four LTAG elementary trees. (2c) is 

the derivation structure showing how these four 

trees combine to yield the derived phrase structure 

in (2b). (2d) shows the dependency structure that 

corresponds to this derivation.  

 

   

 

 

 

    

  

 

 

 

 

 

 

Figure 2. Grammar, phrase structure, and derivation  

for Jan de kinderen zag zwemmen and  
corresponding graph drawing 

 

First, the set of nodes in the dependency struc-

ture corresponds to the set of lexical anchors of the 

elementary trees. For example, Jan anchors an NP 
tree in (2a). Thus, Jan will be a node label in any 
dependency structure induced by an LTAG deriva-

tion involving this tree. Second, the directed edges 

between the nodes in the dependency structure 

mirror the immediate dominance relation in the 

derivation tree.1 E.g. Just as the zwemmen node has 
the zag and de kinderen nodes as its two children 
in (2c), so does the zwemmen node have zag and de 
kinderen as dependents in (2d). Lastly, the order-
ing of the nodes in the dependency structure is ex-

actly the ordering of the terminals in the derived 

phrase structure. 

3.1 The Source of Gaps in LTAG 

In TAG-induced dependency structures, a gap 

arises from an interruption of the dependencies in 

an auxiliary tree. The lexical anchor of an auxiliary 

tree and the pronounced material that is combined 

into that tree will be part of the same projection in 

the induced dependency structure. Pronounced ma-

terial below the foot of the auxiliary tree, however, 

will belong to the tree “hosting” the auxiliary tree, 

and will not be part of the same projection.2 If Tree 

B is adjoined into Tree A, the gap is the material in 

A that is below the foot node of B. E.g. in the deri-

vation in Figure 2, de kinderen is substituted into 
the zwemmen tree below the node into which the 
zag tree adjoins into the zwemmen tree. Thus, de 
kinderen interrupts the pronounced material on the 
left of the zag tree’s foot node, Jan, from the pro-
nounced material on the right of the foot node, zag. 
Since standard TAG auxiliary trees have only one 

foot, each projection in a TAG-induced depend-

ency structures can have at most one gap. 

3.2 Well-nestedness in LTAG 

LTAG-induced dependency structures are all well-

nested.  Recall that the sole source for gaps is pro-

nounced material in the “host” tree below the foot 

of an auxiliary tree.  Suppose an LTAG derivation 

did have a corresponding ill-nested dependency 

structure.  I.e. suppose Tree A and Tree B are dis-

joint subtrees in the dependency structure, nodes 

from Tree A interrupt nodes from Tree B, and 

nodes from Tree B interrupt nodes from Tree A.  If 

the nodes of Tree A interrupt the nodes of Tree B, 

this implies that in the derivation, Tree B is an aux-

                                                 
1 Whereas in standard dependency graphs, adjunction of t2 to 

t1 generally corresponds to a dependency directed from t2 to 

t1, in a TAG-induced dependency graph, adjoining t2 to t1 

corresponds to the reverse dependency. 
2 Since each node of an LTAG-induced dependency structure 

is associated with the lexical anchor of an LTAG tree, we have 

assumed dependency structure nodes to be associated only 

with pronounced material. 

S

X           zwemmen
(swim)

Y                zag
(saw)

NP                X*

Jan               NP

de kinderen
(the children)

 

zag 

Jan 

de kinderen 

zwemmen 

Jan  de kinderen  zag  zwemmen 

(a) 
NP

Jan

X

NPi X*

Y zag
(saw)

de kinderen

NP

(the children)
(swim)

X           zwemmen

S

NP

(b) 

(c) (d) 

Dependency Structures and Unavoidable Ill-nestedness

55



iliary tree that adjoins into Tree A.  However, if the 

nodes of Tree B likewise interrupt the nodes of 

Tree A, this implies that Tree A is also an auxiliary 

tree and that it adjoins into Tree B.  It is not possi-

ble that an LTAG derivation should include Tree A 

and Tree B adjoining into one another. 

4 Linguistic Examples of Ill-nestedness  

4.1 Nestedness and Alternative Analyses 

It is clear that a linguistic example that requires ill-

nestedness will involve at least two discontinuous 

constituents.  However, this is a necessary condi-

tion, not a sufficient one. Apparent ill-nestedness 

can sometimes be avoided via a plausible alternate 

reanalysis. For example, a number of ill-nested 

German examples from a dependency version of 

the TIGER (a phrase structure based treebank to 

which a conversion algorithm has been applied) 

are ill-nested only when the auxiliary is assumed to 

be the root and the main verb and subject are 

daughters of the auxiliary. When the main verb is 

assumed to be the root instead, and the subject and 

auxiliary verb are assumed to be dependents of the 

main verb, the dependency structure becomes well-

nested.3 This is the case with examples in Maier 

and Lichte (2009) (examples from converted de-

pendency treebanks) and also the double extraposi-

tion example in English in Boston et al (2009) (au-

thors’ original example). Because the ill-

nestedness depends on choosing the auxiliary verb 

as the root, we cannot use these examples to make 

the kind of strong claim we would like to: that ill-

nestedness is an unavoidable linguistic reality. 

4.2 Ill-nestedness in German 

Our example from German involves two disconti-

nuities, extraposition from an NP and a split quan-

tifier.  In example (1b) below, the relative clause 

der am meisten Geld hatt ‘who had the most 
money’ has been extraposed away from the NP der 
Student ‘the student,’ and the NP Bücher ‘books’ is 
separated from its quantifier drei ‘three.’  The ca-
nonical order is given in (1a).4 

                                                 
3 Thanks to Marco Kuhlmann for making the TIGER exam-

ples available and to Tatjana Scheffler for this observation. 
4 Appropriate context and intonation will, of course, make this 

reading easier. The example has contrastive stress and a con-

trastive reading and is felicitous in a context such as the one 

below. Tatjana Scheffler is gratefully acknowledged for pro-

viding this example and context. 

(1) a. [Der Student [der  am meisten Geld  
  the student,  who  the  most  money  

  hatte]] hat   [drei  [Bücher]]  gekauft. 
 had  has  three books   bought 

 b. Bücher  hat DER Student drei  gekauft,  

     Books has that student  three  bought 

 der  am  MEIsten Geld  hatte. 

 who  the most  money  had 

 

The ill-nested part of the structure involves the 

sub-structures rooted in Bücher ‘books’ and hatte 
‘had.’  Note that these two root nodes are not in 

any dominance relation and are therefore disjoint.  

The projection of the former includes Bücher and 
drei ‘three.’  The projection of the latter includes 
der Student, der, am moisten Geld, and hatte.  As 
the figure shows, the projection of Bücher is inter-
rupted by der Student, and the projection of hatte is 
interrupted by drei. 

 

 

 

 

 

 
Figure 3. Dependency structure 1 for (1b):  

aux dominates main verb 

 

Interestingly, this German construction remains 

ill-nested when we suppose instead that the main 

verb is the root, reversing the dependency between 

the main verb and the auxiliary.  As can be seen in 

the dependency structure in Fig. 4, the ill-nested 

substructures are unaffected. This alternate analy-

sis lends itself well to a TAG based analysis, which 

would typically assume the main verb to be the 

root (allowing verbs and substitution nodes for 

their arguments to be elementary tree local). 

 

 

 

 

 

 

Figure 4. Dependency structure 2 for (1b):  

main verb dominates aux 

                                                                             
A: Every student bought multiple items in the store. Some 

bought three magazines, some bought two calendars, some 

bought two books, and the oldest student bought three books. 

B: No, hat DER Student drei gekauft, der am meisten Geld 

hatte. 

Buecher gekaufthat dreider Student

books boughthas threethat student

der

who the most money
hatte
had

am meisten Geld

Buecher gekaufthat dreider Student

books boughthas threethat student

der

who the most money
hatte
had

am meisten Geld

Joan Chen-Main, Aravind K. Joshi

56



4.3 Ill-nestedness in Czech 

Boston et al. (2009) note that ill-nested structures 

have been assigned to Czech comparatives. Their 

example, sentence number Ln94209_45.a/18 from 

the PDT 2.0, can be glossed as “A strong individ-

ual will obviously withstand a high risk better than 

a weak individual” and is given in Fig. 5. It is of 

particular interest because, like our German exam-

ple, the ill-nestedness here involves two constitu-

ents between which it would be difficult to justify 

a dependency. This suggests that the substructures 

corresponding to the two constituents will remain 

disjoint under reasonable analyses, and thus, the 

dependency structures will remain ill-nested. 

 

 

 

 

 

 

 
Figure 5. Ill-nested Czech comparative from PDT5 

5 TL-MCTAG Induced Dependency 
Structures 

MCTAG (Weir 1988) is one of the most widely 

used extensions for handling linguistic cases that 

are difficult for classic TAG. Whereas TAG takes 

the basic unit to be a single elementary tree, 

MCTAGs extend the domain of locality to encom-

pass a set of trees. The tree-local MC-extension, in 

which all members of an multi-component set must 

combine into the same “host” tree, allows for lin-

guistically satisfying accounts for a number of at-

tested phenomena, such as: English extraposition 

(Kroch and Joshi 1990), subj-aux inversion in 

combination with raising verbs (Frank 2002), ana-

phoric binding (Ryant and Scheffler 2006), quanti-

fier scope ambiguity (Joshi et al. 2003). 

We have assumed here that each MC-set is lexi-

calized and that the set of nodes in MCTAG-

induced dependency structures corresponds to the 

set of lexical anchors, just as we assumed for 

LTAG-induced dependency structures. Silent ele-

ments, such as traces, do not anchor an elementary 

tree, and so do not correspond to a node in the de-

                                                 
5 The non-lexical root node and punctuation node are removed 

for simplicity.  Thanks is due to Marisa Ferrara Boston for 

making this PDT structure available. 

pendency structure.  Kuhlmann and Möhl (2006) 

show that dependency structures induced from 

tree-local MCTAG derivations in this way include 

structures that are ill-nested and/or gap degree > 1. 

5.1 Additional Source of Gaps in MC-TAGs 

In 3.1, we noted that the source of every gap in an 

LTAG induced dependency structures is an inter-

ruption of the dependencies of an auxiliary tree. 

Thus, a MC-set comprised of two auxiliary trees 

allows the potential for at least two gaps in 

MCTAG induced dependency structures, one asso-

ciated with each foot. There is a second source of 

gaps in MCTAG: a gap may arise as a result of any 

pronounced material between two components.  

Thus, the maximum gap degree = 2n – 1, where n 

is the maximum number of components in any 

elementary tree set. 

5.2 Ill-nestedness in MC-TAG 

Because material between the nodes where two 

components of a MC-set compose into a host tree 

can also create a gap, even a tree-local MCTAG 

that allows only substitution can induce an ill-

nested dependency structure.  Ill-nestedness arises 

when two MC-sets combine into the same host tree 

and the nodes into which each set combines inter-

leave. This will be illustrated below by the TL-

MCTAG derivation for our German example. 

5.3 The Adequacy of TL-MCTAG 

The MC-TAG derivation for (1b) will require a 

tree headed by gekauft ‘bought’ (shown in 6h) into 
which two MC-sets combine, one for Bücher 
‘books’ and its trace (shown in 6b) and a second 

for hatte (and the rest of the relative clause) and its 
trace (shown in 6a). The singleton sets involved 

are also shown in Fig 6c-6h. To derive (1b), drei 
(6f) adjoins into the β component of (6b), which 
substitutes into the lower NP of the gekauft tree, 
(6h). The α component of (6b) adjoins to the root 
of (6h). To accomplish extraposition, we make use 

of flexible composition, the mirror operation of 
adjoining: If tree A adjoins into tree B, the combi-

nation can be alternatively viewed as tree B “flexi-

bly” composing with tree A (Joshi et al. 2003, 

Kallmeyer and Joshi 2003).6By enriching MCTAG  

                                                 
6 A TL-MCTAG with flexible composition can also be viewed 

as an MCTAG allowing delayed tree-locality (Chiang and 
Scheffler, 2008). 

jedinec

individual

slaby

weak

nez

thanwill-defend

ubrani

strong

silnyVysokemu

high

riziku

risk

samozrejme

obviously

lepe

better

se

self

Dependency Structures and Unavoidable Ill-nestedness

57



 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Figure 6. MC-set for extraposition of a relative clause, 

MC-set for split quantifier, and  

singleton sets for deriving example (1b)7 

 

 

 

 

 

 

 

 

 
 

Figure 7. Phrase structure for example (1b) 

 

with this perspective of adjoining, some deriva-

tional steps which appear to permit components 

from the same MC-set to combine into different-

trees can be recast as abiding by tree-locality. Der 
Student, (6c), flexibly composes into the αcompo-
nent of the set in (6a), while der, (6d), and am 
meisten Geld, (6e), substitute into the β compo-
nent. The (derived) α component of (6a) adjoins 
into the highest NP node in (6h), while β, the ex-
traposed relative, adjoins into the root of (6h).  

Additionally, (6g), the auxiliary verb, substitutes 

                                                 
7 The V2 requirement in German can be handled with an 

obligatory adjoining constraint (denoted OA) on the S node of 
the tree for the main verb. The particular implementation of 

the V2 requirement is not relevant to our main argument. See 

(Kinyon et. al. 2006) for a TAG approach to V2. 

into the T node of (6h) the gekauft tree. This deri-
vation yields the phrase structure in Fig. 7 and cor-

responds to the dependency structure in Fig. 4.We 

have not fully committed to the direction of the 

dependency for flexible composition. If flexible 

composition is to be truly viewed as an alternate 

conception of adjoining, then perhaps the direction 

of the dependency when A flexibly composes into 

B should be identical to that of the dependency 

when B adjoins into A.  Whatever the outcome, the 

ill-nestedness of our German example remains, as 

can be seen in the alternate dependency structure in 

Fig. 8. The ill-nestedness involves the same nodes, 

but the roots of the disjoint substructures are now 

Bücher and der Student.8 
 

 

 

 

 

 
Figure 8. Dependency structure 3 for (1b):  

Der student governs hatte 

6 Dependency Structures Across Genera-
tive Frameworks 

6.1 CCGs and Dependency Structures 

Koller and Kuhlmann (2009) show how deriva-

tions in (a fragment of) Combinatory Categorial 

Grammars (CCG) (Steedman, 2001) can be viewed 

as dependency structures. The source of gaps ap-

pears to correspond to alternating application of 

the CCG operations forward and backwards com-

position, making it difficult to state a bound on gap 

degree. As the authors show, it follows that TAG 

(which induces gap degree ≤ 1 structures) does not 
generate the same class of dependency structures 

as CCG. It is unclear, however, whether or not ill-

nested structures are permitted. 

6.2 MGs and Dependency Structures 

Boston et al (2009) approach Minimalist Gram-

mars (MG) (Stabler, 1997) from a dependency 

                                                 
8 Thus, there is some room to accommodate Candito and Ka-
hane’s (1998) arguments that the direction of the dependency 

for adjoining is the reverse of that for substitution. Note fur-

ther that in the MCTAG case, a non-uniform interpretation of 

derivation tree arcs raises the issue of the direction of the de-

pendency in the case where one component adjoins into a host 

tree while a second component combines via substitution. 

NP*

NP

(e)i

α β 
S

S'iS*

NP[+wh]    NP   hatte

(a) 

NP

(e)i

S

NP S*

Buecher

α β 

(b) 

(c) (d) (e) 

(f) (g) (h) 

QP

NP

NP*

drei

NP

der 

NP

am moisten Geld

NP 

der Student 

hat

T

VP

V'

V

gekauft

T

S

NP

NP

(OA) 

S

Buecher

der Student

NP

NP

(e)i

hat

T

V

gekauft

drei

V'

QP

NP

NP

(e)j

NPj

VP

S

S'i

S

der am meisten Geld hatte

Buecher gekaufthat dreider Student

books boughthas threethat student

der

who the most money
hatte
had

am meisten Geld

Joan Chen-Main, Aravind K. Joshi

58



structure perspective, showing that ill-nested struc-

tures are derivable and showing how gaps arise. In 

MG induced dependency structures, every gap 

is associated with movement (although not every 

movement corresponds to a gap).  In MGs, every 

movement involves a liscensor and licensee pair, 

both of which are lexical entries.  At first blush, it 

appears that the unlimited number of movements 

(i.e. uses of these entries) permitted during an MG 

derivation also permits an unbounded number of 

gaps. It turns out, however, that the gap degree for 

the class of dependency structures associated with 

a particular MG is bound by the number of licen-

sees in that MG’s lexicon due to two linguistic 

considerations.  First, each licensee features de-

pends on a linguistically motivated functional 

category. Thus, the number of features permitting 

movement is finite.  Second, the ShortestMove-

mentConstraint, which has been incorporated into 

the MG definition, prohibits subsequent uses of the 

same licensee feature from interacting with the 

first use.  The subderivations are, in the relevant 

sense, independent, generating substructures whose 

gap degree is bound by the number of licensee fea-

tures.  The result is that even as an MG derivation 

grows, the gap degree does not increase beyond the 

number of licensee features. (Boston, Hale, p.c.) 

6.3 Comparison with TL-MCTAG 

The most obvious difference across formalisms is 

the source of gaps and, consequently, the ease with 

which a bound on gap degree can be stated. For 

TL-MCTAG, a bound is straightforwardly stated 

via the maximum number of components permitted 

in an elementary set. Though TL-MCTAG as a 

formal system allows any number of components 

in an MC-set, TL-MCTAG as used in linguistic 

analyses typically uses only two components 

(Chen-Main and Joshi, 2007). In a sense, TL-

MCTAG with two components arises naturally 

from standard TAG, particularly when adjoining is 

viewed as reversible. In the case where tree A ad-

joins into a tree internal node x in B, reversing the 
composition can be recast as  follows: B is split 

into a two-component set at node x with one com-
ponent adjoining into the root of tree A and the 

second component substituting into the foot of A. 

Motivating three-component sets is more difficult. 

A question that remains is whether or not there 

constructions that are unavoidably gap degree 2 or 

more. We are aware of one gap degree 2 example 

from a Hindi dependency treebank that is being 

developed with the annotation scheme detailed in 

(Begum et al, 2008) (Mannem, p.c.), though we 

have not yet investigated whether other plausible 

analyses will retain the gap degree 2 property. 

7 Summary 

This paper raises the question of whether or not 

natural language includes structures that are un-

avoidably ill-nested and/or gap degree > 1, and 

motivates this issue as part of understanding the 

complexity of natural language in dependency 

structure terms. Based on one German linguistic 

example and one Czech example from the PDT, 

we conclude that the answer to the first question is 

affirmative and that a grammar formalism on the 

right track for characterizing human language 

should be able to induce ill-nested structures. TL-

MCTAG’s ability to cover ill-nested structures 

bolsters its candidacy as a good model of natural 

language, but, as yet, it is unclear whether its abil-

ity to also induce dependency structures that are 

gap degree > 1 is linguistically useful or not. The 

next step is to find examples that are unavoidably 

gap degree >1. 

These issues are relevant not only for TL-

MCTAG but also for other generative approaches 

that induce ill-nested, gap degree > 1 dependency 

structures, such as Minimalist Grammars (Boston 

et. al. 2009). Moreover, we predict that other for-

malisms which are equivalent in traditional terms 

will also induce such structures, mirroring the con-

vergence noted in (Joshi et al., 1991).  However, 

because these formalisms employ different formal 

objects and operations, we also expect more nu-

anced differences, such as the source of gaps, or 

the ease with which one can state a bound on gap 

degree in each framework. 

Acknowledgments 

Special thanks is due to Marisa Ferrara Boston, 

Lucas Champollion, John Hale, Marco Kuhlmann, 

Prashanth Mannem, Beatrice Santorini, and Tat-

jana Scheffler for helpful discussion and especially 

assistance with data. 

References  

Rafiya Begum, Samar Husain, Arun Dhwaj, Dipti Misra 

Sharma, Lakshmi Bai and Rajeev Sangal. 2008. De-

Dependency Structures and Unavoidable Ill-nestedness

59



pendency Annotation Scheme for Indian Languages. 

In Proceedings of The Third International Joint Con-
ference on Natural Language Processing, Hydera-
bad, India. 

Manuel Bodirsky, Marco Kuhlmann, and Mathias Möhl. 

2005. Well-nested drawings as models of syntactic 

structure.  In 10th Conference of Formal Grammar 
and 9th Meeting on Mathematics of Language, Edin-
burgh, UK. 

Marisa Ferrara Boston, John T. Hale, and Marco 

Kuhlmann. 2009. Dependency structures derived 

from Minimalist Grammars. In Proceedings of 
Mathematics of Language 11, 11-22. 

Marie-Hélène Candito and Sylvain Kahane. 1998. Can 

the TAG derivation tree represent a semantic graph? 

An answer in the light of Meaning-Text Theory. In 

Proceedings of TAG+4, Philadelphia, USA. 

Joan Chen-Main and Aravind K. Joshi. 2007. Multi-

component Tree Adjoining Grammars, dependency 

graph models, and linguistic analyses. In Proceed-
ings of the ACL 2007 Workshop on Deep Linguistic 
Processing, Prague, 1-8. 

David Chiang and Tatjana Scheffler. 2008. Flexible 

Composition and Delayed Tree-Locality. In Proceed-
ings of TAG+9, Tübingen, Germany. 

Christopher Culy. 1985. The complexity of the vocabu-

lary of Bambara. Linguistics and Philosophy, 8:345-
351. 

Robert Frank. 2002. Phrase Structure Composition and 

Syntactic Dependencies. MIT Press. 

Jan Hajič, Barbora Vidova Hladka, Jarmila Panevová, 
Eva Hajičová, Petr Sgall, and Petr Pajas. 2001. Pra-
gue Dependency Treebank 1.0. LDC, 2001T10. 

Aravind K. Joshi. 1985. How much context-sensitivity 

is required to provide reasonable structural descrip-

tions: Tree adjoining grammars. In David Dowty, 

Lauri Karttunen, and Arnold Zwicky (eds.), Natural 
Language Parsing: Psychological, Computational, 
and Theoretical Perspectives, 206-250. Cambridge 
University Press. 

Aravind K. Joshi, K. Vijay-Shanker, David Weir. 1991. 

The convergence of mildly context-sensitive gram-

mar formalisms. In Peter Sells, Stuart Shieber, Tho-

mas Wasow (eds.), Foundational Issues in Natural 
Language Processing, 31–81. MIT Press. 

Aravind K. Joshi, Laura Kallmeyer, and Maribel Ro-

mero. 2003. Flexible composition in LTAG: quanti-

fier scope and inverse linking. In H. Bunt and R. 

Muskens (eds.), Computing Meaning 3. Kluwer. 

Laura Kallmeyer and Aravind K. Joshi. 2003. Factoring 

predicate argument and scope semantics: underspeci-

fied semantics with LTAG. Research on Language 
and Computation 1(1-2), 3-58. 

Alexandra Kinyon, Owen Rambow, Tatjana Scheffler, 

Sinwon Yoon, and Aravind K. Joshi. 2006. The Me-

tagrammar Goes Multilingual: A Crosslinguistic 

Look at the V2-Phenomenon. In Proceedings of 
TAG+8, Sydney, Australia, 17-24. 

Alexander Koller and Marco Kuhlmann. 2009. Depend-

ency trees and the strong generative capacity of 

CCG. In Proceedings of the 12th Conference of the 
EACL, 460-468, Athens, Greece. 

Anthony Kroch and Aravind K. Joshi. 1990. Extraposi-

tion in a Tree Adjoining Grammar. In G. Huck and 

A. Ojeda, eds., Syntax and Semantics: Discontinuous 
Constituents, 107-149.Matthias Trautner Kromann. 
2003. The Danish Dependency Treebank and the 

DTAG treebank tool. In 2nd Workshop on Treebanks 
and Linguistic Theories (TLT), 217-220. 

Marco Kuhlmann. 2007. Dependency Structures and 

Lexicalized Grammars. PhD thesis, Saarland Univer-

sity, Saarbrücken, Germany. 

Marco Kuhlmann and Mathias Möhl. 2006. Extended 

cross-serial dependencies in Tree Adjoining Gram-

mars. In Proceedings of TAG+8, Sydney, Australia, 
121-126. 

Marco Kuhlmann and Joakim Nivre. 2006. Mildly non-

projective dependency structures. In 21st Interna-

tional Conference on Computational Linguistics and 

44th Annual Meeting of the ACL (COLING-ACL), 

Companion Volume, Sydney, Australia. 

Wolfgang Maier and Timm Lichte. 2009. Characteriz-

ing Discontinuity in Constituent Treebanks. In Pro-
ceedings of the 14th Conference on Formal Gram-
mar, Bordeaux, France. 

Neville Ryant and Tatjana Scheffler. 2006. Binding of 

anaphors in LTAG. In Proceedings of TAG+8, Syd-
ney, Australia, 65-72. 

Stuart Shieber. 1985. Evidence against the context-

freeness of natural language. Linguistics and Phi-
losophy 8:333–343. 

Stabler, Edward P. 1997. Derivational minimalism. In 

Proceedings of Logical Aspects of Computational 
Linguistics, 68-95. 

Mark Steedman. 2001. The Syntactic Process. MIT 
Press. 

David Weir. 1988. Characterizing mildly context-
sensitive grammar formalisms. PhD dissertation, 
University of Pennsylvania, Philadelphia, USA. 

Joan Chen-Main, Aravind K. Joshi

60


