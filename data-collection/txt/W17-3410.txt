



















































(Re)introducing Regular Graph Languages


Proceedings of the 15th Meeting on the Mathematics of Language, pages 100–113,
London, UK, July 13–14, 2017. c©2017 Association for Computational Linguistics

(Re)introducing Regular Graph Languages

Sorcha Gilroy
University of Edinburgh

s.gilroy@sms.ed.ac.uk

Adam Lopez
University of Edinburgh

alopez@inf.ed.ac.uk

Sebastian Maneth
Universität Bremen

smaneth@uni-bremen.de

Pijus Simonaitis
Ecole Normale Supérieure de Lyon

pijus.simonaitis@ens-lyon.fr

Abstract

Distributions over strings and trees can be
represented by probabilistic regular lan-
guages, which characterise many mod-
els in natural language processing. Re-
cently, several datasets have become avail-
able which represent natural language phe-
nomena as graphs, so it is natural to ask
whether there is an equivalent of proba-
bilistic regular languages for graphs. This
paper presents regular graph languages,
a formalism due to Courcelle (1991) that
has not previously been studied in nat-
ural language processing. RGL is cru-
cially a subfamily of both Hyperedge Re-
placement Languages (HRL), which can
be made probabilistic; and Monadic Sec-
ond Order Languages (MSOL), which
are closed under intersection. We give
an accessible introduction to Courcelle’s
proof that RGLs are in MSOL, provid-
ing clues about how RGL may relate to
other recently introduced graph grammar
formalisms.

1 Introduction

NLP systems for machine translation, summarisa-
tion, paraphrasing, and other problems often fail to
preserve the compositional semantics of sentences
and documents because they model language as
bags of words, or at best syntactic trees. To pre-
serve semantics, they must model semantics. In
pursuit of this goal, several datasets have been pro-
duced which pair natural language with composi-
tional semantic representations in the form of di-
rected acyclic graphs (DAGs), including the Ab-
stract Meaning Represenation Bank (AMR; Ba-
narescu et al. 2013), the Prague Czech-English
Dependency Treebank (Hajič et al., 2012), Deep-
bank (Flickinger et al., 2012), and the Univer-
sal Conceptual Cognitive Annotation (Abend and

Anna fehlt
ihrem Kater

Anna’s cat
misses her

miss’ arg0

arg1 cat’

poss

Anna’

Figure 1: Semantic machine translation using AMR (Jones
et al., 2012). The edge labels identify ‘cat’ as the subject of
the verb ‘miss’, ‘Anna’ as the object of ‘miss’ and ‘Anna’ as
the possessor of ‘cat’.

Rappoport, 2013). To make use of this data, we
require probabilistic models of graphs.

Consider how we might use compositional
semantic representations in machine translation
(Figure 1). We first parse a source sentence to its
semantic representation, and then generate a tar-
get sentence from this representation. To do this
practically, we must be able to compose a string-
to-graph model with a graph-to-string model, and
we must be able to compute the probability of this
composition. To compose the models, we need to
be able to compute the intersection of the graph
domains of each model. Hence, we must be able to
define probability distributions over the graph do-
mains and efficiently compute their intersection.

For NLP problems in which data is in the form
of strings and trees, such distributions can be rep-
resented by finite automata (Mohri et al., 2008; Al-
lauzen et al., 2014), which are closed under inter-
section and can be made probabilistic. It is there-
fore natural to ask whether there is a family of
graph languages with similar properties to finite
automata. Recent work in NLP has focused pri-
marily on two families of graph languages: hy-
peredge replacement languages (HRL; Drewes
et al. 1997), a context-free graph rewriting for-
malism that has been studied in an NLP context
by several researchers (Chiang et al., 2013; Peng
et al., 2015; Bauer and Rambow, 2016); and DAG
automata languages, (DAGAL; Kamimura and
Slutzki 1981), studied by (Quernheim and Knight,

100



2012). (Thomas, 1991) showed that the latter
are a subfamily of the monadic second order
languages (MSOL), which are of special interest
to us, since, when restricted to strings or trees,
they exactly characterise the recognisable—or
regular—languages of each (Büchi, 1960; Büchi
and Elgot, 1958; Trakhtenbrot, 1961).

The HRL and MSOL families are incompara-
ble: that is, the context-free graph languages do
not contain the recognisable graph languages, as
is the case in languages of strings and trees (Cour-
celle, 1990). So, while each formalism has appeal-
ing characteristics, neither appear adequate for the
problem outlined above: HRLs can be made prob-
abilistic, but they are not closed under intersection;
and while DAGAL and MSOL are closed under
intersection, it is unclear how to make them prob-
abilistic (Quernheim and Knight, 2012).1

This situation suggests that we might want a
family of languages that is a subfamily of both
HRL and MSOL. Courcelle (1991) defines all
such languages as the family of strongly context-
free languages (SCFL).2,3 Unfortunately, SCFLs
are defined non-constructively, but Courcelle
(1991) exhibits a constructively-defined subfam-
ily: Regular Graph Languages (RGL), defined
as a restricted form of HRL, which Courcelle
demonstrates is also in MSOL.

Recently, two new graph grammar formalisms
have been defined which are also restricted forms
of HRL: Tree-like Grammars (TLG; Matheja et al.
2015) and Restricted DAG Grammars (RDG;
Björklund et al. 2016). TLGs are claimed to be
in SCFL, but the relationship of RDG to SCFL
is unknown. The grammar restrictions of TLGs,
RDGs and RGGs are incomparable, but they share
important characteristics, which we discuss in §5.

This paper provides an accessible proof that
RGL are a subfamily of MSOL, since only a
sketch is provided in Courcelle (1991). Our aim
in studying the proof is to gain insights into the re-

1Semiring-weighted MSOLs have been defined, where
weights may be in the tropical semiring (Droste and Gastin,
2005). However, for the weights to define a probability distri-
bution, they must meet the stronger condition that the sum of
multiplied weights over all definable objects is one. This does
not appear to have been demonstrated for DAGAL, which
violate the sufficient conditions that (Booth and Thompson,
1973) give for probabilistic languages. We suspect that there
are DAGAL (hence MSOL) for which it is not possible.

2Courcelle’s definition of strongly context-free is unre-
lated to use of this term in NLP.

3The equality of SCFL and MSOL ∩ HRL was recently
proved by (Bojanczyk and Pilipczuk, 2016).

HRL∗ MSOL† Graphs

CFTL∗

CFL∗

RTL†∗ Trees

RL†∗ Strings

RGL†∗ DAGAL†

Figure 2: Containment relationships for families of regu-
lar and context-free string and tree languages, hyperedge re-
placement languages (HRL), monadic second order definable
graph languages (MSOL), directed acyclic graph automata
languages (DAGAL), and the regular graph languages (RGL).
∗ indicates that the family of languages is probabilistic and †
indicates that the family of languages is intersectible.

lationship of RGL, TLG, and RDG, which might
enable us to define more general classes of graph
languages that are also within SCFL. Our discus-
sion emphasises points at which Courcelle’s proof
relies on particular restrictions of RGL, and is in-
tended to highlight the places where relaxations of
these restrictions may be possible.

Figure 2 summarises the relationship of RGL to
other formalisms and their properties. The proof
of each Lemma, Proposition and Theorem in this
paper that does not appear here is provided in full
in the supplementary materials.4

2 Monadic Second-Order Logic

The regular string and tree languages precisely
coincide with the monadic second-order logic
(MSO) definable sets of strings and trees, re-
spectively (Büchi, 1960; Büchi and Elgot, 1958;
Trakhtenbrot, 1961), so it is natural to look at
MSO over graphs.

We use the following notation. If n is an integer,
[n] denotes the set {1, . . . , n}. IfA is a set, s ∈ A∗
denotes that s is a sequence of arbitrary length,
each element of which is in A. We denote by |s|
the length of s. A ranked alphabet is an alphabet
A paired with an arity function rank: A→ N.
Definition 1. A hypergraph over a ranked alpha-
bet Γ is a tuple G = (VG, EG, attG, labG, extG)
where VG is a finite set of nodes; EG is a finite
set of edges (distinct from VG); attG : EG → V ∗G
maps each edge to a sequence of nodes; labG :
EG → Γ maps each edge to a label such that
|attG(e)| = rank(labG(e)); and extG is an ordered
subset of VG called the external nodes of G.

4goo.gl/Z5L2gP

101



X
a

b

(1) (2)

G

(2)

c

(1)

a

(3)

d

H

(1)

c
d
a

(2)

ba

G[X/H]

2

1
1

2

1

2
3

2

1
1

2
1

2

2

1
1

2
1

2

1

2

1

2

Figure 3: The replacement of the X-labeled edge in G by the
graph H .

We assume that both the elements of extG and
the elements of attG(e) for each edge e are pair-
wise distinct. An edge e is attached to its nodes
by tentacles, each labeled by an integer indicat-
ing the node’s position in attG(e) = (v1, . . . , vk).
The tentacle from e to vi has label i, so the tenta-
cle labels lie in the set [k] where k = rank(e). To
express that a node v is attached to the i-th tenta-
cle of an edge e we say vert(e, i) = v. The nodes
in extG are labeled by their position in extG. In
figures, the i-th external node is labeled (i). The
rank of an edge e is k if att(e) = (v1, . . . , vk) (or
equivalently, rank(lab(e)) = k). The rank of a hy-
pergraph G is |extG|. An induced subgraph of a
hypergraph G by edges E′ ⊆ EG is the subgraph
of G formed by including all edges in E′ and their
endpoints. Define HGΣ,Γ to be the set of all hy-
pergraphs with node labels in Σ and edge labels in
Γ (the hypergraphs as defined here have no node
labels so are in HG∅,Γ).

Example 1. Hypergraph G in Figure 3 has four
nodes (shown as black dots) and three hyperedges
labeled a, b, and X (shown boxed). The bracketed
numbers (1) and (2) denote its external nodes and
the numbers between edges and the nodes are ten-
tacle labels. Call the top node v1 and, proceeding
clockwise, call the other nodes v2, v3, and v4. Call
its edges e1, e2 and e3. Its definition would state:

attG(e1) = (v1, v2) labG(e1) = a

attG(e2) = (v2, v3) labG(e2) = b

attG(e3) = (v1, v4, v3) labG(e3) = X

extG = (v4, v2).

MSO on graphs quantifies over nodes, sets of
nodes, edges, and sets of edges.5 The atomic
formulas are x ∈ X , x = y, labγ(x), and
vert(x, i) = y. We construct MSO sentences us-
ing the atomic formulas, connectives ∧,∨,¬,⇒,

5Formally, this is called MS2 (Courcelle and Engelfriet,
2011); MS1 only quantifies over nodes and sets of nodes.

and quantifiers ∃, ∀. We allow vert(x, i) = y
to hold only when x is an edge and y is a
node. In the case of edge-labelled graphs, the
x in labγ(x) must be an edge. We define the
formula edg(x, y1, . . . , yk) : vert(x, 1) = y1 ∧
. . . vert(x, k) = yk ∧

∧
k′>k ∀y¬vert(x, k′) = y

which expresses att(x) = (y1, . . . , yk).
We can write down an MSO formula to ex-

press that sets X1, . . . , Xn partition the domain.
PART(X1, . . . , Xn):

∀x[x ∈ X1 ∪ · · · ∪Xn ∧ ¬x ∈ X1 ∩X2
∧¬x ∈ X1 ∩X3 ∧ · · · ∧ ¬x ∈ Xn−1 ∩Xn]

(1)

We use ! to denote unique existential quantifica-
tion. For any formula R:

∃!xR(x) : ∃xR(x) ∧ ∀yR(y)→ x = y.
We can define an MSO statement expressing

that the graph is a string by defining an edge la-
belled graph where the edges have rank 2, there is
exactly one node with no incoming edge, there is
exactly one node with no outgoing edge, and every
node has at most one incoming edge and at most
one outgoing edge:

STRING : ∀y∃!x1∃!x2edg(y, x1, x2)∧
∃!x1∀y¬vert(y, 2) = x1 ∧ ∃!x2∀y¬vert(y, 1) = x2
∧ ∀x¬x = x1 ⇒ ∃!y∃!x′edg(y, x′, x)
∧ ∀x¬x = x2 ⇒ ∃!y∃!x′edg(y, x, x′)

Let First(x) denote that x has no incoming
edges and Last(x) denote that x has no outgoing
edges.

Example 2. Let A be the automaton in Figure 4.
The corresponding MSO quantifies over a subset
Xi for each state qi in the automaton. The subsets
partition the nodes of the string graph to simulate
a run of the automaton.

Finally, we encode each transition of the form
(qi, a, qj) as x ∈ Xi ∧ ∃y∃x′edg(y, x, x′) ∧
laba(y)⇒ x′ ∈ Xj .

From A, we construct the formula autA:

autA : STRING ∧ ∃X0∃X1PART(X0, X1)
∧ ∀xFirst(x)⇒ x ∈ X0
∧ ∀xLast(x)⇒ x ∈ X1
∧∀x ∈ X0∧∃y∃x′edg(y, x, x′)∧laba(y)⇒ x′ ∈ X1
∧∀x ∈ X1∧∃y∃x′edg(y, x, x′)∧laba(y)⇒ x′ ∈ X1
∧∀x ∈ X1∧∃y∃x′edg(y, x, x′)∧labb(y)⇒ x′ ∈ X0

For a graph G and an MSO statement φ we say
that G |= φ (or G satisfies φ) when there is an
assignment of variables of φ to nodes and edges of

102



qo q1

a

b

a

Figure 4: The finite automaton A.

a a b a

Figure 5: The graph representing the string aaba.

G that makes φ true.

Example 3. The string graph G = aaba as shown
in Figure 5 can be produced by automaton A. The
letters are edge labels and call its nodes from left to
right v0, v1, v2, v3, and v4. If we letX0 = {v0, v3}
and X1 = {v1, v2, v4} then G |= autA.

Let aut′A(X0, X1) be the MSO formula identi-
cal to autA with ∃X0∃X1 removed from the begin-
ning of the formula. X0 and X1 are free variables
of aut′A, and we refer to the set of free variables
of a formula as its parameters. Given a graph G
and a formula φ(W) with parametersW , let α be
function fromW to subsets of nodes and edges in
G. Then we say that (G,α) |= φ(W) if G and
α satisfy φ(W). We call α a parameter assign-
ment. The MSO interpretation of an automaton
is satisfied if we can find a parameter assignment
that simulates a run of the automaton—more pre-
cisely, G |= autA if (G,α) |= aut′A(X0, X1). In
general, there may be more than one such α.

Example 4. LetW = {X0, X1} be parameters. If
α(X0) = {v0, v3} and α(X1) = {v1, v2, v4} then
(G,α) |=aut′A(W).

We can use an MSO statement φ to define a
language, L(φ) = {G | G |= φ}, and we
call the family of languages definable this way
as MSOL. We define the intersection of two lan-
guages L(φ1) ∩ L(φ2) = {G | G |= φ1 ∧ φ2}.
This clearly shows that MSO languages are closed
under intersection.

2.1 MSO Transductions
One way to show that a language is MSO defin-
able is to use the backwards translation theorem
(Courcelle and Engelfriet, 2011), which depends
on MSO transductions (MSOT), a generalisation
of finite-state string and tree transductions. The
theorem is a generalisation to graphs of the fact
that regular string and tree languages are closed

under inverse finite-state transductions (Hopcroft
and Ullman, 1979; ?).
Theorem 1 (Backwards Translation Theorem). If
L is an MSO definable graph language and f is
an MSO graph transduction then f−1(L) is effec-
tively MSO definable.

Definition 2. An MSO transducer
τ : HGΣ,Γ → HGΣ′,Γ′ is τ =
〈ρ(W), δ(x,W), (θr(x1, . . . , xN(r),W))r∈R〉.
W is a set of parameters; ρ(W) is a precondition
which input graphs must satisfy; δ(x,W) is a
domain formula defining the output domain
(i.e. nodes); and θr(x1, . . . , xN(r),W) is a
relation formula defining relationships between
the elements in the output domain (i.e. edges).6

The role of parameters here is to allow non-
determinism. Given a graph G and a parame-
ter assignment α from W to VG ∪ EG such that
(G,α) |= ρ(W), we define the output of the
transducer τ(G,α) = (D,R) such that D =
{x ∈ G | (G, x, α) |= δ(x,W)} and R =
{θr(x1, . . . , xN(r)) | (G, x1, . . . , xN(r), α) |=
θr(x1, . . . , xN(r),W), r ∈ R}. Define τ(G) =
{τ(G,α) | (G,α) |= ρ(W)} and for a language
L, τ(L) = {τ(G) | G ∈ L}.

3 Hyperedge Replacement Grammars

If f is a function and S is a set, f |S is the restric-
tion of f to domain elements in S. If f, g are func-
tions, f ◦ g is their composition.
Definition 3. Let G be a hypergraph with an edge
e of rank k and letH be a hypergraph also of rank
k disjoint from G. The replacement of e by H
is the graph G′ = G[e/H]. Let VG′ = (VG ∪
VH)−extH , EG′ = (EG∪EH)−{e}. Let extH =
(v1, . . . , vk), attG(e) = (u1, . . . , uk) and let f :
(VG ∪ VH)→ VG′ replace vi by ui for i ∈ [k] and
be the identity otherwise. The extension of f to
(VG∪VH)∗ is also denoted f . Let E = EG−{e},
then attG′ = attG|E∪(f ◦attH), labG′ = labG|E∪
labH .

Example 5. Replacement is shown in Figure 3.
We denote the replacement as G[X/H] since the
edge is unambiguous given its label.

Definition 4. A hyperedge replacement gram-
mar (HRG) G = (N,T, P, S) consists of disjoint
ranked alphabets N and T of nonterminals and

6Technically, this is a non-copying MSO transducer. In
general, MSO transductions can define multiple copies of
each element of the input domain.

103



Sp :
X

(1)

1 go
1

2
I

arg0
Y Zs :

(1)

(2)

1

2

1

arg0

arg1

Xq : W

Y

(2)

(1)
1

2

1
1

2

arg1

arg0 Wt :

(1)
1

want

Yr : Z

X

(2)

(1)
1

2

1
1

2

arg1

arg0 Zu :

(1)
1

need

Table 1: Productions of a HRG. The labels p, q, r, s, t, and u
label the productions so that we can refer to them in the text.
Note that Y can be rewritten either via production r or s.

terminals, a finite set of productions P , and a start
symbol S ∈ N . Every production in P is of the
form X → H where X ∈ N is of rank k and H is
a hypergraph of rank k over N and T .

A HRG G produces graphs in HG∅,TG . In each
example, we only show terminal edges of rank 2,
and depict them as directed edges where the direc-
tion is determined by the tentacle labels: tentacle
1 attaches to the source and 2 attaches to the tar-
get (Table 1). For each production p : X → G,
we use L(p) to refer to its left-hand side (X) and
R(p) to refer to its right-hand side (G). An edge
is a terminal edge if its label is terminal and a
nonterminal edge if its label is nonterminal. A
graph is terminal if all of its edges are labeled
with terminal symbols. The terminal subgraph
of a graph is the subgraph induced by its terminal
edges. Let NT(p) = {e1, . . . , en} be an enumera-
tion of the nonterminal edges in R(p), let |NT(p)|
be the number of nonterminal edges in R(p) and
let |NT(P )| = maxp∈P |NT(p)|.

Given a HRG G, we say that graph G de-
rives graph G′, denoted G → G′, iff there is an
edge e ∈ EG and a nonterminal X ∈ N such
that labG(e) = X and G′ = G[e/H], where
X → H is in P . We extend the idea of deriva-
tion to its transitive closure G →∗ G′. For ev-
ery X ∈ N we also use X to denote the con-
nected graph consisting of a single edge e with
lab(e) = X and nodes (v1, . . . , vrank(X)) such that

att(e) = (v1, . . . , vrank(X)), and we define the lan-
guage LX(G) = {G | X →∗ G,G is terminal}.
The language of G is thenL(G) = LS(G). We call
the family of languages that can be produced by
any HRG the hyperedge replacement languages
(HRL).

3.1 HRL and MSOT

Since HRGs are context-free, for each HRG G,
there is an underlying regular tree grammar TG
defining the derivation trees of the graphs in L(G).
Each T ∈ TG has node labels in PG and edge la-
bels in |NT(P )|. If a node has label p andR(p) has
n nonterminals X1, . . . , Xn then for each i ∈ [n],
there is an i labelled edge from p to a node la-
belled q where L(q) = Xi. The label of the root
of T must be p for some p with L(p) = S. Let
VAL : L(TG) → L(G) be a mapping from deriva-
tion trees to graphs so that G = VAL(T) iff T is
a derivation tree of G. Since HRGs can be am-
biguous, this mapping is not injective. (Courcelle,
1991) shows that VAL is an MSO transduction.7

This does not imply that HRLs are MSOL, since in
general MSOL is not closed under MSOT. Hence
an MSOT representing the inverse of VAL may not
exist for an arbitrary HRG, but we later discuss a
subfamily for which it does (§4), allowing us to
apply Theorem 1.

To distinguish between elements of a graph and
its derivation tree, we denote a grammar by G,
graph by G, derivation tree by T, derivation tree
node by v, edges and nodes in productions are
written with a bar (v̄) and nodes and edges in G
are unmarked (x).

The transduction VAL preserves the terminal
subgraph of every production used in a deriva-
tion and fuses nodes from different productions
together in the output graph. Node fusion is de-
termined by an equivalence relation ∼ generated
by a relation ∼0. Let NT(p) = (e1, . . . , en) the
nonterminal edges of R(p), let NTi(p) = ei, and
let extG(i) be the ith external node of G.

Definition 5. Let G be a HRG and T be a deriva-
tion tree of G, so that G = VAL(T). Define a bi-
nary relation∼0 on pairs (x̄,v) where x̄ is a node
in R(p) for some p ∈ P and v is a node of T with
label p. Then (x̄,v) ∼0 (ȳ,v′) iff:

1. v,v′ are nodes in T and v′ is the ith child of
v in T.

7It can also be viewed in the related framework of inter-
preted regular tree grammars (Koller and Kuhlmann, 2011).

104



2. p = labT(v), p′ = labT(v′).
3. x̄ is the jth node of NTi(p), ȳ = extR(p′)(j).

We define ∼ as the reflexive, symmetric, transi-
tive closure of ∼0.

The mapping VAL translates derivation trees to
graphs in two steps. First, the terminal subgraph
of every instance of every production used in the
derivation tree is produced in the output. Then, all
equivalent nodes under ∼ are fused. (Courcelle,
1991) shows that each step is a MSOT; their com-
position is also a MSOT.

Example 6. Figure 6 illustrates how VAL maps a
derivation tree to a graph.

The mapping VAL can be defined in terms
of two finer-grained mappings. Let EP =
∪p∈PER(p) and VP = ∪p∈PVR(p). Then he :
EP × VT → EG maps a pair (ē,v) to its im-
age e in the graph, where ē is a terminal edge in p
and lab(v) = p. This mapping is one-to-one since
edges cannot be fused. hv : VP × VT → VG maps
a pair (x̄,v) to its image v, where x̄ is a node in p
and lab(v) = p. It is not one-to-one since nodes
can be fused.

Lemma 1. Let G be a HRG, and let G be a graph
in L(G) with derivation tree T. If x̄ and x̄′ are
nodes such that hv(x̄,v) = hv(x̄′,v′) with v 6= v′
and, if x̄ is internal in R(p) for p =labT(v), then
x̄′ is an external node of R(p′) for p′ = labT(v′)
and v is an ancestor of v′ in T.

Consequently, if hv(x̄,v) = hv(x̄′,v′) then x̄
and x̄′ cannot both be internal.

4 Regular Graph Grammars

A regular graph grammar (RGG; Courcelle 1991)
is a restricted form of HRG. To explain the restric-
tions, we first require some definitions.

Definition 6. Given a graph G, a path in G from
a node v to a node v′ is a sequence

(v0, i1, e1, j1, v1)(v1, i2, e2, j2, v2) . . . (vk−1, ik, ek, jk, vk)

such that vert(er, ir) = vr−1 and
vert(er, jr) = vr for each r ∈ [k], v0 = v,
and vk = v′. The length of this path is k.

A path is terminal if every edge in the path is
terminal. A path is internal if each vi is internal
for 1 ≤ i ≤ k − 1. The endpoints v0 and vk of an
internal path can be external.

Definition 7. A HRG G is a Regular Graph
Grammar if each nonterminal in N has rank at
least one and for each p ∈ PG the following hold:

(C1) R(p) has at least one edge. Either it is a
single terminal edge, all nodes of which are exter-
nal, or each of its edges has at least one internal
node.

(C2) Every pair of nodes in R(p) is connected
by a terminal and internal path.

RGLs are HRLs by definition; we will prove
that they are also MSOLs by constructing the in-
verse of VAL, a transducer from RGL graphs to
their derivation trees. Since the derivation trees
are MSO definable, RGLs must also be MSO de-
finable by Theorem 1. The construction requires
a unique anchor element (a node or edge) for
each production in the grammar. Given an input
graph, the transducer first guesses—via parameter
assignment—the preimage of each edge and the
set of elements whose preimages are anchors. It
then checks whether the guess satisfies constraints
that must be true for every derived graph:

1. It must be possible to partition the graph into
a set of edge-disjoint connected subgraphs, each
isomorphic to the terminal subgraph of some pro-
duction.

2. For each node that is in two such subgraphs,
the node must be the image of two nodes in the
productions that are allowed to be fused under the
grammar.

If these constraints are satisfied, the transducer
outputs each guessed anchor and an edge between
anchors that it identifies to be in a parent-child re-
lationship.

Every valid parameter assignment corresponds
to a different output from the transducer, and we
will show that all derivation trees for any input
graph in the grammar lie in this output set.

Theorem 2. RGL ⊆ MSOL.
The proof of each Lemma and Proposition in

this section either appears here or in the supple-
mentary materials. The proof of Theorem 2 is pro-
vided in §4.2.1.

4.1 Anchors and Parameters
There are two types of productions in RGGs:
those with a single terminal edge, all nodes of
which are external; and those where each edge
has an internal node. We call the former ext-
productions and the latter int-productions. For
each int-production, we arbitrarily choose one of
its internal nodes to be its anchor. For each ext-
production, we choose its single terminal edge to
be the anchor. By Lemma 1, this choice ensures

105



p

(a)

q

t r

q u

t s

u

1

1 2

1 2

21

1

(b)

(1)

p

q

r

q

s

t

t

u

u

(c)

(1)

go
arg0

I

arg1
arg0

arg1
arg0

arg1
arg0

arg1
arg0

want

want

need

need

go
arg0

I

arg1
arg0

arg1
arg0

arg1
arg0

arg1

arg0

want

want

need

need

(d)

(1)

arg1

arg1

arg1

arg1

need

want

need

want

go

I

arg0

arg0

arg0

arg0 arg0

Figure 6: A derivation tree (a), the terminal subgraphs of every copy of every production in the derivation tree (b), the relation
∼ illustrated with dashed lines (c) and the resulting graph (d).

that a pair of anchors cannot be fused, so the set
of anchors in any derived graph is guaranteed to
be in one-to-one correspondence with the nodes
of its derivation tree.

We define two sets of parameters: E and
C, where E guesses preimages of edges, and C
guesses anchors (which may be either nodes or
edges). To define E precisely, we require some
notation. Let G be an RGG, and for each p ∈ P ,
let T(p) = {f̄p,1, . . . , f̄p,|T(p)|} enumerate the ter-
minal edges of R(p) and let γp,j be the label of
f̄p,j for each p ∈ P and j ∈ [|T(p)|]. Let |NT(p)|
be the number of nonterminal edges in p and let
|NT(P )| = maxp∈P |NT(p)|. Given a node v in
a derivation tree T, we say that v is an i-child if
it is the ith child of some other node in T. By
convention, the root node is the only 0-child.

Let G be in L(G) and let T be a derivation tree
of G. For each i ∈ [0, |NT(P )|], p ∈ P and j ∈
[|T (p)|], we define a parameter Ei,p,j :
Ei,p,j = {e ∈ EG | he(f̄p,j ,v) and v is an i-child.}
Let E = {Ei,p,j} for i ∈ [0, |NT(P )|], p ∈ P and
j ∈ [|T(p)|].

For each i ∈ [|NT(P )|] and p ∈ P , define
Ci,p = {h(c̄p,v) | p = labT(v),v is an i-child.}
Where h = he ∪ ev since c̄p can either be an edge
or a node. Let C = ∪i,pCi,p.

pv1

qv2

tv3 r v4

qv5 u v6

tv7 s v8

uv9

1

1 2

1 2

21

1

v5

v4

v10

v11

v12

v9

v3v8

v2
v7

v1
v6 e1

e2

e3

e4

e5

e6

e7

e8

e9

e15

e14

e12

e13

e11 e10

Figure 7: The derivation tree from Figure 6 (a) and the graph
from Figure 6 (d) with variable names for the nodes and
edges.

LetW = E ∪ C.
Example 7. Table 2 shows the productions of Ta-
ble 1 with labels on each node and edge. Figure
7 shows the derivation tree and graph from Figure
6 with variable names added. We use these vari-
able names to refer to specific nodes and edges
in the text. For example, hv(c̄s,v8) = v1, and
he(f̄u,1,v9) = e5.

Example 8. Using the labels in Table 2 and Figure
7, we see that E0,p,1 = {e9}, E1,q,2 = {e12, e14},
and v1 = h(c̄p,v8) is an anchor.

106



Sp :

c̄p

X
x̄1

x̄2

1 f̄p,1
1

2

f̄p,3

f̄p,2
Y Zs :

c̄s

x̄7

x̄8

1

2

1

f̄s,1

f̄s,2

Xq : W

c̄q

Y

x̄3

x̄4
1

2

1
1

2

f̄q,1

f̄q,2 Wt :

x̄9

c̄t

1
f̄t,1

Yr : Z

c̄r

X

x̄5

x̄6
1

2

1
1

2

f̄r,1

f̄r,2 Zu :

x̄10

c̄u

1
f̄u,1

Table 2: The productions from Table 1 with variable names
added to each of the nodes and terminal edges. Node vari-
ables of the form c̄x for x ∈ {p, q, r, s, t, u} indicate anchors.

4.1.1 Path Properties of RGLs

The precondition will exploit the properties of
RGGs, particularly the properties of paths be-
tween nodes. Let G be an RGG, G ∈ L(G), and
let T be a derivation tree of G. In the following,
we relate paths within individual productions in P
(denoted π) to paths in G (denoted λ). For each e
in G, we define o(e) = (i, p, j) iff e ∈ Ei,p,j .

For every path λ in G of the form

(v, i1, e1, j1, v1)(v1, i2, e2, j2, v2) . . . (vk−1, ik, ek, jk, v′)

we define its trace as the sequence
tr(λ) := (o(e1), i1, j1)(o(e2), i2, j2) . . . (o(ek), ik, jk).

Now let π be a path

(v̄, i1, ē1, j1, v̄1) . . . (v̄k−1, ik, ēk, jk, v̄
′)

in R(p) for some p ∈ P . Let v ∈ VT, p =
labT(v). We denote by h(π,v) the following path
in G:

(h(v̄,v), i1, h(ē1,v), j1, h(v̄1,v)) . . .

(h(v̄k−1,v), i1, h(ēk,v), j1, h(v̄
′,v))

If v is an i-child of some node in VT then
tr(h(π,v)) is the sequence

((i, p,m1), i1, j1) . . . ((i, p,mk), ik, jk)

where ēj = f̄p,mj for each j ∈ [k]. Note that
tr(π) = tr(h(π,v)). The trace is a property that
remains constant when a path is projected from
a production into a graph. This projection is not

one-to-one since a production can be applied sev-
eral times; a trace appears in the graph once for
each application of the corresponding production
in a derivation. For v ∈ VT, we write π ∈
R(labT(v)) to denote that π is a path in the pro-
duction which is the label of v.

Example 9. Let π be the path
(x̄3, 2, f̄q,2, 1, c̄q)(c̄q, 1, f̄q,1, 2, x̄4) in produc-
tion q in Table 2. h(π,v4) for v4 is the path
(v11, 2, e13, 1, v4)(v4, 1, e4, 2, v5) in Figure 7,
and its trace is ((1, q, 2), 2, 1)((1, q, 1), 1, 2).

Lemma 2 (Lemma 5.5 from (Courcelle, 1991)).
Let G be an RGG,G be a graph in L(G), and T be
a derivation tree of G. Let λ be a path in G of the
form h(π,v) for some v ∈ VT and some terminal
path π ∈ R(labT(v)). The final node of π may be
internal or external but every other node must be
internal. If λ′ is another path in G with the same
trace and the same initial node as λ, then λ′ = λ.

Lemma 2 guarantees a unique trace for every
path in a graph that is the projection of a path in a
single production. By property C2 of RGGs, this
guarantee must hold for at least one path from the
anchor node of an int-production to every other
node in the production. For ext-productions, all
paths are of the form π = (ē, i, v̄i), where e is
the single nonterminal edge; these paths are also
guaranteed unique traces.

4.1.2 MSO Formulas for the Precondition
Given an assignment to our parameters, we can
use the path property in Lemma 2 to define some
useful MSO statements. The first, ANC, relates an-
chors to the nodes in the graph. Throughout this
section, given a derivation tree T, we will refer to
αT which is the parameter assignment fromW to
VG ∪ EG as defined above.
Lemma 3 (Lemma 5.6 from (Courcelle, 1991)).
Let G be an RGG, G be a graph in L(G), and T
be a derivation tree of G. For every p ∈ P , ev-
ery i ∈ [0, |NT(P )|], and every node x̄ ∈ R(p),
one can construct a formula ANCp,i,x̄(u,w, {W})
such that, for every u ∈ VG ∪ EG, w ∈ VG:
(G, u,w, αT) |= ANCp,i,x̄(u,w, {W})
iff u = h(c̄p,v) and w = hv(x̄,v) for some v ∈
VT which is an i-child and p = labT(v).

We say that node u anchors node v if for some
p, i and x̄, ANCp,i,x̄(u, v, {W}) holds. We use the
fact that a node or edge anchors itself to establish
its corresponding production.

107



Example 10. Looking at Table 2 and Figure 7, we
can establish that ANCp,0,x̄1(v5, v11, {W}) holds
and that v5 ∈ C0,p.

The next MSO formula we construct relates
pairs of anchors to each other. Since the anchors
define the output domain of the transducer, the for-
mula PAR defines the edges of the output.

Lemma 4 (Lemma 5.7 of (Courcelle, 1991)). Let
G be an RGG,G be inL(G), T be a derivation tree
of G, and α be the parameter assignment defined
with respect to T. One can construct a formula
PARp,i,p′,i′(u,w, {W}) such that, for u,w ∈ VG ∪
EG:

(G, u,w, α) |= PARp,i,p′,i′(u,w, {W})
iff u = h(c̄p,v), w = h(c̄p′ ,v′) for some v,v′ in
VT where p = labT(v), p′ = labT(v′), v is an
i-child, and v′ is the i′th child of v in T.

If PARp,i,p′,i′(u, u′, {W}) holds, then u will be-
come the parent of u′ in the output tree. The proof
of this lemma relies on C1 of RGG.

Example 11. From Table 2 and Figure 7,
PARq,1,s,2(v2, v1, {W}) holds.

As introduced in §3, we have a binary equiv-
alence relation ∼ over pairs of the form (x̄,v)
where x̄ is a node in a production p and v is a node
in the derivation tree with label p. We use this
relation for the precondition of the transducer so
that a pair of nodes are only fused if the grammar
and derivation tree allows them to be. We project
∼ into the graph to construct a relation over an-
chors such that FUSEp,i,x̄,p′,i′,x̄′(u, u′, {W}) holds
if and only if (x̄,v) ∼ (x̄′,v′), u = h(c̄p,v), u′ =
h(c̄p′ ,v

′), and h(x̄,v) = h(x̄′,v′).

Lemma 5. Let G be an RGG, G be in L(G), and
T be a derivation tree of G. One can construct
a formula FUSEp,i,x̄,p′,i′,x̄′(u, u′, {W}) such that,
for u, u′ ∈ VG ∪ EG:
(G, u, u′, {W}) |= FUSEp,i,x̄,p′,i′,x̄′(u, u′, {W})
iff u = h(c̄p,v), u′ = h(c̄p′ ,v′) for some v,v′ in
VT where p = labT(v), p′ = labT(v′),v is the
ith child of some node, v′ is the i′th child of some
node, and hv(x̄,v) = hv(x̄′,v′).

Example 12. From Table 2 and Figure 7, we
can see that FUSEp,0,x̄1,s,2,x̄8(v5, v1, {W}) holds
since v5 = hv(c̄p,v1), v1 = hv(c̄s,v8), v11 =
hv(x̄1,v1) = hv(x̄8,v8), ANCp,0,x̄1(v5, v6, {W})
and ANCs,2,x̄8(v1, v11, {W})

4.1.3 The Precondition of the Transducer
Let X be in N , then PX = {p ∈ P |L(p) = X},
and an X-derivation tree is a derivation tree with
respect to X as the start symbol (in this case, the
root will have label in PX ). An S-derivation tree
is referred to simply as a derivation tree.

Edge Requirements
(E1) α(E) partitions EG,
(E2) for all e ∈ α(Ei,p,j) e has label γp,j
(E3) there is a unique p ∈ PX such that

α(E0,p,j) has exactly one element for each j ∈
[|T(p)|] and for every p′ 6= p, α(E0,p′,j) is empty
for all j.

Recall the MSO statement PART(X1, . . . , Xn)
from Equation 1 which expresses that X1, . . . , Xn
form a partition over the domain. We can also de-
fine a partition over a restricted domain Y to be:

resPART(Y,X1, . . . , Xn) :

∀x ∈ Y [x ∈ X1 ∪ · · · ∪Xn ∧ ¬x ∈ X1 ∩X2
∧ ¬x ∈ X1 ∩X3 ∧ · · · ∧ ¬x ∈ Xn−1 ∩Xn]

Using this formula, the requirements E1,E2 and
E3 are all expressible in MSO as follows:

EDGEX(W) : resPART(EG, E)∧∧

i,p,j

∀e ∈ Ei,p,j labγp,j (e)∧
∨

p∈PX
[
∧

j

∃!e ∈ E0,p,j∧
∧

p′∈P,p′ 6=p

∧

j

E0,p′,j = ∅]

Let EDGE(W) = EDGES(W). In using the symbol
∧i,p,j we are quantifying over i ∈ [0, |NT(P )|],
p ∈ P , and j ∈ [|T(p)|].
Lemma 6. Let G be an RGG and let G ∈
L(G) then for each derivation tree T of G,
(G,αT) |=EDGE(W).
Example 13. For the grammar in Table 2, and
derivation tree and graph in Figure 7, we obtain
E = {E0,p,1 = {e9}, E0,p,2 = {e14}, E0,p,3 =
{e15}, E1,q,1 = {e4, e2}, E1,q,2 = {e13, e11},
E2,r,1 = {e3}, E2,r,2 = {e12}, E2,s,1 = {e1},
E2,s,2 = {e10}, E1,t,1 = {e6, e8}, E2,u,1 = {e7},
E1,u,1 = {e5}}. This clearly forms a partition of
the edges, and we can easily check that the rest of
the requirements of EDGE also hold.

Decomposition into Subgraphs This con-
straint partitions the graph into a set of connected
subgraphs, each of which is isomorphic to the ter-
minal subgraph of the right-hand side of some pro-
duction. The requirements are:

(S1) Every node in G is attached to some edge,

108



(S2) for each anchor u ∈ Ci,p we can identify
a unique edge e ∈ Ei,p,j for each j ∈ |T(p)| such
that u anchors all of the endpoints of e,

(S3) for each edge e ∈ Ei,p,j we can identify a
unique anchor u ∈ Ci,p such that u anchors all of
the endpoints of e.

SUBGRAPHi,p,j(W) :
(∀v∃e ∨j vert(e, j) = v)∧(
∀c ∈ Ci,p∃!e ∈ Ei,p,j
∃v1ANCp,i,x̄1(c, v1, {W}) ∧ · · · ∧
∃vjkANCp,i,x̄jk (c, vjk , {W})∧

edg(e, v1, . . . , vjk)
)
∧

(
∀e ∈ Ei,p,j∃!c ∈ Ci,p
∃v1ANCp,i,x̄1(c, v1, {W}) ∧ · · · ∧
∃vjkANCp,i,x̄jk (c, vjk , {W})∧

edg(e, v1, . . . , vjk)
)

Define SUBGRAPH(W) : ∧i,p,jSUBGRAPHi,p,j .

Lemma 7. Let G be an RGG and let G ∈ L(G)
then for each derivation tree T of G, (G,αT) |=
SUBGRAPH(W).

Example 14. For the graph in Figure 7, we
look at SUBGRAPH1,q,1. We need to look at
C1,q = {v4, v2}, and E1,q,1 = {e4, e2}. Look-
ing at the graph, we can see that each of
ANCq,1,c̄q(v4, v4, {W}), ANCq,1,x̄4(v4, v5, {W}),
ANCq,1,c̄q(v2, v2, {W}), ANCq,1,x̄4(v2, v3, {W})
hold. The label ‘arg1’ is on e2, e4 and fq,1 so we
can quickly verify that this shows that the graph
satisfies SUBGRAPH1,q,1.

Subgraph Composition
We require that for a graph G with derivation
tree T, (G,αT) |= ANCp,i,x̄(u, v, {W}) for
u ∈ Ci,p and (G,αT) |= ANCp′,i′,x̄′(u′, v, {W})
for u′ ∈ Ci′,p′ if and only if (G,αT) |=
FUSEp,i,x̄,p′,i′,x̄′(u, u

′, {W}) holds. This part of
the precondition ensures that two different ways
of looking at how nodes can be fused agree with
one another. The first is if a node can be anchored
by two different anchors then this node must be the
image of two nodes from different production ap-
plications. The second is that we have FUSE which
is the equivalence relation generated by a relation
over the neighbouring nodes in the derivation tree.

SHARE(W) :
∧

i,p,x̄,i′,p′,x̄′
∀c1 ∈ Ci,p∀c2 ∈ Ci′,p′

(
ANCp,i,x̄(c1, v, {W})∧

ANCp′,i′,x̄′(c2, v, {W})
↔ FUSEi,p,x̄,i′,p′,x̄′(u, u′, {W})

)

Lemma 8. Let G be an RGG and let G ∈ L(G)
then for each derivation tree T of G, there exists
αT such that (G,αT) |= SHARE(W).
Example 15. Looking at Table 2 and
Figure 7, FUSEp,0,x̄1,s,2,x̄8(v5, v1, {W})
holds and ANCp,0,x̄1(v5, v6, {W}) and
ANCs,2,x̄8(v1, v6, {W}) both also hold.

The proof of each of the above lemmas is avail-
able in the supplementary materials. In each
of these proofs, we prove by induction on the
size of T that (G,αT) |= R(W) for R ∈
{EDGE, SUBGRAPH, SHARE}. In each induction,
we use the equations (defined below) which ex-
press αT in terms of the parameter assignments of
sub-trees of T.

Let G ∈ LX(G) and q : X → H such
that H has nonterminals Y1, . . . , Yn and G =
H[Y1/H1] . . . [Yn/Hn]. Then Hη ∈ LYη(G) for
each η ∈ [n]. Let Tη be a derivation tree for Hη
and let αTη be the assignment ofW to the nodes
and edges in Hη. Then we can define αT(E) in
terms of the set of αTη(E)s:

αT :





e ∈ Ei,p,j if e ∈ EHη , αTη : e ∈ Ei,p,j , i 6= 0
e ∈ Eη,p,j if e ∈ EHη , αTη : e ∈ E0,p,j
e ∈ E0,q,j if e ∈ EH , e = he(f̄q,j ,v0).

(2)

Where e = he(f̄q,j ,v0) means that e can be
uniquely identified as corresponding to f̄q,j since
H and R(q) are isomorphic and v0 is the root of
T. For the anchor set,
αT(C) = c ∪η∈[n] αTη(C) (3)
where c = h(c̄q,v0).

4.1.4 RGLs Satisfy the Precondition
The precondition of the transducer is the conjunc-
tion of each of these formulas,

ρX(W) : EDGEX(W)∧SHARE(W)∧SUBGRAPH(W)
Define ρ(W) = ρS(W).
Proposition 1. Let G be an RGG and let G ∈
L(G), then for each derivation tree T of G,

109



there exists a parameter assignment αT such that
(G,αT) |= ρ(W).

Proof. We use the parameter assignment αT
which is defined from T in §4.1. Lemma 6 proves
that (G,αT) |= EDGE(W). Lemma 7 proves that
(G,αT) |= SUBGRAPH(W). Lemma 8 proves that
(G,αT) |= SHARE(W). Therefore, (G,αT) |=
ρ(W).

4.2 Parsing as Transduction

The transducer is made up of three types of for-
mulas: the precondition, the domain formulas, and
the relation formulas. We have established the pre-
condition ρ(W) and next we define the domain
and relation formulas. The domain formulas de-
fine the nodes of the derivation tree and so we
write node(x, {W}). The relation formulas define
which output node is the ith child of another out-
put node, written childi(x, y, {W}), and the labels
of the output nodes, written labp(x, {W}).

The domain of the output for a parameter as-
signment α is DT where:
DT(α) : {x | (G, x, α) |= node(x, {W})}
and node(x, {W}) : x ∈ C.

The relation formula childr(x, y, {W}) defines
the edges of the output of the transducer. We use
the formula PARp,i,p′,i′(u, u′, {W}) from Lemma
4, this encodes that the derivation tree node corre-
sponding to u′ is the i′th child of the node corre-
sponding to u (which itself is the ith child of some
other node).
childi′(x, y, {W}) :

∨

i,p,p′
(PARp,i,p′,i′(x, y, {W})

We also need to assign labels to the tree nodes
which can be done via the unary relation:
labp(x, {W}) :

∨

i

x ∈ Ci,p

Example 16. Figure 8 shows the output of the
transducer when it takes Figure 7 as input with α
defined as in the previous examples. The domain
formulas specify the existence of the 9 nodes and
the relation formulas specify the edges between
the nodes, labelled by PAR formulas, and the la-
bels of the nodes, according to the Ci,p sets.

We have now defined each part of the transducer
τ from graphs to their derivation trees. Let G be
an RGG, and let X ∈ N . Then the corresponding

pv5 ∈ C0,p

qv4 ∈ C1,q

tv9 ∈ C1,t r v3 ∈ C2,r

qv2 ∈ C1,q u v8 ∈ C2,u

tv7 ∈ C1,t s v1 ∈ C2,s

u v6 ∈ C1,u

PARp,0,q,1(v5, v4)

PARq,1,r,2(v4, v3)PARq,1,t,1(v4, v9)

PARr,2,u,2(v3, v8)PARr,2,q,1(v3, v2)

PARq,1,s,2(v2, v1)PARq,1,t,1(v2, v7)

PARs,2,u,1(v1, v6)

Figure 8: The output of the transducer, variable names are
based on those of Figure 7. The PAR formulas are there to
explain why the edge exists and the v ∈ Ci,p formulas are
there to show where the node labels come from.

transducer τX is
〈ρX({W}), node(x, {W}),
(labp(x, {W}))p∈P ,
(edger(x, y, {W}))r∈[|NT(P )|]〉.

For start symbol S of G, let τ = τS . Let G
be a graph in L(G), and let α be a parameter as-
signment such that (G,α) |= ρ({W}). Then the
output of the transducer with respect to α is
τ(G,α) = (VH , labH , (childiH)i∈[0,|NT(P )|])

where VH = DT(α) = {x | (G, x, α) |=
node(x, {W})}, labH : VH → P such that
labH(x) = p if x ∈ α(Ci,p) for some i, and
childiH : VH → VH such that childHi (x, y) if
(G, x, y, α) |= PARp,i,p′,r(x, y, {W}).

4.2.1 Transducer Output and Derivation
Trees

We will show that for each G ∈ L(G) if T is a
derivation tree of G then T ∈ τ(G). We will also
show that for each T ∈ τ(G), if it is a derivation
tree in TG then it is a derivation tree of G.
Proposition 2. Let G be an RGG and τ be the cor-
responding transducer. Let G ∈ L(G) and T be a
derivation tree of G. Then T ∈ τ(G).

By Proposition 2, we know that for each G,
{T|val(T) = G} ⊆ τ(G).
Proposition 3. Let G be an RGG and G ∈
L(G). Let α be a parameter assignment such that
(G,α) |= ρ(W). Then if T = τ(G,α) is in TG
then VAL(T) = G.

Theorem 2. RGL ⊆ MSOL.

110



Proof. Let G be an RGG and τ be the correspond-
ing transducer. By Propositions 2 and 3, for each
G ∈ L(G), τ(G) is a set which contains all of
the derivation trees of G and possibly other ele-
ments none of which are derivation trees of any
G′ ∈ L(G) where G′ 6= G. Therefore, for each
G ∈ L(G),
τ(G) ∩ TG = {T ∈ TG | VAL(T) = G}.
Therefore,
τ(L(G)) ∩ TG = {T ∈ TG | VAL(T) = G,G ∈ L(G)}.
And since {T ∈ TG | VAL(T) = G,G ∈
L(G)} = TG ,
τ−1(τ(L(G)) ∩ TG) = τ−1(TG).
τ−1(τ(L(G))∩TG) = {G ∈ L(G) | τ(G)∩TG 6=
∅)} = L(G). Therefore,
L(G) = τ−1(TG)
and so by Theorem 1 and the fact that TG is MSO
definable, L(G) is MSO definable.

5 Conclusions and Discussion

Property C1 of RGGs is used repeatedly in the
proof that RGL is in MSOL. This property implies
connectedness of the terminal subgraph, a prop-
erty that both Tree-like Grammars (Matheja et al.,
2015) and Restricted DAG Grammars (Björklund
et al., 2016) share, although both of these for-
malisms allow nodes that are connected only to
nonterminals, which is forbidden in RGG. We sus-
pect that all three families of languages are incom-
parable. That these restricted forms of HRG all
share the property of connectedness suggests that
it may be an important property. In particular, we
plan to investigate whether connectedness of ter-
minal subgraphs implies that an HRL is in MSOL.

Languages which contain graphs of the form
shown in Figure 9 are MSOL but not in RGL or
TLG; hence both RGL and TLG are proper sub-
families of SCFL. Languages of this form can be
produced by RDG, whose relationship to SCFL is
unknown. To produce graphs like this, we must al-
low productions containing nonterminals that are
not incident to any internal node. We would need
to allow this only in certain circumstances how-
ever, as we could easily produce a language of
graphs that look like the graph in Figure 9 with
equal numbers of a-labelled and b-labelled edges;
such languages are not MSO-definable. On a tech-
nical level, allowing such extensions would mean
that PAR no longer holds. (Courcelle, 1991) dis-

cusses this problem and introduces an alternative
representation of derivation trees called reduced
trees which enable some cases of this type to be
defined in MSOL. This point requires further in-
vestigation.

Another possible extension would be to con-
sider alternative forms of Lemma 2. Every MSO
formula in the transducer depends on this lemma.
We could potentially extend RGG if we can de-
fine other cases in which a path could be defined
in terms of its trace and initial vertex. We intend
to investigate such cases in future work.

. . .
a a

Figure 9: A graph where every edge is labelled a and has the
same tail but each edge has a unique head.

Acknowledgments

This work was supported in part by the EPSRC
Centre for Doctoral Training in Data Science,
funded by the UK Engineering and Physical Sci-
ences Research Council (grant EP/L016427/1) and
the University of Edinburgh; and in part by a
Google faculty research award (to AL). We thank
Clara Vania, Sameer Bansal, Ida Szubert, Fed-
erico Fancellu, Antonis Anastasopoulos, Marco
Damonte, and the anonymous reviews for helpful
discussion of this work and comments on previous
drafts of the paper.

References
Omri Abend and Ari Rappoport. 2013. Univer-

sal conceptual cognitive annotation (ucca). In
ACL (1). The Association for Computational
Linguistics, pages 228–238. http://dblp.uni-
trier.de/db/conf/acl/acl2013-1.html#AbendR13.

Cyril Allauzen, William Byrne, Adria de Gispert, Gon-
zalo Iglesias, and Michael Riley. 2014. Pushdown
automata in statistical machine translation. Compu-
tational Linguistics .

Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract meaning representa-
tion for sembanking. In Proceedings of the
7th Linguistic Annotation Workshop and Interoper-
ability with Discourse. Association for Computa-
tional Linguistics, Sofia, Bulgaria, pages 178–186.
http://www.aclweb.org/anthology/W13-2322.

111



Daniel Bauer and Owen Rambow. 2016. Hy-
peredge replacement and nonprojective de-
pendency structures. In Proceedings of the
12th International Workshop on Tree Ad-
joining Grammars and Related Formalisms
(TAG+12), June 29 - July 1, 2016, Heinrich Heine
University, Düsseldorf, Germany. pages 103–
111. http://aclweb.org/anthology/W/W16/W16-
3311.pdf.

Henrik Björklund, Frank Drewes, and Petter Eric-
son. 2016. Between a Rock and a Hard Place
– Uniform Parsing for Hyperedge Replacement
DAG Grammars, Springer International Publishing,
Cham, pages 521–532. https://doi.org/10.1007/978-
3-319-30000-9 40.

Mikolaj Bojanczyk and Michal Pilipczuk. 2016.
Definability equals recognizability for graphs
of bounded treewidth. In Proceedings of
the 31st Annual ACM/IEEE Symposium on
Logic in Computer Science. ACM, New
York, NY, USA, LICS ’16, pages 407–416.
https://doi.org/10.1145/2933575.2934508.

Taylor L. Booth and Richard A. Thompson. 1973. Ap-
plying probability measures to abstract languages.
IEEE Transactions on Computers 22(5):442–450.
https://doi.org/http://doi.ieeecomputersociety.org/10.1109/T-
C.1973.223746.

Julius Richard Büchi. 1960. On a decision method
in restricted second-order arithmetic. Proceedings
Logic, Methodology and Philosophy of Sciences .

Julius Richard Büchi and Calvin Elgot. 1958. Decision
problems of weak second order arithmetic and finite
automata, part i. Notices of the American Mathe-
matical Society page 5;834.

David Chiang, Jacob Andreas, Daniel Bauer,
Karl Moritz Hermann, Bevan Jones, and Kevin
Knight. 2013. Parsing graphs with hyper-
edge replacement grammars. In Proceedings
of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1:
Long Papers). Association for Computational
Linguistics, Sofia, Bulgaria, pages 924–932.
http://www.aclweb.org/anthology/P13-1091.

Bruno Courcelle. 1990. The monadic second-order
logic of graphs i. recognizable sets of finite graphs.
Information and Computation pages 12–75.

Bruno Courcelle. 1991. The monadic second-
order logic of graphs V: on closing the gap
between definability and recognizability. The-
oretical Computer Science 80(2):153–202.
https://doi.org/10.1016/0304-3975(91)90387-H.

Bruno Courcelle and Joost Engelfriet. 2011. Graph
Structure and Monadic Second-Order Logic, a Lan-
guage Theoretic Approach. Cambridge University
Press.

Frank Drewes, Hans-Jörg Kreowski, and Annegret Ha-
bel. 1997. Hyperedge replacement graph grammars.
In Grzegorz Rozenberg, editor, Handbook of Graph
Grammars and Computing by Graph Transforma-
tion, World Scientific, pages 95–162.

Manfred Droste and Paul Gastin. 2005. Weighted
Automata and Weighted Logics, Springer Berlin
Heidelberg, Berlin, Heidelberg, pages 513–525.
https://doi.org/10.1007/11523468 42.

Dan Flickinger, Yi Zhang, and Valia Kordoni. 2012.
Deepbank : a dynamically annotated treebank of the
wall street journal. In Proceedings of the Eleventh
International Workshop on Treebanks and Linguistic
Theories (TLT11). Lisbon, pages 85–96. HU.

Jan Hajič, Eva Hajičová, Jarmila Panevov, Petr
Sgall, Ondřej Bojar, Silvie Cinková, Eva Fučı́ková,
Marie Mikulová, Petr Pajas, Jan Popelka, Jiřı́ Se-
mecký, Jana Šindlerová, Jan Štěpánek, Josef Toman,
Zdeňka Urešová, and Zdeněk Žabokrtský. 2012.
Announcing prague czech-english dependency tree-
bank 2.0. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Thierry Declerck, Mehmet Uur
Doan, Bente Maegaard, Joseph Mariani, Asun-
cion Moreno, Jan Odijk, and Stelios Piperidis, ed-
itors, Proceedings of the Eight International Con-
ference on Language Resources and Evaluation
(LREC’12). European Language Resources Associ-
ation (ELRA), Istanbul, Turkey.

John E. Hopcroft and Jeffrey D. Ullman. 1979. Intro-
duction to automata theory, languages and compu-
tation. Addison-Wesley.

Bevan Jones, Jacob Andreas, Daniel Bauer, Karl Mor-
tiz Hermann, and Kevin Knight. 2012. Semantics-
based machine translation with hyperedge replace-
ment grammars. In Proceedings of COLING.

Tsutomu Kamimura and Giora Slutzki. 1981. Parallel
and two-way automata on directed ordered acyclic
graphs. Information and Control 49(1):10–51.

Alexander Koller and Marco Kuhlmann. 2011. A
generalized view on parsing and translation. In
Proceedings of the 12th International Conference
on Parsing Technologies. Association for Compu-
tational Linguistics, Dublin, Ireland, pages 2–13.
http://www.aclweb.org/anthology/W11-2902.

Christoph Matheja, Christina Jansen, and Thomas
Noll. 2015. Tree-Like Grammars and Separa-
tion Logic, Springer International Publishing, Cham,
pages 90–108. https://doi.org/10.1007/978-3-319-
26529-2 6.

Mehryar Mohri, Fernando C. N. Pereira, and Michael
Riley. 2008. Speech recognition with weighted
finite-state transducers. In Larry Rabiner and Fred
Juang, editors, Handbook on Speech Processing and
Speech Communication, Part E: Speech recognition,
Springer.

112



Xiaochang Peng, Linfeng Song, and Daniel Gildea.
2015. A synchronous hyperedge replacement gram-
mar based approach for AMR parsing. In Pro-
ceedings of the 19th Conference on Computa-
tional Natural Language Learning, CoNLL 2015,
Beijing, China, July 30-31, 2015. pages 32–41.
http://aclweb.org/anthology/K/K15/K15-1004.pdf.

Daniel Quernheim and Kevin Knight. 2012. Towards
probabilistic acceptors and transducers for feature
structures. In Proceedings of the Sixth Workshop on
Syntax, Semantics and Structure in Statistical Trans-
lation. Association for Computational Linguistics,
Stroudsburg, PA, USA, SSST-6 ’12, pages 76–85.
http://dl.acm.org/citation.cfm?id=2392936.2392948.

Wolfgang Thomas. 1991. Automata, Languages
and Programming: 18th International Colloquium
Madrid, Spain, July 8–12, 1991 Proceedings,
Springer Berlin Heidelberg, Berlin, Heidelberg,
chapter On logics, tilings, and automata, pages 441–
454. https://doi.org/10.1007/3-540-54233-7-154.

Boris Trakhtenbrot. 1961. Finite automata and logic of
monadic predicates. Doklady Akademii Nauk SSSR
pages 140:326–329.

113


