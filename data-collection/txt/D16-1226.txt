



















































The Effects of the Content of FOMC Communications on US Treasury Rates


Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2096–2102,
Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics

The Effects of the Content of FOMC Communications on US Treasury Rates

Christopher Rohlfs1 and Sunandan Chakraborty2 and Lakshminarayanan Subramanian2
1Morgan Stanley

2New York University
New York, USA

Christopher.Rohlfs@morganstanley.com, Sunandan@cims.nyu.edu, lakshmi@cims.nyu.edu

Abstract

This study measures the effects of Federal
Open Market Committee text content on the
direction of short- and medium-term interest
rate movements. Because the words relevant
to short- and medium-term interest rates differ,
we apply a supervised approach to learn dis-
tinct sets of topics for each dependent variable
being examined. We generate predictions with
and without controlling for factors relevant to
interest rate movements, and our prediction
results average across multiple training-test
splits. Using data from 1999-2016, we achieve
93% and 64% accuracy in predicting Target
and Effective Federal Funds Rate movements
and 38%-40% accuracy in predicting longer
term Treasury Rate movements. We obtain
lower but comparable accuracies after control-
ling for other macroeconomic and market fac-
tors.

1 Introduction

This study uses the verbal content of Federal Open
Market Committee (FOMC) public communications
to predict the directions of interest rate movements
on the days those communications are released. The
FOMC, who determines government policies rel-
evant to interest rates, meets roughly eight times
a year and releases a statement after each meet-
ing. The FOMC is known to be an important
mover of markets, and economic research has found
that equity and interest rate markets tend to move
when FOMC communications are released (Farka
and Fleissig, 2012; Gürkaynak et al., 2005; Mueller,
2015; Rosa, 2011) that the policy actions alone do

not explain these responses (and thus the content
of the text must be responsible) (Gürkaynak et al.,
2005), and that the directions of market movements
coincide with a human-coded measure of the sen-
timent expressed in the texts (Rosa, 2011). Writ-
ers in the finance industry and in the popular press
have also examined word clouds of FOMC min-
utes (Cofnas, 2010; Durden, 2011) and have dis-
cussed the market implications of the total number
of words included in FOMC minutes (Fitz-gerald,
2014; Kennedy, 2014; Wynne, 2013).

A growing body of research applies NLP meth-
ods to understand the market effects from the con-
tents of these texts. Researchers have applied La-
tent Semantic Analysis (LSA) to describe the key
topics covered in FOMC minutes, obtaining insights
into the FOMC’s deliberation process (Hansen et al.,
2015; Fligstein et al., 2014; Schonhardt, 2013). Ad-
ditionally, researchers have used NLP-derived mea-
sures of the content of FOMC minutes to predict
equity and interest rate volatilities; (Boukus and
Rosenberg, 2006) use LSA-defined topics in a re-
gression context, and (Zadeh and Zollman, 2009)
apply a dependency-based measure of text content to
an expert-classified set of financially relevant words
and then use both regression and SVM to predict
volatility. Papers have found temporary effects of
the sentiments from company-specific news articles
and message board postings on stock prices and
volatility, company earnings, and trading volumes,
using dictionary-based sentiment measures (Davis et
al., 2012; Tetlock, 2007; Tetlock et al., 2007; Tet-
lock, 2011) as well as sentiment measures that are
trained on a human-classified subsample (Antweiler

2096



and Frank, 2004, 2006; Das and Chen, 2007).1 Stud-
ies have found temporary effects even when infor-
mation is “stale” (Tetlock, 2011) and also that short-
sales precede negative news (Fox et al., 2009/2010).
Researchers also find that the readability of corpo-
rate filings is positively associated with earnings and
the precision of analysts’ forecasts about the com-
pany (Li, 2008; Lehavy et al., 2011).

The current study builds upon this literature by
examining a somewhat different question than pre-
vious researchers do and by applying a different set
of techniques that are particularly well-suited for
measuring the market effects of texts. Rather than
examine the texts’ effects on volatility, which in-
creases in response to both positive and negative
sentiments, we predict the direction in which interest
rates move, which is the focus of market participants
as well as the FOMC texts themselves.2 The ques-
tion we ask is also somewhat different than that ex-
amined in the literature because we analyze the rel-
atively short FOMC statements that are released im-
mediately following the meetings—and contain the
key market-moving content (Gürkaynak et al., 2005;
Mueller, 2015)—rather than on the lengthier min-
utes that have more text to analyze but are only re-
leased after the key information from the statements
has been available for three weeks.

In addition to making contributions specific to our
application, this study highlights methods that are
particularly useful for measuring the market effects
of text content. FOMC communications are known
to provide distinct information about short- versus
medium- or long-term policies (Gürkaynak et al.,
2005). We consequently use MedLDA (Zhu et al,
2009), a supervised topic model, to learn separately
the sets of words that are most predictive of move-
ments in short- and medium-term interest rates3

Through this supervised topic model, we generate

1While not examining market data, (Chua et al., 2009)
also examines the problem of classifying sentiment in message
board postings.

2A related study has applied LDA to measure the impacts
on returns and volatility of communications from the Bank of
Canada (Hendry and Madeley, 2010).

3Other classification methods that we attempted but found to
be less effective include regression of rate movements on word
count, logit estimation on the frequencies of the most common
words, and k-nearest neighbor estimation using a word2vec
similarity measure (Mikolov, 2013).

topics, based upon context (which words appear to-
gether) as well as co-movement with the outcome
variables being studied. Hence, the varies depending
upon which dependent variable is being considered.
Second, we address possible bias from one impor-
tant set of omitted variables—releases of macroeco-
nomic data, as discussed by (Rosa, 2011)—by esti-
mating specifications in which we control for those
factors separately and predict whether interest rates
moved more or less than would be expected based
upon the latest data on the macroeconomic environ-
ment. By examining an immediate market response
to the publication of text and controlling for poten-
tial confounding factors, this study demonstrates one
way in which NLP approaches, in addition to their
value in classifying text content, can be applied to
estimate statements’ causal effects. We control for
the effects of macroeconomic data and time-specific
factors like day-of-week effects and time trends us-
ing only observations from non-FOMC dates, so that
we do not lose degrees of freedom in our estima-
tion. Third, unlike Boukus and Rosenberg (2006)
and Hendry and Madeley (2010) but similarly to
Zadeh and Zollman (2009), we split the sample into
training and test sets in order to limit overfitting in
our predicted values. Zadeh and Zollman (2009)
use data from 1967-2000 as a training set, and then
they test their model on data from 2001-2008. Given
the importance of context in predicting interest rate
movements, we instead restrict our sample to ob-
servations from meetings from May 1999 to May
20164. Because autocorrelation in our dependent
variables is relatively limited, we treat the observa-
tions as independent and, among observations in our
sample, average our test performance across multi-
ple training-test splits.

2 Market Effects of Text Content

2.1 Overview of Text Content

FOMC statements contain information about many
aspects of the economy, including interest rates, the
money supply, inflation, unemployment, and eco-
nomic growth. These communications are highly
repetitive, often containing nearly identical sen-
tences and sentence structures from previous meet-

4May 1999 was the date of the last major redesign of the
FOMC statements

2097



ings. Slight changes in the wordings are known to
have major effects on markets (Gürkaynak et al.,
2005).
Pre-processing of text: In order to convert the text
into a format that can be easily processed, we per-
form several cleaning operations to the texts. Non-
alphabetic characters are removed, and the texts are
converted to lower case. Each document is separated
into a bag of words, and common words (e.g., mr
and federal) and stop words are deleted using the
stopwords list from nltk.corpus in Python. Words
are stemmed using the Porter stemming algorithm
(stem from stemming.porter2 in Python), and one-
letter words are dropped.

2.2 MedLDA
LDA (Latent Dirichlet Allocation) (Blei et al.,
2003) is an unsupervised model, whereas super-
vised topic model (sLDA) (Blei and McAuliffe,
2007) introduces a response variable to LDA for
each document. Max-Entropy Discrimination LDA
(MedLDA) (Zhu et al, 2009) is max-margin variant
of the supervised topic models. MedLDA can be
built for both regression and classification prediction
tasks. In this study we employed the model built for
classification task. For classification, the response
variables y are discrete having values {1, 0,−1} de-
noting the movements of the interest rates. Hence,
we consider the multi-class classification version of
the MedLDA. It is defined based on a Support Vector
Machine (SVM), which integrates the max-margin
principle with an underlying LDA model for top-
ics. Formally, the probabiltiies associated with max-
entropy discrimination topic models (MedTM) can
be generally defined as:

mindL(q(H)) +KL(q(Γ)||pp(Γ)) + U(ξ) (1)
where H are hidden variables (e.g., (θ, z) in LDA);
are the parameters of the model pertaining to the pre-
diction task (e.g., η in sLDA); Γ are the parameters
of the underlying topic model (e.g., the Dirichlet pa-
rameter α); and L is a variational upper bound of
the negative log likelihood associated with the un-
derlying topic model. U is a convex function over
slack variables. For the general MedTM model, we
can develop a similar variational EM-algorithm as
for the MedLDA.

We apply the MedLDA model on the FOMC
documents and considering the interest rates as the
response variables (y) to compute topics that are
closely related to variations in the interest rates.
Eventually these topics are used to classify changes
in the rates using the max-margin classifier embed-
ded in the MedLDA model.

2.3 Controlling for Macroeconomic
Information

In addition to these text-based data, we supply our
classifier with “control” variables describing the
latest releases of macroeconomic variables. The
macroeconomic data considered in this analysis are
three of the most important measures of US eco-
nomic health: the Consumer Price Index (CPI) used
to measure inflation, Unemployment, and real an-
nualized growth in the US Gross Domestic Product
(GDP). The values for all three of these statistics are
publicly released on a monthly basis. The CPI and
Unemployment numbers are measured on a monthly
basis and are typically not updated from their ini-
tially released values. The CPI data are typically re-
leased between 15 and 20 days after the end of the
month, and the Unemployment data are typically re-
leased 6 to 10 days after the end of the month. GDP
is measured on a quarterly basis, and three estimates
are provided: “advance,” “preliminary” or “second,”
and “final” or “third,” which are released about one,
two, and three months after the end of the quarter, re-
spectively. The final GDP numbers are occasionally
revised in later releases. Our release date data and
some of the macroeconomic statistics were obtained
from direct requests to the U.S. Bureau of Economic
Analysis (B. of Econ. An. (a), 2015; B. of Econ.
An. (b), 2015) and the U.S. Bureau of Labor Stats
(B. of Lab. Stat. (a), 2015; B. of Lab. Stat. (d),
2009). Additional data on the GDP and unemploy-
ment numbers released were obtained from public
sources (Econ. Anal. (c), 1989; Fed. Res. (a), 15).

If macroeconomic information is released on the
same day as an FOMC communication, it is possi-
ble that this release could influence both the content
of the FOMC statement as well as the interest rate
movements that day. To avoid that possibility, we
implement a modified MedLDA approach using a
dependent variable that is “purged” of these poten-
tially confounding influences. In some of our speci-

2098



Table 1: Accuracy of Medlda Classifier after purging out of control for statements between 1999 and May, 2016 [K (topics) = 20]

Outcome variable MedLDA Baseline (Random Chance)5

None Linear Interactions None Linear Interactions
Target Fed Funds Rate 0.9321 0.9160 0.8954 0.6849 0.6849 0.6849
Effective Fed Funds Rate 0.6421 0.4479 0.5112 0.4589 0.4658 0.4658
Median Treasury Rate 0.4209 0.3803 0.4012 0.4589 0.4247 0.4247
Average Treasury Rate 0.3803 0.4611 0.3924 0.4726 0.4041 0.4041

fications, we first regress the interest rate movements
of interest on these macroeconomic indicators. Our
main set of controls includes the latest values for the
most recent two values of the unemployment rate,
GDP growth rate, and CPI inflation rate and their
changes, a daily time trend, and year, month, and
day-of-the-week dummies. Some specifications use
this set, and others add the full set of two-way inter-
actions across these different variables. For both the
main and the interacted set, we regress the change
in the rate of interest on the full set of controls for
the full set of non-FOMC dates from May 1999
through May 2016. Hence, we estimate the rela-
tionship between interest rate movements and the re-
leases of macroeconomic data using dates in which
FOMC statements or minutes were not released. Us-
ing the coefficients from these regressions, we gen-
erate residuals of interest rate movements for the
FOMC dates and then create indicators for whether
the residual was positive or negative for that interest
rate movement on that FOMC date.

3 Empirical Results

We randomly split the data, containing 146 data
points (FOMC statements and corresponding move-
ments in the interest rates from May 1999 through
May 2016) into a a 80-20% train-test set split to
compute the accuracy of the model to predict the
movement. For each experiment, we varied the
number of topics (K) to see which value of K is
giving the best accuracy. In most cases, the best ac-
curacy is given by K = 20. The results presented in
Table 1 shows the average accuracies of predicting
the movements of the interest rates after purging the
outcome variables out of control. The presented ac-
curacies are the results of 20 fold validation. When
no controls are used, our accuracy is 93% and 64%

for the Target and Effective Federal Funds Rates
(both better than random chance) and 42% and 38%
for the Median and Average Treasury Rates6 The
specifications with control variables have similar but
somewhat lower accuracy rates. Hence, our text-
mining approach is comparable in effectiveness at
measuring whether interest rates moved more or less
than expected, after controlling for the economic en-
vironment, than it is at predicting the raw directions
of movement. MedLDA model is compared against
a simple baseline. The baseline is the accuracy, if the
interest rate movements are randomly guessed from
the prior distribution of each of the interest rates un-
der the different controls. For the Target and Ef-
fective rates, the MedLDA model outperforms the
baseline with a great margin and for the Median and
Average rate, the performance is slightly poorer.

The high target rate prediction accuracy suggests
that the MedLDA model can effectively associate
the text contents of the meetings with the move-
ments in the rate, even though the numeric values
are dropped from the text. Similar arguments can be
applied to the effective rate prediction. On the other
hand, treasury rates are not directly connected to the
text of the FOMC statements, so the factors influenc-
ing these rates are not present or mentioned in the
text. Thus, to have a better prediction accuracies for
these variables information from other sources are
necessary which is beyond the scope of this paper.
However, the present FOMC meeting might give an
indication to future FOMC plans and thus, to the

5Our random chance baseline is a classifier that always se-
lects the most likely of the three outcomes (increase, decrease,
or no change) based upon their frequencies in the full dataset.

6Median Treasury Rate is the median of the -1, 0, and 1 clas-
sifications among the movements of the 3m, 1y, 3y, 5y, and 10y
Treasury Rates. Average Treasury Rate is the -1/0/1 classifica-
tion of the average of those rates.

2099



treasury rates. Hence, the prediction accuracies are
not much worse than the baseline.

4 Conclusion

This study measures the effects of text-based infor-
mation released by the FOMC on daily interest rate
movements. We used the medLDA model on a set
of 146 docs and obtain accuracies of 93% and 64%
in predicting the Federal Funds Target Rate and the
Effective Rate.

References

Werner Antweiler and Murray Z. Frank. Is all that talk
just noise? The information content of internet stock
message boards. J Fin 59(3). Jun 2004.

Werner Antweiler and Murray Z. Frank. Do US stock
markets typically overreact to corporate news sto-
ries? Unpublished manuscript. Aug 2006. Available
at SSRN: http://ssrn.com/abstract=878091

David M. Blei and Jon D. McAuliffe. Supervised topic
models. In NIPS, 2007.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan. La-
tent dirichlet allocation. J. Mach. Learn. Res., 3:993–
1022, Mar. 2003.

Bloomberg. Daily historical time-series of Federal Funds
Target Rate and Futures prices for Federal Funds Rate
and US Treasuries. March 25, 2016.

Ellyn Boukus and Joshua V. Rosenberg. The in-
formation content of FOMC minutes. 2006
http://ssrn.com/abstract=922312

Christopher C. Chua, Maria Milosavljevic, and James R.
Curran. A sentiment detection engine for internet stock
message boards. Proceedings of the Australasian Lan-
guage Technology Association Workshop. Dec 2009.

Abe Cofnas. Sentiment indicators: renko, price break,
kagi, point & figure —what they are and how to use
them to trade. Hoboken, NJ: Wiley. 2010.

Deborah J. Danker and Matthew M. Luecke. Background
on FOMC meeting minutes. Federal Reserve Bulletin
91(2). Spr 2005.

Sanjiv R. Das and Mike Y. Chen. Yahoo! for Amazon:
sentiment extraction from small talk on the web. Man-
agement Science 53(9). Sep 2007.

Angela K. Davis, Jeremy M. Piger, and Lisa M. Sedor.
Beyond the numbers: measuring the information con-
tent of earnings press release language. Contemporary
Accounting Research, 29(3). Fall 2012.

Tyler Durden. FOMC minutes word cloud and
key word count. Zero Hedge. Aug 30, 2011.
http://www.zerohedge.com/news/fomc-minutes-
word-cloud-and-key-word
-count

Mira Farka and Adrian R. Fleissig. The effect of FOMC
statements on asset prices. Intl Rev Appl Econ 26(3).
May 2012.

Keith Fitz-gerald. The huge economic indicator every-
one misses. Money Morning. Mar 25, 2014. Avail-
able at: http://moneymorning.com/2014/03/25/huge-
economic-indicator-everyone-misses/

Neil Fligstein, Jonah Stuart Brundage, and Michael
Schultz. “Why the Federal Reserve failed to see the fi-
nancial crisis of 2008: the role of ‘macroeconomics’ as
a sense making and cultural frame.” University of Cal-
ifornia, Berkeley Institute for Research on Labor and
Employment (IRLE) Working Paper 111-14. Septem-
ber 2014.

Merritt B. Fox, Lawrence R. Glosten, and Paul C. Tet-
lock. Short selling and the news: a preliminary report
on an empirical study. NY Law Sch Rev 54. 2009/2010.

Refet S. Gürkaynak, Brian Sack, and Eric T. Swanson.
Do actions speak louder than words? The response of
asset prices to monetary policy actions and statements.
Intl J Central Banking 1(1). May 2005.

Stephen Hansen, Michael McMahon, and Andrea Prat.
Transparency and deliberation within the FOMC:
a computational linguistics approach. Unpublished
manuscript. Feb 2015.

Scott Hendry and Alison Madeley. Text mining and the
information content of Bank of Canada communica-
tions. Bank of Canada Working Paper 2010-31. Nov
2010.

Simon Kennedy. Word inflation accelerating at Fed justi-
fies investor confusion. Bloomberg. Sep 18, 2014.

Reuven Lehavy, Feng Li, and Kenneth Merkley. The ef-
fect of annual report readability on analyst following
and the properties of their earnings forecasts. Account-
ing Rev 86(3). May 2011.

Feng Li. Annual report readability, current earnings, and
earnings persistence. J Accounting and Econ 45(2-3).
Aug 2008.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. “Distributed representations of words and
phrases and their compositionality.” Advances in Neu-
ral Information Processing Systems, 2013, pp. 3111-9.

Philippe Mueller, Alireza Tahbaz-Salehi, and Andrea
Vedolin. “Exchange rates and monetary policy uncer-
tainty.” Unpublished manuscript, December 2015.

2100



Akin Oyedele. This is how often the Fed talks about
employment and inflation. Business Insider. Feb 18,
2015. http://www.businessinsider.com/fomc-minutes-
on-unemployment-and-
inflation-2015-2

Prattle Analytics. prattle-analytics.com. 2014.

Carlo Rosa. Words that shake traders: the stock markets
reaction to central bank communication in real time. J
Empirical Finance 18(5). Dec 2011.

Cheryl Schonhardt-Bailey. Deliberating American mone-
tary policy: a textual analysis. Cambridge, MA: MIT
Press. Nov 2013.

Paul C. Tetlock. Giving content to investor sentiment: the
role of media in the stock market. J Fin 62(3):1139-68.
Jun 2007.

Paul C. Tetlock. All the news that’s fit to reprint: do in-
vestors react to stale information? Rev Fin Stud 24(5).
May 2011.

Paul C. Tetlock, Maytal Saar-Tsechansky, and Sofus
Macskassy. More than words: quantifying language to
measure firms’ fundamentals. J Fin 63(3) Jun 2008.

United States. Bureau of Economic Analysis, 2015.
“GDP releases 1968 forward.”

United States. Bureau of Economic Analysis, 2015.
“GDP-GDI vintage history.”

United States. Bureau of Economic Analysis, 1989-2015.
Survey of Current Business (all months).

United States. Bureau of Labor Statistics, 2015. “CPI re-
lease dates 2009-2014.”

United States. Bureau of Labor Statistics, 2015. “Release
day and time for the Employment Situation news re-
lease 1966-present.”

United States. Bureau of Labor Statistics, 2015. “Season-
ally adjusted unemployment rate as published, 1957-
present.”

United States. Bureau of Labor Statistics, 2009. “CPI re-
lease dates 1953-2008.”

.S. Department of the Treasury. Daily Treasury yield
curve rates, 1990-2015. Accessed on 3 Apr 2015.
Available at: http://www.treasury.gov/resource-
center/data-chart-center/interest-rates/

United States. Federal Reserve Bank of St. Louis, 2015.
“Consumer Price Index for all urban consumers: all
items, index 1982-1984=100, monthly, seasonally ad-
justed.”

U.S. Federal Reserve Bank. About the FOMC.
http://www.federalreserve.gov/monetarypolicy.fomc.htm.
2015.

U.S. Federal Reserve Bank of St. Louis. Federal Reserve
Economic Data. Accessed on 3 Apr 2015. Available
at: http://research.stlouisfed.org/fred2/

U.S. Federal Reserve System Board of Gov-
ernors. Federal Open Market Commit-
tee. Accessed Apr 2015. Available at:
http://www.federalreserve.gov/monetarypolicy/fomc.htm

U.S. Federal Reserve System Board of Governors.
The Federal Reserve System purposes and functions.
Washington, DC: Board of Governors of the Federal
Reserve System. Jun 2005.

Mark A. Wynne. A short history of FOMC communica-
tion. Economic Letter 8(8), Federal Reserve Bank of
Dallas. Sep 2013.

Reza Bosagh Zadeh and Andreas Zollman. Predicting
market volatility from Federal Reserve Board meeting
minutes. Unpublished manuscript. 2009.

Jun Zhu, Amr Ahmed, and Eric P. Xing. Medlda: Max-
imum margin supervised topic models for regression
and classification. ICML ’09:1257-64, 2009.

United States. Bureau of Economic Analysis, 2015.
“GDP releases 1968 forward.”

United States. Bureau of Economic Analysis, 2015.
“GDP-GDI vintage history.”

United States. Bureau of Economic Analysis, 1989-2015.
Survey of Current Business (all months).

United States. Bureau of Labor Statistics, 2015. “CPI re-
lease dates 2009-2014.”

United States. Bureau of Labor Statistics, 2015. “Release
day and time for the Employment Situation news re-
lease 1966-present.”

United States. Bureau of Labor Statistics, 2015. “Season-
ally adjusted unemployment rate as published, 1957-
present.”

United States. Bureau of Labor Statistics, 2009. “CPI re-
lease dates 1953-2008.”

United States. Federal Reserve Bank of St. Louis, 2015.
“Consumer Price Index for all urban consumers: all
items, index 1982-1984=100, monthly, seasonally ad-
justed.”

U.S. Department of the Treasury. Daily Treasury
yield curve rates, 1990-2015. Accessed on 3 Apr
2015. Available at: http://www.treasury.gov/resource-
center/data-chart-center/interest-rates/

U.S. Federal Reserve Bank. About the FOMC.
http://www.federalreserve.gov/monetarypolicy.fomc.htm.
2015.

U.S. Federal Reserve Bank of St. Louis. Federal Reserve
Economic Data. Accessed on 3 Apr 2015. Available
at: http://research.stlouisfed.org/fred2/

2101



U.S. Federal Reserve System Board of Gov-
ernors. Federal Open Market Commit-
tee. Accessed Apr 2015. Available at:
http://www.federalreserve.gov/monetarypolicy/fomc.htm

2102


