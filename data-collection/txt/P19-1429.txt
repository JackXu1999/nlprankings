



















































Distilling Discrimination and Generalization Knowledge for Event Detection via Delta-Representation Learning


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4366–4376
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

4366

Distilling Discrimination and Generalization Knowledge for Event
Detection via ∆-Representation Learning

Yaojie Lu1,3, Hongyu Lin1,3, Xianpei Han1,2∗, Le Sun1,2
1Chinese Information Processing Laboratory 2State Key Laboratory of Computer Science

Institute of Software, Chinese Academy of Sciences, Beijing, China
3University of Chinese Academy of Sciences, Beijing, China

{yaojie2017,hongyu2016,xianpei,sunle}@iscas.ac.cn

Abstract

Event detection systems rely on discrimina-
tion knowledge to distinguish ambiguous trig-
ger words and generalization knowledge to
detect unseen/sparse trigger words. Cur-
rent neural event detection approaches fo-
cus on trigger-centric representations, which
work well on distilling discrimination knowl-
edge, but poorly on learning generalization
knowledge. To address this problem, this pa-
per proposes a ∆-learning approach to dis-
till discrimination and generalization knowl-
edge by effectively decoupling, incrementally
learning and adaptively fusing event represen-
tation. Experiments show that our method
significantly outperforms previous approaches
on unseen/sparse trigger words, and achieves
state-of-the-art performance on both ACE2005
and KBP2017 datasets.

1 Introduction

Event detection (ED) aims to identify triggers of
specific event types. For instance, an ED system
will identify fired as an Attack event trigger in the
sentence “An American tank fired on the Palestine
Hotel.” Event detection plays an important role in
Automatic Content Extraction (Ahn, 2006), Infor-
mation Retrieval (Allan, 2012), and Text Under-
standing (Chambers and Jurafsky, 2008).

Due to the ambiguity and the diversity of natural
language expressions (Li et al., 2013; Nguyen and
Grishman, 2015), an effective approach should
be able to distill both discrimination and general-
ization knowledge for event detection. Discrimi-
nation knowledge aims to distinguish ambiguous
triggers in different contexts. As shown in Figure
1, to identify fired in S4 as an EndPosition trig-
ger rather than an Attack trigger, an ED system
needs to distill the discrimination knowledge from
S1 and S2 that (fired, Attack) usually co-occurs

∗Corresponding Author

The airline firedEndPosition that pilot for fault in work.S1:

An American tank firedAttack on the Palestine Hotel.S2:

A man was hacked to death by the criminal.    AttackS5:

Discrimination Generalization

S3:A heavily armed soldier shotAttack the enemy to death.

Training

Evaluation

S4:That officer was fired from his job. EndPosition

Figure 1: Examples of event instances. Identifing am-
biguous word fired requires discrimination knowledge
and identifing unseen word hacked requires generaliza-
tion knowledge.

with {tank, death, enemy, ...} and (fired, EndPo-
sition) usually co-occurs with {work, fault, job,
...}. Unlike discrimination knowledge, generaliza-
tion knowledge aims to detect unseen or sparsely
labeled triggers, thus needs to be transferred be-
tween different trigger words. For example, to
identify the unseen word hacked in S5 as an At-
tack trigger, an ED system needs to distill the gen-
eralized Attack pattern “[Trigger] to death” from
S3.

Currently, most neural network ED methods
(Chen et al., 2015; Nguyen and Grishman, 2015,
2016; Duan et al., 2017; Yang and Mitchell, 2017)
work well on distilling discrimination knowledge,
but poorly on distilling generalization knowledge.
Table 1 shows the performances of several mod-
els on both sparsely (OOV/OOL) and densely
(Other) labeled trigger words. These models work
well on densely labeled trigger words, i.e., they
have a good discrimination ability. But they per-
form poorly on unseen/sparsely labeled trigger
words, i.e., they have a poor generalization abil-
ity. This is because these approaches are mostly
trigger-centric, thus hard to be generalized well
to sparse/unseen words. Furthermore, the lack of



4367

Models OOV OOL Other
DMCNN 34.3 8.8 76.1
Bi-LSTM 35.3 9.3 75.5

ELMo 31.3 9.0 75.7

Table 1: F1 Scores of previous approaches on differ-
ent types of triggers (ACE2005), where OOV words
are the out-of-vocabulary words in the training corpus,
OOL words are the out-of-label words, i.e., an instance
whose (word, event type) never occurs in the training
corpus but the word is not OOV. DMCNN (Chen et al.,
2015) refers to dynamic multi-pooling based CNN; Bi-
LSTM (Duan et al., 2017) refers to bidirectional LSTM
based RNN. ELMo refers to the fixed task-independent
word representations proposed by Peters et al. (2018).

large-scale training data also limits the generaliza-
tion ability of learned models. Table 1 also shows
the performance of using general pre-trained word
representation – ELMo (Peters et al., 2018). We
can see that, this task-independent lexical-centric
representation achieves nearly the same perfor-
mance to task-specific representations.

In this paper, we propose a ∆-representation
learning approach, which can incrementally dis-
till both discrimination and generalization knowl-
edge for event detection. ∆-representation learn-
ing aims to decouple, learn, and fuse alterable ∆-
parts for event representation, instead of learning
a single comprehensive representation. Specif-
ically, we decouple an event representation red
into three parts red = rw

⊕
rd

⊕
rg (Section 2),

where rw is the pre-trained word representation of
trigger words, rd is the lexical-specific event rep-
resentation which captures discrimination knowl-
edge for distinguishing ambiguous triggers, rg is
the lexical-free event representation which cap-
tures generalization knowledge for detecting un-
seen/sparse triggers, and

⊕
is the fusion function

to fuse different parts. Here rd and rg are the ∆-
parts of our representation, i.e., they are indepen-
dently learned starting from rw and are intended
for capturing incremental knowledge for event de-
tection. To incrementally learn the ∆-parts rd and
rg, we propose a ∆-learning framework (Section
3), i.e., a lexical enhanced ∆-learning algorithm
is designed to learn the discrimination knowledge
rd which is both event-related and lexical-relevant
part, and a lexical adversarial ∆-learning is de-
signed to learn the generalization knowledge rg
which is event-related but lexical-irrelevant part.
Finally, a lexical gate fusion mechanism

⊕
(Sec-

Decoupled
Representations

That officer was fired from his job.

Lexical
Gate Fusion

Lexical-Free
Representation!w

Trigger
Candidate

EndPosition

Enhanced
Δ-Learning

Adversarial
Δ-Learning

Δ Δ

Lexical-Specific
Representation

!d !g
Lexi

Δ-Learning

Figure 2: The framework of our ∆-learning approach.
Dashed lines indicate the learning process; solid lines
indicate the event detection process.

tion 2.3) is proposed to adaptively fuse these
learned representations. Figure 2 shows the archi-
tecture of our method.

We conduct experiments1 on two standard
event detection datasets: ACE20052 and TAC
KBP 2017 Event Nugget Detection Evaluation3

(KBP2017). Experimental results show that the
proposed method significantly improves the per-
formance on sparsely labeled triggers, and retains
a high performance on densely labeled triggers.

The main contributions of this paper are:
1. We propose a new representation learning

framework - ∆-learning, which can incremen-
tally distill both discrimination and generalization
knowledge during representation learning. Since
the ambiguity and the diversity problem of nat-
ural language expressions are common in NLP,
our framework can potentially benefit many other
NLP tasks.

2. We design a new event detection approach.
By effectively decoupling, independently learn-
ing, and adaptively fusing event representation,
our approach works well on both sparsely and
densely labeled triggers and achieves the state-
of-the-art performance on both ACE2005 and
KBP2017 datasets.

2 Decoupling Lexical-Specific and
Lexical-Free Representations for Event
Detection

To distill both discrimination and generalization
knowledge, this section decouples event represen-

1Our source code is openly available at
https://www.github.com/luyaojie/delta-learning-for-ed.

2https://catalog.ldc.upenn.edu/LDC2006T06
3https://tac.nist.gov/2017/KBP/data.html



4368

tation into three parts: red = rw
⊕

rd
⊕

rg,
where rw is the word representation of trigger
words, such as word embeddings/ELMo (noted
that rw is fixed during all our training process);
rd is a lexical-specific event representation which
captures discrimination knowledge; rg is a lexical-
free representation which captures generalization
knowledge. By decoupling event representations,
rd and rg will be independently learned using our
∆-learning algorithm in Section 3. Finally, a
gate mechanism is proposed to adaptively fuse the
above representations for event detection.

Formally, an event detection instance is a pair
of trigger candidate and its context, i.e., x =
(t, c), where t is a trigger candidate, and c =
{c−m, ..., c−1, c1, ..., cm} is its context. For exam-
ple, (fired, “That officer was from his job.”) is an
instance for candidate fired.

Following previous work (Nguyen and Grish-
man, 2015; Liu et al., 2018a), given an instance
x, we embed each token ti as ti = [pw;pp;pe],
where pw is its word embedding, pp is its posi-
tion embedding, and pe is its entity tag embed-
ding. Therefore t0 is the representation of trigger
candidate. In this paper, lexical-specific model Θd
and lexical-free model Θg use independent em-
beddings.

2.1 Lexical-Specific Representation

Lexical-specific representation aims to capture
discriminative information for distinguishing am-
biguous trigger words. For example, we want our
representation to capture {officer, job, ...} clues
for distinguishing (fired, EndPosition) from (fired,
Attack), and {tank, soldiers, ...} for distinguishing
(fired, Attack) from (fired, EndPosition).

To capture discriminative clues for trigger can-
didates, we design a lexical-centered context se-
lection attention. And we refer it as ATT-RNN and
describe it as follows.
Lexical-Centered Context Selection. To select
discriminative context words, the attentive context
selection mechanism models the association be-
tween the trigger candidate and its context words.
For instance, we want our attention mechanism to
capture the association between “work” and fired
in S1, and between “tank” and fired in S2.

Concretely, we first feed [t−m, ..., t0, ..., tm]
into a bidirectional GRU to get all tokens’ context-
aware token encoding [h−m, ...,h0, ...,hm]. Then
our attention mechanism models (trigger, context

word) pair’s relevance with a Multi-Layer Percep-
tron (MLP), and uses a softmax function normal-
izing relevance scores to attention weights:

αi =
exp(MLP([h0;hi]))∑
j∈c exp(MLP([h0;hj ]))

(1)

Given the attention weights, the lexical-specific
context representation is summarized as c0 =∑

i∈C αi · hi. And the final lexical-specific rep-
resentation of instance x is the concatenation of
its token representation h0 and the lexical-specific
context representation c0, i.e., rd = [h0; c0].

The lexical-specific representation can effec-
tively disambiguate trigger words by capturing
(trigger, context word) associations. However, this
representation is lexical-specific, thus hard to gen-
eralize well to sparse/unseen words.

2.2 Lexical-Free Representation

In contrast to lexical-specific representation,
lexical-free event representation rg aims to cap-
ture generalization knowledge for ED, which can
be transferred between different trigger words. For
example, we want to capture the trigger word-
irrelevant knowledge such as “[Trigger] to death”
being a strong trigger pattern for Attack event,
which can be used to detect many different trig-
ger words, such as fired, hacked, beat. In this way,
even an unseen trigger candidate t can be easily
identified by leveraging such knowledge.

Obviously, the lexical-free event representation
rg should be lexical-irrelevant, but event-specific.
To this end, we represent all tokens in x as ti,
then employ a lexical-independent context selec-
tion module for rg. We simply use DMCNN
(Chen et al., 2015) as our lexical-independent con-
text selection module, but design a new adversar-
ial ∆-learning algorithm in Section 3.2 which can
eliminate lexical-relevant information from rg.
Lexical-Independent Context Selection. To se-
lect lexical-independent but event-relevant context
words, we employ the same CNN architecture as
Chen et al. (2015). For instance, we want to cap-
ture “to death” and “criminal” being relevant for
Attack event in S5.

Given token sequence [t−m, ..., t0, ..., tm], a h-
width convolutional layer captures local context
feature li from ti:i+h−1: li = tanh(w · ti:i+h−1+
b), where w is the convolutional filter, and b is the
bias term. To summarize important signals from
different pieces of a sentence, a dynamic pooling
layer (Chen et al., 2015) is used to produce the left



4369

and right context features lleft, lright:

lleft = max
j<0

lj , l
right = max

j≥0
lj (2)

Finally, we concatenate the left context feature
lleft and the right context feature lright as our
lexical-free representation rg = [lleft; lright].

2.3 Lexical Gate Mechanism for
Representation Fusion

The above two representations are complementary
to each other: rd captures discrimination knowl-
edge, and rg captures generalization knowledge.
However, simple concatenation is not effective
for event detection: for frequently labeled trigger
words in training data, lexical-specific representa-
tion is more useful; and for sparsely labeled or un-
seen trigger words, lexical-free representation is
more helpful. Based on this observation, our sys-
tem needs to rely more on rd to detect frequent
candidate fired, but more on rg to detect the OOV
candidate hacked. That is, we need to adaptively
fuse different representations for different words,
rather than simply concatenate them.

To adaptively fuse lexical-specific representa-
tion rd, lexical-free representation rg and word
representation rw, we design a lexical gate mech-
anism to fuse different representations: red =
rw

⊕
rd

⊕
rg, where

⊕
is the fusion gate, and

red is the final event representation. Concretely,
we first map these representations to a universal
space:

r′d = fSpec→U (rd)
r′g = fFree→U (rg)
r′w = fLexi→U (rw)

(3)

where fSpec→U (·), fFree→U (·) and fLexi→U (·)
are linear layers with a nonlinear function; then
we fuse them via the gated mechanism:

g̃i = fU→G(r
′
i), i ∈ {d, g, w}

gi =
exp(g̃i)∑

j∈{d,g,w} exp(g̃j)

(4)

gi (i ∈ {d, g, w}) correspondingly indicates the
confidence of the evidences provided by r′s, r′f
and r′l; gi and g̃i have the same dimensions as r′i;
fU→G(·) is a linear layer with a nonlinear func-
tion. Finally, we combine all representations:

red = gd � r′d + gg � r′g + gw � r′w (5)
where � is element-wise multiplication.

After fusion, red will be fed to the event de-
tection classifier, which computes a classification

(a) Lexical-Enhanced 

Event
Detection
Classifier

Binary 
Lexical 

Classifier

Lexical-specific
Representation

Learning

Event
Detection
Classifier

Lexical-free
Representation

LearningLexi

Binary 
Lexical 

Classifier

(b) Lexical-Adversarial

EventType EventType 1/01/0

Lexi

(t, c) t / w (t, c)t / w

+ Lexi − Lexi

Figure 3: The framework of our ∆-learning algo-
rithms.

probability for each event type yt (including NIL
for not a trigger):

P (yt|x) =
exp(wt · red + bt)∑T
t=1 exp(wt · red + bt)

(6)

where wt is the weight vector, and bt is the bias
term. In this way, we identify trigger words of all
pre-defined event types.

3 Distilling Discrimination and
Generalization knowledge via
∆-Learning

This section describes our ∆-learning framework,
which can learn lexical-specific representation rd
and lexical-free representation rg independently.
To distill discrimination knowledge to rd, we de-
sign a lexical-enhanced ∆-learning algorithm. To
distill generalization knowledge to rg, we design a
lexical adversarial ∆-learning algorithm. Finally,
we fine-tune the full event detection model in Fig-
ure 2.

3.1 Distilling Discrimination Knowledge via
Lexical-Enhanced ∆-Learning

This section describes our lexical-enhanced ∆-
learning algorithm for lexical-specific represen-
tation rd. To ensure rd be both event-relevant
and lexical-specific, we use two types of supervi-
sion signals: first, we want the learned represen-
tation rd can predict its event type y with the help
of word representation rw; second, we want the
learned rd can also predict its trigger word t. For
example, we want the learned rd of the instance
(fired, An solider to death) can predict both its
event type Attack and its trigger word fired.



4370

To achieve the above goal, we remove the
lexical-free part in Figure 2 and show the lexical-
enhanced ∆-learning framework in Figure 3 (a).
The input of our lexical-enhanced learning frame-
work is a triple (t, c, w), where t is the trigger, c
is its context, and w is a sampled word. The out-
put is two-fold: the event classifier will output the
event type of (t, c), and the auxiliary lexical classi-
fier will output 1 if t = w and 0 otherwise. In this
way, the event classifier can propagate the event
type supervision signal to our lexical-specific rep-
resentation learning component, and the auxiliary
lexical binary classifier ensures that the learned
representation rd is lexical-specific.

Specifically, for each ED instance x = (t, c),
we generate a positive lexical-enhanced training
instance (t, c, t) with label (y, 1), and n negative
instances4 (t, c, w) with label (y, 0), where w is a
word randomly sampled from context c.

For each ED instance x = (t, c) in the train
dataset D, the event classifier loss is:

Levent = −
∑

(xk,yk)∈D

logP (yk|xk) (7)

and the lexical binary classifier loss is:

Llexical =
∑
xk∈D

− logP (1|xk, t)

−
n∑

j=1

logP (0|xk, wkj)
(8)

Therefore, the loss function of lexical-enhanced
∆-learning is:

Lenhance = Levent + Llexical (9)

By adding the auxiliary lexical classification task,
this learning algorithm will ensure the learned
representation be both event-related and lexical-
relevant.

3.2 Distilling Generalization Knowledge via
Lexical-Adversarial ∆-Learning

In contrast to lexical-specific representation rd,
the lexical-free representation rg needs to elimi-
nate lexical-specific information, so that it can be
transferred between different words. To achieve
this goal, we adopt adversarial techniques and de-
sign a lexical-adversarial ∆-learning algorithm.

Specifically, we remove the lexical-specific part
in Figure 2 and show the lexical-adversarial ∆-
learning framework in Figure 3 (b). We can see

4In this paper, we set n = 1.

that, the input and the output of our adversarial ∆-
learning framework are still (t, c, w) and (y, 1/0).
The event classifier is used to propagate the event
type supervision signal to our lexical-free repre-
sentation learning component, so that rg will cap-
ture event related information. The difference be-
tween Figure 3 (a) and 3 (b) is that they use dif-
ferent auxiliary tasks: Figure 3 (a) uses a lexical-
enhanced auxiliary task, and Figure 3 (b) uses a
lexical-adversarial auxiliary task.

To eliminate lexical-specific information, we
design a two-player min-max game (Goodfellow
et al., 2014) for the lexical-adversarial auxiliary
task. Given (t, c, w), our binary lexical classifier
ΘDeLexi attempts to predict whether rg is specific
to w, but the lexical-free model Θg tries to pro-
duce rg to confuse ΘDeLexi. The min-max objec-
tive function for lexical-adversarial ∆-learning is:

Lminmax =
∑
xk∈D

− logP (1|xk, t)

−
n∑

j=1

logP (0|xk, wkj)

θ̂ = min
ΘDeLexi

max
Θg
Lminmax

(10)

In this way, we can remove the lexical-specific in-
formation from rg.

The above adversarial loss leads two different
optimized directions for Θg and ΘDeLexi, which
can be implemented by a gradient reversal layer
(Ganin et al., 2016) during backpropagation. That
is, Lminmax is jointly optimized with the main ED
task objective Levent, while gradients from adver-
sarial loss are reversed with the factor λadv when
they reach rg. By this means, we can unify the
optimized directions of these components. There-
fore, the loss function of our lexical-adversarial
∆-learning is:

Ladversary = Levent + Lminmax (11)

Following Liu et al. (2019), we divide the
lexical-adversarial ∆-learning into two stages:

1. In the pretraining stage, we first update Θg
using the main ED task objective, then freeze Θg
and update ΘDeLexi using the Equation 10.

2. In the adversarial learning stage, we update
parameters using Equation 11.

In practice, we find that the factor λadv is sen-
sitive to the even of min-max game. A large λadv
is easy to make the binary lexical classifier to be
weak (the binary classfication accuracy tends to



4371

50%). In this paper, λadv is set as 1−3, and the
accuracy of our binary lexical classifier ΘDeLexi
always keep over 75% in the adversarial learning
stage.

By adding the auxiliary lexical-adversarial task,
this learning algorithm will ensure the learned rep-
resentation be event-related but lexical-irrelevant.

3.3 Full Model Fine-Tuning

Given the pre-trained lexical-specific representa-
tion model Θd and the pre-trained lexical-free rep-
resentation model Θg, we finally fine-tune the full
model Θ in Figure 2 by optimizing the event clas-
sification loss function:

L(Θ) = Levent + λreg · ‖Θ‖2 (12)

where λreg is the weight coefficient of regulariza-
tion item and Θ indicates all parameters. L(Θ)
can be optimized using mini-batch based stochas-
tic gradient descent algorithms, such as Adadelta
(Zeiler, 2012).

4 Experiments

4.1 Experimental Settings

Dataset. We conduct experiments on two stan-
dard English event detection datasets: ACE2005
and KBP2017.

ACE2005 (LDC2006T06) contains 599 docu-
ments annotated with 33 event types. Following
previous studies (Liao and Grishman, 2010; Li
et al., 2013; Chen et al., 2015; Liu et al., 2017,
2018a), we use the same 529/30/40 train/dev/test
document splits in our experiments. We use
ACE2005 as the primary dataset, as the same as
previous studies (Nguyen and Grishman, 2018).

KBP2017 (LDC2017E55) contains 500 docu-
ments with RichERE annotations for TAC KBP
2017 evaluation. For model training, we use pre-
viously annotated RichERE datasets, including
LDC2015E29, LDC2015E68, LDC2016E31 and
TAC KBP 2015-2016 Evaluation datasets. Fol-
lowing previous work (Lin et al., 2018a), we ran-
domly sample 20 documents from the 2016 evalu-
ation dataset as the development set.

We evaluate different event detection sys-
tems using precision, recall, and F1-score. For
ACE2005, we compute these criteria as the same
as previous work (Li et al., 2013; Chen et al.,
2015). For KBP2017, because TAC KBP2017 al-
lows each team to submit 3 different runs, to make
our results comparable with the evaluation results,

we select 3 best runs of each system on the de-
velopment set and report the best test performance
among them using the official evaluation toolkit5,
which is referred as Best3 in previous work (Lin
et al., 2018a).

Baselines. We compare our approach with three
types of baselines:

Feature based Approaches rely on rich hand-
designed features, including: MaxEnt (Li et al.,
2013) which employs hand-designed features and
uses Max-Entropy Classifier; Combined PSL (Liu
et al., 2016b) – the best reported feature-based sys-
tem which combines global and latent features us-
ing Probabilistic Soft Logic framework.

Representation Learning based Approaches
employ neural networks to automatically extract
features for event detection, including: DMCNN
(Chen et al., 2015) which uses CNN as sentence
feature extractor and concatenates sentence fea-
ture and lexical feature for event detection clas-
sifier; NC-CNN (Nguyen and Grishman, 2016)
which extends traditional CNN by modeling skip-
grams for exploiting non-consecutive k-grams; Bi-
RNN (Nguyen et al., 2016) which embeds each to-
ken using additional dependency features for bi-
directional RNN feature extractor, and jointly ex-
tracts triggers with its arguments.

External Resource based Approaches aim to
enhance event detection with external resources,
including: SA-ANN-Arg (Liu et al., 2017) which
injects event arguments information via super-
vised attention mechanism; GCN-ED (Nguyen
and Grishman, 2018) which exploits syntactic in-
formation to capture more accurate context using
Graph Convolutional Networks (GCN); GMLATT
(Liu et al., 2018a) which exploits the multi-lingual
information for more accurate context modeling;
HBTNGMA (Chen et al., 2018) which fuses both
sentence-level and document-level information,
and collectively detects different events in a sen-
tence.

For our approach and all baselines, we adopt
the pre-trained word embedding using Skip-gram
6 and the open released ELMo models7. We also
report the performance of ELMo as a baseline for
demonstrating the performance of universal pre-
trained representations. All hyper-parameters are
tuned on development set.

5https://github.com/hunterhector/EvmEval
6https://code.google.com/archive/p/word2vec
7https://allennlp.org/elmo



4372

P R F1
Feature based Approaches
MaxEnt 74.5 59.1 65.9
Combined-PSL 75.3 64.4 69.4
Representation Learning based Approaches
DMCNN 75.6 63.6 69.1
Bi-RNN 66.0 73.0 69.3
NC-CNN - - 71.3
External Resource based Approaches
SA-ANN-Arg (+Arguments) 78.0 66.3 71.7
GMLATT (+Multi-Lingual) 78.9 66.9 72.4
GCN-ED (+Syntactic) 77.9 68.8 73.1
HBTNGMA (+Document) 77.9 69.1 73.3
Our Approach
ELMo 75.6 62.3 68.3
∆concatw2v 71.8 70.8 71.3
∆concatELMo 73.7 71.9 72.8
∆w2v 74.0 70.5 72.2
∆ELMo 76.3 71.9 74.0

Table 2: Experiment results on ACE 2005. For a fair
comparison, the results of baselines are adapted from
their original papers.

4.2 Overall Performance

Table 2 shows the overall ACE2005 results of all
baselines and our approach. For our approach, we
show the results of four settings: our approach
using word embedding as its word representa-
tion rw – ∆w2v; our approach using ELMo as
rw - ∆ELMo; our approach simply concatenating
[rd, rg, rw] as instance representation - ∆concat∗ .
From Table 2, we can see that:

1. By distilling both discrimination and
generalization knowledge, our method achieves
state-of-the-art performance. Compared with
the best feature system, ∆w2v and ∆ELMo gain
2.8 and 4.6 F1-score improvements. Compared to
the representation learning based baselines, both
∆w2v and ∆ELMo outperform all of them. No-
tably, ∆ELMo outperforms all the baselines using
external resources.

2. By incrementally distilling generalization
knowledge, our method can achieve both high
recall and high precision. Our method obtains a
high recall – 71.9, which outperforms most meth-
ods by a large margin, and retains a high precision
– 76.3. We believe this is because the generaliza-
tion knowledge is incrementally distilled using ∆-
learning, so there is no need to make the precision-
recall tradeoff during training.

3. The lexical gate provides an effective
mechanism for adaptively fusing discrimina-

P R F1
Top 3 in TAC 2017 ED Track
3rd in TAC 2017 54.27 46.59 50.14
2nd in TAC 2017 52.16 48.71 50.37
1st in TAC 2017 56.83 55.57 56.19
Our Approach
∆w2v 62.84 50.36 55.91
∆ELMo 62.30 53.77 57.72

Table 3: Experiment results on TAC KBP 2017 evalua-
tion datasets.

tion and generalization knowledge. Compared
with the naive fusion baselines - ∆concat∗ , ∆w2v
and ∆ELMo correspondingly gain 0.9 and 1.2 F1
improvements. This means that an adapative fu-
sion mechanism can get benefits from both dis-
crimination and generalization knowledge, rather
than make tradeoff between them.

4. Although universal pre-trained repre-
sentations can achieve a good performance,
task-specific representations are still crucial.
Compared with the strong universal representa-
tion baseline ELMo, our task-specific event detec-
tion representations all achieve a significant per-
formance improvements. This also verifies that
∆-learning is an effective way for incrementally
learning task-specific representation.

Table 3 further compares our method with the
Top 3 systems in TAC 2017 Event Detection Track
(Mitamura et al., 2017). Because these teams
had no access to gold entity information during
evaluation, we exclude entity embedding in our
KBP2017 experiments for a fair comparison. We
can see that, the proposed method can significantly
outperform the best ED systems in TAC 2017, de-
spite these systems are ensemble models which
have leveraged various external resources.

4.3 Detailed Analysis

To analyze the effect of our method in detail, Table
4 shows the performance of our method on differ-
ent types of trigger words, including:

OOV (out-of-vocabulary) and OOL (out-of-
label) are of the same as in Table 1.

Sparse instance means the event trigger rate of
the given word P (e|w) = #(e,w)#(w) is less than 10%
in training corpus, i.e,< 10% occurrences of word
w are labeled with the event type e (NIL includ-
ing).

Dense means all other instances except OOV,



4373

OOL and Sparse.
Let

⊕
be our lexical gate, Table 4 shows the re-

sults of following settings: rd
⊕

rw, rg
⊕

rw and
rd

⊕
rg

⊕
rw (i.e., our full model). To demon-

strate the effects of ∆-learning, Table 4 also
shows the results of the non-∆-learning version of
rd

⊕
rw, rg

⊕
rw and rd

⊕
rg

⊕
rw. In this set-

ting, rd and rg are trained without using auxiliary
tasks. From Table 4, we can see that:

1. Previous approaches work well on dis-
tilling discrimination knowledge, but poorly on
distilling generalization knowledge. Previous
approaches achieve high F1-scores on Dense in-
stances, but their performance on sparsely labeled
instances is poor. The task specific representation
(ATT-RNN and DMCNN) merely achieves a sim-
ilar performance with the general word represen-
tation rw (ELMo).

2. ∆-learning is effective for incrementally
distilling knowledge. Compared with its non-
∆-learning version, rg

⊕
rw can distill general-

ization knowledge, i.e., gains 8.5, 12.3 and 9.8
F1 improvements on OOV, OOL and Sparse in-
stances. And rd

⊕
rw can distill more discrimina-

tion knowledge than its non-∆-learning version.
3. The decomposition strategy, i.e, learn-

ing and fusing independent knowledge is ef-
fective for representation learning. Through
decomposition, rg

⊕
rw can capture generaliza-

tion knowledge, rd
⊕

rw can capture discrimina-
tion knowledge, which are complementary to each
other. Starting from rw, our method can incre-
mentally distill knowledge in both rd and rg via
∆-learning. By fusing the independent knowl-
edge in rd and rg via an effective lexical gate,
rd

⊕
rg

⊕
rw achieves the best performance on

OOV, OOL and Dense instances.

5 Related Work

Event Detection. In recent years, neural ap-
proaches have achieved significant progress in
event detection. Most neural approaches focus on
learning effective instance representations (Chen
et al., 2015; Nguyen and Grishman, 2015, 2016;
Nguyen et al., 2016; Feng et al., 2016; Ghaeini
et al., 2016; Lin et al., 2018b). The main drawback
of these methods is that they mostly only learn
a single and lexical-specific representation, which
works well on distilling discrimination knowledge
but poorly on generalization knowledge.

Some approaches enhance representation learn-

Representations OOV OOL Sparse Dense
ATT-RNN 38.7 6.2 36.7 77.7
DMCNN∗ 32.4 9.0 43.1 77.6

ELMo 31.3 9.0 47.1 78.0
rd

⊕
rw (w/o ∆) 40.0 8.8 50.0 78.7

rg
⊕

rw (w/o ∆) 47.1 11.1 54.6 78.8
rd

⊕
rg

⊕
rw (w/o ∆) 40.0 11.4 52.8 78.8

rd
⊕

rw 32.3 12.3 43.1 79.1
rg

⊕
rw 55.6 23.4 64.4 78.2

rd
⊕

rg
⊕

rw 57.4 26.7 55.6 80.0

Table 4: The results (F1-scores) of different represen-
tations (ELMo as word representation rw) on different
types of trigger words. For a fair comparison, different
from standard DMCNN (Chen et al., 2015) in Table 1
and Table 2, DMCNN∗ excludes lexical feature but in-
cludes entity feature.

ing using external resources. One strategy is to
employ extra knowledge for better representation
learning, such as document (Duan et al., 2017;
Chen et al., 2018; Liu et al., 2018b), syntactic
information (Nguyen and Grishman, 2018; Sha
et al., 2018; Orr et al., 2018; Liu et al., 2018c),
event arguments (Liu et al., 2017), knowledge
bases (Yang and Mitchell, 2017; Lu and Nguyen,
2018) and multi-lingual information (Liu et al.,
2018a). The other strategy is generating addi-
tional training instances from extra knowledge
bases (Liu et al., 2016a; Chen et al., 2017) or news
paragraph clusters (Ferguson et al., 2018). Our
method does not use any external resources, which
could be a good complementary to these methods.

Representation Learning via Auxiliary Learn-
ing. In recent years, many auxiliary learning
techniques have been proposed for better repre-
sentation learning. Self-supervised learning learns
representation by designing auxiliary tasks rather
than using manually labeled data. Examples in-
clude colorization in vision tasks (Doersch and
Zisserman, 2017), language modeling in text tasks
(Rei, 2017). Adversarial learning attempts to fool
models through malicious input (Kurakin et al.,
2016), it has been broadly used in many scenar-
ios, e.g., domain adaptation (Zeng et al., 2018),
knowledge distillation (Qin et al., 2017) and at-
tribute cleaning (Elazar and Goldberg, 2018).

Some adversarial-based techniques have been
used for event detection. Hong et al. (2018) over-
comes spurious features during training via self-
regularization. Liu et al. (2019) distills extra
knowledge from external NLP resources using a
teacher-student network. This paper employs ad-



4374

versarial ∆-learning algorithm to eliminate lexi-
cal information in event representation so that both
discrimination and generalization knowledge can
be incrementally distilled.

6 Conclusions

This paper proposes a new representation learn-
ing framework – ∆-learning, which can distill
both discrimination and generalization knowledge
for event detection. Specifically, two effective
∆-learning algorithms are proposed to distill dis-
crimination and generalization knowledge inde-
pendently, and a lexical gate mechanism is de-
signed to fuse different knowledge adaptively. Ex-
perimental results demonstrate the effectiveness of
our method. Representation learning is a funda-
mental technique for NLP tasks, especially for re-
solving the ambiguity and the diversity problem of
natural language expressions. For future work, we
plan to investigate new auxiliary ∆-learning algo-
rithms using our ∆-learning framework.

Acknowledgments

We sincerely thank the reviewers for their valu-
able comments. Moreover, this work is supported
by the National Key R&D Program of China un-
der Grant 2018YFB1005100; the National Nat-
ural Science Foundation of China under Grants
no. 61433015, 61572477 and 61772505; and the
Young Elite Scientists Sponsorship Program no.
YESS20160177.

References
David Ahn. 2006. The stages of event extraction. In

Proceedings of the Workshop on Annotating and
Reasoning about Time and Events, pages 1–8, Syd-
ney, Australia. Association for Computational Lin-
guistics.

James Allan. 2012. Topic detection and tracking:
event-based information organization, volume 12.
Springer Science & Business Media.

Nathanael Chambers and Dan Jurafsky. 2008. Unsu-
pervised learning of narrative event chains. In Pro-
ceedings of ACL-08: HLT, pages 789–797. Associa-
tion for Computational Linguistics.

Yubo Chen, Shulin Liu, Xiang Zhang, Kang Liu, and
Jun Zhao. 2017. Automatically labeled data gener-
ation for large scale event extraction. In Proceed-
ings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 409–419, Vancouver, Canada. Associa-
tion for Computational Linguistics.

Yubo Chen, Liheng Xu, Kang Liu, Daojian Zeng,
and Jun Zhao. 2015. Event extraction via dy-
namic multi-pooling convolutional neural networks.
In Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers), pages
167–176, Beijing, China. Association for Computa-
tional Linguistics.

Yubo Chen, Hang Yang, Kang Liu, Jun Zhao, and Yan-
tao Jia. 2018. Collective event detection via a hier-
archical and bias tagging networks with gated multi-
level attention mechanisms. In Proceedings of the
2018 Conference on Empirical Methods in Natural
Language Processing, pages 1267–1276. Associa-
tion for Computational Linguistics.

Carl Doersch and Andrew Zisserman. 2017. Multi-
task self-supervised visual learning. In The IEEE In-
ternational Conference on Computer Vision (ICCV),
pages 2051–2060.

Shaoyang Duan, Ruifang He, and Wenli Zhao. 2017.
Exploiting document level information to improve
event detection via recurrent neural networks. In
Proceedings of the Eighth International Joint Con-
ference on Natural Language Processing (Volume 1:
Long Papers), pages 352–361. Asian Federation of
Natural Language Processing.

Yanai Elazar and Yoav Goldberg. 2018. Adversarial
removal of demographic attributes from text data.
In Proceedings of the 2018 Conference on Empiri-
cal Methods in Natural Language Processing, pages
11–21. Association for Computational Linguistics.

Xiaocheng Feng, Lifu Huang, Duyu Tang, Heng Ji,
Bing Qin, and Ting Liu. 2016. A language-
independent neural network for event detection. In
Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 2:
Short Papers), pages 66–71. Association for Com-
putational Linguistics.

James Ferguson, Colin Lockard, Daniel Weld, and
Hannaneh Hajishirzi. 2018. Semi-supervised event
extraction with paraphrase clusters. In Proceed-
ings of the 2018 Conference of the North American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, Volume 2
(Short Papers), NAACL ’2018, pages 359–364. As-
sociation for Computational Linguistics.

Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan,
Pascal Germain, Hugo Larochelle, François Lavio-
lette, Mario Marchand, and Victor Lempitsky. 2016.
Domain-adversarial training of neural networks. J.
Mach. Learn. Res., 17(1):2096–2030.

Reza Ghaeini, Xiaoli Fern, Liang Huang, and Prasad
Tadepalli. 2016. Event nugget detection with
forward-backward recurrent neural networks. In
Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 2:

http://aclweb.org/anthology/W/W06/W06-0901.pdf
https://link.springer.com/book/10.1007%2F978-1-4615-0933-2
https://link.springer.com/book/10.1007%2F978-1-4615-0933-2
http://aclweb.org/anthology/P08-1090
http://aclweb.org/anthology/P08-1090
http://aclweb.org/anthology/P17-1038
http://aclweb.org/anthology/P17-1038
http://www.aclweb.org/anthology/P15-1017
http://www.aclweb.org/anthology/P15-1017
http://aclweb.org/anthology/D18-1158
http://aclweb.org/anthology/D18-1158
http://aclweb.org/anthology/D18-1158
http://openaccess.thecvf.com/content_ICCV_2017/papers/Doersch_Multi-Task_Self-Supervised_Visual_ICCV_2017_paper.pdf
http://openaccess.thecvf.com/content_ICCV_2017/papers/Doersch_Multi-Task_Self-Supervised_Visual_ICCV_2017_paper.pdf
http://aclweb.org/anthology/I17-1036
http://aclweb.org/anthology/I17-1036
http://aclweb.org/anthology/D18-1002
http://aclweb.org/anthology/D18-1002
https://doi.org/10.18653/v1/P16-2011
https://doi.org/10.18653/v1/P16-2011
http://aclweb.org/anthology/N18-2058
http://aclweb.org/anthology/N18-2058
http://dl.acm.org/citation.cfm?id=2946645.2946704
http://anthology.aclweb.org/P16-2060
http://anthology.aclweb.org/P16-2060


4375

Short Papers), pages 369–373, Berlin, Germany. As-
sociation for Computational Linguistics.

Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets. In Advances in Neural Information
Processing Systems, pages 2672–2680. Curran As-
sociates, Inc.

Yu Hong, Wenxuan Zhou, Jingli Zhang, Qiaoming
Zhu, and Guodong Zhou. 2018. Self-regulation:
Employing a generative adversarial network to im-
prove event detection. In Proceedings of the 56th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 515–526. Association for
Computational Linguistics.

Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio.
2016. Adversarial machine learning at scale. CoRR,
abs/1611.01236.

Qi Li, Heng Ji, and Liang Huang. 2013. Joint event
extraction via structured prediction with global fea-
tures. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 73–82, Sofia, Bulgaria.
Association for Computational Linguistics.

Shasha Liao and Ralph Grishman. 2010. Using doc-
ument level cross-event inference to improve event
extraction. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 789–797. Association for Computational
Linguistics.

Hongyu Lin, Yaojie Lu, Xianpei Han, and Le Sun.
2018a. Adaptive scaling for sparse detection in in-
formation extraction. In Proceedings of the 56th An-
nual Meeting of the Association for Computational
Linguistics, pages 1033–1043. Association for Com-
putational Linguistics.

Hongyu Lin, Yaojie Lu, Xianpei Han, and Le Sun.
2018b. Nugget proposal networks for chinese event
detection. In Proceedings of the 56th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 1565–1574. Association for Computa-
tional Linguistics.

Jian Liu, Yubo Chen, and Kang Liu. 2019. Exploit-
ing the ground-truth: An adversarial imitation based
knowledge distillation approach for event detection.
In The Thirty-Third AAAI Conference on Artificial
Intelligence, AAAI ’2019. Association for the Ad-
vancement of Artificial Intelligence.

Jian Liu, Yubo Chen, Kang Liu, and Jun Zhao. 2018a.
Event detection via gated multilingual attention
mechanism. In The Thirty-Second AAAI Conference
on Artificial Intelligence, AAAI ’2018, pages 4865–
4872, New York, NY, USA. Association for the Ad-
vancement of Artificial Intelligence.

Shaobo Liu, Rui Cheng, Xiaoming Yu, and Xueqi
Cheng. 2018b. Exploiting contextual information
via dynamic memory network for event detection.
In Proceedings of the 2018 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1030–1035. Association for Computational Linguis-
tics.

Shulin Liu, Yubo Chen, Shizhu He, Kang Liu, and
Jun Zhao. 2016a. Leveraging framenet to improve
automatic event detection. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
2134–2143, Berlin, Germany. Association for Com-
putational Linguistics.

Shulin Liu, Yubo Chen, Kang Liu, and Jun Zhao. 2017.
Exploiting argument information to improve event
detection via supervised attention mechanisms. In
Proceedings of the 55th Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 1789–1798, Vancouver,
Canada. Association for Computational Linguistics.

Shulin Liu, Kang Liu, Shizhu He, and Jun Zhao. 2016b.
A probabilistic soft logic based approach to exploit-
ing latent and global information in event classifi-
cation. In Proceedings of the Thirtieth AAAI Con-
ference on Artificial Intelligence, AAAI’16, pages
2993–2999. AAAI Press.

Xiao Liu, Zhunchen Luo, and Heyan Huang. 2018c.
Jointly multiple events extraction via attention-
based graph information aggregation. In Proceed-
ings of the 2018 Conference on Empirical Methods
in Natural Language Processing, pages 1247–1256.
Association for Computational Linguistics.

Weiyi Lu and Thien Huu Nguyen. 2018. Similar but
not the same - word sense disambiguation improves
event detection via neural representation matching.
In Proceedings of the 2018 Conference on Empiri-
cal Methods in Natural Language Processing, pages
4822–4828. Association for Computational Linguis-
tics.

Teruko Mitamura, Zhengzhong Liu, and Eduard H
Hovy. 2017. Events detection, coreference and se-
quencing: What’s next? overview of the tac kbp
2017 event track. In TAC.

Thien Huu Nguyen, Kyunghyun Cho, and Ralph Gr-
ishman. 2016. Joint event extraction via recurrent
neural networks. In Proceedings of the 2016 Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics: Human
Language Technologies, pages 300–309, San Diego,
California. Association for Computational Linguis-
tics.

Thien Huu Nguyen and Ralph Grishman. 2015. Event
detection and domain adaptation with convolutional
neural networks. In Proceedings of the 53rd Annual
Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference

http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf
http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf
http://aclweb.org/anthology/P18-1048
http://aclweb.org/anthology/P18-1048
http://aclweb.org/anthology/P18-1048
http://arxiv.org/abs/1611.01236
http://www.aclweb.org/anthology/P13-1008
http://www.aclweb.org/anthology/P13-1008
http://www.aclweb.org/anthology/P13-1008
http://aclweb.org/anthology/P10-1081
http://aclweb.org/anthology/P10-1081
http://aclweb.org/anthology/P10-1081
http://aclweb.org/anthology/P18-1095
http://aclweb.org/anthology/P18-1095
http://aclweb.org/anthology/P18-1145
http://aclweb.org/anthology/P18-1145
https://www.aaai.org/ocs/index.php/AAAI/AAAI19/index
https://www.aaai.org/ocs/index.php/AAAI/AAAI19/index
https://www.aaai.org/ocs/index.php/AAAI/AAAI19/index
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16371/16017
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16371/16017
http://aclweb.org/anthology/D18-1127
http://aclweb.org/anthology/D18-1127
http://www.aclweb.org/anthology/P16-1201
http://www.aclweb.org/anthology/P16-1201
http://aclweb.org/anthology/P17-1164
http://aclweb.org/anthology/P17-1164
https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11990/12052
https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11990/12052
https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11990/12052
http://aclweb.org/anthology/D18-1156
http://aclweb.org/anthology/D18-1156
http://aclweb.org/anthology/D18-1517
http://aclweb.org/anthology/D18-1517
http://aclweb.org/anthology/D18-1517
https://tac.nist.gov/publications/2017/additional.papers/TAC2017.KBP_Event_Nugget_overview.proceedings.pdf
https://tac.nist.gov/publications/2017/additional.papers/TAC2017.KBP_Event_Nugget_overview.proceedings.pdf
https://tac.nist.gov/publications/2017/additional.papers/TAC2017.KBP_Event_Nugget_overview.proceedings.pdf
http://www.aclweb.org/anthology/N16-1034
http://www.aclweb.org/anthology/N16-1034
http://www.aclweb.org/anthology/P15-2060
http://www.aclweb.org/anthology/P15-2060
http://www.aclweb.org/anthology/P15-2060


4376

on Natural Language Processing (Volume 2: Short
Papers), pages 365–371, Beijing, China. Associa-
tion for Computational Linguistics.

Thien Huu Nguyen and Ralph Grishman. 2016. Mod-
eling skip-grams for event detection with convolu-
tional neural networks. In Proceedings of the 2016
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 886–891, Austin, Texas.
Association for Computational Linguistics.

Thien Huu Nguyen and Ralph Grishman. 2018. Graph
convolutional networks with argument-aware pool-
ing for event detection. In The Thirty-Second AAAI
Conference on Artificial Intelligence, AAAI ’2018,
pages 5900–5907, New York, NY, USA. Association
for the Advancement of Artificial Intelligence.

Walker Orr, Prasad Tadepalli, and Xiaoli Fern. 2018.
Event detection with neural networks: A rigorous
empirical evaluation. In Proceedings of the 2018
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 999–1004. Association for
Computational Linguistics.

Matthew Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018. Deep contextualized word repre-
sentations. In Proceedings of the 2018 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers), pages 2227–
2237. Association for Computational Linguistics.

Lianhui Qin, Zhisong Zhang, Hai Zhao, Zhiting Hu,
and Eric Xing. 2017. Adversarial connective-
exploiting networks for implicit discourse relation
classification. In Proceedings of the 55th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers), pages 1006–
1017, Vancouver, Canada. Association for Compu-
tational Linguistics.

Marek Rei. 2017. Semi-supervised multitask learn-
ing for sequence labeling. In Proceedings of the
55th Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers),
pages 2121–2130, Vancouver, Canada. Association
for Computational Linguistics.

Lei Sha, Feng Qian, Baobao Chang, and Zhifang Sui.
2018. Jointly extracting event triggers and argu-
ments by dependency-bridge rnn and tensor-based
argument interaction. In The Thirty-Second AAAI
Conference on Artificial Intelligence, AAAI ’2018,
pages 5916–5923, New York, NY, USA. Association
for the Advancement of Artificial Intelligence.

Bishan Yang and Tom Mitchell. 2017. Leveraging
knowledge bases in lstms for improving machine
reading. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers), pages 1436–1446. Asso-
ciation for Computational Linguistics.

Matthew D. Zeiler. 2012. Adadelta: An adaptive learn-
ing rate method. CoRR, abs/1212.5701.

Jiali Zeng, Jinsong Su, Huating Wen, Yang Liu,
Jun Xie, Yongjing Yin, and Jianqiang Zhao. 2018.
Multi-domain neural machine translation with word-
level domain context discrimination. In Proceed-
ings of the 2018 Conference on Empirical Methods
in Natural Language Processing, pages 447–457,
Brussels, Belgium. Association for Computational
Linguistics.

https://aclweb.org/anthology/D16-1085
https://aclweb.org/anthology/D16-1085
https://aclweb.org/anthology/D16-1085
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16329/16155
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16329/16155
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16329/16155
http://aclweb.org/anthology/D18-1122
http://aclweb.org/anthology/D18-1122
http://aclweb.org/anthology/N18-1202
http://aclweb.org/anthology/N18-1202
http://aclweb.org/anthology/P17-1093
http://aclweb.org/anthology/P17-1093
http://aclweb.org/anthology/P17-1093
http://aclweb.org/anthology/P17-1194
http://aclweb.org/anthology/P17-1194
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16222/16157
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16222/16157
https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16222/16157
https://doi.org/10.18653/v1/P17-1132
https://doi.org/10.18653/v1/P17-1132
https://doi.org/10.18653/v1/P17-1132
http://arxiv.org/abs/1212.5701
http://arxiv.org/abs/1212.5701
https://www.aclweb.org/anthology/D18-1041
https://www.aclweb.org/anthology/D18-1041

