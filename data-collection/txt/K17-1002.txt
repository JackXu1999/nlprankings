



















































Rational Distortions of Learners' Linguistic Input


Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), page 2,
Vancouver, Canada, August 3 - August 4, 2017. c©2017 Association for Computational Linguistics

Invited Talk

Rational Distortions of
Learners’ Linguistic Input

Naomi Feldman
University of Maryland

Abstract: Language acquisition can be modeled as a statistical inference problem: children use
sentences and sounds in their input to infer linguistic structure. However, in many cases, children
learn from data whose statistical structure is distorted relative to the language they are learning. Such
distortions can arise either in the input itself, or as a result of children’s immature strategies for encoding
their input. This work examines several cases in which the statistical structure of children’s input differs
from the language being learned. Analyses show that these distortions of the input can be accounted for
with a statistical learning framework by carefully considering the inference problems that learners solve
during language acquisition

Bio: Naomi Feldman is an associate professor in the Department of Linguistics and the Institute for
Advanced Computer Studies at the University of Maryland. She received her PhD in Cognitive Science
from Brown University in 2011. Her research lies at the intersection of cognitive science, computer
science, and linguistics. She uses methods from machine learning to create formal models of how
people learn and represent the structure of their language, and has been developing methods that take
advantage of naturalistic speech corpora to study how listeners encode information from their linguistic
environment.

2


