










































Using the Web to Train a Mobile Device Oriented Japanese Input Method Editor


International Joint Conference on Natural Language Processing, pages 1209–1215,
Nagoya, Japan, 14-18 October 2013.

Using the Web to Train a Mobile Device Oriented
Japanese Input Method Editor

Xianchao Wu, Rixin Xiao, Xiaoxin Chen
Baidu Inc.

wuxianchao@gmail.com, {xiaorixin, chenxiaoxin}@baidu.com

Abstract

This paper describes the construction of a
Japanese Input Method Editor (IME) sys-
tem for mobile devices, using the large-
scale Web pages. We provide the training
process of our IME model, n-pos model
for local Kana-Kanji conversion and n-
gram model for online cloud service. Es-
pecially, we propose an online algorithm
of mining new compound words, together
with the detailed post-filtering process to
prune the billion level entries to be used
in mobile services. Experiments show that
our IME system outperforms two state-of-
the-art Japanese IME baselines. We have
released our system in a completely free
form1 and the system is currently used by
millions of users.

1 Introduction

Mobile devices such as smart phones and tablet
PCs are used by billions of users. For example,
Google’s Android system has obtained more than
900 million2 active devices till May 2013. In this
paper, we use large-scale Web pages to train a
Japanese IME system for mobile devices.

Languages such as Chinese and Japanese can
not been typed directly using Latin keyboards.
This is because there are only 26 English letters
in a Latin keyboard, yet the number of Chinese
characters are in tens thousands level. Further-
more, by connecting several Chinese characters
together, the number of yielded words and fre-
quently used phrases/idioms are in million level.
Thus, language-dependent Input Method Editor
(IME) systems are indispensable which maps from
combinations of English letters to Chinese char-

1http://simeji.me/
2http://www.android.com/

acters/words/phrases and Japanese Kanji/Kana se-
quences.

For example, suppose we want to input a
Japanese verb “炒める” (means “fry”, “炒”　is a
Japanese Kanji character, “める” are two Japanese
Kana characters). We first need to know the Kana
pronunciation of the Kanji character “炒”, which
is “いた”. That is, the verb is pronunced as “いた
める”. Then, we need to know the mapping from
English letters to Japanese Kanas. Here, “い”,
“た”, “め”, “る” respectively correspond to “i”,
“ta”, “me”, “ru”, which can be directly typed by
using the Latin keyboards. This mapping (e.g.,
from “i” to “い”) is unique and predefined already.
Thus, the real challenge for constructing an IME
system for Japanese is to provide the most reason-
able Kanji sequence from a given Kana sequence:

• one Kanji character can have several correct
Kana pronunciations (e.g., “炒” can be pro-
nounced as “いた”, “しょう”, “そう”, etc.);

• one Kana sequence corresponds to numerous
Kanji candidates (such as “いためる” for
“炒める”, “痛める” (pain), etc.);

It is the context that determines the selection of
the most reasonable Kanji sequence. For example,
“心をいためる” (“心” = heart, “を” is a Japanese
particle right follows an argument and before the
argument’s predicate) requires the Kanji to be “痛
める" (heart pain) and “野菜をいためる” needs
the Kanji to be “炒める” (fry vegetables). How-
ever, it is not a trivial work for modelling the con-
text. That is, how to choice the context from large-
scale Web pages such that the context is optimized
to be used in a mobile device oriented Japanese
IME?

To answer this question, we need to consider the
following constraints:

• mobile devices need more strict controlling
of CPU and memory usages than laptops;

1209



• free wireless services are not supposed to be
available anywhere, any time.

Consequently, we have to limit the number of
Kana-Kanji entries to be loaded into memory and
ensure a high precision of Kana-Kanji conversion
even without on-line services (such as cloud in-
put).

2 The Model

Our Japanese IME system is constructed based on
the n-pos3 model (Mori et al., 1999; Komachi et
al., 2008; Kudo et al., 2011). For statistical Kana-
Kanji conversion, we predicate the optimal mixed
Kana-Kanji sequence ŷ (= w1...wn) from the in-
put Hirakana sequence x:

ŷ = argmaxyP (y)P (x|y) (1)

P (y) =

n∏
i=1

P (wi|ci)P (ci|ci−1) (2)

P (x|y) =
n∏

i=1

P (ri|wi) (3)

As shown in Figure 1, for training this model,
we used 2.5TB Japanese Web pages as the train-
ing data. We run Mecab4 with IPA dictionary5

on Hadoop6, an open source software that im-
plemented the Map-Reduce framework (Dean and
Ghemawat, 2004), for parallel word segmenting,
Part-of-Speech (POS) tagging, and Kana pronun-
ciation annotating. Then, based on maximum like-
lihood estimation, we estimate:

• P (ci|ci−1), bi-gram POS tag model;

• P (wi|ci), POS-to-word emission model,
from ci to a word wi; and,

• P (ri|wi), pronunciation model, from wi to
its Kana pronunciation ri.

There are several lexicons/models to be used
in the final IME system. The first is called the
basic lexicon. An entry in this lexicon is alike
< wi+mi , c

i+m
i , r

i+m
i >. Here, w

i+m
i stands for

m + 1 words (of wi...wi+m). One word wi ex-
actly corresponds to one POS tag ci and one Kana

3n-pos model is short for n-gram part-of-speech model
4https://code.google.com/p/mecab/
5http://code.google.com/p/mecab/downloads/detail?

name=mecab-ipadic-2.7.0-20070801.tar.gz
6http://hadoop.apache.org/

 

 

Web pages (2.5TB) 

Cloud Service 
word segmentation, POS 

tagging, and pronunciation 

annotating 

1. Basic 

lexicon 

2. Compound 
lexicon 

n-gram 

model 

filtering 

chunk-based 

dependency parsing 

wireless network service 

3. P(ci|ci-1); P(wi|ci); 

P(ri|wi) 

Figure 1: The main process of using the Web to
train the IME system.

sequence ri as its pronunciation. One word se-
quence with multiple reasonable POS sequences
and/or Kana pronunciations will be stored sepa-
rately as different entries. This lexicon contains:
(1) Japanese words (such as particles, adjectives,
adverbs, verbs, nouns, etc.) with the highest fre-
quencies, and (2) the most frequently used idioms
which are collected manually by our Japanese lan-
guage experts.

The second is the compound lexicon which
contains new words, collocations, and predicate-
argument phrases. As drawn in Figure 1, depen-
dency parsing is performed before mining. Web
sentences were parsed by a state-of-the-art chunk-
based Japanese dependency parser, Cabocha7

(Kudo and Matsumoto, 2002a). The mining and
filtering process will be introduced in the next sec-
tion. The motivation of constructing this lexicon is
to extract the most important context information,
such as the strong constraints among predicates
and their arguments. For example, as former men-
tioned, the pre-predicate arguments such as “心”
(heart) or “野菜” (vegetables) with given Kana se-
quence “をいためる” will determine which pred-
icate verb to choose, “痛める” or “炒める”.

The third is the n-pos model with three kinds of
probabilities which are used during decoding, i.e.,
searching the n-best ys from a given input Kana

7http://code.google.com/p/cabocha/

1210



sequence x.
Finally, we train a 4-gram language model on

surface word level and construct a cloud Kana-
Kanji conversion service through wireless network
communication between a mobile device and the
cloud. The only difference with former n-pos
model is the factorization of P (y):

P (y) =

n∏
i=1

P (wi|wi−1, wi−2, wi−3) (4)

The first three lexicons/models are stored in the
mobile devices to be accessed during Kana-Kanji
decoding using Equation 1. The final 4-gram lan-
guage model is estimated in a different way from
the n-pos model. Thus, we are forced to interpo-
late cloud’s m-best Kanji candidates into local mo-
bile device’s n-best Kanji candidates. We perform
duplicated candidate removing before interpolat-
ing. Possible methods includes:

• insert the cloud candidates into fixed posi-
tions, e.g., from the second position to the
m+1 position of the local n-best list; or,

• upload the local n-best candidates to the
cloud and then use the 4-gram language
model to compute the candidates’ language
model scores; or,

• download POS tags of the m-best candidates
from the cloud and locally compute their
scores under the local n-pos model.

The first method is the simplest without a large us-
age of the wireless network. The later two meth-
ods make the direction comparison of cloud and
local candidates yet possibly take a large usage of
the network. For simplicity, we choose the first
method (e.g., taking cloud result as the first candi-
date) in our IME system.

3 Compound Word Mining and Filtering

3.1 Mining Process

The basic lexicon used in our Japanese IME sys-
tem is short at capturing new words and phrases,
which are appearing everyday in the latest Web
pages. For example, person names, technical
terms and organization names are newly created
and used in Web pages such as news, blogs,
question-answering systems. We argue it is es-
sential for the IME system to regularly update

its compound lexicon to cover these new and hot
words/phrases.

Alike the format of the basic lexicon, entries
with m + 1 (m differs among the entries) words
in the compound lexicon is also triples of <
wi+mi , c

i+m
i , r

i+m
i >. In this paper, we mine three

types of new compound words, together with their
pronunciations from Japanese Web pages:

• words, which are combinations of single
characters and shorter words (e.g., “副/ふ
く垢/あか" = “secondary (twitter) account”);

• collocations, which are combinations of
words (e.g., “ドバイ ショック” = “Dubai
(debt) crisis” ). Here, Japanese collocations
are allowed to include Kanjis, Katakanas and
Hirakanas. Different from many former re-
searches (Manning and Schütze, 1999; Liu et
al., 2009) which only mine collocations of
two words, we do not limit the number of
words in our “collocation” lexicon; and,

• predicate-argument phrases, which are com-
binations of chunks constrained by semantic
dependency relations (e.g., “心を痛める” =
heart pain).

New words and collocations are mined from
single chunks in the dependency trees gener-
ated by Cabocha. This mining idea is based on
the fact that an Japanese morphological analyser
(e.g., Mecab) tends to split one out-of-vocabulary
(OOV) word into a sequence of known Kanji char-
acters, and most of these known Kanji characters
are annotated to be notional words. Consequently,
Cabocha, which takes words/characters and their
POS tags as features for discriminative training us-
ing a SVM model (Kudo and Matsumoto, 2002b),
can still correctly tend to include these single-
Kanji-character words into one chunk. Thus, we
can re-combine the wrongly separated pieces into
one (compound) word.

Predicate-argument phrases are mined from ad-
jacent chunks with dependency relations. Since
Japanese is a Subject-Object-Verb (SOV) lan-
guage, the predicate frequently follows its sub-
ject/object arguments.

Figure 2 and 3 give the distributions (number of
words per compound word vs. the frequency of
compound words in a similar number of words) of
single/double chunk lexicons (without any filter-
ing yet). For new words and collocations mined

1211



0

100

200

300

400

500

600

1 2 3 4 5 6 7 8 9

fr
e

q
u

e
n

cy
 o

f 
co

m
p

o
u

n
d

s
M

il
li

o
n

# of words in single chunk compounds

cut.1

Figure 2: The distributions of the number of words
per compound in single chunk lexicon, mined
from the 2.5TB web data.

0

200

400

600

800

1000

1200

1400

1600

1800

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15

fr
e

q
u

e
n

cy
 o

f 
co

m
p

o
u

n
d

s
M

il
li

o
n

# of words in double chunk compounds

cut.1

Figure 3: The distributions of the number of words
per predicate-argument phrases, mined from the
2.5TB web data.

from single chunks, we limit the number of words
frequently ranges from 2 to 8. For predicate-
argument phrases, most number (of words) is in
the interval of [2, 11].

Frequency information is used for pruning the
compound entries to be finally used in mobile de-
vices. The mining algorithm can be performed
in an online way. For one aspect, we can timely
crawl the latest Web pages and execute the min-
ing process. The frequencies of lastly mined en-
tries can be simply accumulated to the existing en-
tries. On the other hand, we allow the users to up-
load their input logs to the cloud and execute the
mining process to extract single user oriented per-
sonally entries. Again, the frequencies of similar
words/phrases are simply accumulated.

Recall the n-pos model and the n-gram language
model. Since all the probabilities are estimated
in a maximum likelihood way, we can simply up-
date the probabilities in these models by accumu-

lating frequencies to similar words/phrases. Thus,
we say that our IME system is self-growing as the
Web becoming larger and users using it longer.

3.2 Filtering Process
After successful mining of the compound lexicon,
it is still challenging to prune it to be used in mo-
bile devices with limited computing ability and
memory. The trade-off is that, we have to maintain
a good enough local lexicon yet with extremely
limited number of entries. We use the following
algorithms step by step for filtering:

• use the likelihood ratio method as described
in (Manning and Schütze, 1999);

• use the LH score as described in (Okazaki
and Ananiadou, 2006);

• use the log file of the cloud service; and,

• use hand-made deep filtering rules.

We hereafter describe these filtering strategies.
Likelihood ratio is an approach to hypothesis test-
ing, which has been proved to be appropriate for
sparse data (Manning and Schütze, 1999). That is,
even for candidate phrases will relatively low fre-
quencies, if they share a strong relation with each
other, then they are still possibly kept. Likelihood
ratio is simply a number that tells us how much
more likely one hypothesis is than the other one:

• Hypothesis 1. P (w2|w1) = p = P (w2| −
w1);

• Hypothesis 2. P (w2|w1) = p ̸= P (w2| −
w1).

The first hypothesis judges if the occurrence
of word w2 is independence with word w1,
and the second hypothesis is about dependence
which is good evidence for an interesting col-
location candidate. The computing of logλ =
log(L(H1)/L(H2)) exactly follows the defini-
tions in (Manning and Schütze, 1999). Deal to
short of space, we skip the detail here. Note that
for phrases with more than two words (e.g., three
words), we separately take the first/last two words
as one unit, and the other word as another unit.
Then, if and only if both w1w2, w3 and w1, w2w3
are collocation candidates, then w1w2w3 is taken
as one reasonable collocation.

After likelihood ratio based filtering, we
checked the remaining entities and found too

1212



many nested entries. For example, even both
w1w2w3 and w1w2 were kept in the final com-
pound lexicon, only one of them was judged man-
ually to be the correct one. Dealing with this prob-
lem, we use the LH score formula as described
in (Okazaki and Ananiadou, 2006). we reuse the
heuristic LH formula to compute the collocation
likelihood LH(c) for a candidate c:

LH(c) = freq(c)−
∑
t∈Tc

freq(t)× freq(t)∑
t∈Tc freq(t)

.

Here, c is a Kanji (sub-)sequence candidate;
freq(c) denotes the frequency of co-occurrence of
c with the final/first word(s) of the phrases; and Tc
is a set of nested Kanji sequence candidates, each
of which consists of a preceding (or, succeeding)
Kanji or Kana character followed by (or, follows)
the candidate c. This LH score can be computed
in left-to-right (i.e., taking the former one or more
words as no-changing words and seek the word
list that follows these former words) direction or
right-to-left direction. For example, for left-to-
right computing, we can collect all the phrases
starts with the similar word w1 and then collect
all the compound entries start with w1. Then, after
computing LH score, we can limit the number of
entries start with w1.

Even after these two automatic filtering algo-
rithms, we still find there are too many entries re-
maining in the compound lexicon. The third step
of filtering is the usage of the cloud log file which
stores the entries that users uploads to the cloud.
This filtering strategy is to only keep those entries
whose Kana pronunciations were found in the log
file. The consideration is to connect the Web to the
real requirements of the users.

Finally, we manually check the remaining lex-
icon and construct deep filtering rules. For ex-
ample, entries that starts with “ない”, “等” are
pruned out; entries with POS tags of “particles”,
“auxilary verbs” are pruned out. Note that, this
manual checking is performed before the final lex-
icon is generated. Filtering rules are constructed
after this manual checking step and further used
for filtering the test set as can be find in the next
section (22 entries were filtered from the 5K en-
tries in the test set).

4 Experimental Results

We have described in detail the training and filter-
ing process for constructing lexicons and models.

Missing
Systems top-1 top-6 top-12 Words
Baseline1 84.91 89.11 89.31 532
Baseline2 82.64 94.23 94.80 112
IME-basic 81.36 85.82 85.82 705
+ compound 85.78 91.22 91.30 431
+ cloud (1st) 88.99 94.98 96.44 41

Table 1: The top-1/6/12 precisions (%) of the
baselines and our IME system under several con-
figurations. Here, IME-basic stands for our IME
system with only the basic lexicon; + compound
stands for the system together with the basic lexi-
con and the compound lexicon; + cloud stands for
taking cloud’s best candidate as IME’s first candi-
date.

In terms of the decoding algorithm, we use beam
searching for n-best Viterbi decoding (Huang and
Chiang, 2005). The training data is a 2.5TB
Japanese Web page set. Our basic lexicon contains
around 100k entries, while the compound lexicon
is limited to contain around 50k entries. No limi-
tation is set to the 4-gram language model running
in the cloud.

Our test set contains 4,978 Kana-Kanji entries
of frequently used word, idioms, and phrases. The
entries of this test set comes from the following
three lexicons/corpora:

• (partial) “JDMWE” (Japanese Dictionary
of Multi-Word Expressions) (Shudo et al.,
2011) lexicon with 2,169 entries;

• “Nagoya” compound word lexicon8 with
3,628 entries such as idioms;

• 16,611 long form words in the “BCCWJ”
(Balanced Corpus of Contemporary Written
Japanese) corpus (Maekawa, 2008).

We then retrieve each entry in these three lexicons
using Google9 and only keep the top 5K entries
with higher frequencies. After obtaining the 5K
entries, we perform manually constructed deep fil-
tering rules (which have been used during train-
ing) and remove 22 entries which are judged to be
not suitable to be taken as collocations with com-
plete meaning.

We use top-n precisions Pn to evaluate the ac-
curacy of the IME systems. We use <km, rm> to

8http://kotoba.nuee.nagoya-u.ac.jp/jc2/base/list
9https://www.google.co.jp/

1213



express one entry in the test set, where m ranges
from 1 to M, km is the Kana input and rm is the
Kanji reference.

Pn =

∑M
m=1{δ(rm, IMEn(km))}

M
(5)

Given one km, IMEn(km) generates the n-best
Kanji candidate for km. The δ() function is de-
fined as follows:

δ(rm, IMEn(km)) =
{

1 if rm ∈ IMEn(km),
0 otherwise.

When n takes 1, P1 is equivalent to the traditional
definition of precision.

Table 1 shows the top-n precisions and the
number of missing words of two starte-of-the-
art Japanese IME baseline systems and our
IME system under several configurations of lexi-
cons/models. Both the baseline systems and our
IME systems are in mobile device versions.

Here, baseline110 is a commercial Japanese
IME system whose lexicon contains around 200k
entries. This baseline system is constructed by us-
ing statistical methods on relatively a small-scale
training data and a lot of hand-made Kana-Kanji
conversion rules. Deal to resource limitation, we
could not obtain further detailed technical infor-
mation of this system and can only buy one copy
and test it in an open testing way.

The second baseline IME system (Kudo et al.,
2011), baseline211, is constructed in a statistical
way by using the large-scale Japanese Web pages
as the training data. N-pos model is also the major
model supporting its training and decoding algo-
rithms. This system can be freely obtained.

From the table, we have the following observa-
tions:

• when only using the basic lexicon, our IME
system is worse than both of the baselines;

• when the compound lexicon is appended, the
top-1 precision of our IME system is bet-
ter than baselines, yet top-6/12 precisions
are still not good (by checking the lexicon
size of baseline2, we found that around 300k
to 400k entries were contained. Yet there
are only around 100k+50k entries in our ba-
sic/compound lexicons);

10http://www.justsystems.com/jp/products/atok_android/
11https://play.google.com/store/apps/details

?id=com.google.android.inputmethod.japanese

Missing
Systems top-1 top-6 top-12 Words
IME 76.12 82.05 82.05 224
+ log 79.41 87.74 87.82 152
improves 3.29 5.69 5.77 -72

Table 2: The top-1/6/12 precisions (%) of our IME
system under several configurations. Here, IME
stands for the system using basic and compound
lexicons; + log stands for appending compound
entries mined from users’ log.

• finally, by using cloud service, the top-n pre-
cisions are significantly better than two base-
lines.

We did another experiment for testifying the
“online” ability of our IME system. The training
data is the users’ logs. We used these logs (of
during two months) to extract compound words
and append them to existing compound lexicons.
There are 6k entries appended. The testing data
(which contains 1,248 entries) is a set of com-
pound words using logs of the latest three days.

Table 2 shows the changes of top-1/6/12 pre-
cisions by appending the compound entries mined
from users’ log. We observe that the precisions are
improved 3.29% to 5.77%. These improvements
show evidence that the IME system can grow itself
in an online way with more data and more users.

5 Conclusion

We have described the construction of a Japanese
Input Method Editor (IME) system for mobile
devices, using 2.5TB Web pages. We provided
the training process of our IME model, n-pos
model for local Kana-Kanji conversion and n-
gram model for online cloud service. In particular,
we described an online algorithm of mining new
compound words, together with the detailed post-
filtering process to prune the billion level entries to
be used in mobile services. Experiments showed
that our IME system outperforms two state-of-the-
art Japanese IME baselines. We have released our
system in a completely free form and the system
has been downloaded by more than 5 million users
and is currently used by users in million level12.

12https://play.google.com/store/apps/details
?id=com.adamrocker.android.input.simeji

1214



References
Jeffrey Dean and Sanjay Ghemawat. 2004. Mapre-

duce: simplified data processing on large clusters.
In Proceedings of OSDI.

Liang Huang and David Chiang. 2005. Better k-best
parsing. In Proceedings of IWPT.

Mamoru Komachi, Shinsuke Mori, and Hiroyuki Toku-
naga. 2008. Japanese, the ambiguous, and input
methods (in japanese). In Proceedings of the Sum-
mer Programming Symposium of Information Pro-
cessing Society of Japan.

Taku Kudo and Yuji Matsumoto. 2002a. Japanese de-
pendency analysis using cascaded chunking. In Pro-
ceedings of Co-NLL, pages 63–69.

Taku Kudo and Yuji Matsumoto. 2002b. Japanese de-
pendency analysis using cascaded chunking. In Pro-
ceedings of CoNLL-2002, pages 63–69. Taipei, Tai-
wan.

Taku Kudo, Taiyaki Komatsu, Toshiyuki Hanaoka, Jun
Mukai, and Yusuke Tabata. 2011. Mozc: A sta-
tistical kana-kanji conversion system (in japanese).
In Proceedings of Japan Natural Language Process-
ing, pages 948–951.

Zhanyi Liu, Haifeng Wang, Hua Wu, and Sheng Li.
2009. Collocation extraction using monolingual
word alignment method. In Proceedings of EMNLP,
pages 487–495, Singapore, August.

Kikuo Maekawa. 2008. Compilation of the kotonoha-
bccwj corpus (in japanese). Nihongo no kenkyu
(Studies in Japanese), 4:82–95.

Chris Manning and Hinrich Schütze. 1999. Foun-
dations of Statistical Natural Language Processing.
MIT Press, Cambridge, Massachusetts, May.

Shinsuke Mori, Masatoshi Tsuchiya, Osamu Yamaji,
and Makoto Nagao. 1999. Kana-kanji conversion
by a stochastic model (in japanese). Journal of In-
formation Processing Society of Japan, 40(7).

Naoaki Okazaki and Sophia Ananiadou. 2006. Build-
ing an abbreviation dictionary using a term recogni-
tion approach. Bioinformatics, 22(22):3089–3095.

Kosho Shudo, Akira Kurahone, and Toshifumi Tanabe.
2011. A comprehensive dictionary of multiword ex-
pressions. In Proceedings of ACL-HLT, pages 161–
170, Portland, Oregon, USA, June.

1215


