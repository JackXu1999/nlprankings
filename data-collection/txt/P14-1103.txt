



















































Nonparametric Learning of Phonological Constraints in Optimality Theory


Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1094–1103,
Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics

Nonparametric Learning of Phonological Constraints in Optimality
Theory

Gabriel Doyle
Department of Linguistics

UC San Diego
La Jolla, CA, USA 92093
gdoyle@ucsd.edu

Klinton Bicknell
Department of Linguistics
Northwestern University

Evanston, IL, USA 60208
kbicknell@northwestern.edu

Roger Levy
Department of Linguistics

UC San Diego
La Jolla, CA, USA 92093

rlevy@ucsd.edu

Abstract

We present a method to jointly learn fea-
tures and weights directly from distri-
butional data in a log-linear framework.
Specifically, we propose a non-parametric
Bayesian model for learning phonologi-
cal markedness constraints directly from
the distribution of input-output mappings
in an Optimality Theory (OT) setting. The
model uses an Indian Buffet Process prior
to learn the feature values used in the log-
linear method, and is the first algorithm
for learning phonological constraints with-
out presupposing constraint structure. The
model learns a system of constraints that
explains observed data as well as the
phonologically-grounded constraints of a
standard analysis, with a violation struc-
ture corresponding to the standard con-
straints. These results suggest an alterna-
tive data-driven source for constraints in-
stead of a fully innate constraint set.

1 Introduction

Many aspects of human cognition involve the in-
teraction of constraints that push a decision-maker
toward different options, whether in something so
trivial as choosing a movie or so important as
a fight-or-flight response. These constraint-driven
decisions can be modeled with a log-linear system.
In these models, a set of constraints is weighted
and their violations are used to determine a prob-
ability distribution over outcomes. But where do
these constraints come from?

We consider this question by examining the
dominant framework in modern phonology, Opti-
mality Theory (Prince and Smolensky, 1993, OT),
implemented in a log-linear framework, MaxEnt
OT (Goldwater and Johnson, 2003), with output
forms’ probabilities based on a weighted sum of

constraint violations. OT analyses generally as-
sume that the constraints are innate and univer-
sal, both to obviate the problem of learning con-
straints’ identities and to limit the set of possible
languages.

We propose a new approach: to learn con-
straints with limited innate phonological knowl-
edge by identifying sets of constraint violations
that explain the observed distributional data, in-
stead of selecting constraints from an innate set
of constraint definitions. Because the constraints
are identified as sets of violations, this also per-
mits constraints specific to a given language to
be learned. This method, which we call IBPOT,
uses an Indian Buffet Process (IBP) prior to define
the space of possible constraint violation matri-
ces, and uses Bayesian reasoning to identify con-
straint matrices likely to have generated the ob-
served data. In identifying constraints solely by
their extensional violation profiles, this method
does not directly identify the intensional defini-
tions of the identified constraints, but to the extent
that the resulting violation profiles are phonologi-
cally interpretable, we may conclude that the data
themselves guide constraint identification. We test
IBPOT on tongue-root vowel harmony in Wolof, a
West African language.

The set of constraints learned by the model sat-
isfy two major goals: they explain the data as well
as the standard phonological analysis, and their vi-
olation structures correspond to the standard con-
straints. This suggests an alternative data-driven
genesis for constraints, rather than the traditional
assumption of fully innate constraints.

2 Phonology and Optimality Theory

2.1 OT structure
Optimality Theory has been used for constraint-
based analysis of many areas of language, but we
focus on its most successful application: phonol-
ogy. We consider an OT analysis of the mappings

1094



between underlying forms and their phonological
manifestations – i.e., mappings between forms in
the mental lexicon and the actual vocalized forms
of the words.1

Stated generally, an OT system takes some in-
put, generates a set of candidate outputs, deter-
mines what constraints each output violates, and
then selects a candidate output with a relatively
unobjectionable violation profile. To do this, an
OT system contains four major components: a
generator GEN, which generates candidate out-
put forms for the input; a set of constraints CON,
which penalize candidates; a evaluation method
EVAL, which selects an winning candidate; and
H , a language-particular weighting of constraints
that EVAL uses to determine the winning candi-
date. Previous OT work has focused on identifying
the appropriate formulation of EVAL and the val-
ues and acquisition of H , while taking GEN and
CON as given. Here, we expand the learning task
by proposing an acquisition method for CON.

To learn CON, we propose a data-driven
markedness constraint learning system that avoids
both innateness and tractability issues. Unlike pre-
vious OT learning methods, which assume known
constraint definitions and only learn the relative
strength of these constraints, the IBPOT learns
constraint violation profiles and weights for them
simultaneously. The constraints are derived from
sets of violations that effectively explain the ob-
served data, rather than being selected from a pre-
existing set of possible constraints.

2.2 OT as a weighted-constraint method
Although all OT systems share the same core
structure, different choices of EVAL lead to dif-
ferent behaviors. In IBPOT, we use the log-
linear EVAL developed by Goldwater and John-
son (2003) in their MaxEnt OT system. MEOT
extends traditional OT to account for variation
(cases in which multiple candidates can be the
winner), as well as gradient/probabilistic produc-
tions (Anttila, 1997) and other constraint interac-
tions (e.g., cumulativity) that traditional OT can-
not handle (Keller, 2000). MEOT also is motivated
by the general MaxEnt framework, whereas most
other OT formulations are ad hoc constructions
specific to phonology.

In MEOT, each constraint Ci is associated with
1Although phonology is usually framed in terms of sound,

sign languages also have components that serve equivalent
roles in the physical realization of signs (Stokoe, 1960).

a weight wi < 0. (Weights are always negative
in OT; a constraint violation can never make a
candidate more likely to win.) For a given input-
candidate pair (x, y), fi(y, x) is the number of vi-
olations of constraint Ci by the pair. As a maxi-
mum entropy model, the probability of y given x
is proportional to the exponential of the weighted
sum of violations,

∑
iwifi(y, x). If Y(x) is the

set of all output candidates for the input x, then
the probability of y as the winning output is:

p(y|x) = exp (
∑

iwifi(y, x))∑
z∈Y(x) exp (

∑
iwifi(z, x))

(1)

This formulation represents a probabilistic
extension of the traditional formulation of
OT (Prince and Smolensky, 1993). Traditionally,
constraints form a strict hierarchy, where a single
violation of a high-ranked constraint is worse than
any number of violations of lower-ranked con-
straints. Traditional OT is also deterministic, with
the optimal candidate always selected. In MEOT,
the constraint weights define hierarchies of vary-
ing strictness, and some probability is assigned to
all candidates. If constraints’ weights are close to-
gether, multiple violations of lower-weighted con-
straints can reduce a candidate’s probability below
that of a competitor with a single high-weight vio-
lation. As the distance between weights in MEOT
increases, the probability of a suboptimal candi-
date being chosen approaches zero; thus the tradi-
tional formulation is a limit case of MEOT.

2.3 OT in practice
Figure 1 shows tableaux, a visualization for
OT, applied in Wolof (Archangeli and Pulley-
blank, 1994; Boersma, 1999). We are interested
in four Wolof constraints that combine to induce
vowel harmony: *I, PARSE[rtr], HARMONY, and
PARSE[atr]. The meaning of these constraints will
be discussed in Sect. 4.1; for now, we will only
consider their violation profiles. Each column rep-
resents a constraint, with weights decreasing left-
to-right. Each tableau looks at a single input form,
noted in the top-left cell: ete, EtE, Ite, or itE.

Each row is a candidate output form. A black
cell indicates that the candidate, or input-candidate
pair, violates the constraint in that column.2 A
white cell indicates no violation. Grey stripes are

2In general, a constraint can be violated multiple times
by a given candidate, but we will be using binary constraints
(violated or not) in this work. See Sect. 5.2 for further discus-
sion.

1095



ete *ɪ Parse(rtr) Harmony Parse(atr) Score ɪte *ɪ Parse(rtr) Harmony Parse(atr) Score
ete 0 ite -32
ɛte -24 ɪte -80
etɛ -24 itɛ -56
ɛtɛ -8 ɪtɛ -72

ɛtɛ *ɪ Parse(rtr) Harmony Parse(atr) Score itɛ *ɪ Parse(rtr) Harmony Parse(atr) Score
ete -32 ite -32
ɛte -48 ɪte -120
etɛ -48 itɛ -16
ɛtɛ 0 ɪtɛ -72

Figure 1: Tableaux for the Wolof input forms ete, EtE, Ite, and itE. Black indicates violation, white no
violation. Scores are calculated for a MaxEnt OT system with constraint weights of -64, -32, -16, and -8,
approximating a traditional hierarchical OT design. Values of grey-striped cells have negligible effects
on the distribution (see Sect. 4.3).

overlaid on cells whose value will have a negligi-
ble impact on the distribution due to the values of
higher-ranked constraint.

Constraints fall into two categories, faithful-
ness and markedness, which differ in what infor-
mation they use to assign violations. Faithfulness
constraints penalize mismatches between the in-
put and output, while markedness constraints con-
sider only the output. Faithfulness violations in-
clude phoneme additions or deletions between the
input and output; markedness violations include
penalizing specific phonemes in the output form,
regardless of whether the phoneme is present in
the input.

In MaxEnt OT, each constraint has a weight,
and the candidates’ scores are the sums of the
weights of violated constraints. In the ete tableau
at top left, output ete has no violations, and there-
fore a score of zero. Outputs Ete and etE vio-
late both HARMONY (weight 16) and PARSE[atr]
(weight 8), so their scores are 24. Output EtE vi-
olates PARSE[atr], and has score 8. Thus the log-
probability of output EtE is 1/8 that of ete, and the
log-probability of disharmonious Ete and etE are
each 1/24 that of ete. As the ratio between scores
increases, the log-probability ratios can become
arbitrarily close to zero, approximating the deter-
ministic situation of traditional OT.

2.4 Learning Constraints

Choosing a winning candidate presumes that a
set of constraints CON is available, but where do
these constraints come from? The standard as-
sumption within OT is that CON is innate and
universal. But in the absence of direct evidence
of innate constraints, we should prefer a method

that can derive the constraints from cognitively-
general learning over one that assumes they are
pre-specified. Learning appropriate model features
has been an important idea in the development of
constraint-based models (Della Pietra et al., 1997).

The innateness assumption can induce tractabil-
ity issues as well. The strictest formulation of in-
nateness posits that virtually all constraints are
shared across all languages, even when there is
no evidence for the constraint in a particular lan-
guage (Tesar and Smolensky, 2000). Strict uni-
versality is undermined by the extremely large
set of constraints it must weight, as well as
the possible existence of language-particular con-
straints (Smith, 2004).

A looser version of universality supposes that
constraints are built compositionally from a set
of constraint templates or primitives or phono-
logical features (Hayes, 1999; Smith, 2004; Id-
sardi, 2006; Riggle, 2009). This version allows
language-particular constraints, but it comes with
a computational cost, as the learner must be able
to generate and evaluate possible constraints while
learning the language’s phonology. Even with rel-
atively simple constraint templates, such as the
phonological constraint learner of Hayes and Wil-
son (2008), the number of possible constraints ex-
pands exponentially. Depending on the specific
formulation of the constraints, the constraint iden-
tification problem may even be NP-hard (Idsardi,
2006; Heinz et al., 2009). Our approach of casting
the learning problem as one of identifying viola-
tion profiles is an attempt to determine the amount
that can be learned about the active constraints in a
paradigm without hypothesizing intensional con-
straint definitions. The violation profile informa-

1096



tion used by our model could then be used to nar-
row the search space for intensional constraints,
either by performing post-hoc analysis of the con-
straints identified by our model or by combining
intensional constraint search into the learning pro-
cess. We discuss each of these possibilities in Sec-
tion 5.2.

Innateness is less of a concern for faithfulness
than markedness constraints. Faithfulness viola-
tions are determined by the changes between an
input form and a candidate, yielding an indepen-
dent motivation for a universal set of faithfulness
constraints (McCarthy, 2008). Some markedness
constraints can also be motivated in a universal
manner (Hayes, 1999), but many markedness con-
straints lack such grounding.3 As such, it is un-
clear where a universal set of markedness con-
straints would come from.

3 The IBPOT Model

3.1 Structure

The IBPOT model defines a generative process for
mappings between input and output forms based
on three latent variables: the constraint violation
matrices F (faithfulness) and M (markedness),
and the weight vector w. The cells of the violation
matrices correspond to the number of violations of
a constraint by a given input-output mapping. Fijk
is the number of violations of faithfulness con-
straint Fk by input-output pair type (xi, yj);Mjl is
the number of violations of markedness constraint
M·l by output candidate yj . Note that M is shared
across inputs, as Mjl has the same value for all
input-output pairs with output yj . The weight vec-
tor w provides weight for both F and M . Proba-
bilities of output forms are given by a log-linear
function:

p(yj |xi) =
exp (

∑
k wkFijk +

∑
l wlMjl)∑

yz∈Y(xi)
exp (

∑
k wkFizk +

∑
l wlMzl)

(2)

Note that this is the same structure as Eq. 1
but with faithfulness and markedness constraints
listed separately. As discussed in Sect. 2.4, we as-
sume that F is known as part of the output of GEN
(Riggle, 2009). The goal of the IBPOT model is to

3McCarthy (2008, §4.8) gives examples of “ad hoc” in-
tersegmental constraints. Even well-known constraint types,
such as generalized alignment, can have disputed structures
(Hyde, 2012).

learn the markedness matrix M and weights w for
both the markedness and faithfulness constraints.

As for M , we need a non-parametric prior, as
there is no inherent limit to the number of marked-
ness constraints a language will use. We use the
Indian Buffet Process (Griffiths and Ghahramani,
2005), which defines a proper probability distri-
bution over binary feature matrices with an un-
bounded number of columns. The IBP can be
thought of as representing the set of dishes that
diners eat at an infinite buffet table. Each diner
(i.e., output form) first draws dishes (i.e., con-
straint violations) with probability proportional
to the number of previous diners who drew it:
p(Mjl = 1|{Mzl}z<j) = nl/j. After choosing
from the previously taken dishes, the diner can
try additional dishes that no previous diner has
had. The number of new dishes that the j-th cus-
tomer draws follows a Poisson(α/j) distribution.
The complete specification of the model is then:

M ∼ IBP (α); Y(xi) = Gen(xi)
w ∼ −Γ(1, 1); y|xi ∼ LogLin(M,F,w,Y(xi))
3.2 Inference

To perform inference in this model, we adopt a
common Markov chain Monte Carlo estimation
procedure for IBPs (Görür et al., 2006; Navarro
and Griffiths, 2007). We alternate approximate
Gibbs sampling over the constraint matrix M ,
using the IBP prior, with a Metropolis-Hastings
method to sample constraint weights w.

We initialize the model with a randomly-drawn
markedness violation matrix M and weight vector
w. To learn, we iterate through the output forms
yj ; for each, we splitM−j· into “represented” con-
straints (those that are violated by at least one
output form other than yj) and “non-represented”
constraints (those violated only by yj). For each
represented constraintM·l, we re-sample the value
for the cell Mjl. All non-represented constraints
are removed, and we propose new constraints, vi-
olated only by yj , to replace them. After each it-
eration throughM , we use Metropolis-Hastings to
update the weight vector w.

Represented constraint sampling We begin by
resampling Mjl for all represented constraints
M·l, conditioned on the rest of the violations
(M−(jl), F ) and the weights w. This is the sam-
pling counterpart of drawing existing features in
the IBP generative process. By Bayes’ Rule, the

1097



posterior probability of a violation is propor-
tional to product of the likelihood p(Y |Mjl =
1,M−jl, F, w) from Eq. 2 and the IBP prior prob-
ability p(Mjl = 1|M−jl) = n−jl/n, where n−jl
is the number of outputs other than yj that violate
constraint M·l.

Non-represented constraint sampling After
sampling the represented constraints for yj , we
consider the addition of new constraints that are
violated only by yj . This is the sampling coun-
terpart to the Poisson draw for new features in
the IBP generative process. Ideally, this would
draw new constraints from the infinite feature ma-
trix; however, this requires marginalizing the like-
lihood over possible weights, and we lack an ap-
propriate conjugate prior for doing so. We approx-
imate the infinite matrix with a truncated Bernoulli
draw over unrepresented constraints (Görür et al.,
2006). We consider in each sample at most K∗

new constraints, with weights based on the auxil-
iary vector w∗. This approximation retains the un-
bounded feature set of the IBP, as repeated sam-
pling can add more and more constraints without
limit.

The auxiliary vector w∗ contains the weights
of all the constraints that have been removed in
the previous step. If the number of constraints
removed is less than K∗, w∗ is filled out with
draws from the prior distribution over weights. We
then consider adding any subset of these new con-
straints to M , each of which would be violated
only by yj . Let M∗ represent a (possibly empty)
set of constraints paired with a subset of w∗. The
posterior probability of drawingM∗ from the trun-
cated Bernoulli distribution is the product of the
prior probability of M∗

( α
K∗

NY +
α
K∗

)
and the like-

lihood p(Y |M∗, w∗,M,w, F ), including the new
constraints M∗.

Weight sampling After sampling through
all candidates, we use Metropolis-Hastings
to estimate new weights for both con-
straint matrices. Our proposal distribution is
Gamma(wk2/η, η/wk), with mean wk and
mode wk − ηwk (for wk > 1). Unlike Gibbs
sampling on the constraints, which occurs only on
markedness constraints, weights are sampled for
both markedness and faithfulness features.

4 Experiment

4.1 Wolof vowel harmony

We test the model by learning the markedness con-
straints driving Wolof vowel harmony (Archangeli
and Pulleyblank, 1994). Vowel harmony in gen-
eral refers to a phonological phenomenon wherein
the vowels of a word share certain features in the
output form even if they do not share them in the
input. In the case of Wolof, harmony encourages
forms that have consistent tongue root positions.

The Wolof vowel system has two relevant fea-
tures, tongue root position and vowel height. The
tongue root can either be advanced (ATR) or re-
tracted (RTR), and the body of the tongue can be in
the high, middle, or low part of the mouth. These
features define six vowels:

high mid low
ATR i e @
RTR I E a

We test IBPOT on the harmony system provided
in the Praat program (Boersma, 1999), previ-
ously used as a test case by Goldwater and John-
son (2003) for MEOT learning with known con-
straints. This system has four constraints:4

• Markedness:
– *I: do not have I (high RTR vowel)
– HARMONY: do not have RTR and ATR

vowels in the same word

• Faithfulness:
– PARSE[rtr]: do not change RTR input to

ATR output
– PARSE[atr]: do not change ATR input to

RTR output

These constraints define the phonological stan-
dard that we will compare IBPOT to, with a rank-
ing from strongest to weakest of *I>> PARSE[rtr]
>> HARMONY >> PARSE[atr]. Under this rank-
ing, Wolof harmony is achieved by changing a
disharmonious ATR to an RTR, unless this cre-
ates an I vowel. We see this in Figure 1, where
three of the four winners are harmonic, but with
input itE, harmony would require violating one
of the two higher-ranked constraints. As in previ-
ous MEOT work, all Wolof candidates are faithful

4The version in Praat includes a fifth constraint, but its
value never affects the choice of output in our data and is
omitted in this analysis.

1098



with respect to vowel height, either because height
changes are not considered by GEN, or because
of a high-ranked faithfulness constraint blocking
height changes.5

The Wolof constraints provide an interesting
testing ground for the model, because it is a small
set of constraints to be learned, but contains the
HARMONY constraint, which can be violated by
non-adjacent segments. Non-adjacent constraints
are difficult for string-based approaches because
of the exponential number of possible relation-
ships across non-adjacent segments. However, the
Wolof results show that by learning violations di-
rectly, IBPOT does not encounter problems with
non-adjacent constraints.

The Wolof data has 36 input forms, each of the
form V1tV2, where V1 and V2 are vowels that agree
in height. Each input form has four candidate out-
puts, with one output always winning. The outputs
appear for multiple inputs, as shown in Figure 1.
The candidate outputs are the four combinations
of tongue-roots for the given vowel heights; the
inputs and candidates are known to the learner.
We generate simulated data by observing 1000 in-
stances of the winning output for each input.6 The
model must learn the markedness constraints *I
and HARMONY, as well as the weights for all four
constraints.

We make a small modification to the constraints
for the test data: all constraints are limited to bi-
nary values. For constraints that can be violated
multiple times by an output (e.g., *I twice by ItI),
we use only a single violation. This is necessary in
the current model definition because the IBP pro-
duces a prior over binary matrices. We generate
the simulated data using only single violations of
each constraint by each output form. Overcoming
the binarity restriction is discussed in Sect. 5.2.

4.2 Experiment Design

We run the model for 10000 iterations, using de-
terministic annealing through the first 2500 it-

5In the present experiment, we assume that GEN does not
generate candidates with unfaithful vowel heights. If unfaith-
ful vowel heights were allowed by GEN, these unfaithful can-
didates would incur a violation approximately as strong as *I,
as neither unfaithful-height candidates nor I candidates are at-
tested in the Wolof data.

6Since data, matrix, and weight likelihoods all shape the
learned constraints, there must be enough data for the model
to avoid settling for a simple matrix that poorly explains the
data. This represents a similar training set size to previous
work (Goldwater and Johnson, 2003; Boersma and Hayes,
2001).

erations. The model is initialized with a ran-
dom markedness matrix drawn from the IBP and
weights from the exponential prior. We ran ver-
sions of the model with parameter settings be-
tween 0.01 and 1 for α, 0.05 and 0.5 for η, and
2 and 5 for K∗. All these produced quantitatively
similar results; we report values for α = 1, η =
0.5, and K∗ = 5, which provides the least bias
toward small constraint sets.

To establish performance for the phonological
standard, we use the IBPOT learner to find con-
straint weights but do not update M . The resultant
learner is essentially MaxEnt OT with the weights
estimated through Metropolis sampling instead of
gradient ascent. This is done so that the IBPOT
weights and phonological standard weights are
learned by the same process and can be compared.
We use the same parameters for this baseline as
for the IBPOT tests. The results in this section are
based on nine runs each of IBPOT and MEOT; ten
MEOT runs were performed but one failed to con-
verge and was removed from analysis.

4.3 Results

A successful set of learned constraints will satisfy
two criteria: achieving good data likelihood (no
worse than the phonological-standard constraints)
and acquiring constraint violation profiles that are
phonologically interpretable. We find that both of
these criteria are met by IBPOT on Wolof.

Likelihood comparison First, we calculate the
joint probability of the data and model given the
priors, p(Y,M,w|F, α), which is proportional to
the product of three terms: the data likelihood
p(Y |M,F,w), the markedness matrix probabil-
ity p(M |α), and the weight probability p(w). We
present both the mean and MAP values for these
over the final 1000 iterations of each run. Results
are shown in Table 1.

All eight differences are significant according
to t-tests over the nine runs. In all cases but mean
M , the IBPOT method has a better log-probability.
The most important differences are those in the
data probabilities, as the matrix and weight prob-
abilities are reflective primarily of the choice of
prior. By both measures, the IBPOT constraints
explain the observed data better than the phono-
logically standard constraints.

Interestingly, the mean M probability is lower
for IBPOT than for the phonological standard.
Though the phonologically standard constraints

1099



MAP Mean
IBPOT PS IBPOT PS

Data -1.52 -3.94 -5.48 -9.23
M -51.7 -53.3 -54.7 -53.3
w -44.2 -71.1 -50.6 -78.1

Joint -97.4 -128.4 -110.6 -140.6

Table 1: Data, markedness matrix, weight vec-
tor, and joint log-probabilities for the IBPOT and
the phonological standard constraints. MAP and
mean estimates over the final 1000 iterations for
each run. All IBPOT/PS differences are significant
(p < .005 for MAP M ; p < .001 for others).

exist independently of the IBP prior, they fit the
prior better than the average IBPOT constraints do.
This shows that the IBP’s prior preferences can be
overcome in order to have constraints that better
explain the data.

Constraint comparison Our second criterion
is the acquisition of meaningful constraints,
that is, ones whose violation profiles have
phonologically-grounded explanations. IBPOT
learns the same number of markedness constraints
as the phonological standard (two); over the final
1000 iterations of the model runs, 99.2% of the it-
erations had two markedness constraints, and the
rest had three.

Turning to the form of these constraints, Figure
2 shows violation profiles from the last iteration
of a representative IBPOT run.7 Because vowel
heights must be faithful between input and out-
put, the Wolof data is divided into nine separate
paradigms, each containing the four candidates
(ATR/RTR × ATR/RTR) for the vowel heights in
the input.

The violations on a given output form only
affect probabilities within its paradigm. As a
result, learned constraints are consistent within
paradigms, but across paradigms, the same con-
straint may serve different purposes.

For instance, the strongest learned markedness
constraint, shown as M1 in Figure 2, has the same
violations as the top-ranked constraint that ac-
tively distinguishes between candidates in each
paradigm. For the five paradigms with at least
one high vowel (the top row and left column),
M1 has the same violations as *I, as *I penal-
izes some but not all of the candidates. In the

7Specifically, from the run with the median joint posterior.

other four paradigms, *I penalizes none of the
candidates, and the IBPOT learner has no rea-
son to learn it. Instead, it learns that M1 has
the same violations as HARMONY, which is the
highest-weighted constraint that distinguishes be-
tween candidates in these paradigms. Thus in the
high-vowel paradigms, M1 serves as *I, while in
the low/mid-vowel paradigms, it serves as HAR-
MONY.

The lower-weighted M2 is defined noisily, as
the higher-ranked M1 makes some values of M2
inconsequential. Consider the top-left paradigm of
Figure 2, the high-high input, in which only one
candidate does not violate M1 (*I). Because M1
has a much higher weight than M2, a violation of
M2 has a negligible effect on a candidate’s prob-
ability.8 In such cells, the constraint’s value is in-
fluenced more by the prior than by the data. These
inconsequential cells are overlaid with grey stripes
in Figure 2.

The meaning of M2, then, depends only on the
consequential cells. In the high-vowel paradigms,
M2 matches HARMONY, and the learned and stan-
dard constraints agree on all consequential viola-
tions, despite being essentially at chance on the in-
distinguishable violations (58%). On the non-high
paradigms, the meaning of M2 is unclear, as HAR-
MONY is handled by M1 and *I is unviolated. In
all four paradigms, the model learns that the RTR-
RTR candidate violates M2 and the ATR-ATR can-
didate does not; this appears to be the model’s at-
tempt to reinforce a pattern in the lowest-ranked
faithfulness constraint (PARSE[atr]), which the
ATR-ATR candidate never violates.

Thus, while the IBPOT constraints are not
identical to the phonologically standard ones,
they reflect a version of the standard constraints
that is consistent with the IBPOT framework.9

In paradigms where each markedness constraint
distinguishes candidates, the learned constraints
match the standard constraints. In paradigms
where only one constraint distinguishes candi-
dates, the top learned constraint matches it and the
second learned constraint exhibits a pattern con-
sistent with a low-ranked faithfulness constraint.

8Given the learned weights in Fig. 2, if the losing candi-
date violates M1, its probability changes from 10−12 when
the preferred candidate does not violate M2 to 10−8 when it
does.

9In fact, it appears this constraint organization is favored
by IBPOT as it allows for lower weights, hence the large dif-
ference in w log-probability in Table 1.

1100



*ɪ Harmony M1 M2 *ɪ Harmony M1 M2 *ɪ Harmony M1 M2
iti eti əti
ɪti ɛti ati
itɪ etɪ ətɪ
ɪtɪ ɛtɪ atɪ
ite ete əte
ɪte ɛte ate
itɛ etɛ ətɛ
ɪtɛ ɛtɛ atɛ
itə etə ətə
ɪtə ɛtə atə
ita eta əta
ɪta ɛta ata

LearnedPhono. Std.

hi
hi

hi
mid

hi
lo

Phono. Std. Learned

mid
lo

mid
mid

mid
hi

Phono. Std. Learned

lo
hi

lo
mid

lo
lo

Figure 2: Phonologically standard (*I, HARMONY) and learned (M1,M2) constraint violation profiles for
the output forms. Learned weights for the standard constraints are -32.8 and -15.3; for M1 and M2, they
are -26.5 and -8.4. Black indicates violation, white no violation. Grey stripes indicate cells whose values
have negligible effects on the probability distribution.

5 Discussion and Future Work

5.1 Relation to phonotactic learning

Our primary finding from IBPOT is that it is possi-
ble to identify constraints that are both effective at
explaining the data and representative of theorized
phonologically-grounded constraints, given only
input-output mappings and faithfulness violations.
Furthermore, these constraints are successfully ac-
quired without any knowledge of the phonological
structure of the data beyond the faithfulness vio-
lation profiles. The model’s ability to infer con-
straint violation profiles without theoretical con-
straint structure provides an alternative solution to
the problems of the traditionally innate and univer-
sal OT constraint set.

As it jointly learns constraints and weights,
the IBPOT model calls to mind Hayes and
Wilson’s (2008) joint phonotactic learner. Their
learner also jointly learns weights and constraints,
but directly selects its constraints from a composi-
tional grammar of constraint definitions. This lim-
its their learner in practice by the rapid explosion
in the number of constraints as the maximum con-
straint definition size grows. By directly learning
violation profiles, the IBPOT model avoids this ex-
plosion, and the violation profiles can be automat-
ically parsed to identify the constraint definitions
that are consistent with the learned profile. The
inference method of the two models is different
as well; the phonotactic learner selects constraints
greedily, whereas the sampling on M in IBPOT
asymptotically approaches the posterior.

The two learners also address related but dif-
ferent phonological problems. The phonotactic

learner considers phonotactic problems, in which
only output matters. The constraints learned by
Hayes and Wilson’s learner are essentially OT
markedness constraints, but their learner does not
have to account for varied inputs or effects of faith-
fulness constraints.

5.2 Extending the learning model

IBPOT, as proposed here, learns constraints based
on binary violation profiles, defined extensionally.
A complete model of constraint acquisition should
provide intensional definitions that are phonolog-
ically grounded and cover potentially non-binary
constraints. We discuss how to extend the model
toward these goals.

IBPOT currently learns extensional constraints,
defined by which candidates do or do not violate
the constraint. Intensional definitions are needed
to extend constraints to unseen forms. Post hoc vi-
olation profile analysis, as in Sect. 4.3, provides
a first step toward this goal. Such analysis can
be integrated into the learning process using the
Rational Rules model (Goodman et al., 2008) to
identify likely constraint definitions composition-
ally. Alternately, phonological knowledge could
be integrated into a joint constraint learning pro-
cess in the form of a naturalness bias on the con-
straint weights or a phonologically-motivated re-
placement for the IBP prior.

The results presented here use binary con-
straints, where each candidate violates each con-
straint only once, a result of the IBP’s restriction
to binary matrices. Non-binarity can be handled
by using the binary matrix M to indicate whether
a candidate violates a constraint, with a second

1101



distribution determining the number of violations.
Alternately, a binary matrix can directly capture
non-binary constraints; Frank and Satta (1998)
converted existing non-binary constraints into a
binary OT system by representing non-binary con-
straints as a set of equally-weighted overlapping
constraints, each accounting for one violation. The
non-binary harmony constraint, for instance, be-
comes a set {*(at least one disharmony), *(at least
two disharmonies), etc.}.

Lastly, the Wolof vowel harmony problem pro-
vides a test case with overlaps in the candidate sets
for different inputs. This candidate overlap helps
the model find appropriate constraint structures.
Analyzing other phenomena may require the iden-
tification of appropriate abstractions to find this
same structural overlap. English regular plurals,
for instance, fall into broad categories depending
on the features of the stem-final phoneme. IBPOT
learning in such settings may require learning an
appropriate abstraction as well.

6 Conclusion

A central assumption of Optimality Theory has
been the existence of a fixed inventory of uni-
versal markedness constraints innately available to
the learner, an assumption by arguments regarding
the computational complexity of constraint iden-
tification. However, our results show for the first
time that nonparametric, data-driven learning can
identify sparse constraint inventories that both ac-
curately predict the data and are phonologically
meaningful, providing a serious alternative to the
strong nativist view of the OT constraint inventory.

Acknowledgments

We wish to thank Eric Baković, Emily Mor-
gan, Mark Myslı́n, the UCSD Computational Psy-
cholinguistics Lab, the Phon Company, and the re-
viewers for their discussions and feedback on this
work. This research was supported by NSF award
IIS-0830535 and an Alfred P. Sloan Foundation
Research Fellowship to RL.

References

Arto Anttila. 1997. Variation in Finnish phonology
and morphology. Ph.D. thesis, Stanford U.

Diana Archangeli and Douglas Pulleyblank. 1994.
Grounded phonology. MIT Press.

Paul Boersma. 1999. Empirical tests of the Gradual
Learning Algorithm. Linguistic Inquiry, 32:45–86.

Paul Boersma and Bruce Hayes. 2001. Optimality-
theoretic learning in the Praat program. In Proceed-
ings of the Institute of Phonetic Sciences of the Uni-
versity of Amsterdam.

Stephen Della Pietra, Vincent Della Pietra, and John
Lafferty. 1997. Inducing features of random fields.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 19:380–393.

Robert Frank and Giorgio Satta. 1998. Optimality the-
ory and the generative complexity of constraint vio-
lability. Computational Linguistics, 24:307–315.

Sharon Goldwater and Mark Johnson. 2003. Learning
OT constraint rankings using a Maximum Entropy
model. In Proceedings of the Workshop on Variation
within Optimality Theory.

Noah Goodman, Joshua Tenebaum, Jacob Feldman,
and Tom Griffiths. 2008. A rational analysis of rule-
based concept learning. Cognitive Science, 32:108–
154.

Dilan Görür, Frank Jäkel, and Carl Rasmussen. 2006.
A choice model with infinitely many latent features.
In Proceedings of the 23rd International Conference
on Machine Learning.

Thomas Griffiths and Zoubin Ghahramani. 2005. Infi-
nite latent feature models and the Indian buffet pro-
cess. Technical Report 2005-001, Gatsby Computa-
tional Neuroscience Unit.

Bruce Hayes and Colin Wilson. 2008. A maximum en-
tropy model of phonotactics and phonotactic learn-
ing. Linguistic Inquiry, 39:379–440.

Bruce Hayes. 1999. Phonetically driven phonology:
the role of optimality theory and inductive ground-
ing. In Darnell et al, editor, Formalism and Func-
tionalism in Linguistics, vol. 1. Benjamins.

Jeffrey Heinz, Gregory Kobele, and Jason Riggle.
2009. Evaluating the complexity of Optimality The-
ory. Linguistic Inquiry.

Brett Hyde. 2012. Alignment constraints. Natural
Language and Linguistic Theory, 30:789–836.

William Idsardi. 2006. A simple proof that Optimal-
ity Theory is computationally intractable. Linguistic
Inquiry, 37:271–275.

Frank Keller. 2000. Gradience in grammar: Ex-
perimental and computational aspects of degrees of
grammaticality. Ph.D. thesis, U. of Edinburgh.

John McCarthy. 2008. Doing Optimality Theory.
Blackwell.

Daniel Navarro and Tom Griffiths. 2007. A nonpara-
metric Bayesian method for inferring features from
similarity judgments. In Advances in Neural Infor-
mation Processing Systems 19.

1102



Alan Prince and Paul Smolensky. 1993. Optimality
theory: Constraint interaction in generative gram-
mar. Technical report, Rutgers Center for Cognitive
Science.

Jason Riggle. 2009. Generating contenders. Rutgers
Optimality Archive, 1044.

Jennifer Smith. 2004. Making constraints composi-
tional: toward a compositional model of Con. Lin-
gua, 114:1433–1464.

William Stokoe. 1960. Sign Language Structure. Lin-
stok Press.

Bruce Tesar and Paul Smolensky. 2000. Learnability
in Optimality Theory. MIT Press.

1103


