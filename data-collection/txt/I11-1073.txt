















































Distributed Minimum Error Rate Training of SMT using Particle Swarm Optimization


Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 649–657,
Chiang Mai, Thailand, November 8 – 13, 2011. c©2011 AFNLP

Distributed Minimum Error Rate Training of SMT
using Particle Swarm Optimization

Jun Suzuki, Kevin Duh, and Masaaki Nagata
NTT Communication Science Laboratories, NTT Corp.

2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237 Japan
{suzuki.jun, kevin.duh, nagata.masaaki}@lab.ntt.co.jp

Abstract

The direct optimization of a translation
metric is an integral part of building state-
of-the-art SMT systems. Unfortunately,
widely used translation metrics such as
BLEU-score are non-smooth, non-convex,
and non-trivial to optimize. Thus, stan-
dard optimizers such as minimum error
rate training (MERT) can be extremely
time-consuming, leading to a slow turn-
around rate for SMT research and exper-
imentation. We propose an alternative ap-
proach based on particle swarm optimiza-
tion (PSO), which can easily exploit the
fast growth of distributed computing to
obtain solutions quickly. For example in
our experiments on NIST 2008 Chinese-
to-English data with 512 cores, we demon-
strate a speed increase of up to 15x and
reduce the parameter tuning time from 10
hours to 40 minutes with no degradation in
BLEU-score.

1 Introduction

Recent statistical machine translation (SMT) sys-
tems employ a linear combination of several
model components, such as translation models,
language models, and reordering models. Trans-
lation is performed by selecting the most-likely
translation, which is the candidate translation with
the highest score based on the different model
components. We usually refer to this search pro-
cess as ‘decoding’. Although the development of
decoding algorithms is a key topic in SMT re-
search, if we are to construct better SMT systems
it is also important to find a way to determine the
weights of different model components. We refer
to this process as ‘parameter tuning’.

The current standard strategy for tuning the pa-
rameters of SMT systems is to search for the
weights that maximize a given translation quality

metric such as BLEU-score (Papineni et al., 2002).
In fact, minimum error rate training (MERT) pro-
posed by (Och, 2003) is the most widely used pa-
rameter tuning method in SMT community. This
is because, empirically, we obtain better trans-
lation system performance by directly optimiz-
ing the translation metric than by maximizing the
likelihood function. However, translation met-
rics such as BLEU-score are often non-smooth,
non-convex, and non-trivial to optimize, and di-
rect maximization does not allow us simply to ap-
ply well-known fast and robust optimization tech-
niques such as the gradient-ascent method. This
restriction makes the parameter tuning process ex-
tremely slow.

In this paper, we propose a novel distributed
MERT framework based on particle swarm opti-
mization (PSO) (Kennedy and Eberhart, 1995),
a population based stochastic optimization tech-
nique, to improve the slow parameter tuning pro-
cess. The main characteristics of our method are
that: (1) it directly optimizes a metric such as
BLEU-score, (2) it greatly reduces the parame-
ter tuning time compared with the conventional
MERT, and (3) it is highly scalable, meaning that
additional distributed processors lead to better and
faster performance.

Our main motivation is to improve the experi-
ment turn-around time for SMT system develop-
ment. A faster parameter tuning algorithm would
have a positive impact on research on all the com-
ponents of the SMT system. Imagine a researcher
designing a new pruning algorithm for decoding,
a new word alignment model, or a new domain
adaptation method. Any of these methods need
to be evaluated in the context of a full SMT sys-
tem, which requires parameter tuning. If we can
reduce the parameter tuning time from 10 hours to
1 hour, this can greatly increase the pace of inno-
vation. Thus our motivation is orthogonal to re-
cent research on improving MERT, such as efforts
to escape local maxima problems (Cer et al., 2008;

649



Foster and Kuhn, 2009; Moore and Quirk, 2008),
or incorporate lattices (Macherey et al., 2008).

2 Parameter Tuning for SMT Systems

Most recently developed SMT systems consist
of several model components, such as translation
models, language models, and reordering models.
To combine evidence obtained from these differ-
ent components, we often define a discriminative
(log-)linear model.

Suppose the SMT system has D components.
The log probabilities of the components are usu-
ally treated as features in the discriminative model.
We denote the d-th feature, or log probability of
the d-th component given a source sentence f and
its translation e, as φd(e, f). We also denote the
d-th weight as λd. Then, finding the most likely
translation ê of a given source sentence f with the
SMT system can be written in the following max-
imization problem:

ê = arg max
e

∑

d={1,...,D}
λdφd(e, f). (1)

This process is called ‘decoding’ in SMT.
Next, to obtain better translation quality for any

translations, we need somehow to tune the com-
ponent weights λd for all d. The current standard
strategy for parameter tuning is to directly maxi-
mize a translation quality measure such as BLEU-
score rather than likelihood.

Suppose we have a dataset consisting of S sen-
tences. Let fs be the s-th input sentence (source
language) in the tuning dataset. We also sup-
pose that each fs has Q reference translations that
are usually generated by hand. Thus, let rs,q be
the q-th reference translation of fs. We write the
weights in the vector representation as, for exam-
ple, λ = {λd}Dd=1, and a system translation of fs
obtained when the weights are λ as ê(f , λ) to pro-
vide a better explanation. Then, the direct maxi-
mization of a translation metric M can be written
in the following form:

λ∗ = arg max
λ

M({fs, {rs,q}Qq=1, ês(fs, λ)}Ss=1).
(2)

where λ∗ represents the optimal solution.

2.1 Outline of Och’s MERT

The most widely used parameter tuning frame-
work for solving Equation 2 in SMT is MERT

proposed by (Och, 2003). There are several vari-
ations for updating weights during the iterative
tuning process in MERT. The most commonly
used algorithm for MERT is usually called Koehn-
coordinate descent (KCD), which is used in the
MERT utility packaged in the popular Moses sta-
tistical machine translation system (Koehn et al.,
2007). Another choice is Powell’s method that
was advocated when MERT was first introduced
for SMT (Och, 2003). Since KCD tends to be
marginally more effective at optimizing the MERT
objective, and is much simpler to implement than
Powell’s method, this paper focuses only on KCD.

KCD is a variant of a coordinate ascent (or
descent) algorithm. At each iteration, it moves
along the coordinate, which allows for the great-
est progress of the maximization. The routine per-
forms a trial line maximization along each coordi-
nate to determine which one should be selected. It
then updates the weight vector with the coordinate
that it found to be the best objective in the trial.

To perform an iterative parameter update with
MERT, it is necessary to evaluate the system trans-
lation quality given by the current weights by the
translation metric to be optimized. This process
obviously requires us to perform decoding (Equa-
tion 1), and decoding is usually a very expensive
process. Thus, it often becomes infeasible to un-
dertake decoding every iteration if the size of the
tuning dataset is relatively large. To overcome this
issue, Och (2003) has also introduced the N -best
approximation method. This method separates de-
coding and the parameter tuning process into an
outer and an inner loop. The outer loop first runs
the decoder over the source sentences in the tun-
ing dataset with the current weights to generate
N -best lists of translations. Then, the method
employs the inner loop procedure to optimize the
weights based on those N -best lists instead of de-
coding the tuning dataset. After obtaining the op-
timal weights from the inner loop, we repeat the
outer loop to generate a new N -best list. Figure
1 shows the system outline, which is described in
detail elsewhere (Bertoldi et al., 2009).

We note here that the method proposed in this
paper essentially involves the replacement of the
inner loop algorithm of the conventional MERT.

3 Particle Swarm Optimization (PSO)

Particle Swarm Optimization (PSO) is an (itera-
tive) stochastic optimization technique proposed

650



Decoder results

(n-best lists)

Tuning dataset

decoder

scorer

References

Translation 

metric

Model

components

Outer loop

Inner loop

optimizer

final 

weights

weights

weights

(i.e., BLEU-score)

Figure 1: System outline of MERT proposed by
(Och, 2003); This system diagram was first pub-
lished in (Bertoldi et al., 2009)

in (Kennedy and Eberhart, 1995). This optimiza-
tion technique is explained in terms of emulating
the social behavior of flocks of birds and shoals
of fish, or taking advantage of the concept of the
social sharing of information.

The basic strategy of this optimization tech-
nique is that each particle flies individually
through the search space to find the best position
in the search space. By this iterative search pro-
cess, each particle can learn from the experience
of other particles in the same population (called a
swarm). In other words, each particle in the itera-
tive search process would adjust its flying velocity
as well as position based on both its own acquain-
tance and the flying experience of other particles
in the swarm. PSO has been shown to be effec-
tive in solving a variety of complex optimization
problems in practice. Thus, PSO may also work
relatively well in MERT since optimizing transla-
tion metric such as BLEU-score is also a complex
optimization problem.

3.1 Basic definition
Suppose we have a D-dimensional problem space
(search space) given by the task at hand. Then,
we also assume that we have an objective function
F , which is generally called a fitness function in
the context of PSO, to evaluate the solution. Basi-
cally, solving the task is equivalent to either max-
imizing or minimizing the objective function. For
example, with the parameter tuning of SMT sys-
tems, the objective function F is BLEU-score, and
the solution should be the parameter set that maxi-
mizes the BLEU-score over a given tuning dataset.
Hereafter, we assume a maximization problem.

For PSO, we assume that the swarm consists of
K particles. Each individual particle Pk, where
k ∈ {1, . . . , K}, can be represented as a three-
tuple Pk = (xk,vk,bk), where xk is the cur-
rent position in the search space, vk is the current
velocity, and bk is the personal best position in
the search space. Note that xk, vk,and bk are all
represented as D-dimensional vectors. As briefly
explained in Section 3, PSO is an iterative opti-
mization technique. The personal best position,
bk, corresponds to the position in the search space
where particle k has the largest value of objective
function F over all the past iterations. Hereafter,
let t represent the PSO iteration counter, where
t ∈ {1, . . . , T}, and T represents the maximum
iteration number given by a user, or is possibly set
at infinity. In our case, we set T = 100, 000.

Formally, the personal best values for the k-th
particle at the t-th iteration, bk(t), is updated by
the following equation:

bk(t + 1) ={
xk(t + 1) if F (xk(t + 1)) > F (bk(t))
bk(t) otherwise

,(3)

where we set bk(0) = xk(0) for all k.
The position yielding the largest objective

among all the particles in the swarm is called the
global best position. We denote this global best
position as g, and denote the global best position
at t-iteration as g(t). g(t) can be easily obtained
by finding the bk(t) that has the largest objective,
which is written as follows:

g(t) = arg max
b∈{b1(t),b2(t),...,bK(t)}

F (b). (4)

We assume U(a, b) is a function that returns a
value between a and b drawn from a uniform dis-
tribution. We denote U(a, b) as a D-dimensional
vector all of whose elements are U(a, b). Then,
the iterative PSO tuning process is mainly built on
the following equations:

vk(t + 1) = ξ(t)vk(t)
+c1U(0, 1)(bk(t) − xk(t))
+c2U(0, 1)(g(t) − xk(t)),

(5)

xk(t + 1) = xk(t) + vk(t + 1). (6)

where ξ is the inertia weight of the past velocity,
and c1 and c2 are acceleration constants regulat-
ing the relative velocities with respect to the best
personal and global positions. We use c1 = 2.0,

651



c2 = 2.0, and ξ(t) = 1.0 − t/T , which are one
standard setting for PSO. We also define vk(0) =
U(−1, 1) and xk(0) = U(−1, 1) for all k.

To summarize the process, the velocities vk for
all particles Pk are individually updated at the be-
ginning of each iteration t by using the (personal)
past velocity, and information about the personal
and global best position. The new velocity for
each particle is then added to its own current posi-
tion xk to obtain the next position of the particle.
After that, each particle updates its personal best
position by using Equation 3, and finally the global
best position of the swarm is updated by the mu-
tual sharing of the personal best positions. PSO
performs the above process iteratively until con-
vergence is reached or iterations attain the maxi-
mum number T defined by the user.

The key feature of the PSO architecture is that
information regarding the global best position g is
shared by all particles as shown in Equation 5.

3.2 Extension to guarantee local convergence
The standard PSO algorithm described in the pre-
vious section does not guarantee convergence on a
local maximum. It merely means that all the par-
ticles have converged on the best position discov-
ered so far by the swarm. To address this issue,
we use the modified version of PSO proposed in
(van den Bergh and Engelbrecht, 2002) that can
guarantees convergence to a local maximum. The
basic idea of the modification is allow the global
best particle to move until it has reached a local
maximum. To achieve this, they introduced a new
velocity update equation for the global best parti-
cle. Note that particles other than the global best
particle in the swarm continue to use the usual ve-
locity update as shown in Equation 5.

Let τ be the index of the global best particle.
Then, we use the following equation to update the
velocity of the global best particle at the t-th iter-
ation:

vτ (t + 1) = −xτ (t) + g(t) + ξ(t)vτ (t)
+ρ(t)U(−1, 1), (7)

where ρ is a scaling factor of the stochastic term
U(−1, 1), which is defined as follows:

ρ(t + 1) =





2ρ(t) if #S > Ts
0.5ρ(t) if #F > Tf
ρ(t) otherwise

, (8)

where #S and #F , respectively, denote the num-
ber of consecutive failures or successes in finding

a new global best point where a failure is defined
as f(g(t)) = f(g(t − 1)).

Then, in the same manner as Equation 6, the
new position can be calculated by adding the new
velocity:

xτ (t + 1) = xτ (t) + vτ (t + 1)
= g(t) + ξ(t)vτ (t) + ρ(t)U(−1, 1).

(9)
The −xτ (t) term in the velocity update is can-
celed when updating the position. This means that
a new position is always updated from the global
best position g(t). This is one of the key tricks
of the modification; the global best particle always
searches for a new position around the current best
position until new global best position is found. ρ
also plays an important role in guaranteeing the
locally convergence of the method. The diameter
of this search area is controlled by the parameter
ρ. The updating of ρ means that if the global best
objective function value does not change, then ρ
shrinks to half its original size and the search space
around the global best position becomes smaller.
The initial default value of ρ(0) = 1.0.

Finally, if we cannot find a new global best po-
sition around the current global best position in
a certain number of iterations Tc then the current
global best position can be considered a local max-
imum. We use Tc = 15.

A proof of guaranteed convergence to lo-
cal maxima for this algorithm can be found in
(van den Bergh and Engelbrecht, 2002). Note that
this modification still does not guarantee conver-
gence to the global optimum position unless the
objective function is a convex function.

4 MERT-PSO for SMT

This section describes a way to incorporate PSO
into the MERT framework. First, the position x
in PSO corresponds to the component weights in
the SMT system λ. Next, the objective function F
in PSO can be defined as a translation metric such
as BLEU-score M shown in Equation 2. There-
fore, in our case, F is calculated by using a tun-
ing dataset D and system translations of the tun-
ing dataset given by the current weight (position)
x. We denote a translation metric such as BLEU-
score as F (x, D) for MERT-PSO.

In PSO, each particle can individually update
its velocity, position and personal best position.
Thus, we design MERT-PSO to work in a par-
allel computing environment. Basically, we uti-

652



Algorithm: MERT-PSO
Input: K: number of particles, D: degree of parame-
ter dimension, T : maximum number of iterations, Tc:
threshold of convergence evaluation, I: iteration number
for update trial, D: tuning dataset, F : objective function.
Main procedure:
1: initParticle(Pk) ∀k in parallel processing
2: (τ,g(0))← Eq. 4
3: T ′ ← 0
4: for t in 0, . . . , T − 1
5: execParticle(t, Pk, τ ) ∀k in parallel processing
6: (τ,g(t + 1))← Eq. 4
7: T ′ = T ′ + 1 if F (g(t + 1),D) = F (g(t),D),

or T ′ = 0 otherwise
8: break if T ′ ≥ Tc
9: end for

10: output g(t + 1)
procedure: initParticle(Pk)
1: v′k ← U(−1, 1) and x′k ← U(−1, 1)
2: vk(0)← P(v′k) and xk(0)← P ′(x′k)
3: bk(0)← xk(0)

procedure: execParticle(t, Pk, τ)
1: for i in 1, . . . , I
2: v′ ←V(k, t) or V′(k, t) if k = τ (Eq. 5 or 7)
3: vtmp ← P(v′) (Eq. 10)
4: x′ ← xk(t) + vtmp (Eq. 6)
5: xtmp ← P ′(x′) (Eq. 11)
6: if F (xtb,D) < F (xtmp,D)
7: xtb ← xtmp and vtb ← vtmp
8: end if
9: end for

10: xk(t + 1)← xtb, and vk(t + 1)← vtb
11: bk(t + 1)← Eq. 3 using D

Figure 2: MERT-PSO algorithm implemented in
the inner loop of MERT.

lize a master-slave architecture for parallelization.
We simply allocate one particle to one slave node
(or processor), and the master node manages the
global best position and the convergence test.

4.1 Extensions
This section describes our four proposed exten-
sions for PSO that make it possible to fit PSO to
parameter tuning for SMT systems.

The value of each dimension of every velocity
is usually clamped to the range [−vmax, vmax] to
avoid having too large an absolute velocity and
thus realizing better convergence. Here, we intro-
duce another procedure that can also avoid having
velocities that are too large. Our proposed proce-
dure is well-known as a ‘norm projection’ in the
discriminative machine learning community, i.e.,
(Shalev-Shwartz et al., 2007), which can be de-
fined as follows:

P(v) = min
{

1,
β

||v||p

}
v, (10)

where β represents the radius of Lp-norm ball. In

our experiments, we set β = 1 and p = 1. We
project the velocity vector into the Lp-norm ball
immediately after we update the velocities.

Next, in a similar manner to Equation 10, we
also project the current positions for all particles
‘onto’ Lp-norm ball after updating. We use the
following function:

P ′(x) = 1||x||p
x, (11)

Suppose x′ = P(x), then note that ê(f ,x) and
ê(f ,x′) for any f can be identical. This is be-
cause we assume the translation models used in
our method to be the linear model described by
Equation 1. This assumption guarantees that any
system translation ê given by Equation 1 is never
changed as a result of this position projection.
This fact implies that we can find the solution onto
an Lp-norm ball with a fixed radius. Thus, this
projection may lead to faster convergence since it
enables us to reduce the search space of PSO.

Third, for each iteration, we update the veloc-
ity and position of each particle to those with
the best objective value among I trials, in our
case I = 10. Let the right-hand side of Equa-
tions 5 and 7 be V(k, t) and V′(τ, t), respectively,
that is V(k, t) = ξ(t)vk(t) + c1U(0, 1)(bk(t) −
xk(t)) + c2U(0, 1)(g(t) −xk(t)), and V′(τ, t) =
−xτ (t) + g(t) + ξ(t)vτ (t) + ρ(t)U(−1, 1). Both
V(k, t) and V′(τ, t) have randomness character-
ized by U. Therefore, we select the best position
and velocity in I random trials as the position and
velocity of t + 1 in t iterations. This extension re-
duces the number of inefficient searches (and also
the communication cost between particles). Thus,
this may also lead to a faster tuning process.

Finally, we slightly modify the update scheme
of ρ explained in Equation 8 to simplify the pro-
cess as follows:

ρ(t+1) =

{
0.5ρ(t) if F (g(t)) = F (g(t − 1))
1.0 otherwise

.

To summarize our method, Figure 2 shows its
overall algorithm.

4.2 Implementations
Basically, we implemented the PSO algorithm de-
scribed above in Moses, one of the leading open
source implementations of phrase-based machine
translation (Koehn et al., 2007). More specifically,
we substituted our PSO method for the inner loop

653



weightsweights

Decoder results

….

Tuning dataset

processor.1

decoder decoder decoder

processor.2 processor.K

particle.1 particle.2 Particle.K

processor.1 processor.Kprocessor.2 ….

MERT-PSO

Decoder results

Tuning dataset

decoder

processor.1

MERT

processor.1

Decoder results

….

Tuning dataset

processor.1

decoder decoder decoder

processor.2 processor.K

MERT MERT MERT

processor.1 processor.Kprocessor.2 ….
(merge)

A partitioned 

tuning dataset

Decoder results of 

a partitioned 

tuning dataset

Select weight set that 

gives the maximum BLUE 

on tuning dataset

Moses-MERT (original: single processor) Moses-MERT (parallel: processors=K) MERT-PSO (processors=K)

weights weights

final 

weights
final 

weights

final 

weights

weights

Figure 3: Outline process images (a) Moses-MERT (original), (b) Moses-MERT (our parallel version),
and (c) MERT-PSO

NIST-08 WMT-10
Source lang. Chinese German
Target lang. English English
# of sent. in tuning dataset (S) 2679 2524
# of reference per sent. (Q) 4 1
# of dimensions (D) 8 14
# of N -best per sent. (N ) 100 100

Table 1: Details of data used in our experiments.

of Moses MERT. The source code was written in
C++ with boost:::MPI libraries for parallelization.

Moreover, we also substituted the code we de-
veloped for the outer loop code to run a decoder
in parallel to work on a large number of computa-
tional resources such as cluster PCs. This is sim-
ply accomplished by separating the tuning dataset,
and then each computational resource executes the
decoder independently to decode part of the parti-
tioned dataset.

Additionally, in our experiments, we also im-
plemented a parallel version of Moses-MERT as
a competitor for comparison with our method. In
this case, we independently performed the inner-
loop algorithm of the original Moses-MERT in
many computers with randomly selected initial
weights. After completing all the Moses-MERT
procedures, we selected a weight set that provided
the best BLED-score.

Outline process images for three different im-
plementations are shown in Figure 3.

5 Experiments

In our experiments, we evaluated the effective-
ness of the proposed MERT-PSO in terms of both
performance and runtime by comparison with a
MERT package in Moses (Moses-MERT), and our
parallel extended version of Moses (Moses-MERT
parallel). All three algorithms use the Moses de-

coder (Koehn et al., 2007) to select the best trans-
lation given a source sentence (Equation 1).

We conducted our experiments on NIST-08 and
WMT-10 datasets. Table 1 summarizes the data
statistics used in our experiments. Note that the
tuning datasets are formed from NIST-04 and
NIST-05 test data for NIST-08, and WMT-09
test data for WMT-10. For both tasks, we train
phrase tables from the provided training data using
the standard GIZA++ pipeline and train language
models using SRILM. The feature set consists of
the standard 5 translation model probabilities, 1
language model probability, 1 distortion feature
and 1 word penalty feature for 8 features, and an
additional 6 reordering models for 14 features.

6 Results and Discussion

6.1 Evaluations for overall tuning process
Tables 2, and 3 show the results of our exper-
iments comparing the parameter tuning qualities
of the original Moses-MERT, Moses-MERT (par-
allel) and MERT-PSO. All the experiments were
performed ten times using different random seeds
for each trial. We assumed the number of avail-
able computational resources, which we refer to
as ‘#PN’, to be 512 in these experiments. In the
tables, Ave, Max., Min., and Std. represent the
average, maximum, minimum and standard devia-
tion of ten trials, respectively.

Clearly, MERT-PSO greatly reduced the total
runtime compared with the original Moses-MERT.
Although MERT-PSO used a lot more computa-
tional resources than the original Moses-MERT,
the original Moses-MERT can never achieve the
tuning speed of MERT-PSO.1 Additionally, we

1It should be noted that Moses-MERT (parallel) is our

654



Moses-MERT Moses-MERT MERT-PSO
(original) (#PN=512) (#PN=512)

BLEU Ave. 30.18 30.26 30.26
score Max. 30.25 30.28 30.30

Min. 30.06 30.24 30.20
Std. .0033 .0003 .0008

#.of Ave. 9.9 9.0 7.1
outer Min. 7 6 6
loop Max. 17 11 8

Std. 2.03 1.61 0.73
inner loop Ave. 01.00.16 01.01.45 00.05.21
total time Min. 00.26.48 00.26.06 00.03.40

(hh.mm.ss) Max. 02.31.39 01.31.09 00.07.14
opt. total Ave. 09.40.08 01.40.40 00.36.41

time Min. 06.44.39 00.51.58 00.27.26
(hh.mm.ss) Max. 13.28.29 02.19.26 00.43.20

Table 2: Results for NIST-08 dataset.

0:00:00

1:00:00

2:00:00

Moses-MERT

(original)

Moses-MERT

(#PN=512)

MERT-PSO

(#PN=512)

MERT

Decoder

Disk I/O

E
la

p
se

d
 t

im
e

 (
h

:m
m

:s
s)

(8.22.52)

Figure 4: Detailed rates of parameter tuning pro-
cess (inner loop), decoding (outer loop), and disk
I/O times in total runtimes for NIST-08 dataset.

can find the tendency that the standard deviations
of the BLEU-scores for MERT-PSO are relatively
small. This implies that MERT-PSO has the power
to produce a robust solution. This property is im-
portant for stochastic optimization algorithms.

The results of our developed parallel Moses-
MERT are largely similar to those obtained by
MERT-PSO in terms of BLEU-scores. However,
the average runtimes of MERT-PSO are at least
three times faster than those of Moses-MERT (par-
allel). These observations may be interesting;
PSO searches almost randomly for the model com-
ponent weights during the parameter tuning pro-
cess, but it can still find good weights sufficiently
quickly. The faster runtime of MERT-PSO is also
explained by this simple randomized update pro-
cedure of PSO in contrast to KCD used in Moses-
MERT, which tries to find the optimal coordinate
by using an iterative line search.

Another interesting finding is that MERT-PSO
tends to reduce the number of outer loops. This
can be a good characteristic for the current MERT
framework since decoding (outer loop) is usually
expensive.

own developed system that is not implemented in the orig-
inal Moses open source software.

Moses-MERT Moses-MERT MERT-PSO
(original) (#PN=512) (#PN=512)

BLEU Ave. 20.17 20.21 20.23
score Max. 20.21 20.24 20.26

Min. 20.06 20.13 20.19
Std. .0552 .0331 .0245

#.of Ave. 13.0 12.5 7.4
outer Min. 10 10 5
loop Max. 17 16 9

Std. 2.06 1.80 1.20
inner loop Ave. 03.40.22 03.18.43 00.09.09
total time Min. 02.02.11 02.12.57 00.04.11

(hh.mm.ss) Max. 05.55.01 05.14.53 00.13.23
opt. total Ave. 25.40.38 07.14.40 02.07.12

time Min. 20.08.22 05.20.47 01.15.40
(hh.mm.ss) Max. 37.51.22 10.04.13 02.23.24

Table 3: Results for WMT-10 dataset.

Figure 4 summarizes the parameter tuning pro-
cess (inner loop), decoding (outer loop), and disk
I/O times for each method for NIST-08 dataset.
Most SMT researchers would agree that the most
of the MERT runtime is spent on decoding (outer
loop). As shown in this figure, this is basically
true for Moses-MERT (original) when the tun-
ing dataset is large. However, with the parallel
method, it appears not always to be true. For
example, the dominant process of Moses-MERT
(parallel) is parameter tuning process (inner loop).
Thus, developing a faster parameter tuning algo-
rithms is still meaningful.

6.2 Evaluations for inner loop process

This section evaluates the compared methods in
terms of single inner loop process. To allow fair
comparisons, all the methods are evaluated using
the same N -best lists, even though running multi-
ple iterations of MERT would normally produce
different N -best lists. To perform this experi-
ment, we first constructed models using the origi-
nal Moses. Then, we utilized the generated inter-
mediate files for the experiments described in this
section.

6.2.1 Effect of parallelization
Figure 5 shows the effect of parallelization in
terms of BLEU-score and runtime. It is clear
that smaller #PN provided lower BLEU-score in
MERT-PSO. MERT-PSO generally requires a cer-
tain number of particles (processors) to work well.
It seems that we need at least 64 particles for a sta-
ble tuning in our setting. However, when MERT-
PSO employed sufficiently many particles, it out-
performed Moses-MERT and provided stable con-
vergence even though MERT-PSO is a stochastic
optimization method.

655



29.6

29.7

29.8

29.9

30.0

30.1

30.2

30.3

30.4

1111 4444 8888 16161616 32323232 64646464 128128128128 256256256256 555511112222

Moses-MERT MERT-PSO

B
L
E

U
 s

c
o

r
e

# of CPUs (fixed S=2678, N=900, D=8)

0

100

200

300

400

500

600

700

800

1111 4444 8888 16161616 32323232 64646464 128128128128 256256256256 555511112222

Moses-MERT MERT-PSO

# of CPUs (fixed S=2678, N=900, D=8)

E
la

p
se

d
ti

m
e

 [
se

c.
]

Figure 5: Runtimes and BLEU-score of changing
parallelization number in a single inner loop pro-
cess for NIST-08 dataset (vertical line at each bar
represents Std.).

Note that larger #PN provided better BLEU-
score but slower runtime in Moses-MERT. This
is because Moses-MERT (parallel) runs the orig-
inal MERT processes individually on every pro-
cessors. Thus, the runtime of Moses-MERT de-
pends on the slowest MERT process for all MERT
processes. Instead, it can select the weights that
provide the best BLEU score among all the results
of the MERT processes. This is the reason of this
observation.

6.2.2 Robustness against S and N
Figure 6 shows the runtimes against the average
number of N -best lists in a single inner loop,
where the number of sentences in a tuning set is
fixed, and runtimes against the sentences in a sin-
gle inner loop, where the average number of N -
best list is fixed.

We can find MERT-PSO has an almost linear
relation in both figures in the same way as Moses-
MERT. These figures also clarified that MERT-
PSO is very robust as regards increasing the num-
ber of sentences and the average N -best list size
per sentence.

6.3 Test data performance

Table 4 shows the average BLEU-scores provided
by ten models of Moses-MERT and MERT-PSO
with 512 parallel processing for the test data. We

0

500

1000

1500

2000

2500

3000

0 400 800 1200 1600

Moses-MERT

(#PN=32)

Moses-MERT

(#PN=128)

Moses-MERT

(#PN=512)

MERT-PSO

(#PN=32)

MERT-PSO

(#PN=128)

MERT-PSO

(#PN=512)

E
la

p
se

d
 T

Im
e

 [
se

c.
]

Average N-best list size per sample (fixed S=2524, D=14)

0

200

400

600

800

1000

1200

1400

0 500 1000 1500 2000 2500 3000

Moses-MERT

(#PN=32)

Moses-MERT

(#PN=128)

Moses-MERT

(#PN=512)

MERT-PSO

(#PN=32)

MERT-PSO

(#PN=128)

MERT-PSO

(#PN=512)

E
la

p
se

d
 T

Im
e

 [
se

c.
]

# of sentences (fixed N=700, D=14)

Figure 6: Runtimes vs. average N -best list size
per sentence (top), and number of sentences in tun-
ing dataset (bottom) in a single inner loop process
for WMT-10 dataset.

Moses-MERT MERT-PSO
(#PN=512) (#PN=512)

NIST-08 (Ch-En) Ave. 21.32 21.40
WMT-10 (Ge-En) Ave. 21.25 21.22

Table 4: Results for test data comparing Moses-
MERT (parallel: #PN=512) and MERT-PSO
(#PN=512).

confirmed that the translation qualities of MERT-
PSO for unseen sentences are nearly the same
level as those of Moses-MERT in terms of BLEU-
score. This empirical evidence encourage us to use
MERT-PSO as a replacement of Moses-MERT:
MERT-PSO can provide the same quality level
models as those provided by Moses-MERT with
much faster runtime.

7 Conclusion

Our main goal was to provide a method to im-
prove the experiment turn-around time for SMT
system development. This paper proposed a novel
distributed MERT framework based on particle
swarm optimization (MERT-PSO). When there are
abundant computational resources such as cluster
PCs, our method can provide very much faster pa-
rameter tuning for SMT systems while maintain-
ing the translation quality provided by the standard
parameter tuning algorithms such as BLEU-score.
Even though MERT-PSO is a stochastic approach,
the experimental results showed that MERT-PSO
is very robust, and in most cases, provides better
results than the original Moses-MERT.

656



References
Nicola Bertoldi, Barry Haddow, and Jean-Baptiste

Fouet. 2009. Improved Minimum Error Rate Train-
ing in Moses. Prague Bulletin of Mathematical Lin-
guistics, No. 91:7–16.

Daniel Cer, Dan Jurafsky, and Christopher D. Manning.
2008. Regularization and search for minimum er-
ror rate training. In Proceedings of the Third Work-
shop on Statistical Machine Translation, pages 26–
34, Columbus, Ohio, June. Association for Compu-
tational Linguistics.

George Foster and Roland Kuhn. 2009. Stabilizing
minimum error rate training. In Proceedings of the
Fourth Workshop on Statistical Machine Transla-
tion, pages 242–249, Athens, Greece, March. As-
sociation for Computational Linguistics.

James F. Kennedy and Russell C. Eberhart. 1995.
Particle Swarm Optimization. In Proceedings of
IEEE International Conference on Neural Networks,
pages 1942–1948.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Proceedings of the 45th Annual Meeting of
the Association for Computational Linguistics Com-
panion Volume Proceedings of the Demo and Poster
Sessions, pages 177–180, Prague, Czech Republic,
June. Association for Computational Linguistics.

Wolfgang Macherey, Franz Och, Ignacio Thayer, and
Jakob Uszkoreit. 2008. Lattice-based minimum er-
ror rate training for statistical machine translation.
In Proceedings of the 2008 Conference on Empiri-
cal Methods in Natural Language Processing, pages
725–734, Honolulu, Hawaii, October. Association
for Computational Linguistics.

Robert C. Moore and Chris Quirk. 2008. Random
restarts in minimum error rate training for statistical
machine translation. In Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics (Coling 2008), pages 585–592, Manchester, UK,
August. Coling 2008 Organizing Committee.

Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting of the Association for Com-
putational Linguistics, pages 160–167.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Research Report
RC22176, IBM Research Division, Thomas J. Wat-
son Research Center, pages 311–318.

Shai Shalev-Shwartz, Yoram Singer, and Nathan Sre-
bro. 2007. Pegasos: Primal Estimated sub-
GrAdient SOlver for SVM. In Proceedings of

the Twenty-Fourth International Conference on Ma-
chine Learning, pages 807–814.

Frans van den Bergh and Andries P. Engelbrecht. 2002.
A new locally convergent particle swarm optimizer.
In Proceedings of IEEE International Conference on
Systems, Man, and Cybernetics, pages 96–101.

657


