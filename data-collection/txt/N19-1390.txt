




































Combining Discourse Markers and Cross-lingual Embeddings for Synonym–Antonym Classification


Proceedings of NAACL-HLT 2019, pages 3899–3905
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

3899

Combining Discourse Markers and Cross-lingual Embeddings for
Synonym–Antonym Classification

Michael Roth1, Shyam Upadhyay2
1Institute for Natural Language Processing, University of Stuttgart

2Department of Computer and Information Science, University of Pennsylvania
rothml@ims.uni-stuttgart.de, shyamupa@seas.upenn.edu

Abstract

It is well-known that distributional seman-
tic approaches have difficulty in distinguish-
ing between synonyms and antonyms (Grefen-
stette, 1992; Padó and Lapata, 2003). Recent
work has shown that supervision available in
English for this task (e.g., lexical resources)
can be transferred to other languages via cross-
lingual word embeddings. However, this kind
of transfer misses monolingual distributional
information available in a target language,
such as contrast relations that are indicative
of antonymy (e.g., hot…while…cold). In this
work, we improve the transfer by exploit-
ing monolingual information, expressed in the
form of co-occurrences with discoursemarkers
that convey contrast. Our approach makes use
of less than a dozen markers, which can eas-
ily be obtained for many languages. Compared
to a baseline using only cross-lingual embed-
dings, we show absolute improvements of 4–
10% F1-score in Vietnamese and Hindi.

1 Introduction

Recent work has shown that monolingual word
embeddings in different languages can be aligned
in an unsupervised manner (Artetxe et al., 2018;
Kementchedjhieva et al., 2018). The resulting
cross-lingual embeddings can be used to share
supervision for lexical classification tasks across
languages, when annotated data is not available
in one language. For instance, a model for dis-
tinguishing lexical relations such as hypernymy
and meronymy can be transferred to other lan-
guages (Glavaš and Vulić, 2018). However, this
kind of transfer, using only cross-lingual em-
beddings, misses useful monolingual information
available in the target language.
In this paper, we consider one lexical clas-

sification task, namely the distinction between
synonyms and antonyms, which is important

English German

hot cold
new old

ruhig

kalt
kühl

hitzig
scharf
heiß

kalt …WOBEI …heiß
(‘cold …WHILE …hot’)

co-occurrences with
discourse markers

Figure 1: Supervision for distinguishing antonyms
from synonyms can be derived using discourse mark-
ers. Here, antonyms available in English (denoted
by solid edge between hot and cold) are translated
to German via cross-lingual word embeddings. Us-
ing co-occurrences with discourse markers indicative
of antonymy (shown in box), we can identify pairs of
words in the n-best translations (clouds) that are also
antonymous (e.g., dashed edge between kalt and heiß).

for downstream applications such as contradic-
tion detection (Harabagiu et al., 2006; Marneffe
et al., 2008; Voorhees, 2008) and machine trans-
lation (Marton et al., 2011). To facilitate better
transfer, we propose to use monolingual informa-
tion in the form of word co-occurrences in con-
trast relations, in addition to cross-lingual embed-
dings (see Figure 1). In particular, we utilize the
fact that discourse markers conveying contrast are
more likely to be surrounded by antonyms than
synonyms (e.g., hot…while…cold), as shown by
Roth and Schulte im Walde (2014).
Our analysis reveals that (1) fine-grained se-

mantic information that is required to distinguish
synonyms from antonyms is insufficiently pre-
served cross-lingually in word embeddings, but (2)
such information can be recovered (at least par-
tially) by relying on linguistic intuitions about con-
trast relations in discourse.



3900

2 Related Work

The identification of paradigmatic relations such
as synonymy and antonymy has been a task of
interest for more than a decade. Early work fo-
cused on the identification of instances of a sin-
gle relation: for example, Charles and Miller
(1989) investigated co-occurrences as an indicator
for antonymy, Hearst (1992) introduced a pattern-
based approach to identify hypernymy, and Ed-
monds and Hirst (2002) applied distributional
statistics to identify synonymy.
Beyond the identification of instances of a

particular relation, more recent approaches at-
tempt to distinguish relations such as synonymy
and antonymy, based on lexico-syntactic pat-
terns, distributional information, or combinations
of both (Lin et al., 2003; Shwartz and Dagan,
2016). As supervision for weighting different fea-
tures, most recent work makes use of lexical re-
sources and/or lists of affix patterns that indicate
contrast morphologically (Yih et al., 2012; Mo-
hammad et al., 2013; Ono et al., 2015).
Supervision for lexical classification tasks is

not available in all languages. To overcome this
difficulty, some approaches (Mrkšić et al., 2017;
Glavaš andVulić, 2018) combine resources for En-
glish and cross-lingual word embeddings to distin-
guish lexical relations in other languages. That is,
they train and test one model across different lan-
guages. In contrast, we propose to first use unsu-
pervised translation techniques to transfer supervi-
sion into a target language, given resources avail-
able in English. More specifically, our approach
transfers supervision using a combination of unsu-
pervised cross-lingual embeddings (Artetxe et al.,
2018) and word co-occurrences with discourse
markers that indicate contrast. In doing so, our
approach generalizes the discourse-marker based
model for relation classification by Roth and
Schulte imWalde (2014) to a cross-lingual setting.

3 Our Approach

In this work, we address the task of distinguishing
synonyms and antonyms cross-lingually: given
a word pair (a, b) in a target language, a model
trained in a different source language determines
whether this constitutes a synonym or an antonym
pair. Our approach consists of two main ingre-
dients: a translation module that creates training
data in a target language (see Figure 2), and a clas-
sification module that uses this data in a supervised

English

corpus
synonyms &
antonyms
⟨more,less⟩

German

corpus

vecmap

more

less
mehr

kaum

weniger

cross-lingual
distance
(see §3.1)

n-best
translations
⟨mehr,mehr⟩

⟨kaum,weniger⟩
re-ranking

discourse
cues

(see §3.2)

German
train data

⟨mehr,weniger⟩

Figure 2: In our approach, we create training data
in multiple languages by translating English data via
cross-lingual word embeddings and discourse cues.

fashion. Our focus is on the first part, which we
describe in more detail below. For classification,
we re-use the LexNet model by Shwartz and Da-
gan (2016), which is a feed-forward network that
uses distributional word representations as input.

3.1 Cross-lingual Embeddings for
Translation

Our transfer approach addresses a general setting
that only assumes availability of monolingual data.
Accordingly, we induce a translation dictionary of
synonyms and antonyms in an unsupervised way,
instead of relying on manually crafted dictionar-
ies. We achieve this by finding n-best translations
of English words in a cross-lingual word embed-
ding space. We create this space using vecmap,
a method that aligns and maps embedding spaces
in two languages (Artetxe et al., 2018). Formally,
we define the nth best translation w(n)t of a source
word ws to be the nth nearest neighbor in the joint
semantic space (based on cosine similarity).

3.2 Re-ranking n-best Translations
While 1st best translations are often accurate, er-
roneous translations occur for example when two
related words in a source language are close to the
same words in the target language (e.g., less and
more share the same nearest neighbor in Figure 2:
mehr ’more’). In such cases, we aim to use mono-
lingual information about lexical relations in the
form of discourse cues. Specifically, given two
antonymous words as and bs (henceforth as⊥ bs)



3901

Language Corpus size Data size Ratio
(in words) (in pairs) (#syn:#ant)

English (train) 2.1 B 10 932 50:50
German (dev) 0.7 B 811 52:48
Hindi 0.5 B 1 000 50:50
Vietnamese 0.2 B 353 45:55

Table 1: Data statistics of the classification datasets as
well as the corpora used to create word representations.
Note that the data used here consist of only synonyms
and antonyms (approximately in equal proportions).

in the source language, we want to choose transla-
tions a(i)t and b

(j)
t that are most likely antonymous

as well. We achieve this by re-ranking translations
a
(i)
t and b

(j)
t such that the probability Pr(a

(i)
t ⊥b

(j)
t )

of them appearing in contrast relations is maxi-
mized. We only assume a set of discourse mark-
ers M that indicate contrast as knowledge about
the target language. We approximate Pr(a(i)t ⊥
b
(j)
t ) by computing the pointwise mutual informa-
tion (PMI) between two terms, conditioned on co-
occurrence around a discourse markerm ∈ M :

Pr(a(i)t ⊥ b
(j)
t ) ∼ min

m∈M
log

N(m) n(a
(i)
t , b

(j)
t |m)

n(a
(i)
t |m) n(b

(j)
t |m)

whereN(m) is the frequency of discourse marker
m in the corpus, n(w|m) is the number of times
term w occurs with m, and n(w1, w2|m) is the
number of co-occurrences w1…m…w2. For sim-
plicity, we count all joint occurrences within a
sentence, regardless of sentence length and dis-
tance between words. In practice, the set M
is constructed by manually translating eight dis-
course markers that frequently indicate contrast re-
lations according to the Penn Discourse Treebank
2.0 (Prasad et al., 2007): although, by compari-
son, by contrast, however, nevertheless, nonethe-
less, though, and thus.

4 Experiments

Our experiments test the performance of an off-
the-shelf system for lexical relation classification
under different cross-lingual settings. In particu-
lar, we evaluate the performance of unsupervised
cross-lingual word embeddings and assess the ben-
efits of translation and re-ranking, taking into ac-
count word co-occurrences in contrast relations.

Experimental setup. For our experiments, we
use four languages: English, German, Hindi and

Vietnamese. The antonymy and synonymy dataset
by Nguyen et al. (2017) is used for training and
estimating an upper bound in English. For cross-
lingual development and hyper-parameter selec-
tion, we use the German dataset by Glavaš and
Vulić (2018). Specifically, we select the number of
hidden layers {0, 1}, learning rate {0.001,…,0.1},
dropout rate {0.0, 0.5}, and whether to include in-
formation on paths between words {yes, no}.1 As
examples of under-resourced languages, we eval-
uate on the Vietnamese dataset ViCon by Nguyen
et al. (2018) and on a new Hindi dataset, which we
crawled from hindi2dictionary.com.2 Note
that annotated data in these languages is held out
exclusively for testing.
The task addressed here is to distinguish syn-

onymous from antonymous words. Accordingly,
we consider only word pairs for training and test-
ing that are marked as antonyms or synonyms,
even if the original dataset also contains unrelated
words or other relations. Statistics of all consid-
ered word pairs, the ratio between synonyms and
antonyms, as well as sizes of the text corpora used
in our experiments are given in Table 1.

Models. We test our proposed approach against
two baselines: NoTrans andBestTrans. NoTrans
simply uses the training data in English and allows
us to test in how far semantic properties related to
the distinction between synonymy and antonymy
are preserved cross-lingually. BestTrans uses 1st
best translations of the English training data in a
target language, as described in Section 3.1.
Our own approach, henceforth called Ling-

Trans, is based on n-best translations and exploits
word co-occurrences in contrast relations for re-
ranking, as described in Section 3.2.
All three models take cross-lingual word em-

beddings as input. We created these as follows.
First, the unsupervised morphological analyzer of
Xu et al. (2018) is used to lemmatize the mono-
lingual corpora for the respective languages—the
German Wikipedia, the Vietnamese portion of the
LORELEI pack (Strassel and Tracey, 2016), and
the HindEnCorp corpus (Bojar et al., 2014). This
step ensures that we can compare the (stems of)

1Since we do not assume access to syntactic paths in the
target languages, we only experimented with lexical surface
paths and found them to consistently degrade performance.

2To verify the correctness of the crawled data, we asked
a native speaker to validate all instances. Since syn-
onym/antonym labels were derived automatically, validation
was only performed to remove noisy instances.



3902

LexNet-crosslingual de (dev) hi vi

NoTrans 59.9 54.6 42.2
BestTrans 62.2 59.2 46.9
LingTrans 64.2* 63.5* 56.8**

LexNet-monolingual (en) 70.1
+ path embeddings 74.3

Table 2: Macro-averaged F1-scores for crosslingual
synonymy/antonymy distinction in German (de), Hindi
(hi), and Vietnamese (vi). Significant differences
from NoTrans are marked by asterisk(s) (* p<0.1,
** p<0.01). Monolingual results in English (en) are
only shown for comparison.

word tokens in text to those of the word forms
that actually appear in the synonymy/antonymy
datasets. Note that, while we use an unsuper-
vised morphological analyzer, a stemmer can also
be used, if available for that language. Next,
we created monolingual embeddings for each lan-
guage using fastText (Bojanowski et al., 2017).
Finally, we applied the unsupervised variant of
vecmap (Artetxe et al., 2018) to compute align-
ments and cross-lingual mappings.
The word and discourse marker co-occurrence

counts required for our approach are computed on
the same monolingual corpora used for training
monolingual embeddings.

Results. Table 2 shows macro-averaged F1-
scores for crosslingual synonymy/antonymy dis-
tinction (top part) as well as monolingual results in
English for comparison (bottom part). The mono-
lingual results show that word embeddings pro-
vide appropriate information for classification in
most instances, achieving an F1-score of 70.1. The
comparatively low cross-lingual results by No-
Trans indicate that aligning and mapping embed-
ding spaces does not preserve all semantic proper-
ties relevant to the distinction between synonymy
and antonymy. The use of first-best translations
in BestTrans alleviates this issue partially and im-
proves F1 by up to 4.6 points. Our intuition re-
garding discourse cues in LingTrans leads to fur-
ther improvements of up to 9.9 additional points in
F1 and considerably closes the gap between mono-
lingual and cross-lingual results (56.8−64.2 vs.
70.1 F1). Based on an approximate randomization
test over the respective test items (Yeh, 2000), we
find the improvements of our proposed approach
LingTrans overNoTrans to be significant in Viet-

namese (p<0.01), German and Hindi (p<0.1). In
contrast, there is no significant difference in per-
formance between BestTrans and NoTrans, con-
firming that both translation and reranking are re-
quired to achieve consistent gains.

5 Analysis

Weexamine how far our proposed approach affects
performance on the task of synonymy–antonymy
distinction and discuss remaining shortcomings.
A first observation concerns the general vari-

ance of results across languages. In addition
to differences in terms of available corpus sizes,
we observe different challenges in each language
and dataset. Notably, each dataset is created
with its own linguistically motivated definitions
of antonymy and synonymy, some of which are
more relaxed than others. For example, Nguyen
et al. (2018) consider “words which are strongly
associated but highly dissimilar to each other” as
antonyms and “words that are highly similar in
meaning” as synonyms.
The performance of our baseline NoTrans sug-

gests that the distinction between synonyms and
antonyms in the crosslingual space is harder for
Vietnamese than for the other languages. At least
partially, this is due to errors and noise from
preprocessing (i.e., lemmatization). Also, Viet-
namese belongs to a different language family than
English. Consequently, information relevant to
the synonymy–antonymy distinction may be dis-
tributed differently in the target language space
than in the source language. In Hindi, some errors
specific to the data involve synonyms that denote
the same mythological deity (e.g., हनुमान / बजरंग-
बली ‘Hanuman/Bajrangbali’) and thus require fac-
tual knowledge for classification.
Even for our development language German, re-

sults suggest that there is room for improvement.
We examine the improvements achieved and re-
maining errors in German in more detail below.

Classification improvements. The main im-
provement of our LingTrans approach over Best-
Trans is reflected in an increased number of
correctly classified antonyms, mostly including
antonymous adjectives (e.g., ständig ‘steadily’
vs. sporadisch ‘sporadically’) but also mutu-
ally exclusive nouns (e.g., Privatgelände ‘private
grounds’ vs.Öffentlichkeit ‘public’). Compared to
the NoTrans baseline, we find BestTrans to sub-
stantially increase the number of correctly clas-



3903

sified synonyms (by almost 20%). In particu-
lar, this affects words derived from the same stem
(unzählig/zahllos ‘countless’), synonymous verbs
(pfuschen/schummeln ‘cheat’) as well as (near-
)synonymous adjectives (verfügbar/verwendbar
‘available/usable’).

Translation improvements. The observed
quantitative improvements are in line with
qualitative improvements that we see in the auto-
matically generated training data. For example,
more and less have the same 1st-best translation
in German according to the cross-lingual space
(mehr ‘more’); as illustrated in Figure 2, rerank-
ing is required to find the correct translation for
the latter word (i.e., weniger ‘less’). To quan-
tify translation improvements of our proposed
reranking method, we count the number of words
overlapping between the automatically translated
data and data available in the target languages.
Compared to the BestTrans baseline, we find our
LingTrans approach to improve overlap for Ger-
man, Hindi, and Vietnamese by 2%, 5% and 5%,
respectively. Despite the increase in word overlap,
it is worth noting that the overlap between training
and testing in terms of actual data instances (i.e.,
pairs of words) remains constant between 0% and
1%. A partial explanation for the improved results
could thus be that our reranking approach lets us
find translations that are generally more likely to
have an antonym (or synonym)—regardless of
which other word they are presented with. A sim-
ilar observation was made by Levy et al. (2015)
regarding hypernymy classification, in which they
found some words to be generally more likely
to be “category words”. Whether similar biases
exist in synonymy–antonymy classification will
be subject of future work.

Remaining errors. We categorized a randomly
selected subset of 30 mis-classifications. We
found 30% of the errors to be related to spar-
sity. In these cases, at least one word was in-
frequent or the word pair never co-occurred in
the corpus (e.g., unversöhnbar/unvereinbar ‘un-
forgiving/irreconcilable’). 27% of the errors can
be attributed to problems with the test data because
it contains “synonyms” that are only indirectly re-
lated (e.g., parieren/ausweichen ‘parry/dodge’).
The 42% remaining cases involve a number of

challenging antonyms and synonyms, but also a
few remarkably easy cases. The latter includemor-

phologically marked antonyms (e.g., Richtigkeit
‘correctness’ vs. Unrichtigkeit ‘incorrectness’)
and instances of synonyms that involve two iden-
tical words (e.g., Verwandtschaft/Verwandtschaft
‘kinship’), which presumably is an artifact of the
automatic translation step used in creating the
German dataset (see Glavaš and Vulić (2018)).
Both types of errors could be identified by sim-
ple heuristics but are incorrectly classified by the
model. On the other hand, hard cases involve
words of different linguistic register, which are ex-
pected to be distributed differently and therefore
hard to capture by distributional methods (e.g.,
mittellos/verarmt ‘penniless/impoverished’).
In summary, we find substantial improvement

through our transfermethod, compared to the base-
lines. However, further improvements could be
achieved, for example, taking into account regis-
ter (e.g., formal vs. colloquial) and morphological
marking (e.g., negation affixes).

6 Conclusion

We proposed to combine unsupervised cross-
lingual embeddings and discourse cues to gener-
ate supervision for distinguishing synonyms and
antonyms in under-resourced languages. Com-
pared to a baseline that uses only cross-lingual em-
beddings, we showed that the use of a small set of
discourse markers indicating contrast can yield ab-
solute improvements of up to 10% F1-score. The
simplicity of our approach allows to easily incor-
porate other features (e.g., morphological mark-
ing) and it can be extended to further languages
or lexical relations. For example, discourse mark-
ers that indicate specification and instantiation re-
lations (e.g. specifically, for instance) could be
used to detect hypernymy (cf. Roth and Schulte im
Walde (2014)). Beyond classification, another di-
rection for future work is to extend our approach
to distinguish synonyms and antonyms from unre-
lated word pairs. An interesting direction to pur-
sue would be to use multiple related languages,
to aid lexical relation classification in an under-
resourced language, instead of transferring super-
vision from a single language (English).

Acknowledgements

This research was supported by the German Re-
search Foundation (DFG EXC 285), and by Con-
tract HR0011-15-2-0025 and Agreement HR0011-
15-2-0023 with the US DARPA.



3904

References
Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2018.

A Robust Self-learning Method for Fully Unsuper-
vised Cross-lingual Mappings of Word Embeddings.
In Proceedings of the 56th Annual Meeting of the As-
sociation for Computational Linguistics, pages 789–
798. Association for Computational Linguistics.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
TomasMikolov. 2017. EnrichingWord Vectors with
Subword Information. Transactions of the Associa-
tion for Computational Linguistics, 5:135–146.

Ondřej Bojar, Vojtěch Diatka, Pavel Rychlý, Pavel
Straňák, Vít Suchomel, Aleš Tamchyna, and Daniel
Zeman. 2014. HindEnCorp - Hindi-English and
Hindi-only Corpus for Machine Translation. In
Proceedings of the Ninth International Conference
on Language Resources and Evaluation (LREC’14),
Reykjavik, Iceland. European Language Resources
Association (ELRA).

Walter G Charles and George AMiller. 1989. Contexts
of Antonymous Adjectives. Applied psycholinguis-
tics, 10(3):357–375.

Philip Edmonds and Graeme Hirst. 2002. Near-
Synonymy and Lexical Choice. Computational lin-
guistics, 28(2):105–144.

Goran Glavaš and Ivan Vulić. 2018. Discriminating be-
tween Lexico-Semantic Relations with the Special-
ization Tensor Model. In Proceedings of the 2018
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 181–187. Associa-
tion for Computational Linguistics.

Gregory Grefenstette. 1992. Finding Semantic Simi-
larity in raw text: The Deese Antonyms. In Fall
Symposium Series, Working Notes, Probabilistic Ap-
proaches to Natural Language, pages 61–65.

Sanda Harabagiu, Andrew Hickl, and Finley Lacatusu.
2006. Negation, Contrast and Contradiction in Text
Processing. In AAAI, volume 6, pages 755–762.

M. A. Hearst. 1992. Automatic Acquisition of Hy-
ponyms from Large Text Corpora. In Proceedings
of the 14th Conference on Computational linguistics,
pages 539–545, Morristown, NJ, USA. Association
for Computational Linguistics.

Yova Kementchedjhieva, Sebastian Ruder, Ryan Cot-
terell, and Anders Søgaard. 2018. Generalizing Pro-
crustes Analysis for Better Bilingual Dictionary In-
duction. In Proceedings of the 22nd Conference on
Computational Natural Language Learning, pages
211–220. Association for Computational Linguis-
tics.

Omer Levy, Steffen Remus, Chris Biemann, and Ido
Dagan. 2015. Do Supervised Distributional Meth-
ods Really Learn Lexical Inference Relations? In
Proceedings of the 2015 Conference of the North

American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 970–976. Association for Computational Lin-
guistics.

Dekang Lin, Shaojun Zhao, Lijuan Qin, and Ming
Zhou. 2003. Identifying Synonyms among Distribu-
tionally Similar Words. In IJCAI, volume 3, pages
1492–1493.

Marie-Catherine Marneffe, Anna N Rafferty, and
Christopher D Manning. 2008. Finding Contradic-
tions in Text. InProceedings of ACL-08: HLT, pages
1039–1047.

Yuval Marton, Ahmed El Kholy, and Nizar Habash.
2011. Filtering Antonymous, Trend-contrasting,
and Polarity-dissimilar Distributional Paraphrases
for Improving Statistical Machine Translation. In
Proceedings of the SixthWorkshop on StatisticalMa-
chine Translation, pages 237–249. Association for
Computational Linguistics.

Saif M Mohammad, Bonnie J Dorr, Graeme Hirst, and
Peter D Turney. 2013. Computing Lexical Contrast.
Computational Linguistics, 39(3):555–590.

Nikola Mrkšić, Ivan Vulić, Diarmuid Ó Séaghdha, Ira
Leviant, Roi Reichart, Milica Gašić, Anna Korho-
nen, and Steve Young. 2017. Semantic Special-
ization of Distributional Word Vector Spaces using
Monolingual and Cross-Lingual Constraints. Trans-
actions of the Association for Computational Lin-
guistics, 5:309–324.

Kim Anh Nguyen, Sabine Schulte im Walde, and
Ngoc Thang Vu. 2017. Distinguishing Antonyms
and Synonyms in a Pattern-based Neural Network.
In Proceedings of the 15th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics: Volume 1, Long Papers, pages 76–85.
Association for Computational Linguistics.

Kim Anh Nguyen, Sabine Schulte im Walde, and
Ngoc Thang Vu. 2018. Introducing Two Vietnamese
Datasets for Evaluating Semantic Models of (Dis-
)Similarity and Relatedness. In Proceedings of the
2018 Conference of the North American Chapter
of the Association for Computational Linguistics:
Human Language Technologies, Volume 2 (Short
Papers), pages 199–205. Association for Computa-
tional Linguistics.

Masataka Ono, Makoto Miwa, and Yutaka Sasaki.
2015. Word Embedding-based Antonym Detection
using Thesauri and Distributional Information. In
Proceedings of the 2015 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 984–989.

Sebastian Padó and Mirella Lapata. 2003. Construct-
ing Semantic SpaceModels from Parsed Corpora. In
Proceedings of the 41st Annual Meeting of the As-
sociation for Computational Linguistics, pages 128–
135, Sapporo, Japan. Association for Computational
Linguistics.



3905

Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, Alan
Lee, Aravind Joshi, Livio Robaldo, and Bonnie L
Webber. 2007. The Penn Discourse Treebank 2.0
annotation manual. Technical report.

Michael Roth and Sabine Schulte im Walde. 2014.
Combining Word Patterns and Discourse Markers
for Paradigmatic Relation Classification. In Pro-
ceedings of the 52nd Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 524–
530, Baltimore, Maryland. Association for Compu-
tational Linguistics.

Vered Shwartz and Ido Dagan. 2016. Path-based vs.
Distributional Information in Recognizing Lexical
Semantic Relations. In Proceedings of the 5th Work-
shop on Cognitive Aspects of the Lexicon (CogALex
- V), pages 24–29, Osaka, Japan. The COLING 2016
Organizing Committee.

Stephanie Strassel and Jennifer Tracey. 2016.
LORELEI Language Packs: Data, Tools, and
Resources for Technology Development in Low
Resource Languages. In LREC.

Ellen M Voorhees. 2008. Contradictions and Justifi-
cations: Extensions to the Textual Entailment Task.
Proceedings of ACL-08: HLT, pages 63–71.

Hongzhi Xu, Mitchell Marcus, Charles Yang, and Lyle
Ungar. 2018. Unsupervised Morphology Learn-
ing with Statistical Paradigms. In Proceedings of
the 27th International Conference on Computational
Linguistics, pages 44–54, Santa Fe, New Mexico,
USA. Association for Computational Linguistics.

Alexander Yeh. 2000. More accurate tests for the statis-
tical significance of result differences. In Proceed-
ings of the 18th International Conference on Com-
putational Linguistics, Volume 2, pages 947–953.

Wen-tau Yih, Geoffrey Zweig, and John C Platt. 2012.
Polarity Inducing Latent Semantic Analysis. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, pages 1212–
1222. Association for Computational Linguistics.


