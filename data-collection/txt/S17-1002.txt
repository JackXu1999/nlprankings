



















































Learning Antonyms with Paraphrases and a Morphology-Aware Neural Network


Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017), pages 12–21,
Vancouver, Canada, August 3-4, 2017. c©2017 Association for Computational Linguistics

Learning Antonyms with Paraphrases
and a Morphology-Aware Neural Network

Sneha Rajana∗ Chris Callison-Burch∗ Marianna Apidianaki∗Ψ Vered ShwartzΦ
∗Computer and Information Science Department, University of Pennsylvania, USA

ΨLIMSI, CNRS, Université Paris-Saclay, 91403 Orsay
ΦComputer Science Department, Bar-Ilan University, Israel

{srajana,ccb,marapi}@seas.upenn.edu vered1986@gmail.com

Abstract

Recognizing and distinguishing antonyms
from other types of semantic relations is
an essential part of language understand-
ing systems. In this paper, we present a
novel method for deriving antonym pairs
using paraphrase pairs containing negation
markers. We further propose a neural net-
work model, AntNET, that integrates mor-
phological features indicative of antonymy
into a path-based relation detection algo-
rithm. We demonstrate that our model
outperforms state-of-the-art models in dis-
tinguishing antonyms from other semantic
relations and is capable of efficiently han-
dling multi-word expressions.

1 Introduction

Identifying antonymy and expressions with con-
trasting meanings is valuable for NLP systems
which go beyond recognizing semantic related-
ness and require to identify specific semantic re-
lations. While manually created semantic tax-
onomies, like WordNet (Fellbaum, 1998), define
antonymy relations between some word pairs that
native speakers consider antonyms, they have lim-
ited coverage. Further, as each term of an antony-
mous pair can have many semantically close
terms, the contrasting word pairs far outnum-
ber those that are commonly considered antonym
pairs, and they remain unrecorded. Therefore,
automated methods have been proposed to deter-
mine for a given term-pair (x, y), whether x and y
are antonyms of each other, based on their occur-
rences in a large corpus.

Charles and Miller (1989) put forward the co-
occurrence hypothesis that antonyms occur to-
gether in a sentence more often than chance. How-
ever, non-antonymous semantically related words

Paraphrase Pair Antonym Pair
not sufficient/insufficient sufficient/insufficient
insignificant/negligible significant/negligible

dishonest/lying honest/lying
unusual/pretty strange usual/pretty strange

Table 1: Examples of antonyms derived from
PPDB paraphrases. The antonym pairs in column
2 were derived from the corresponding paraphrase
pairs in column 1.

such as hypernyms, holonyms, meronyms, and
near-synonyms also tend to occur together more
often than chance. Thus, separating antonyms
from pairs linked by other relationships has proven
to be difficult. Approaches to antonym detec-
tion have exploited distributional vector represen-
tations relying on the distributional hypothesis of
semantic similarity (Harris, 1954; Firth, 1957) that
words co-occurring in similar contexts tend to be
semantically close. Two main information sources
are used to recognize semantic relations: path-
based and distributional. Path-based methods con-
sider the joint occurrences of the two terms in
a given sentence and use the dependency paths
that connect the terms as features (Hearst, 1992;
Roth and Schulte im Walde, 2014; Schwartz et al.,
2015). For distinguishing antonyms from other re-
lations, Lin et al. (2003) proposed to use antonym
patterns (such as either X or Y and from X to
Y ). Distributional methods are based on the dis-
joint occurrences of each term and have recently
become popular using word embeddings (Mikolov
et al., 2013; Pennington et al., 2014) which pro-
vide a distributional representation for each term.
Recently, combined path-based and distributional
methods for relation detection have also been
proposed (Shwartz et al., 2016; Nguyen et al.,
2017). They showed that a good path representa-

12



tion can provide substantial complementary infor-
mation to the distributional signal for distinguish-
ing between different semantic relations.

While antonymy applies to expressions that
represent contrasting meanings, paraphrases are
phrases expressing the same meaning, which usu-
ally occur in similar textual contexts (Barzilay and
McKeown, 2001) or have common translations
in other languages (Bannard and Callison-Burch,
2005). Specifically, if two words or phrases are
paraphrases, they are unlikely to be antonyms of
each other. Our first approach to antonym de-
tection exploits this fact and uses paraphrases for
detecting and generating antonyms (The demen-
tors caught Sirius Black/ Black could not escape
the dementors). We start by focusing on phrase
pairs that are most salient for deriving antonyms.
Our assumption is that phrases (or words) contain-
ing negating words (or prefixes) are more help-
ful for identifying opposing relationships between
term-pairs. For example, from the paraphrase pair
(caught/not escape), we can derive the antonym
pair (caught/escape) by just removing the negat-
ing word ‘not’.

Our second method is inspired by the recent
success of deep learning methods for relation de-
tection. Shwartz et al. (2016) proposed an inte-
grated path-based and distributional model to im-
prove hypernymy detection between term-pairs,
and later extended it to classify multiple semantic
relations (Shwartz and Dagan, 2016) (LexNET).
Although LexNET was the best performing sys-
tem in the semantic relation classification task of
the CogALex 2016 shared task, the model per-
formed poorly on synonyms and antonyms com-
pared to other relations. The path-based compo-
nent is weak in recognizing synonyms, which do
not tend to co-occur, and the distributional infor-
mation caused confusion between synonyms and
antonyms, since both tend to occur in the same
contexts. We propose AntNET, a novel exten-
sion of LexNET that integrates information about
negating prefixes as a new morphological pat-
tern feature and is able to distinguish antonyms
from other semantic relations. In addition, we op-
timize the vector representations of dependency
paths between the given term pair, encoded using
a neural network, by replacing the embeddings of
words with negating prefixes by the embeddings
of the base, non-negated, forms of the words.
For example, for the term pair unhappy/joyful,

we record the negating prefix of unhappy using
a new path feature and replace the word embed-
ding of unhappy with happy in the vector represen-
tation of the dependency path between unhappy
and sad. The proposed model improves the path
embeddings to better distinguish antonyms from
other semantic relations and gets higher perfor-
mance than prior path-based methods on this task.
We used the antonym pairs extracted from the
Paraphrase Database (PPDB) (Ganitkevitch et al.,
2013; Pavlick et al., 2015b) in the paraphrase-
based method as training data for our neural net-
work model.

The main contributions of this paper are:

• We present a novel technique of using para-
phrases for antonym detection and success-
fully derive antonym pairs from paraphrases
in the PPDB, the largest paraphrase resource
currently available.

• We demonstrate improvements to an inte-
grated path-based and distributional model,
showing that our morphology-aware neural
network model, AntNET, performs better
than state-of-the-art methods for antonym de-
tection.

2 Related Work

Paraphrase Extraction Methods Paraphrases
are words or phrases expressing the same mean-
ing. Paraphrase extraction methods that exploit
distributional or translation similarity might how-
ever propose paraphrase pairs that are not mean-
ing equivalent but linked by other types of re-
lations. These methods often extract pairs hav-
ing a related but not equivalent meaning, such as
contradictory pairs. For instance, Lin and Pan-
tel (2001) extracted 12 million “inference rules"
from monolingual text by exploiting shared depen-
dency contexts. Their method learns paraphrases
that are truly meaning equivalent, but it just as
readily learns contradictory pairs such as (X rises,
X falls). Ganitkevitch et al. (2013) extract over
150 million paraphrase rules from parallel cor-
pora by pivoting through foreign translations. This
multilingual paraphrasing method often learns hy-
pernym/hyponym pairs, due to variation in the
discourse structure of translations, and unrelated
pairs due to misalignments or polysemy in the for-
eign language. Pavlick et al. (2015a) added inter-
pretable semantics to PPDB (see Section 3.1 for

13



Method #pairs
(x,y) from paraphrase (x̃,y)/(x,ỹ) 80,669

(x, paraphrase(y)), (paraphrase(x), y) 81,221
(x, synset(y)), (synset(x), y) 692,231

Table 2: Number of unique antonym pairs derived
from PPDB at each step. Paraphrases and synsets
were obtained from PPDB and WordNet respec-
tively.

details) and showed that paraphrases in this re-
source represent a variety of relations other than
equivalence, including contradictory pairs like no-
body/someone and close/open.

Pattern-based Methods Pattern-based methods
for inducing semantic relations between a pair of
terms (x, y) consider the lexico-syntactic paths
that connect the joint occurrences of x and y in
a large corpus. A variety of approaches have been
proposed that rely on patterns between terms in
a corpus to distinguish antonyms from other rela-
tions. Lin et al. (2003) used translation informa-
tion and lexico-syntactic patterns to extract dis-
tributionally similar words, and then filtered out
words that appeared with the patterns ‘from X to
Y’ or ‘either X or Y’ significantly often. The in-
tuition behind this was that if two words X and Y
appear in one of these patterns, they are unlikely to
represent a synonymous pair. Roth and Schulte im
Walde (2014) combined general lexico-syntactic
patterns with discourse markers as indicators for
the specific semantic relations between word pairs
(e.g. contrast relations might indicate antonymy
and elaborations may indicate synonymy or hy-
ponymy). Unlike previous pattern-based methods
which relied on the standard distribution of pat-
terns, Schwartz et al. (2015) used patterns to learn
word embeddings. They presented a symmetric
pattern-based model for representing word vectors
in which antonyms are assigned to dissimilar vec-
tor representations. More recently, Nguyen et al.
(2017) presented a pattern-based neural network
model that exploits lexico-syntactic patterns from
syntactic parse trees for the task of distinguishing
between antonyms and synonyms. They applied
HypeNET Shwartz et al. (2016) to the task of dis-
tinguishing between synonyms and antonyms, re-
placing the direction feature with the distance in
the path representation.

Source #pairs
WordNet 18,306

PPDB 773,452

Table 3: Number of unique antonym pairs derived
from different sources. The number of pairs ob-
tained from PPDB far outnumbers the antonym
pairs present in EVALution and WordNet.

3 Paraphrase-Based Antonym
Derivation

Existing semantic resources like WordNet (Fell-
baum, 1998) contain a much smaller set of
antonyms compared to other semantic relations
(synonyms, hypernyms and meronyms). Our
aim is to create a large resource of high quality
antonym pairs using paraphrases.

3.1 The Paraphrase Database

The Paraphrase Database (PPDB) contains over
150 million paraphrase rules covering three para-
phrase types: lexical (single word), phrasal (multi-
word), and syntactic restructuring rules, and is the
largest collection of paraphrases currently avail-
able. PPDB . In this paper, we focus on lexical and
phrasal paraphrases up to two words in length. We
examine the relationships between phrase pairs in
the PPDB focusing on phrase pairs that are most
salient for deriving antonyms.

3.2 Antonym Derivation

Selection of Paraphrases We consider all
phrase pairs from PPDB (p1, p2) up to two words
in length such that one of the two phrases either
begins with a negating word like not, or contains
a negating prefix.1 We chose these two types of
paraphrase pairs since we believe them to be the
most indicative of an antonymy relationship be-
tween the target words. There are 7,878 unordered
phrase pairs of the form (p′1, p2) where p′1 be-
gins with ‘not’, and 183,159 phrases of the form
(p′1, p2) where p′1 contains a negating prefix.

Paraphrase Transformation For paraphrases
containing a negating prefix, we perform morpho-
logical analysis to identify and remove the negat-
ing prefixes. For a phrase pair like unhappy/sad,
an antonymy relation is derived between the base
form of the negated word, without the negation
prefix, and its paraphrase (happy/sad). We use

1Negating prefixes include de, un, in, anti, il, non, dis

14



Unrelated Paraphrases Categories Entailment Other relation
much/worthless correct/that’s right Japan/Korea investing/ twinkle/dark

increased investment
disability/present simply/merely black/red efficiency/ naw/not gonna

operational efficiency
equality/gap till/until Jan/Feb valid/equally valid access/available

Table 4: Examples of different types of non-antonyms derived from PPDB.

MORSEL (Lignos, 2010) to perform morpholog-
ical analysis and identify negation markers. For
multi-word phrases with a negating word, the
negating word is simply dropped to obtain an
antonym pair (e.g. different/not identical → dif-
ferent/identical). Some examples of PPDB para-
phrase pairs and antonym pairs derived from them
are shown in Table 1. The derived antonym pairs
are further expanded by associating the synonyms
(from WordNet) and lexical paraphrases (from
PPDB) of each phrase with the other phrase in
the derived pair. While expanding each phrase
in the derived pair by its paraphrases, we filter
out paraphrase pairs with a PPDB score (Pavlick
et al., 2015a) of less than 2.5. In the above ex-
ample, unhappy/sad, we first derive happy/sad as
an antonym pair and expand it by considering all
synonyms of happy as antonyms of sad (e.g. joy-
ful/sad), and all synonyms of sad as antonyms
of happy (e.g. happy/gloomy). Table 2 shows
the number of pairs derived at each step using
PPDB. In total, we were able to derive around
773K unique pairs from PPDB. This is a much
larger dataset than existing resources like Word-
Net and EVALution as shown in Table 3.

Analysis We performed a manual evaluation of
the quality of the extracted antonyms by randomly
selecting 1000 pairs classified as ‘antonym’ and
observed that the dataset contained about 63%
antonyms. Errors mostly consisted of phrases and
words that do not have an opposing meaning after
the removal of the negation pattern. For example,
the equivalent pair till/until that was derived from
the PPDB paraphrase rule not till/until. Other non-
antonyms derived from the above methods can be
classified into unrelated pairs (background/figure),
paraphrases or pairs that have an equivalent mean-
ing (admissible/permissible), words that belong to
a category (Africa/Asia), pairs that have an entail-
ment relation (valid/equally valid) and pairs that
are related but not with an antonym relationship
(twinkle/dark). Table 4 gives some examples of

categories of non-antonyms.

Annotation Since the pairs derived from PPDB
seemed to contain a variety of relations in addi-
tion to antonyms, we crowdsourced the task of la-
belling a subset of these pairs in order to obtain the
true labels.2 We asked workers to choose between
the labels: antonym, synonym (or paraphrase for
multi-word expressions), unrelated, other, entail-
ment, and category. We showed each pair to 3
workers, taking the majority label as truth.

4 LSTM-Based Antonym Detection

In this section we describe AntNET, a long short
term memory (LSTM) based, morphology-aware
neural network model for antonym detection. We
first focus on improving the neural embeddings of
the path representation (Section 4.1), and then in-
tegrate distributional signals into our network re-
sulting in a combined method (Section 4.2).

4.1 Path-Based Network

Similarly to prior work, we represent each de-
pendency path as a sequence of edges that leads
from x to y in the dependency tree. We use
the same path-based features proposed by Shwartz
et al. (2016) for recognizing hypernym relations:
lemma and part-of-speech (POS) tag of the source
node, the dependency label, and the edge direction
between two subsequent nodes. Additionally, we
also add a new feature that indicates whether the
source node is negated.

Rather than treating an entire dependency path
as a single feature, we encode the sequence
of edges using a long short term memory net-
work (Hochreiter and Schmidhuber, 1997). The
vectors obtained for the different paths of a given
(x, y) pair are pooled, and the resulting vector is
used for classification. The overall network struc-
ture is depicted in Figure 1.

25884 pairs were randomly chosen and were annotated on
www.crowdflower.com

15



Figure 1: Illustration of the AntNET model. Each pair is represented by several paths and each path
is a sequence of edges. An edge consists of five features: lemma, POS, dependency label, dependency
direction, and negation marker.

Edge Representation We denote each edge as
lemma/pos/dep/dir/neg. We are only inter-
ested in checking if x and/or y have negation
markers but not the intermediate edges since nega-
tion information for intermediate lemmas is un-
likely to contribute to identifying whether there is
an antonym relationship between x and y. Hence,
in our model, neg is represented in one of three
ways: negated if x or y is negated, not-negated if
x or y is not negated, and unavailable for the inter-
mediate edges. If the source node is negated, we
replace the lemma by the lemma of its base, non-
negated, form. For example, if we identified un-
happy as a ‘negated’ word, we replace the lemma
embedding of unhappy by the embedding of happy
in the path representation. The negation feature
will help in separating antonyms from other se-
mantic relations, especially those that are hard to
distinguish from, like synonyms.

The replacement of a negated word’s embed-
ding by its base form’s embedding is done for a
few reasons. First, words and their polar antonyms
are more likely to co-occur in sentences compared
to words and their negated forms. For example,
Neither happy nor sad is probably a more com-
mon phrase than Neither happy nor unhappy, so
this technique will help our model to identify an
opposing relationship between both types of pairs,
happy/unhappy and happy/sad. Second, a com-
mon practice for creating word embeddings for
multi-word expressions (MWEs) is by averaging
over the embeddings of each word in the expres-
sion. Ideally, this is not a good representation

for phrases like not identical since we lose out on
the negating information obtained from not. In-
dicating the presence of not using a negation fea-
ture and replacing the embedding of not identical
by identical will increase the classifier’s probabil-
ity of identifying not identical/different as para-
phrases and identical/different as antonyms. And
finally, this method helps us distinguish between
terms that are seemingly negated but are not in re-
ality (e.g. invaluable). We encode the sequence
of edges using an LSTM network. The vectors
obtained for all the paths connecting x and y are
pooled and combined, and the resulting vector is
used for classification. The vector representation
of each edge is the concatenation of its feature vec-
tors:

~vedge = [~vlemma, ~vpos, ~vdep, ~vdir, ~vneg]

where ~vlemma, ~vpos, ~vdep, ~vdir, ~vneg represent the
vector embeddings of the negation marker, lemma,
POS tag, dependency label and dependency direc-
tion, respectively.

Path Representation The representation for
a path p composed of a sequence of edges
edge1, edge2, .., edgek is a sequence of edge vec-
tors: p = [ ~edge1, ~edge2, ..., ~edgek]. The edge vec-
tors are fed in order to a recurrent neural network
(RNN) with LSTM units, resulting in the encoded
path vector ~vp.

Classification Task Given a lexical or phrasal
pair (x, y) we induce patterns from a corpus where
each pattern represents a lexico-syntactic path

16



connecting x and y. The vector representation for
each term pair (x, y) is computed as the weighted
average of its path vectors by applying average
pooling as follows:

(1)~vp(x,y) =

∑
p∈P (x,y)fp.~vp∑

p∈P (x,y)fp

~vp(x,y) refers to the vector of the pair (x, y);
P (x, y) is the multi-set of paths connecting x and
y in the corpus and fp is the frequency of p in
P (x, y). The vector ~vp(x,y) is then fed into a neu-
ral network that outputs the class distribution c for
each class (relation type), and the pair is assigned
to the relation with the highest score r:

(2a)c = softmax(MLP (~vp(x,y))
(2b)r = argmaxic[i]

MLP stands for Multi Layer Perceptron and can
be computed with or without a hidden layer (equa-
tions 4 and 5 respectively).

(3)~h = tanh(W1.~vp(x,y) + b1)

(4)MLP (~vp(x,y)) = W2.~h + b2

(5)MLP (~vp(x,y)) = W1.~vp(x,y) + b1

W refers to a matrix of weights that projects in-
formation between two layers; b is a layer-specific
vector of bias terms and ~h is the hidden layer.

4.2 Combined Path-Based and Distributional
Network

The path-based supervised model in Section 4.1
classifies each pair (x, y) based on the lexico-
syntactic patterns that connect x and y in a cor-
pus. Inspired by the improved performance of
Shwartz et al.’s (2016) integrated path-based and
distributional method over a simpler path-based
algorithm, we integrate distributional features into
our path-based network. We create a combined
vector representation using both the syntactic path
features and the co-occurrence distributional fea-
tures of x and y for each pair (x, y). The com-
bined vector representation for (x, y), ~vc(xy), is
computed by simply concatenating the word em-
beddings of x (~vx) and y (~vy) to the path-based
feature vector ~vp(x,y):

(6)~vc(xy) = [~vx, ~vp(x,y), ~vy]

5 Experiments

We experiment with the path-based and combined
models for antonym identification by performing
two types of classification: binary and multiclass
classification.

Train Test Val Total
5,122 1,829 367 7,318

Table 5: Number of instances present in the
train/test/validation splits of the crowdsourced
dataset.

5.1 Dataset

Neural networks require a large amount of train-
ing data. We use the labelled portion of the dataset
that we created using PPDB, as described in Sec-
tion 3. In order to induce paths for the pairs in
the dataset, we identify sentences in the corpus
that contain the pair and extract all patterns for
the given pair. Pairs with an antonym relationship
are considered as positive instances in both clas-
sification experiments. In the binary classification
experiment, we consider all pairs related by other
relations (entailment, synonymy, category, unre-
lated, other) as negative instances. We also per-
form a variant of the multiclass classification with
three classes (antonym, other, unrelated). Due to
the skewed nature of the dataset, we combined cat-
egory, entailment and synonym/paraphrases into
one class. For both classification experiments, we
perform random split with 70% train, 25% test,
and 5% validation sets. Table 5 displays the num-
ber of relations in our dataset. Wikipedia3 was
used as the underlying corpus for all methods and
we perform model selection on the validation set
to tune the hyper-parameters of each method. We
apply grid search for a range of values and pick the
ones that yield the highest F1 score on the valida-
tion set. The best hyper-parameters are reported in
the appendix.

5.2 Baselines

Majority Baseline The majority baseline is
achieved by labelling all the instances with the
most frequent class occuring in the dataset i.e.
FALSE (binary) or UNRELATED (multiclass).

3We used the English Wikipedia dump from May 2015 as
the corpus.

17



Model Binary Multiclass
P R F1 P R F1

Majority baseline 0.304 0.551 0.392 0.222 0.472 0.303
SP baseline 0.661 0.568 0.436 0.583 0.488 0.344

Path-based SD baseline 0.723 0.724 0.722 0.636 0.675 0.651
Path-based AntNET 0.732 0.722 0.713 0.652 0.687 0.661**

Combined SD baseline 0.790 0.788 0.788 0.744 0.750 0.738
Combined AntNET 0.803 0.802 0.802* 0.746 0.757 0.746*

Table 6: Performance of the AntNET models in comparison to the baseline models.

Feature Model Binary Multiclass
P R F1 P R F1

Distance Path-based 0.727 0.727 0.724 0.665 0.692 0.664
Combined 0.789 0.788 0.788 0.732 0.743 0.734

Negation Path-based 0.732 0.722 0.713 0.652 0.687 0.661
Combined 0.803 0.802 0.802 0.746 0.757 0.746

Table 7: Comparing the novel negation marking feature with the distance feature proposed by Nguyen
et al. (2017).

Distributed Baseline The method proposed by
Schwartz et al. (2015) uses symmetric patterns
(SPs) for generating word embeddings. The au-
thors automatically acquired symmetric patterns
(defined as a sequence of 3–5 tokens consisting of
exactly 2 wildcards and 1–3 words) from a large
plain-text corpus, and generated vectors where
each co-ordinate represented the co-occurrence in
symmetric patterns of the represented word with
another word of the vocabulary. For antonym rep-
resentation, the authors relied on the patterns sug-
gested by (Lin et al., 2003) to construct word em-
beddings containing an antonym parameter that
can be turned on in order to represent antonyms as
dissimilar, and that can be turned off to represent
antonyms as similar. To evaluate the SP method
on our data, we used the pre-trained SP embed-
dings4 with 500 dimensions. We use the SVM
classifier with RBF kernel for the classification of
word pairs.

Path-based and Combined Baseline Since
AntNET is an extension of the path-based and
combined models proposed by (Shwartz and Da-
gan, 2016) for classifying multiple semantic rela-
tions, we use their models as additional baselines.
Because their model used a different dataset that
contained very few antonym instances, we repli-

4https://homes.cs.washington.edu/
~roysch/papers/sp_embeddings/sp_
embeddings.html

cated the baseline (SD) with the dataset and corpus
information as in Sectionn 5.1 rather than compar-
ing to the reported results.

5.3 Results

Table 6 displays the performance scores of
AntNET and the baselines in terms of precision,
recall and F1. Our combined model significantly5

outperforms all baselines in both binary and mul-
ticlass classifications. Both path-based and com-
bined models of AntNET achieve a much better
performance in comparison to the majority class
and SP baselines.

Comparing the path-based methods, the
AntNET model achieves a higher precision com-
pared to the path-based SD baseline for binary
classification, and outperforms the SD model in
precision, recall and F1 in the multiclass clas-
sification experiment. The low precision of the
SD model stems from its inability to distinguish
between antonyms and synonyms, and between
related and unrelated pairs which are common in
our dataset, causing many false positive pairs such
as difficult/harsh, bad/cunning, finish/far which
were classified as antonyms.

Comparing the combined models, the AntNET
model outperforms the SD model in precision, re-
call and F1, achieving state-of-the-art results for
antonym detection. In all the experiments, the

5We used paired t-test. *p < 0.1, **p < 0.05

18



performance of the model in the binary classifi-
cation task was better than in the multiclass clas-
sification. Multiclass classification seems to be in-
herently harder for all methods, due to the large
number of relations and the smaller number of in-
stances for each relation. We also observed that as
we increased the size of the training dataset used
in our experiments, the results improved for both
path-based and combined models, confirming the
need for large-scale datasets that will benefit train-
ing neural models.

Effect of the Negation-marking Feature In our
models, the novel negation marking feature is suc-
cessfully integrated along the syntactic path to rep-
resent the paths between x and y. In order to eval-
uate the effect of our novel negation-marking fea-
ture for antonym detection, we compare this fea-
ture to the distance feature proposed by Nguyen
et al. (2017). In their approach, they integrate
the distance between related words in a lexico-
syntactic path as a new pattern feature, along
with lemma, POS and dependency for the task
of distinguishing antonyms and synonyms. We
re-implemented this model by making use of the
same information regarding dataset and patterns as
in Section 5.1 and then replacing the direction fea-
ture in the SD models by the distance feature.

The results are shown in Table 7 and indicate
that the negation marking feature and the replace-
ment of the embeddings of negated words by the
ones of their base forms enhance the performance
of our models more effectively than the distance
feature does, across both binary and multiclass
classifications. Although, the distance feature has
previously been shown to perform well for the task
of distinguishing antonyms from synonyms, this
feature is not very effective in the multiclass set-
ting.

5.4 Error Analysis
Figure 2 displays the confusion matrices for the
binary and multiclass experiments of the best per-
forming AntNET model. The confusion matrix
shows that pairs were mostly assigned to the cor-
rect relation more than to any other class.

False Positives We analyzed the false positives
from both the binary and multiclass experiments.
We sampled about 20% false positive pairs and
identified the following common errors. The ma-
jority of the misclassification errors stem from
antonym-like or near-antonym relations: these are

Figure 2: Confusion matrices for the combined
AntNET model for binary (left) and multiclass
(right) classifications. Rows indicate gold labels
and columns indicate predictions. The matrix is
normalized along rows, so that the predictions for
each (true) class sum to 100%.

relations that could be considered as antonymy but
were annotated by crowd-workers as other rela-
tions because they contain polysemous terms, for
which the relation holds in a specific sense. For
example: north/south and polite/sassy were la-
belled as category and other respectively. Other
errors stem from confusing antonyms and unre-
lated pairs.

False Negatives We again sampled about 20%
false positive pairs from both the binary and mul-
ticlass experiments and analyzed the major types
of errors. Most of these pairs had only few co-
occurrences in the corpus often due to infrequent
terms (e.g. cisc/risc which define computer ar-
chitectures). While our model effectively handled
negative prefixes, it failed to handle negative suf-
fixes causing incorrect classification of pairs like
spiritless/spirited. A possible future work is to
simply extend this model to handle negative suf-
fixes as well.

6 Conclusion

In this paper, we presented an original technique
for deriving antonyms using paraphrases from
PPDB. We also proposed a novel morphology-
aware neural network model, AntNET, which im-
proves antonymy prediction for path-based and
combined models. In addition to lexical and syn-
tactic information, we suggested to include a novel
morphological negation-marking feature.

Our models outperform the baselines in two re-
lation classification tasks. We also demonstrated
that the negation marking feature outperforms pre-
viously suggested path-based features for this task.

19



Since our proposed techniques for antonymy de-
tection are corpus based, they can be applied to
different languages and relations. The paraphrase-
based method can be applied to other languages
by extracting the paraphrases for these languages
from the PPDB and using a morphological analy-
sis tool (e.g. Morfette for French (Chrupala et al.,
2008)) or by looking up the negation prefixes in a
grammar book for languages that do not dispose of
such a tool. The LSTM-based model could also be
used in other languages since the method is corpus
based, but we would need to create a training set
for new languages. This would not however be too
difficult; the training set used by the model is not
that big (the one used here was around 6000 pairs)
and could be easily labelled through crowdsourc-
ing.

We release our code and the large-scale dataset
derived from PPDB, annotated with semantic rela-
tions.

Acknowledgments

This material is based in part on research spon-
sored by DARPA under grant number FA8750-
13-2-0017 (the DEFT program). The U.S. Gov-
ernment is authorized to reproduce and distribute
reprints for Governmental purposes. The views
and conclusions contained in this publication are
those of the authors and should not be interpreted
as representing official policies or endorsements
of DARPA and the U.S. Government.

This work has also been supported by the
French National Research Agency under project
ANR-16-CE33-0013 and partially supported by an
Intel ICRI-CI grant, the Israel Science Foundation
grant 880/12, and the German Research Founda-
tion through the German-Israeli Project Coopera-
tion (DIP, grant DA 1600/1-1).

We would like to thank our anonymous review-
ers for their thoughtful and helpful comments.

References
Colin Bannard and Chris Callison-Burch. 2005. Para-

phrasing with Bilingual Parallel Corpora. In Pro-
ceedings of the 43rd Annual Meeting on Association
for Computational Linguistics (ACL’05). Strouds-
burg, PA, pages 597–604.

Regina Barzilay and Kathleen R. McKeown. 2001. Ex-
tracting Paraphrases from a Parallel Corpus. In Pro-
ceedings of the 39th Annual Meeting on Association
for Computational Linguistics (ACL’01). Toulouse,
France, pages 50–57.

Walter G. Charles and George A. Miller. 1989. Con-
texts of antonymous adjectives. Applied Psychology
10:357–375.

Grzegorz Chrupala, Georgiana Dinu, and Josef van
Genabith. 2008. Learning Morphology with Mor-
fette. In Proceedings of the Sixth International
Conference on Language Resources and Evalua-
tion (LREC’08). Marrakech, Morocco, pages 2362–
2367.

Christiane Fellbaum, editor. 1998. WordNet: an elec-
tronic lexical database. MIT Press.

J. R. Firth. 1957. A synopsis of linguistic theory, 1930–
1955. In Studies in Linguistic Analysis, Basil Black-
well, Oxford, United Kingdom, pages 1–32.

Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The Paraphrase
Database. In Proceedings of the 2013 Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies (NAACL/HLT). Atlanta, Geor-
gia, pages 758–764.

Zellig S. Harris. 1954. Distributional structure. Word
10(23):146–162.

Marti Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings
of the 14th International Conference on Compu-
tational Linguistics (COLING’92). Nantes, France,
pages 539–545.

Sepp Hochreiter and Jurgen Schmidhuber. 1997.
Long short-term memory. Neural Computation
9(8):1735–1780.

Constantine Lignos. 2010. Learning from Unseen
Data. In Proceedings of the Morpho Challenge 2010
Workshop. Aalto University School of Science and
Technology, Helsinki, Finland, pages 35–38.

Dekang Lin and Patrick Pantel. 2001. DIRT - Discov-
ery of Inference Rules from Text. In Proceedings
of the Seventh ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining
(KDD’01). San Francisco, California, pages 323–
328.

Dekang Lin, Shaojun Zhao, Lijuan Qin, and Ming
Zhou. 2003. Identifying synonyms among distribu-
tionally similar words. In Proceedings of the Eigh-
teenth International Joint Conference on Artificial
Intelligence (IJCAI ’03). Acapulco, Mexico, pages
1492–1493.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed Represen-
tations of Words and Phrases and their Composition-
ality. In Proceedings of the 26th International Con-
ference on Neural Information Processing Systems
(NIPS’13). Lake Tahoe, Nevada, pages 3111–3119.

20



Kim Anh Nguyen, Sabine Schulte im Walde, and
Ngoc Thang Vu. 2017. Distinguishing antonyms
and synonyms in a pattern-based neural network. In
Proceedings of the 15th Conference of the European
Chapter of the Association for Computational Lin-
guistics (EACL’17). Valencia, Spain, pages 76–85.

Ellie Pavlick, Johan Bos, Malvina Nissim, Charley
Beller, Benjamin Van Durme, and Chris Callison-
Burch. 2015a. Adding Semantics to Data-Driven
Paraphrasing. In The 53rd Annual Meeting
of the Association for Computational Linguistics
(ACL’15). Beijing, China, pages 1512–1522.

Ellie Pavlick, Pushpendre Rastogi, Juri Ganitkevich,
and Chris Callison-Burch Ben Van Durme. 2015b.
PPDB 2.0: Better paraphrase ranking, fine-grained
entailment relations, word embeddings, and style
classification. In Proceedings of the 53rd Annual
Meeting of the Association for Computational Lin-
guistics (ACL’15). Beijing, China, pages 425–430.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. GloVe: Global Vectors for Word
Representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP’14). Doha, Qatar, pages 1532–
1543.

Michael Roth and Sabine Schulte im Walde. 2014.
Combining Word Patterns and Discourse Markers
for Paradigmatic Relation Classification. In Pro-
ceedings of the 52nd Annual Meeting of the Associ-
ation for Computational Linguistics (ACL’14). Bal-
timore, MD, pages 524–530.

Roy Schwartz, Roi Reichart, and Ari Rappoport. 2015.
Symmetric Pattern Based Word Embeddings for Im-
proved Word Similarity Prediction. In Proceed-
ings of the Nineteenth Conference on Computational
Natural Language Learning (CoNLL’15). Beijing,
China, pages 258–267.

Vered Shwartz and Ido Dagan. 2016. CogALex-V
Shared Task: LexNET - Integrated Path-based and
Distributional Method for the Identification of Se-
mantic Relations. In Proceedings of the 5th Work-
shop on Cognitive Aspects of the Lexicon (CogALex-
V). Osaka, Japan, pages 80–85.

Vered Shwartz, Yoav Goldberg, and Ido Dagan. 2016.
Improving Hypernymy Detection with an Integrated
Path-based and Distributional Method. In Pro-
ceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (ACL’16).
Berlin, Germany, pages 2389–2398.

A Supplemental Material

For deriving antonyms using PPDB, we used
the XXXL size of PPDB version 2.0 found in
http://paraphrase.org/.

To compute the metrics in Tables 6 and 7, We
used scikit-learn with the "averaged setup", which

computes the metrics for each relation and reports
their average weighted by support (the number of
true instances for each relation). Note that it can
result in a F1 score that is not the harmonic mean
of precision and recall.

During preprocessing we handled removal of
punctuation. Since our dataset only contains short
phrases, we removed any stop words occurring at
the beginning of a sentence (Example: a man →
man) and we also removed plurals. The best hy-
perparameters for all models mentioned in this pa-
per are shown in Table 8. The learning rate was
set to 0.001 for all experiments.

Model Type Dropout
SD-path Binary 0.2
SD-path Multiclass 0.4

SD-combined Binary 0.4
SD-combined Multiclass 0.2

ASD-path Binary 0.0
ASD-path Multiclass 0.2

ASD-combined Binary 0.0
ASD-combined Multiclass 0.2
AntNET-path Binary 0.0
AntNET-path Multiclass 0.2

AntNET-combined Binary 0.4
AntNET-combined Multiclass 0.2

Table 8: The best hyper-parameters in every
model.

21


