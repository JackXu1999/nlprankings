Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1371–1378,

Beijing, August 2010

1371

Detecting Speech Repairs Incrementally

Using a Noisy Channel Approach

Simon Zwarts, Mark Johnson and Robert Dale

Centre for Language Technology

Macquarie University

{simon.zwarts|mark.johnson|robert.dale}@mq.edu.au
Abstract

Unrehearsed spoken language often
contains disﬂuencies. In order to cor-
rectly interpret a spoken utterance,
any such disﬂuencies must be identi-
ﬁed and removed or otherwise dealt
with. Operating on transcripts of
speech which contain disﬂuencies, our
particular focus here is the identiﬁca-
tion and correction of speech repairs
using a noisy channel model. Our aim
is to develop a high-accuracy mecha-
nism that can identify speech repairs
in an incremental fashion, as the ut-
terance is processed word-by-word.

We also address the issue of the evalu-
ation of such incremental systems. We
propose a novel approach to evalua-
tion, which evaluates performance in
detecting and correcting disﬂuencies
incrementally, rather than only assess-
ing performance once the processing of
an utterance is complete. This demon-
strates some shortcomings in our ba-
sic incremental model, and so we then
demonstrate a technique that improves
performance on the detection of disﬂu-
encies as they happen.

1 Introduction

One of the most obvious diﬀerences between
written language and spoken language is the
fact that the latter presents itself incremen-
tally over some time period. Most natural lan-
guage processing applications operate on com-
plete sentences; but for real time spontaneous
speech, there are potential beneﬁts to incre-
mentally processing the input so that a system
can stay responsive and interact directly be-

fore a speaker’s utterance is complete. Work
in psycholinguistics supports the view that the
human parsing mechanism works incremen-
tally, with partial semantic interpretations be-
ing produced before the complete utterance
has been heard (Marslen-Wilson, 1973). Our
interest is in developing similarly incremental
processing techniques for natural language in-
terpretation, so that, for example, a speech
recognizer might be able to interject during
a long utterance to object, cut the speaker
short, or correct a mistaken assumption; such
a mechanism is even required for the appro-
priate timing of backchannel signals. Addi-
tionally the incremental nature of the model
allows potential application of this model in
speech recognition models.

Another feature of unrehearsed spoken lan-
guage that has no obvious correlate in written
language is the presence of disﬂuencies.1 Dis-
ﬂuencies are of diﬀerent types, ranging from
simple ﬁlled pauses (such as um and uh) to
more complicated structures where the se-
quence of words that make up the utterance is
‘repaired’ while it is being produced. Whereas
simpler disﬂuencies may be handled by sim-
ply deleting them from the sequence of words
under consideration, the editing terms in a
speech repair are part of the utterance, and
therefore require more sophisticated process-
ing.

There are three innovations in the present
paper. First, we demonstrate that a noisy
channel model of speech repairs can work ac-
curately in an incremental fashion. Second,
we provide an approach to the evaluation of

1Although some disﬂuencies can be considered
grammatical errors, they are generally quite distinct
in both cause and nature from the kinds of grammat-
ical errors found in written text.

1372

such an incremental model. Third, we tackle
the problem of the early detection of speech
repairs, and demonstrate a technique that de-
creases the latency (as measured in tokens)
involved in spotting that a disﬂuency has oc-
curred.

The rest of the paper is structured as fol-
lows. Section 2 provides some background
on speech repairs and existing approaches to
handling them, including Johnson and Char-
niak’s (2004) model, which we use as a start-
ing point for our incremental model. Section
3 describes our model in detail, focusing on
the noisy channel model and the incremental
component of this model. Section 4 introduces
some considerations that arise in the develop-
ment of techniques for the evaluation of in-
cremental disﬂuency detection; we then pro-
vide a quantitative assessment of our perfor-
mance using these techniques. Our evaluation
reveals that our basic incremental model does
not perform very well at detecting disﬂuencies
close to where they happen, so in Section 5 we
present a novel approach to optimise detection
of these disﬂuencies as early as possible. Fi-
nally Section 6 concludes and discusses future
work.

2 Speech Repairs

We adopt the terminology and deﬁnitions in-
troduced by Shriberg (1994) to discuss disﬂu-
ency. We are particularly interested in what
are called repairs. These are the hardest
types of disﬂuency to identify since they are
not marked by a characteristic vocabulary.
Shriberg (1994) identiﬁes and deﬁnes three
distinct parts of a repair, referred to as the
reparandum, the interregnum and the re-
pair. Consider the following utterance:

I want a ﬂight

to Boston,

uh, I mean

to Denver

on Friday

(1)

{

reparandum

z

}|

}

|

interregnum

repair

{z

}

|

{z

The reparandum to Boston is the part of the
utterance that is being edited out; the inter-
regnum uh is a ﬁller, which may not always be

present; and the repair to Denver replaces the
reparandum.

Given an utterance that contains such a re-
pair, we want to be able to correctly detect
the start and end positions of each of these
three components. We can think of each word
in an utterance as belonging to one of four
categories: ﬂuent material, reparandum, in-
terregnum, or repair. We can then assess the
accuracy of techniques that attempt to detect
disﬂuencies by computing precision and recall
values for the assignment of the correct cate-
gories to each of the words in the utterance,
as compared to the gold standard as indicated
by annotations in the corpus.

An alternative means of evaluation would
be to simply generate a new signal with the
reparandum and ﬁller removed, and compare
this against a ‘cleaned-up’ version of the ut-
terance; however, Core and Schubert (1999)
argue that, especially in the case of speech
repairs, it is important not to simply throw
away the disﬂuent elements of an utterance,
since they can carry meaning that needs to
be recovered for proper interpretation of the
utterance. We are therefore interested in the
ﬁrst instance in a model of speech error detec-
tion, rather than a model of correction.

Johnson and Charniak (2004) describe such
a model, using a noisy-channel based approach
to the detection of the start and end points of
reparanda, interregna and repairs. Since we
use this model as our starting point, we pro-
vide a more detailed explanation in Section 3.
The idea of using a noisy channel model
to identify speech repairs has been explored
for languages other than English. Honal and
Schultz (2003) use such a model, compar-
ing speech disﬂuency detection in spontaneous
spoken Mandarin against that in English. The
approach performs well in Mandarin, although
better still in English.

Both the models just described operate on
transcripts of completed utterances.
Ideally,
however, when we deal with speech we would
like to process the input word by word as it is
received. Being able to do this would enable
tighter integration in both speech recognition

1373

and interpretation, which might in turn im-
prove overall accuracy.

The requirement for incrementality is recog-
nised by Schuler et al. (2010), who employ
an incremental Hierarchical Hidden Markov
Model (HHMM) to detect speech disﬂuen-
cies. The HHMM is trained on manually an-
notated parse trees which are transformed by
a right corner transformation; the HHMM is
then used in an incremental fashion on un-
seen data, growing the parse structure each
time a new token comes in. Special subtrees
in this parse can carry a marker indicating
that the span of the subtree consists of tokens
corresponding to a speech disﬂuency. Schuler
et al.’s approach thus provides scope for de-
tecting disﬂuencies in an incremental fashion.
However, their reported accuracy scores are
not as good as those of Johnson and Char-
niak (2004): they report an F-score of 0.690
for their HHMM+RCT model, as compared
to 0.797 for Johnson and Charniak’s parser
model.

Our aim in this paper, then, is to investigate
whether it is possible to adapt Johnson and
Charniak’s model to process utterances incre-
mentally, without any loss of accuracy. To
deﬁne the incremental component more pre-
cisely, we investigate the possibility of mark-
ing the disﬂuencies as soon as possible during
the processing of the input. Given two models
that provide comparable accuracy measured
on utterance completion, we would prefer a
model which detects disﬂuencies earlier.

3 The Model

In this section, we describe Johnson and Char-
niak’s (2004) noisy channel model, and show
how this model can be made incremental.

As a data set to work with, we use the
Switchboard part of the Penn Treebank 3 cor-
pus. The Switchboard corpus is a corpus of
spontaneous conversations between two par-
ties. In Penn Treebank 3, the disﬂuencies are
manually annotated. Following Johnson and
Charniak (2004), we use all of sections 2 and
3 for training; we use conversations 4[5-9]* for
a held-out training set; and conversations 40*,

41[0-4]* and 415[0-3]* as the held-out test set.

3.1 The Noisy Channel Model

To ﬁnd the repair disﬂuencies a noisy channel
model is used. For an observed utterance with
disﬂuencies, y, we wish to ﬁnd the most likely
source utterance, ˆx, where:

ˆx = argmaxx p(x | y)

= argmaxx p(y | x) p(x)

(2)

Here we have a channel model p(y|x) which
generates an utterance y given a source x and
a language model p(x). We assume that x
is a substring of y, i.e., the source utterance
can be obtained by marking words in y as a
disﬂuency and eﬀectively removing them from
this utterance.

Johnson and Charniak (2004) experiment
with variations on the language model; they
report results for a bigram model, a trigram
model, and a language model using the Char-
niak Parser (Charniak, 2001). Their parser
model outperforms the bigram model by 5%.
The channel model is based on the intuition
that a reparandum and a repair are generally
very alike: a repair is often almost a copy of
the reparandum.
In the training data, over
60% of the words in a reparandum are lexically
identical to the words in the repair. Exam-
ple 1 provides an example of this: half of the
repair is lexically identical to the reparandum.
The channel model therefore gives the high-
est probability when the reparandum and re-
pair are lexically equivalent. When the poten-
tial reparandum and potential repair are not
identical, the channel model performs dele-
tion,
insertion or substitution. The proba-
bilities for these operations are deﬁned on a
lexical level and are derived from the training
data. This channel model is formalised us-
ing a Synchronous Tree Adjoining Grammar
(STAG) (Shieber and Schabes, 1990), which
matches words from the reparandum to the
repair. The weights for these STAG rules are
learnt from the training text, where reparanda
and repairs are aligned to each other using a
minimum edit-distance string aligner.

1374

For a given utterance, every possible ut-
terance position might be the start of a
reparandum, and every given utterance po-
sition thereafter might be the start of a re-
pair (to limit complexity, a maximum distance
between these two points is imposed). Ev-
ery disﬂuency in turn can have an arbitrary
length (again up to some maximum to limit
complexity). After every possible disﬂuency
other new reparanda and repairs might occur;
the model does not attempt to generate cross-
ing or nested disﬂuencies, although they do
very occasionally occur in practice. To ﬁnd
the optimal selection for reparanda and re-
pairs, all possibilities are calculated and the
one with the highest probability is selected.
A chart is ﬁlled with all the possible start
and end positions of reparanda,
interregna
and repairs; each entry consists of a tuple
hrmbegin, irbegin, rrbegin, rrendi, where rm is the
reparandum, ir is the interregnum and rr is
the repair. A Viterbi algorithm is used to ﬁnd
the optimal path through the utterance, rank-
ing each chart entry using the language model
and channel model. The language model, a
bigram model, can be easily calculated given
the start and end positions of all disﬂuency
components. The channel model is slightly
more complicated because an optimal align-
ment between reparandum and repair needs
to be calculated. This is done by extending
each partial analysis by adding a word to the
reparandum, the repair or both. The start po-
sition and end position of the reparandum and
repair are given for this particular entry. The
task of the channel model is to calculate the
highest probable alignment between reparan-
dum and repair. This is done by initialising
with an empty reparandum and repair, and
‘growing’ the analysis one word at a time. Us-
ing a similar approach to that used in calculat-
ing the edit-distance between reparandum and
repair, the reparandum and repair can both be
extended with one of four operations: deletion
(only the reparandum grows), insertion (only
the repair grows), substitution (both grow),
or copy (both grow). When the reparandum
and the repair have their length correspond-

ing to the current entry in the chart, the chan-
nel probability can be calculated. Since there
are multiple alignment possibilities, we use dy-
namic programming to select the most proba-
ble solutions. The probabilities for insertion,
deletion or substitution are estimated from
the training corpus. We use a beam-search
strategy to ﬁnd the ﬁnal optimum when com-
bining the channel model and the language
model.

3.2

Incrementality

Taking Johnson and Charniak’s model as a
starting point, we would like to develop an in-
cremental version of that algorithm. We sim-
ulate incrementality by maintaining for each
utterance to be processed an end-of-preﬁx
boundary; tokens after this boundary are
not available for the model to use. At each
step in our incremental model, we advance this
boundary by one token (the increment), un-
til ﬁnally the entire utterance is available. We
make use of the notion of a preﬁx, which is
a substring of the utterance consisting of all
tokens up to this boundary marker.

Just as in the non-incremental model, we
keep track of all the possible reparanda and re-
pairs in a chart. Every time the end-of-preﬁx
boundary advances, we update the chart: we
add all possible disﬂuencies which have the
end position of the repair located one token
before the end-of-preﬁx boundary, and we add
all possible start points for the reparandum,
interregna and repair, and end points for the
reparandum and interregna, given the order-
ing constraints of these components.

In our basic incremental model, we leave the
remainder of the algorithm untouched. When
the end-of-preﬁx boundary reaches the end of
the utterance, and thus the entire utterance
is available, this model results in an iden-
tical analysis to that provided by the non-
incremental model, since the chart contains
identical entries, although calculated in a dif-
ferent order.
Intuitively, this model should
perform well when the current preﬁx is very
close to being a complete utterance; and it
should perform less well when a potential dis-

1375

ﬂuency is still under construction, since these
situations are not typically found in the train-
ing data. We will return to this point further
below.

We do not change the training phase of the
model and we assume that the optimal values
found for the non-incremental model are also
optimal for the incremental model, since most
weights which need to be learned are based on
lexical values. Other weights are bigram based
values, and values dealing with unknown to-
kens (i.e., tokens which occur in the test data,
but not in the training data); it is not unrea-
sonable to assume these weights are identical
or very similar in both the incremental and
the non-incremental model.

4 Evaluation Models and Their

Application

As well as evaluating the accuracy of the anal-
ysis returned at the end of the utterance, it
seems reasonable to also evaluate how quickly
and accurately an incremental algorithm de-
tects disﬂuencies on a word-by-word basis as
the utterance is processed. In this section, we
provide the methodological background to our
approach, and in Section 5.2 we discuss the
performance of our model when evaluated in
this way.

Incremental systems are often judged solely
on the basis of their output when the utter-
ance being processed is completed. Although
this does give an insight into how well a system
performs overall, it does not indicate how well
the incremental aspects of the mechanism per-
form. In this section we present an approach
to the evaluation of a model of speech repair
detection which measures the performance of
the incremental component.

One might calculate the accuracy over all
preﬁxes using a simple word accuracy score.
However, because each preﬁx is a superstring
of each previous preﬁx, such a calculation
would not be fair: tokens that appear in early
in the utterance will be counted more often
than tokens that appear later in the utterance.
In theory, the analysis of the early tokens can
change at each preﬁx, so arguably it would

make sense to reevaluate the complete analy-
sis so far at every step. In practice, however,
these changes do not happen, and so this mea-
surement would not reﬂect the performance of
the system correctly.

Our approach is to deﬁne a measure of re-
sponsiveness:
that is, how soon is a dis-
ﬂuency detected? We propose to measure
responsiveness in two ways. The time-to-
detection score indicates how many tokens
following a disﬂuency are read before the given
disﬂuency is marked as one; the delayed ac-
curacy score looks n tokens back from the
boundary of the available utterance and, when
there is a gold standard disﬂuency-marked to-
ken at that distance, counts how often these
tokens are marked correctly.

We measure the time-to-detection score by
two numbers, corresponding to the number of
tokens from the start of the reparandum and
the number of tokens from the start of the re-
pair. We do this because disﬂuencies can be of
diﬀerent lengths. We assume it is unlikely that
a disﬂuency will be found before the reparan-
dum is completed, since the reparandum it-
self is often ﬂuent. We measure the time-to-
detection by the ﬁrst time a given disﬂuency
appears as one.

Since the model is a statistical model, it
is possible that the most probable analysis
marks a given word at position j as a disﬂu-
ency, while in the next preﬁx the word in the
same position is now no longer marked as be-
ing disﬂuent. A preﬁx later this word might
be marked as disﬂuent again. This presents
us with a problem. How do we measure when
this word was correctly identiﬁed as disﬂuent:
the ﬁrst time it was marked as such or the sec-
ond time? Because of the possibility of such
oscillations, we take the ﬁrst marking of the
disﬂuency as the measure point. Disﬂuencies
which are never correctly detected are not part
of the time-to-detection score.

Since the evaluation starts with disﬂuencies
found by the model, this measurement has
precision-like properties only. Consequently,
there are easy ways to inﬂate the score arti-
ﬁcially at the cost of recall. We address this

1376

by also calculating the delayed accuracy. This
is calculated at each preﬁx by looking back n
tokens from the preﬁx boundary, where n = 0
for the preﬁx boundary. For each n we cal-
culate the accuracy score at that point over
all preﬁxes. Each token is only assessed once
given a set value of n, so we do not suﬀer
from early preﬁxes being assessed more often.
However, larger values of n do not take all to-
kens into account, since the last y tokens of
an utterance will not play a part in the ac-
curacy when y < n. Since we evaluate given
a gold standard disﬂuency, this measurement
has recall-like properties.

Together with the ﬁnal accuracy score over
the entire utterance, the time-to-detection
and delayed accuracy scores provide diﬀerent
insights and together give a good measure-
ment of the responsiveness and performance
of the model.

Our incremental model has the same ﬁ-
nal accuracy as the original non-incremental
model; this corresponds to an F-score (har-
monic mean) of 0.778 on a word basis.

We found the average time to detection,
measured in tokens for this model to be 8.3
measured from the start of reparandum and
5.1 from the start of repair. There are situ-
ations where disﬂuencies can be detected be-
fore the end of the repair; by counting from
the start rather than the end of the disﬂuency
components, we provide a way of scoring in
such cases. To provide a better insight into
what is happening, we also report the average
distance since the start of the reparandum.
We ﬁnd that the time to detect is larger than
the average repair length; this implies that,
under this particular model, most disﬂuencies
are only detected after the repair is ﬁnished.
In fact the diﬀerence is greater than 1, which
means that in most cases it takes one more to-
ken after the repair before the model identiﬁes
the disﬂuency.

Table 1 shows the delayed accuracy. We can
see that the score ﬁrst rises quickly after which
the increases become much smaller. As men-
tioned above, a given disﬂuency detection in
theory might oscillate. In practice, however,

oscillating disﬂuencies are very rare, possibly
because a bigram model operates on a very lo-
cal level. Given that oscillation is rare, a quick
stabilisation of the score indicates that, when
we correctly detect a disﬂuency, this happens
rather quickly after the disﬂuency has com-
pleted, since the accuracy for the large n is
calculated over the same tokens as the accu-
racy for the smaller n (although not in the
same preﬁx).

5 Disﬂuencies around Preﬁx

Boundaries

5.1 Early detection algorithm

Our model uses a language model and a chan-
nel model to locate disﬂuencies. It calculates
a language model probability for the utterance
with the disﬂuency taken out, and it calculates
the probability of the disﬂuency itself with the
STAG channel model.

Consider the following example utterance

fragment where a repair disﬂuency occurs:

. . . wi

rni+1 rni+2

rri+3 rri+4 wi+5 . . .

(3)

reparandum

repair

}|

{

z

}|

{

z

Here, the subscripts indicate token position in
sequence; w is a token outside the disﬂuency;
and rn is a reparandum being repaired by
the repair rr. The language model estimates
the continuation of the utterance without the
disﬂuency. The model considers whether the
utterance continuation after the disﬂuency is
probable given the language model; the rel-
evant bigram here is p(rri+3|wi), continuing
with p(rri+4|rri+3). However, under the in-
cremental model, it is possible the utterance
has only been read as far as token i + 3, in
which case the probability p(wi+4|wi+3) is un-
deﬁned.
We would like to address the issue of look-
ing beyond a disﬂuency under construction.
We assume the issue of not being able to look
for an utterance continuation after the repair
component of the disﬂuency can be found back
in the incremental model scores. A disﬂuency
is usually only detected after the disﬂuency is
completely uttered, and always requires one

1377

n tokens back 1
accuracy

0.500

2
0.558

3
0.631

4
0.665

5
0.701

6
0.714

Table 1: delayed accuracy, n tokens back from the end of preﬁxes

n tokens back 1
accuracy

0.578

2
0.633

3
0.697

4
0.725

5
0.758

6
0.770

Table 2: delayed accuracy under the updated model

more token in the basic model. In the given
instance this means it is unlikely that we will
detect the disﬂuency before i + 5.

In order to make our model more respon-
sive, we propose a change which makes it
possible for the model to calculate channel
probabilities and language model probabili-
ties before the repair is completed. Assum-
ing we have not yet reached the end of utter-
ance, we would like to estimate the continua-
tion of the utterance with the relevant bigram
p(rri+4|rri+3). Since rri+4 is not yet avail-
able we cannot calculate this probability. The
correct thing to do is to sum over all possible
continuations, including the end of utterance
token (for the complete utterance, as opposed
to the current preﬁx). This results in the fol-
lowing bigram estimation:

Xt∈vocabulary

p(t|wi)

(4)

This estimation is not one we need to derive
from our data set, since p is a true probability.
In this case, the sum over all possible continu-
ations (this might include an end of utterance
marker, in which case the utterance is already
complete) equals 1. We therefore modify the
algorithm so that it takes this into account.
This solves the problem of the language model
assessing the utterance with the disﬂuency cut
out, when nothing from the utterance contin-
uation after a disﬂuency is available.

The other issue which needs to be addressed
is the alignment of the reparandum with the
repair when the repair is not yet fully avail-
able. Currently the model is encouraged to
align the individual tokens of the reparandum
with those of the repair. The algorithm has

lower estimations when the reparandum can-
not be fully aligned with the repair because
the reparandum and repair diﬀer considerably
in length.

We note that most disﬂuencies are very
short: reparanda and repairs are often only
one or two tokens each in length, and the inter-
regnum is often empty. To remove the penalty
for an incomplete repair, we allow the repair to
grow one token beyond the preﬁx boundary;
given the relative shortness of the disﬂuencies,
this seems reasonable. Since this token is not
available, we cannot calculate the lexical sub-
stitution value. Instead we deﬁne a new opera-
tion in the channel model: in addition to dele-
tion, insertion, copy, and substitution, we add
an additional substitution operation, the in-
cremental completion substitution. This
operation does not compete with the copy op-
eration or the normal substitution operation,
since it is only deﬁned when the last token of
the repair falls at the preﬁx boundary.

5.2 Results for the Early detection

algorithm

The results of these changes are reﬂected
in new time-to-detection and delayed accu-
racy scores. Again we calculated the time-
to-detection, and found this to be 7.5 from
the start of reparandum and 4.6 from the
start of repair. Table 2 shows the results un-
der the new early completion model using the
delayed accuracy method. We see that the
updated model has lower time-to-detection
scores (close to a full token earlier); for de-
layed accuracy, we note that the scores sta-
bilise in a similar fashion, but the scores for
the updated model rise slightly more quickly.

1378

6 Conclusions and Future Work

Acknowledgements

This work was supported by the Australian
Research Council as part of the Thinking
Head Project, ARC/NHMRC Special Re-
search Initiative Grant # TS0669874. We
thank the anonymous reviewers for their help-
ful comments.

References

Charniak, Eugene. 2001.

Immediate-head pars-
ing for language models. In Proceedings of the
39th Annual Meeting on Association for Com-
putational Linguistics, pages 124–131.

Core, Mark and Lenhart Schubert. 1999. A model
of speech repairs and other disruptions.
In
AAAI Fall Symposium on Psychological Mod-
els of Communication in Collaborative Systems,
pages 48–53.

Honal, Matthias and Tanja Schultz. 2003. Correc-
tion of Disﬂuencies in Spontaneous Speech us-
ing a Noisy-Channel Approach. In Proceedings
of the 8th Eurospeech Conference.

Johnson, Mark and Eugene Charniak. 2004. A
tag-based noisy channel model of speech repairs.
In Proceedings of the 42nd Annual Meeting of
the Association for Computational Linguistics,
pages 33–39.

Marslen-Wilson, W. 1973. Linguistic structure
and speech shadowing at very short latencies.
Nature, 244:522–533.

Schuler, William, Samir AbdelRahman, Tim
Miller, and Lane Schwartz.
2010. Broad-
Coverage Parsing using Human-Like Mem-
ory Constraints. Computational Linguistics,
36(1):1–30.

Shieber, Stuart M. and Yves Schabes. 1990. Syn-
chronous tree-adjoining grammars. In Proceed-
ings of the 13th International Conference on
Computational Linguistics, pages 253–258.

Shriberg, Elizabeth.

1994. Preliminaries to a
Theory of Speech Disuencies. Ph.D. thesis, Uni-
versity of California, Berkeley.

We have demonstrated an incremental model
for ﬁnding speech disﬂuencies in spoken lan-
guage transcripts. When we consider com-
plete utterances, the incremental model pro-
vides identical results to those of a non-
incremental model that delivers state-of-the-
art accuracy in speech repair detection. We
have investigated a number of measures which
allow us to evaluate the model on an incremen-
tal level. Most disﬂuencies are identiﬁed very
quickly, typically one or two tokens after the
disﬂuency has been completed. We addressed
the problems of the model around the end of
preﬁx boundaries. These are repairs which are
either still in the process of being uttered or
have just been completed. We have addressed
this issue by making some changes to how the
model deals with preﬁx boundaries, and we
have shown that this improves the responsive-
ness of the model.

The work reported in this paper uses a n-
gram model as a language model and a STAG
based model for the repair. We would like
to replace the n-gram language model with a
better language model. Previous work (John-
son and Charniak, 2004) has shown that dis-
ﬂuency detection can be improved by replac-
ing the n-gram language model with a statis-
tical parser. Besides a reported 5% accuracy
improvement, this also provides a structural
analysis, something which an n-gram model
does not. We would like to investigate a sim-
ilar extension in our incremental approach,
which will require the integration of an in-
cremental statistical parser with our noisy
channel model. While transcripts of spoken
texts come with manually annotated sentence
boundaries, real time spoken language does
not. The language model in particular takes
these sentence boundaries into account. We
therefore propose to investigate the proper-
ties of this model when sentence boundaries
are removed.

