










































WordTopic-MultiRank: A New Method for Automatic Keyphrase Extraction


International Joint Conference on Natural Language Processing, pages 10–18,
Nagoya, Japan, 14-18 October 2013.

WordTopic-MultiRank : A New Method for Automatic Keyphrase
Extraction

Fan Zhang† Lian’en Huang† Bo Peng‡
†The Shenzhen Key Lab for Cloud Computing Technology and Applications
Peking University Shenzhen Graduate School, Shenzhen 518055, P.R.China

fan.zhgf@gmail.com, hle@net.pku.edu.cn
‡Institute of Network Computing and Information Systems

Peking University, Beijing 100871, P.R.China
pb@net.pku.edu.cn

Abstract

Automatic keyphrase extraction aims to
pick out a set of terms as a representa-
tion of a document without manual assign-
ment efforts. Supervised and unsupervised
graph-based ranking methods have been s-
tudied for this task. However, previous
methods usually computed importance s-
cores of words under the assumption of
single relation between words. In this
work, we propose WordTopic-MultiRank
as a new method for keyphrase extraction,
based on the idea that words relate with
each other via multiple relations. First
we treat various latent topics in documents
as heterogeneous relations between words
and construct a multi-relational word net-
work. Then, a novel ranking algorithm,
named Biased-MultiRank, is applied to s-
core the importance of words and topics si-
multaneously, as words and topics are con-
sidered to have mutual influence on each
other. Experimental results on two differ-
ent data sets show the outstanding perfor-
mance and robustness of our proposed ap-
proach in automatic keyphrase extraction
task.

1 Introduction

Keyphrases refer to the meaningful words and
phrases that can precisely and compactly represen-
t documents. Appropriate keyphrases help users a
lot in better grasping and remembering key ideas
of articles, as well as fast browsing and reading.
Moreover, qualities of some information retrieval
and natural language processing tasks have been
improved with the help of document keyphrases,
such as document indexing, categorizing, cluster-

‡Corresponding author.

ing and summarizing (Gutwin et al., 1999; Krul-
wich and Burkey, 1996; Hammouda et al., 2005).

Usually, keyphrases are manually assigned by
authors, which is time consuming. With the fast
development of Internet, it becomes impractical
to label them by human effort as articles on the
Web increase exponentially. Therefore, automat-
ic keyphrase extraction plays an important role in
keyphrases assignment task.

In most existing work, words are assumed under
a single relation and then scored or judged with-
in it. Considering the famous TextRank (Mihal-
cea and Tarau, 2004), a term graph under a sin-
gle relatedness was built first, then a graph-based
ranking algorithm, such as PageRank (Page et al.,
1999), was used to determine the importance s-
core for each term. Another compelling example
is (Liu et al., 2010), where words were scored un-
der each topic separately.

In this study, inspired by some multi-relational
data mining techniques, such as (Ng et al., 2011),
we assume each topic as a single relation type and
construct an intra-topic word network for each re-
lation type. In other words, it is to map word relat-
edness within multiple topics to heterogeneous re-
lations, meaning that words have interactions with
others based on different topics.

A multi-relational words example of our pro-
posed WordTopic-MultiRank model is shown in
Figure 1(a). There are four words and three re-
lations in this example, implying that there are
three potential topics contained in the documen-
t. Further, we represent such multi-relational data
in a tensor shape in Figure 1(b), where each two-
dimensional plane represents an adjacency ma-
trix for one type of topics. Then the heteroge-
neous network can be depicted as a tensor of size
4×4×3, where (i, j, k) entry is nonzero if the ith
word is related to the jth word under kth topic.

After that, we raise a novel measurement of
word relatedness considering different topics, and

10



Figure 1: (a) An example of multi-relational words
in graph representation and (b) the corresponding
tensor representation.

then apply Biased-MultiRank algorithm to deal
with multi-relational words for co-ranking pur-
pose, based on the idea that words and topics have
mutual influence on each other. More specifically,
a word, connected with highly scored words via
highly scored topics, should receive a high score
itself, and similarly, a topic, connecting highly s-
cored words, should get a high score as well.

Experiments have been performed on two dif-
ferent data sets. One is a collection of scientif-
ic publication abstracts, while the other consists
of news articles with human-annotated keyphras-
es. Experimental results demonstrate that our
WordTopic-MultiRank method outperforms repre-
sentative baseline approaches in specified evalua-
tion metrics. And we have investigated how dif-
ferent parameter values influence the performance
of our method.

The rest of this paper is organized as follows.
Section 2 introduces related work. In Section 3,
details of constructing and applying WordTopic-
MultiRank model are presented. Section 4 shows
experiments and results on two different data sets.
Finally, in Section 5, conclusion and future work
are discussed .

2 Related Work

Existing methods for keyphrase extraction task
can be divided into supervised and unsupervised
approaches. The supervised methods mainly treat
keyphrase extraction as a classification task, so
a model needs to be trained before classifying
whether a candidate phrase is a keyphrase or not.
Turney (1999) firstly utilized a genetic algorithm
with parameterized heuristic rules for keyphrase
extraction, then Hulth (2003) added more linguis-
tic knowledge as features to achieve better perfor-

mance. Jiang et al. (2009) employed linear Rank-
ing SVM, a learning to rank method, to extrac-
t keyphrase lately. However, supervised methods
require a training set which would demand time-
consuming human-assigned work, making it im-
practical in the vast Internet space. In this work,
we principally concentrate on unsupervised meth-
ods.

Among those unsupervised approaches, clus-
tering and graph-based ranking methods showed
good performance in this task. Representative s-
tudies of clustering approaches are (Liu et al.,
2009) and (Grineva et al., 2009). Liu et al. (2009)
made use of clustering methods to find exemplar
terms and then selected terms from each cluster as
keyphrases. Grineva et al. (2009) applied graph
community detection techniques to partition the
term graph into thematically cohesive groups and
selected groups that contained key terms, discard-
ing groups with unimportant terms. But as is wide-
ly known, one of the major difficulties in cluster-
ing is to predefine the cluster number which influ-
ences performance heavily.

As for basic graph-based approaches, such as
(Mihalcea and Tarau, 2004) and (Litvak and Last,
2008), a graph based on word linkage or word
similarity was first constructed, then a ranking al-
gorithm was used to determine the importance s-
core of each term. Wan et al. (2007) present-
ed an idea of extracting summary and keyword-
s simultaneously under the assumption that sum-
mary and keywords of the same document can
be mutually boosted. Moreover, Wan and Xiao
(2008a) used a small number of nearest neighbor
documents for providing more knowledge to im-
prove performance and similarly, Wan and Xiao
(2008b) made use of multiple documents with a
cluster context. Recently, topical information was
under consideration to be combined with graph-
based approaches. One of the outstanding s-
tudies was Topic-sensitive PageRank (Haveliwala,
2002), which computed scores of web pages by in-
corporating topics of the context. As another rep-
resentative, Topical PageRank (Liu et al., 2010)
applied a Biased PageRank to assign an impor-
tance score to each term under every latent topic
separately.

To the best of our knowledge, previous graph-
based researches are based on the assumption that
all words exist under a unified relation, while in
this work, we view latent topics within documents

11



as word relations and words as multi-relational da-
ta, in order to make full use of word-word relat-
edness, word-topic interaction and inter-topic im-
pacts.

3 WordTopic-MultiRank Method

In this section, we will introduce our proposed
WordTopic-MultiRank method in details, includ-
ing topic decomposition, word relatedness mea-
surement, heterogeneous network construction
and Biased-MultiRank algorithm.

3.1 Topic Detection via Latent Dirichlet
Allocation

There are some existing methods to infer latent
topics of words and documents. Latent Dirichlet
Allocation (LDA) (Blei et al., 2003) is adopted in
our work as it is more feasible for inference and it
can reduce the risk of over-fitting.

Firstly, we denote the learning corpus for LDA
as C, and |C| represents the total number of doc-
uments in C. The ith document in the corpus is
denoted as di, in which i = 1, 2, · · · , |C|. Then,
words are denoted as wij where i indicates that
word wij appears in document di and j refers to
jth position in di (j = 1, 2, · · · , |di|, |di| is the to-
tal word number in di). Further, topics inferred
from |C| is zk, k = 1, 2, · · · , |T |, while T stand-
s for the topic set detected from C and |T | is the
total number of topics.

According to LDA, observed words in each
document are supposed to be generated by a
document-specific mixture of corpus-wide latent
topics. More specifically, each word wij in doc-
ument di is generated by first sampling a topic zk
from di’s document-topic multinomial distribution
θdi , and then sampling a word from zk’s topic-
word multinomial distribution ϕzk . And each θdi
is generated by a conjugate Dirichlet prior with pa-
rameter α, while each ϕzk is generated by a con-
jugate Dirichlet prior with parameter β. The full
generative model for wij is given by:

p(wij |di, α, β) =
|T |∑
k=1

p(wij |zk, β)p(zk|di, α)

(1)
Using LDA, we finally obtain the document-

topic distribution, namely p(zk|di) for all the top-
ics zk on each document di, as well as the topic-
word distribution, namely p(wij |zk) for all the
words wij on each topic zk.

In this work, we use GibbsLDA++1, a C/C++
implementation of LDA using Gibbs Sampling, to
detect latent topics.

3.2 Measurement of Word Relatedness
under Multi-relations

Next, we apply Bayes’ theorem to get word-topic
distribution p(zk|wij) for every word in a given
document di:

p(zk|wij) =
p(wij |zk, β)p(zk|di, α)∑|T |

k=1 p(wij |zk, β)p(zk|di, α)
(2)

Therefore, we can obtain word relatedness as
follows:

p(wim|win, zk) = p(wim|zk)p(zk|win) (3)

where m,n = 1, 2, · · · , |di|, and p(wim|win, zk)
represents the relatedness of word wim and word
win under kth topic.

From the view of probability, p(zk|win) is the
probability of word win being assigned to topic
zk and p(wim|zk) is the probability of generat-
ing word wim from the same topic zk. Therefore,
p(wim|win, zk) shows the probability of generat-
ing word wim if we have observed word win under
topic zk. Obviously, this point of view correspond-
s with LDA and it connects words via topics.

3.3 Constructing a Heterogeneous Network
on Words

Like Figure 1(a) shown in Introduction, now we
construct a multi-relational network for words. In
the same way mentioned by typical graph-based
methods, for every document di in corpus C, we
treat every single word as a vertex and make use
of word co-occurrences to construct a word graph
as it indicates the cohesion relationship between
words in the context of document di. In this pro-
cess, a sliding window with maximum W words
is used upon the word sequences of documents.
Those words appearing in the same window will
have a link to each other under all the relations in
the network.

Further, we obtain the word relatedness under
every topic from Formula (3), and use them as
weights of edges for constructing the heteroge-
neous network. For instance, p(wim|win, zk) is
regarded as the weight of the edge from win to
wim under kth relation if there is a co-occurrence
relation between the two words in document di.

1GibbsLDA++: http://gibbslda.sourceforge.net

12



As (Hulth, 2003) pointed out, most manually
assigned keyphrases were noun groups whose pat-
tern was zero or more adjectives followed by one
or more nouns. We only take adjectives and nouns
into consideration while constructing networks in
experiments.

3.4 Ranking Algorithm

In our proposed method, we employ Biased-
MultiRank algorithm for co-ranking the impor-
tance of words and topics. It is obtained by
adding prior knowledge of words and topics to
Basic-MultiRank, a basic co-ranking scheme de-
signed for objects and relations in multi-relational
data. Therefore, we will demonstrate Basic-
MultiRank first, then derive Biased-MultiRank al-
gorithm from it.

3.4.1 Basic-MultiRank Algorithm
In this subsection, we take document di into dis-
cussion for convenience. First, we call A =
(awim,win,zk) a real (2, 1)th order (|di| × |T |)-
dimensional rectangular tensor, where awim,win,zk
denotes p(wim|win, zk) obtained in last subsec-
tion, in which m,n = 1, 2, · · · , |di| and k =
1, 2, · · · , |T |. For example, Figure 1(b) is a
(2, 1)th order (4×3)-dimensional tensor represen-
tation of a document, in which there are 4 words
and 3 topics.

Then two transition probability tensors O =
(owim,win,zk) and R = (rwim,win,zk) are con-
structed with respect to words and topics by nor-
malizing all the entries of A:

owim,win,zk =
awim,win,zk∑|di|

m=1 awim,win,zk
(4)

rwim,win,zk =
awim,win,zk∑|T |

k=1 awim,win,zk
(5)

Here we deal with dangling node problem in the
same way as PageRank (Page et al., 1999). Name-
ly, if awim,win,zk is equal to 0 for all words wim,
which means that word win had no link out to any
other words via topic zk, we set owim,win,zk to be
1/|di|. Likewise, if awim,win,zk is equal to 0 for all
zk, which means that word win had no link out to
words wim via all topics, we set rwim,win,zk to be
1/|T |. In this way, we ensure that

0 ≤ owim,win,zk ≤ 1,
|di|∑

m=1

owim,win,zk = 1

0 ≤ rwim,win,zk ≤ 1,
|T |∑
k=1

rwim,win,zk = 1

Following the rule of Markov chain, we derive
the probabilities like:

P [Xt=wim]=

|di|∑
n=1

|T |∑
k=1

owim,win,zk×P [Xt−1=win,Yt=zk]

(6)

P [Yt=zk]=

|di|∑
m=1

|di|∑
n=1

rwim,win,zk×P [Xt=wim,Xt−1=win]

(7)

where subscript t denotes the iteration number.
Notice that Formula (6) and (7) accord with our

basic idea that, a word connected with high proba-
bility words via high probability relations, should
have a high probability so that it will be visited
more likely, and a topic connecting words with
high probabilities, should also get a high one.

After employing a product form of individu-
al probability distributions, we decouple the two
joint probability distributions in Formula (6) and
(7) as follows:

P [Xt−1=win,Yt=zk]=P [Xt−1=win]P [Yt=zk] (8)

P [Xt=wim,Xt−1=win]=P [Xt=wim]P [Xt−1=win]
(9)

Considering stationary distributions of words
and topics, while t goes infinity, the WordTopic-
MultiRank values are given by:

x=[xwi1 ,xwi2 ,···,xwi|di| ]
T (10)

y=[yz1 ,yz2 ,···,yz|T |]
T (11)

with
xwim= limt→∞

P [Xt=wim] (12)

yzk= limt→∞
P [Yt=zk] (13)

Under the assumptions from Formula (8) to
(13), we can derive these from Formula (6) and
(7):

xwim=

|di|∑
n=1

|T |∑
k=1

owim,win,zkxwinyzk (14)

yzk=

|di|∑
m=1

|di|∑
n=1

rwim,win,zkxwimxwin (15)

13



which mean that the score of wim depends on it-
s weighted-links with other words via all topics
and the score of zk depends on scores of the words
which it connects with.

Now we are able to solve two tensor equations
shown below to obtain the WordTopic-MultiRank
values of words and relations according to tensor
operations Formula (14) and (15):

Oxy=x (16)

Rx2=y (17)
Ng et al. (2011) show the existence and unique-

ness of stationary probability distributions x and y,
then propose MultiRank, an iterative algorithm, to
solve Formula (16) and (17) utilizing Formula (14)
and (15). We refer it as Basic-MultiRank algorith-
m, shown as Algorithm 1, for the reason that it
will be modified later in the following subsection.

Algorithm 1 Basic-MultiRank algorithm
Require: Tensor A , initial probability distri-

butions x0 and y0 (
∑|di|

m=1[x0]wm=1 and∑|T |
k=1[y0]zk=1) , tolerance ϵ

Ensure: Two stationary probability distributions
x and y

1: compute tensor O and R;
2: set t = 1;
3: Compute xt=Oxt−1yt−1;
4: Compute yt=Rx2t ;
5: if ||xt−xt−1||+||yt−yt−1||<ϵ, then stop, oth-

erwise set t=t+1 and goto Step 3;
6: return xt and yt.

3.4.2 Biased-MultiRank Algorithm
Inspired by the idea of Biased PageRank (Liu et
al., 2010), we treat document-word distribution
p(wij |di), which can be computed from Formula
(1), and document-topic distribution p(zk|di), ac-
quired from topic decomposition, as prior knowl-
edge for words and topics in each document di.
Therefore, we modify Formula (16) and (17) by
adding prior knowledge to it as follows:

(1−λ)Oxy+λxp=x (18)

(1−γ)Rx2+γyp=y (19)
where, xp=[p(wi1|di),p(wi2|di),···,p(wi|di||di)]T and
yp=[p(z1|di),p(z2|di),···,p(z|T ||di)]

T .
Then we propose Biased-MultiRank, shown as

Algorithm 2, as a new algorithm to solve the
prior-tensors and Formula (18) and (19). Finally
it is used in our WordTopic-MultiRank model.

Algorithm 2 Biased-MultiRank algorithm
Require: Tensor A, initial probability distri-

butions x0 and y0 (
∑|di|

m=1[x0]wm=1 and∑|T |
k=1[y0]zk=1), prior distribution of words

xp and topics yp, parameters λ and γ (0≤λ,γ<
1), tolerance ϵ

Ensure: Two stationary probability distributions
x and y

1: compute tensors O and R;
2: set t = 1;
3: Compute xt=(1−λ)Oxt−1yt−1+λxp;
4: Compute yt=(1−γ)Rx2t +γyp;
5: if ||xt−xt−1||+||yt−yt−1||<ϵ, then stop, oth-

erwise set t=t+1 and goto Step 3;
6: return xt and yt.

4 Experiment

To evaluate the performance of WordTopic-
MultiRank in automatic keyphrase extraction task,
we utilize it on two different data sets and describe
the experiments specifically in this section.

4.1 Experiments on Scientific Abstracts

4.1.1 Data Set

We first employ WordTopic-MultiRank model to
conduct experiments on a data set of scientific
publication abstracts from the INSPEC database
with corresponding manually assigned keyphras-
es2. The data set is also used by Hulth (2003), Mi-
halcea and Tarau (2004), Liu et al. (2009), and Liu
et al. (2010), meaning that it is classically used in
the task of keyphrase extraction, and is convenient
for comparison.

Actually, this data set contains 2,000 abstracts
of research articles and 19,254 manually annotated
keyphrases, and is split into 1,000 for training, 500
for validation and 500 for testing.

In this study, we use the 1,000 training doc-
uments as corpus C for topic detection and like
other unsupervised ranking methods, 500 test doc-
uments are used for comparing the performance
with baselines. Following previous work, only the
manually assigned uncontrolled keyphrases that
occur in the corresponding abstracts are viewed as
standard answers.

2It can be obtained from http-
s://github.com/snkim/AutomaticKeyphraseExtraction

14



4.1.2 Baselines and Evaluation Metrics
We choose methods proposed by Hulth (2003),
Mihalcea and Tarau (2004), Liu et al. (2009),
and Liu et al. (2010) as baselines for the rea-
son that they are either classical or outstanding in
keyphrase extraction task.

Evaluation metrics are precision, recall, F1-
measure shown as follows:

P=
TP

TP+FP
, R=

TP

TP+FN
, F1=

2PR

P+R
(20)

where TP is the total number of correctly extract-
ed keyphrases, FP is the number of incorrectly
extracted keyphrases, and FN is the number of
those keyphrases which are not extracted.

4.1.3 Data Pre-processing and Configuration
Documents are pre-processed by removing stop
words and annotated with POS tags using Stanford
Log-Linear Tagger3.

Based on the research result of (Hulth, 2003),
only adjectives and nouns are used in constructing
multi-relational words network for ranking, and
keyphrases corresponding with following pattern
are considered as candidates:

(JJ)∗(NN |NNS|NNP )+

in which, JJ indicates adjectives while NN, NNS
and NNP represent various forms of nouns.

At last, top-M keyphrases, which have highest
sum scores of words contained in them, are ex-
tracted and compared with standard answers after
stemming by Porter stemmer4.

In experiments, we set α=1, β=0.01 for For-
mula (1) to (3) empirically, and λ=0.5, γ=0.9 for
Formula (18), (19) indicated by (Li et al., 2012).
Influences of these parameters will not be dis-
cussed further in this work as they have been s-
tudied intensively in previous researches.

4.1.4 Experimental Results
In this subsection, we investigate how different pa-
rameter values influence performance of our pro-
posed model first, then compare the best results
obtained by baseline methods and our model.

First of all, we inspect influences of topic num-
ber |T | on our model performance. Table 1 shows
experimental results when |T | ranges from 20 to
100 while setting window size W=2 and max ex-
tracted number M=10.

3http://nlp.stanford.edu/software/tagger.shtml
4http://tartarus.org/martin/PorterStemmer/

Topic Number Precision Recall F1
20 0.463 0.498 0.479
40 0.464 0.500 0.480
60 0.465 0.502 0.482
80 0.462 0.499 0.480

100 0.462 0.499 0.480

Table 1: Influence of Topic Number |T |

From Table 1, we observe that the performance
does not change much when the number of topics
varies, showing our model’s robustness under the
situation that the actual number of topics is un-
known, which is commonly seen in Information
Retrieval and Natural Language Processing appli-
cations. We can see that |T |=60 produces the best
result for this corpus, so we choose 60 for |T | in
comparison with baselines.

Then, we fix |T |=60 and M=10 to demonstrate
how our model is affected by the windows size W .
Table 2 presents the metrics when W ranges from
2 to 10.

Window Size Precision Recall F1
2 0.465 0.502 0.482
4 0.461 0.496 0.477
6 0.462 0.500 0.480
8 0.461 0.499 0.479

10 0.461 0.498 0.478

Table 2: Influence of Window Size W

Our results are consistent with the findings re-
ported by Liu et al. (2009) and Liu et al. (2010),
indicating that performance usually does not vary
much when W ranges. More details point out that
W=2 is the best.

Moreover, we explore the influence of max ex-
tracted number M by setting W=2 and |T |=60.

M Precision Recall F1
5 0.602 0.393 0.475

10 0.465 0.502 0.482
15 0.420 0.550 0.476

Table 3: Influence of Max Extracted Number M

Table 3 indicates that as M increases, precision
falls down while recall raises up, and M=10 per-
forms best in F1-measure.

At last, Table 4 shows the best results of base-
line methods and our proposed model. In fac-

15



Method Precision Recall F1
Hulth’s (Hulth, 2003) 0.252 0.517 0.339

TextRank (Mihalcea and Tarau, 2004) 0.312 0.431 0.362
Topical PageRank (Liu et al., 2010) 0.354 0.183 0.242

Clustering (Liu et al., 2009) 0.350 0.660 0.457
WordTopic-MultiRank 0.465 0.502 0.482

Table 4: Comparison on Scientific Abstracts

Method Precision Recall F1
ExpandRank(Wan and Xiao, 2008a) 0.288 0.354 0.317
CollaRank(Wan and Xiao, 2008b) 0.283 0.348 0.312
Topical PageRank(Liu et al., 2010) 0.282 0.348 0.312

WordTopic-MultiRank 0.296 0.399 0.340

Table 5: Comparison on DUC2001

t, the best result of (Hulth, 2003) was obtained
by adding POS tags as features for classification,
while running PageRank on an undirected graph,
which was built via using window W=2 on word
sequence, resulted best of (Mihalcea and Tarau,
2004). According to (Liu et al., 2009), spectral
clustering method got best performance in preci-
sion and F1-measure. On the other hand, Top-
ical PageRank (Liu et al., 2010) performed best
when setting window size W=10, topic number
|T |=1,000. Since the influences of parameters
have been discussed above, we set W=2, |T |=60
and M=10 as they result in best performance of
our model on the same data set.

Table 4 demonstrates that our proposed mod-
el outperforms all baselines in both precision and
F1-measure. Noting that baseline methods are all
under a single relation type assumption for word
relatedness, estimations of their word ranking s-
cores are limited, while WordTopic-MultiRank as-
sumes words as multi-relational data and consid-
ers interactions between words and topics more
comprehensively.

4.2 Experiments on DUC2001
In order to show the generalization performance of
our model, we also conduct experiments on anoth-
er data set for automatic keyphrase extraction task
and describe it in this subsection briefly.

Following (Wan and Xiao, 2008a), (Wan and X-
iao, 2008b) and (Liu et al., 2010), a data set an-
notated by Wan and Xiao5 was used in this ex-
periment for evaluation. This data set is the test-
ing part of DUC2001(Over and Yen, 2004), con-

5http://wanxiaojun1979.googlepages.com/

taining 308 news articles with 2,488 keyphras-
es manually labeled. And at most 10 keyphras-
es were assigned to each document. Again, we
choose precision, recall and F1-measure as eval-
uation metrics and use the train part of DUC2001
for topic detection. At last, keyphrases extracted
by our WordTopic-MultiRank model will be com-
pared with the ones occurring in corresponding ar-
ticles after stemming.

As indicated in (Wan and Xiao, 2008b), perfor-
mance on test set does not change much when co-
occurrence window size W ranges from 5 to 20,
and (Liu et al., 2010) also reports that it does not
change much when topic number ranges from 50
to 1,500. Therefore, we pick co-occurrence win-
dow size W=10 and topic number |T |=60 to run
WordTopic-MultiRank model. As for Keyphrase
number M , we vary it from 1 to 20 to obtain dif-
ferent performances. Results are shown in Figure
2.

Figure 2: performance vs. Keyphrase number M

From Figure 2, we can observe how perfor-
mances of our model change with M . Actually,

16



as M increases from 1 to 20, precision decreas-
es from 0.528 to 0.201 in our experiment, while
recall increases from 0.065 to 0.551. As for F1-
measure, it obtains maximum value 0.340 when
M=10 and decreases gradually as M leaves 10
farther. Therefore, W=10, |T |=60 and M=10
are optimal for our proposed method on this test
set.

Table 5 lists the best performance comparison
between our method and previous ones. All pre-
vious methods perform best on DUC2001 test set
while setting co-occurrence window size W=10
and Keyphrase number M=10, which is consis-
tent with our model.

Experimental results on this data set demon-
strate the effectiveness of our proposed model a-
gain as it outperforms baseline methods over all
three metrics.

5 Conclusion and Future Work

In this study, we propose a new method named
WordTopic-MultiRank for automatic keyphrase
extraction task. It treats words in documents as ob-
jects and latent topics as relations, assuming words
are under multiple relations. Based on the idea that
words and topics have mutual influence on each
other, our model ranks importance of words and
topics simultaneously, then extracts highly scored
phrases as keyphrases. In this way, it makes full
use of word-word relatedness, word-topic interac-
tion and inter-topic impacts. Experiments demon-
strate that WordTopic-MultiRank achieves better
performance than baseline methods on two differ-
ent data sets. It also shows the good effectiveness
and strong robustness of our method after we ex-
plored the influence of different parameter values.

In future work, for one thing, we would like
to investigate how different corpora influence our
method and choose a large-scale and general cor-
pus, such as Wikipedia, for experiments. For an-
other, exploring more algorithms to deal with het-
erogeneous relation network may help to unearth
more knowledge between words and topics, and
improve our model performance.

Acknowledgments

This research is financially supported by NSFC
Grant 61073082 and NSFC Grant 61272340.

References
D.M. Blei, A.Y. Ng, and M.I. Jordan. 2003. Latent

dirichlet allocation. the Journal of machine Learn-
ing research, 3:993–1022.

Maria Grineva, Maxim Grinev, and Dmitry Lizorkin.
2009. Extracting key terms from noisy and multi-
theme documents. In Proceedings of the 18th inter-
national conference on World wide web, pages 661–
670. ACM.

Carl Gutwin, Gordon Paynter, Ian Witten, Craig Nevill-
Manning, and Eibe Frank. 1999. Improving brows-
ing in digital libraries with keyphrase indexes. De-
cision Support Systems, 27(1):81–104.

Khaled M Hammouda, Diego N Matute, and Mo-
hamed S Kamel. 2005. Corephrase: Keyphrase ex-
traction for document clustering. In Machine Learn-
ing and Data Mining in Pattern Recognition, pages
265–274. Springer.

Taher H Haveliwala. 2002. Topic-sensitive pagerank.
In Proceedings of the 11th international conference
on World Wide Web, pages 517–526. ACM.

A. Hulth. 2003. Improved automatic keyword extrac-
tion given more linguistic knowledge. In Proceed-
ings of EMNLP, pages 216–223.

Xin Jiang, Yunhua Hu, and Hang Li. 2009. A ranking
approach to keyphrase extraction. In Proceedings
of the 32nd international ACM SIGIR conference on
Research and development in information retrieval,
pages 756–757. ACM.

Bruce Krulwich and Chad Burkey. 1996. Learning
user information interests through extraction of se-
mantically significant phrases. In Proceedings of the
AAAI spring symposium on machine learning in in-
formation access, pages 100–112.

Xutao Li, Michael K Ng, and Yunming Ye. 2012.
Har: Hub, authority and relevance scores in multi-
relational data for query search. In SDM, pages 141–
152.

Marina Litvak and Mark Last. 2008. Graph-based
keyword extraction for single-document summariza-
tion. In Proceedings of the workshop on multi-
source multilingual information extraction and sum-
marization, pages 17–24. Association for Computa-
tional Linguistics.

Z. Liu, P. Li, Y. Zheng, and M. Sun. 2009. Clustering
to find exemplar terms for keyphrase extraction. In
Proceedings of EMNLP, pages 257–266.

Z. Liu, W. Huang, Y. Zheng, and M. Sun. 2010. Auto-
matic keyphrase extraction via topic decomposition.
In Proceedings of EMNLP, pages 366–376.

R. Mihalcea and P. Tarau. 2004. Textrank: Bringing
order into texts. In Proceedings of EMNLP, pages
404–411.

17



M.K.P. Ng, X. Li, and Y. Ye. 2011. Multirank: co-
ranking for objects and relations in multi-relational
data. In Proceedings of the 17th ACM SIGKDD,
pages 1217–1225.

Paul Over and James Yen. 2004. Introduction to duc-
2001: an intrinsic evaluation of generic news tex-
t summarization systems. In Proceedings of DUC
2004 Document Understanding Workshop, Boston.

Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: bringing order to the web.

Peter D Turney. 1999. Learning to extract keyphrases
from text. national research council. Institute for In-
formation Technology, Technical Report ERB-1057.

X. Wan and J. Xiao. 2008a. Single documen-
t keyphrase extraction using neighborhood knowl-
edge. In Proceedings of AAAI, pages 855–860.

Xiaojun Wan and Jianguo Xiao. 2008b. Col-
labrank: towards a collaborative approach to single-
document keyphrase extraction. In Proceedings of
the 22nd International Conference on Computation-
al Linguistics-Volume 1, pages 969–976. Associa-
tion for Computational Linguistics.

X. Wan, J. Yang, and J. Xiao. 2007. Towards an iter-
ative reinforcement approach for simultaneous doc-
ument summarization and keyword extraction. In
ACL, page 552.

18


