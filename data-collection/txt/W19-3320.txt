



















































Towards Universal Semantic Representation


Proceedings of the First International Workshop on Designing Meaning Representations, pages 177–181
Florence, Italy, August 1st, 2019 c©2019 Association for Computational Linguistics

177

Towards Universal Semantic Representation

Huaiyu Zhu
IBM Research - Almaden

650 Harry Road,
San Jose, CA 95120

huaiyu@us.ibm.com

Yunyao Li
IBM Research - Almaden

650 Harry Road,
San Jose, CA 95120

yunyaoli@us.ibm.com

Laura Chiticariu
IBM Watson

650 Harry Road,
San Jose, CA 95120

chiti@us.ibm.com

Abstract

Natural language understanding at the seman-
tic level and independent of language varia-
tions is of great practical value. Existing ap-
proaches such as semantic role labeling (SRL)
and abstract meaning representation (AMR)
still have features related to the peculiarities
of the particular language. In this work we
describe various challenges and possible so-
lutions in designing a semantic representation
that is universal across a variety of languages.

1 Introduction

Natural languages have many syntactic variations
for expressing the same meaning, not only within
each language but more so across languages, mak-
ing syntactical analysis cumbersome to use by
downstream applications. Semantic understanding
of natural language is fundamental for many ap-
plications that take natural language texts as part
of their input. Semantic Role Labeling (SRL) an-
alyzes the predicate-role structure at the shallow
semantic parsing level (e.g., PropBank (Kings-
bury and Palmer, 2002)). At a deeper level, Ab-
stract Meaning Representation (AMR) provides a
rooted, directional and labeled graph representing
the meaning of a sentence (Banarescu et al., 2013),
focusing on semantic relations between concepts
such as PropBank predicate-argument structures
while abstracting away from syntactic variation.

Many applications require multilingual capabil-
ities, but SRL and AMR annotation schemes de-
signed for individual languages have language-
dependent features. For example, Hajic et al.
(2014); Xue et al. (2014) observed AMRs de-
signed for different languages have differences,
some accidental but others are more fundamen-
tal. Several efforts are underway to create more
cross-lingual natural language resources. Uni-
versal Dependencies (UD) is a framework for

cross-linguistically consistent grammatical anno-
tation.(De Marneffe et al., 2014). The Universal
Proposition Banks project aims to annotate text
in different languages with a layer of ”universal”
semantic role labeling annotation, by using the
frame and role labels of the English Proposition
Bank to label shallow semantics in sentences in
new target languages(Akbik et al., 2015). Simi-
larly, Damonte and Cohen (2018) use AMR an-
notations for English as a semantic representation
for sentences written in other languages, utilizing
an AMR parser for English and parallel corpora to
learn AMR parsers for additional languages.

Despite these efforts, some remaining inter-
language variations important for practical usage
are not yet captured by the efforts so far. They cre-
ate obstacles to a truly cross-lingual meaning rep-
resentation which would enable the downstream
applications be written for one language and appli-
cable for other languages. The purpose of this pa-
per is two-fold. One objective is to highlight some
of these remaining issues and call the attention of
the community to resolving them. Another objec-
tive is to advocate a form of abstract meaning rep-
resentation geared towards cross-lingual universal
applicability, in the same spirit of AMR but some-
what simplified, with the following major similar-
ities and differences

• Like AMR, it makes use of PropBank style
predicate-argument structures.

• It does not have AMR style concept nodes. It
does not infer relations among instances and
concepts other than those expressed explic-
itly, nor perform co-reference resolution.

• It is geared towards cross-lingual represen-
tation of logical structures, such as conjunc-
tions and conditionals.

• It assigns features to nodes, to promote struc-
tural simplicity and to increase extensibility.



178

We will illustrate, through several examples, the
kinds of issues that arise from attempting to create
a universal meaning representation, and the chal-
lenges in resolving these issues. We will describe
our tentative solutions and call the attention of the
community to these issues.

2 Examples of semantic variations

Across different languages, semantic structures
are much more uniform than syntactic structures.
However, there are still language variations in
shallow semantics. In this section we look at a
number of examples.

2.1 Temporal semantics
Predicates often represent actions that happen, or
states or properties that exist or change, in a cer-
tain time frame. Different languages have differ-
ent ways to express such temporal relations. In
English, auxiliary verbs and main verbs are usu-
ally combined with morphological change to ex-
press tense and aspect. For example,

I am going to speak to him. (future-simple)
I have spoken to him. (present-perfect)
I was speaking to him. (past-progressive)

Similar meanings are represented differently in
other languages. For example, German usually
does not distinguish verbs between present-perfect
and the past-simple as English, even though it for-
mally has corresponding syntactic structures. In-
stead the distinction is implied by temporal argu-
ments such as a prepositional phrases. In Chinese
the corresponding concepts are represented by ad-
verbs and participles. For example,

I have been reading for a week. (pres.-perf.-prog.)
Ich lese seit einer Woche. (past-simple)
我已已已经经经读读读了了了一个星期了了了. (adverb-verb-participle)

A more abstract representation for tense should be
able to unify all these variations. Among avail-
able linguistic theories, Reichenbach (1947)’s the-
ory of tense covers a large proportion of these vari-
ations. It consists of three points in time: point
of event (E), point of reference (R) and point of
speech (S), and two ordering relations: anterior-
ity and simultaneity among these points. In En-
glish, the relation between S and R corresponds
to tense, and the relation between R and E cor-
responds to aspect. For example, “E–S,R” cor-
responds to present-perfect and “E,R–S” corre-
sponds to past-simple. The “progressive” aspect
is not represented in this framework. It can be

added as an additional property. In related work,
Smith (1997) provides a richer semantics by re-
garding temporal aspects as relations among time
intervals. TimeML (Saurı et al., 2006) defines a
rich variety of time related concepts.

2.2 Expressing modality

In English, modal verbs are auxiliary verbs that
express various likelihood of the main verb. These
include certainty and necessity (must, shall), in-
tention (would), ability or possibility (can, may,
might), etc. Additional idiomatic expressions pro-
vide similar functionality. For example,

is capable of, used to, had better to, is willing to

AMR represents syntactic modals with concepts
like possible-01, likely-01, obligate-01, permit-
01, recommend-01, prefer-01, etc. This English-
inspired classification of modality must be ex-
tended for other languages. For example, in Chi-
nese the modal verbs include at least the follow-
ing: 能 (can, may)，会 (can, will, be able to)，
要 (want, wish, intend to)，肯 (be willing to, con-
sent)，敢 (dare)，可能 (may)，可以 (can, be
allowed to)，应该 (should)，愿意 (be willing
to). When combined with negation, these also
include 不愿意 (be reluctant to, be unwilling to),
etc. There is no compelling reason, other than En-
glish convention, that modality has special rela-
tion to modal verbs. Considerations of additional
languages will likely further extend types of such
meanings as well as further refine these meanings.

A cross-lingual framework must allow for all
these variation, while providing basic features that
allow easy categorization of them. In analogy of
Reichenbach’s theory of tense, we propose to cate-
gorize the modality by considering several dimen-
sions that jointly affect the likelihood of an action:

• Probability or certainty

• Requirement or obligation

• Advisability, recommendation or suggestion

• Ability, capability or permit

• Desire or hope

• Willingness or intention

Each modality expression may have values in one
or more of these dimensions.



179

2.3 Conditionality
The most basic language construct expressing “if
A, then B” probably exists in most languages with
syntactic variations. For example, in English it is
more natural to say “if A, B” or “B if A”. Syntac-
tical differences aside, such structures essentially
express a relation of two things, A as antecedent
and B as consequent. Natural languages can also
express, but often not in the same sentence, the
more complete structure “if A, then B, else C”,
There does not appear to be a generally adopted
linguistic term for the C part.

Unlike formal logic, natural language often as-
sociates additional mood, modality and temporal
element with these expressions

X only if Y
X as long as Y
If it were not you, it would not have ....
Had I known it, I would have ...

In English, the subjunctive mood is often associ-
ated with conditional structures in making coun-
terfactual assumptions. The term subjunctive cor-
responds to several different concepts in different
languages. For example, in Spanish, the subjunc-
tive can be used with verbs for wishes, emotions,
impersonal expressions, recommendations, doubt,
denial, hope and other verbs to express what is es-
sentially modality. To accommodate such varia-
tions across different languages, one possible de-
sign is to consider the two aspects of condition-
alality expressions separately. One aspect deals
with the logical implication A → B. The other
aspect is to assign tense and modality to the con-
ditionals. The tense can be useful for expressions
like “Do A until B”, and the modality assigned to
the conditional can be used to express the modal-
ity associated with the conditional itself, not to the
antecedent or consequent.

3 A framework for cross-lingual
meaning representation

The refined meanings discussed in previous sec-
tion must be expressed in a certain framework.
SRL does not have sufficient abstract structures
for this task. AMR is a better candidate, but we
have found it lacking in two aspects. On the one
hand, it has a substantial amount of extra infor-
mation that is neither explicitly expressed in the
sentence nor required by downstream applications.
On the other hand, it still lacks sufficient structure
to express the refined meanings discussed above.

We propose a meaning representation that at-
tempts to simplify AMR while allowing easy in-
corporation of additional features. The proposed
representation is a graph with a small number of
node types, flexible features on the nodes, and la-
beled and directed connections among the nodes.
It is not necessarily a tree.

3.1 Nodes

We consider the following types of nodes:

Predicate A predicate in the sense of PropBank

Role A core argument, such as A0, A1, etc., in the
sense of PropBank.

Context A non-core argument, such as AM-TMP,
AM-LOC, etc. in the sense of PropBank.

Conditional Representation of “if-then-else”
structure, including variations like “unless”,
“as long as”, “whenever”.

Conjunction Representation of “and”, “but”,
“or”, etc. Linguistic conjunctions include
“and”, “but”, “or”, “nor”, etc. Like AMR, it
includes both conjunctions and disjunctions
as well negated expressions in terms of logic.

Relational Representation of a linguistic relation
among entities that is usually expressed in
English with prepositions such as “in”, “on”,
“under”, or similar structures representing
possessive (e.g, “A’s B” vs “B of A”).

3.2 Features

Each node is associated with additional features
specific to the node type. For example, a Predicate
node is associated with features such as the verb
sense (eg.“speak.01”), as well as tense, modality,
polarity, etc.

3.3 Edges

The nodes are connected by edges with well de-
fined types

• Role and Context nodes are connected to
Predicate nodes with SRL labels. Context
might also be connected to other nodes, such
as Conditional, as discussed above.

• A Conditional node is connected to an an-
tecedent node and a consequent node, and op-
tionally to an “else” node.

• A Conjunction node is connected to its con-
stituents.



180

• A Relation node is connected to its con-
stituents.

3.4 Example representation
An example can illustrate various aspects of this
framework. Consider the sentence

Had I studied harder last year, I would have been
able to pass the exam by the end of the winter and
got an A.

This sentence is constructed so that it can be used
to illustrate the issues discussed in this paper.

We will express the graph by describing the
nodes and their features. We use Json style no-
tation for features as key-value pairs. Some of
the values are literal values, others are references
to other nodes, essentially representing the edges
with labels. In this example, for the sake of expo-
sition, we will use features that correspond more
closely to conventional English linguistic features.
For example, Predicates have features tense, as-
pect, modality and polarity.

A = Conditional {mood: conterfactural, antecedent:
B, consequent C }.

B = Predicate {sense: study.01, tense: past, aspect:
simple, polarity: positive, modality: normal}.

B1 = Role {content: I, predicate: B, type: A0 }.
B2 = Context {content: harder, predicate: B, type:

AM-MNR }.
B3 = Context {content: last year, predicate: B,

type: AM-TMP }
C = Conjunction {type: and, members: [C1, C2] }
C1 = Predicate {sense: pass.07, tense: past, aspect:

perfect, polarity: positive, modality: ability}.
C2 = Predicate {sense: get.01, tense: past, aspect:

perfect, polarity: positive, modality: ability}.
C11 = Role {content: I, predicate: C1, type: A0 }.
C12 = Role {content: exam, predicate: C1, type:

A1 }.
C13 = Context {content: by the end of the winter,

predicate: C1, type: AM-TMP }
. . .

Note the following points:

• The structure of this graph is simpler than
AMR graph, mostly by virtue of removing
the AMR concept nodes.

• For the remaining nodes the edges connect-
ing them are similar to those in AMR graphs.

• The nodes are typed. Each type has a specific
set of features.

Although we have used more traditional feature
sets in this example, it is obvious that more or-
thogonal feature designs as discussed in the previ-
ous section can be used instead, without changing
the overall structure of the graph.

3.5 Learning features from data

Using techniques similar to those used to trans-
fer SRL and AMR from one language to an-
other(Akbik et al., 2015; Damonte and Cohen,
2018), it is possible to transfer labeling schemes
for the additional fewatures and structures dis-
cussed in this paper from one language to another.
The cross-lingual transfer may also help to dis-
cover better feature sets from data. For exam-
ple, by analyzing equivalent sentences in differ-
ent languages, it is possible to discover additional
candidates for modalilty or better classification of
modality. Akbik et al. (2016) showed that it is pos-
sible to use correspondences between verb senses
in two languages to discover the duplication and
aliasing of verb senses. Similar techniques can be
applied to verb features such as tense and modal-
ity, as well as structural featues such as condi-
tional and relational features. It is our hope that
this framework provides a sufficiently versatile
scafolding for the community to work together to-
wards a more complete cross-lingual representa-
tion of meanings.

4 Conclusions

Creating a universal semantic representation that
works across a large number of languages is an
important objective for the NLP community. In
this paper we described our attempts towards this
goal, highlighting the issues and challenges that
arise from such efforts. In particular, we described
specific issues related to representing tense and
modality of predicates, as well issues for express-
ing relational structures among the entities and
predicates. We also present a framework for cre-
ating an overall structure to hold the cross-lingual
semantics. It is similar to AMR but with a dif-
ferent emphasis. Instead of identifying all the in-
tricate relations among the constituents of a sen-
tence as well as the concepts they correspond to,
this representation is aimed at expressing the es-
sential structures and important features of these
structures in a cross-lingual fashion. As such it
sacrifices certain capabilities of AMR (such as
concepts and variables) while emphasizing oth-
ers (such as defining the features for various node
types). It is our hope that this framework can stim-
ulate the community to make progress on the de-
sign issues for various features of these structures,
and we call upon the community to work together
to refine this framework.



181

References
Alan Akbik, Marina Danilevsky, Yunyao Li, Shivaku-

mar Vaithyanathan, Huaiyu Zhu, et al. 2015. Gen-
erating high quality proposition banks for multilin-
gual semantic role labeling. In Proceedings of the
53rd Annual Meeting of the Association for Compu-
tational Linguistics and the 7th International Joint
Conference on Natural Language Processing (Vol-
ume 1: Long Papers), volume 1, pages 397–407.

Alan Akbik, Xinyu Guan, and Yunyao Li. 2016. Mul-
tilingual aliasing for auto-generating proposition
banks. In Proceedings of COLING 2016, the 26th
International Conference on Computational Lin-
guistics: Technical Papers, pages 3466–3474.

Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract meaning representation
for sembanking. In Proceedings of the 7th Linguis-
tic Annotation Workshop and Interoperability with
Discourse, pages 178–186.

Marco Damonte and Shay B. Cohen. 2018. Cross-
lingual abstract meaning representation parsing. In
Proc. 2018 NAACL-HLT, pages 1146–1155, New
Orleans, Louisiana. Association for Computational
Linguistics.

Marie-Catherine De Marneffe, Timothy Dozat, Na-
talia Silveira, Katri Haverinen, Filip Ginter, Joakim
Nivre, and Christopher D Manning. 2014. Universal
Stanford dependencies: A cross-linguistic typology.
In LREC, volume 14, pages 4585–92.

Jan Hajic, Ondrej Bojar, and Zdenka Uresova. 2014.
Comparing Czech and English AMRs. In Proceed-
ings of Workshop on Lexical and Grammatical Re-
sources for Language Processing, pages 55–64.

Paul Kingsbury and Martha Palmer. 2002. From Tree-
Bank to PropBank. In LREC, pages 1989–1993.

Hans Reichenbach. 1947. Elements of Symbolic Logic.
Macmillan & Co, New York.

Roser Saurı, Jessica Littman, Bob Knippen, Robert
Gaizauskas, Andrea Setzer, and James Pustejovsky.
2006. TimeML annotation guidelines version 1.2. 1.

C.S. Smith. 1997. The parameters of aspect.

Nianwen Xue, Ondrej Bojar, Jan Hajic, Martha Palmer,
Zdenka Uresova, and Xiuhong Zhang. 2014. Not an
interlingua, but close: Comparison of english amrs
to chinese and czech. In LREC, volume 14, pages
1765–1772. Reykjavik, Iceland.


