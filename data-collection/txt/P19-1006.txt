



















































Constructing Interpretive Spatio-Temporal Features for Multi-Turn Responses Selection


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 44–50
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

44

Constructing Interpretive Spatio-Temporal Features for Multi-Turn
Responses Selection

Junyu Lu†, Chenbin Zhang†, Zeying Xie, Guang Ling, Chao Zhou, Zenglin Xu†
† SMILE Lab, University of Electronic Science and Technology of China, Sichuan, China

{cs.junyu, aleczhang13, swpdtz, zacharyling}@gmail.com,
tom.chaozhou@foxmail.com, zenglin@gmail.com

Abstract
Response selection plays an important role
in fully automated dialogue systems. Given
the dialogue context, the goal of response se-
lection is to identify the best-matched next-
utterance (i.e., response) from multiple can-
didates. Despite the efforts of many previ-
ous useful models, this task remains challeng-
ing due to the huge semantic gap and also
the large size of candidate set. To address
these issues, we propose a Spatio-Temporal
Matching network (STM) for response selec-
tion. In detail, soft alignment is first used to
obtain the local relevance between the con-
text and the response. And then, we con-
struct spatio-temporal features by aggregating
attention images in time dimension and make
use of 3D convolution and pooling operations
to extract matching information. Evaluation
on two large-scale multi-turn response selec-
tion tasks has demonstrated that our proposed
model significantly outperforms the state-of-
the-art model. Particularly, visualization anal-
ysis shows that the spatio-temporal features
enables matching information in segment pairs
and time sequences, and have good inter-
pretability for multi-turn text matching.

1 Introduction

Fully automated dialogue systems (Litman and
Silliman, 2004; Banchs and Li, 2012; Lowe et al.,
2017; Zhou et al., 2018) are becoming increas-
ingly important area in natural language process-
ing. An important research topic in dialogue sys-
tems is response selection, as illustrated in Figure
1, which aims to select an optimal response from
a pre-defined pool of potential responses (Kum-
merfeld et al., 2018). Practical methods to re-
sponse selection are usually retrieval-based, that
focus on matching the semantic similarity between
the response and utterances in the dialogue his-
tory (Shang et al., 2015; Zhang et al., 2018).

Recently, convolutional operation, as a useful
attempt to explore local correlation, has been in-

Figure 1: Examples of the Ubuntu dataset provided by
NOESIS 1. Text segments with the same color symbols
across context and response can be seen as matched
pairs.

vestigated to extract the matching features from
the attention grid (Wu et al., 2017; Zhou et al.,
2018). Unfortunately, these methods usually do
not perform well when there are many candidate
responses.

In fact, in multi-turn dialogues, the next sen-
tence is generally based on what was presented be-
fore and tends to match a recent local context. This
is because the topic in a conversation may change
over time, and the effective matching between the
dialogue may only appear in a local time period.
This phenomena generally appear in video pro-
cessing (Hara et al., 2018; Tran et al., 2014), im-
age caption (Chen et al., 2017) and action recog-
nition (Girdhar and Ramanan, 2017).

Therefore, it is natural to adopt convolutional
structure or attention mechanism to extract lo-
cal matching information from the sentence se-
quences. Analogously, each turn of dialogue can
be regarded as a frame of a video. This moti-
vates us to propose the Spatio-Temporal Match-
ing block (STM) to construct the spatio-temporal

1Noetic End-to-End Response Selection Challenge is de-
scribed in detail at http://workshop.colips.org/
dstc7.

http://workshop.colips.org/dstc7
http://workshop.colips.org/dstc7


45

Figure 2: The proposed spatio-temporal matching framework for response selection.

features of local semantic relation between each
turn of dialog and candidates by soft-attention
mechanism. In detail, we model the response
selection problem as a multi-class classification
problem with sequences as input, where the la-
bel of the true response is set to one and the
other candidates are set to zero. As illustrated
in Figure 2, the proposed STM framework in-
cludes two parts: (i) representation module and
(ii) matching block. Specifically, representa-
tions of the dialogue context and candidate an-
swers are first learned through from dual en-
coders, and deep 3D ConvNets (Ji et al., 2013)
are then used to match attentions between the di-
alogue contexts and candidate answers. Evalua-
tion on the NOESIS datasets has demonstrated the
outstanding performance of our proposed model
against other well-known frameworks. Further-
more, our model enjoys a merit of good inter-
pretation with the visualization of the attention
weight as a thermal map. Our code is released
under https://github.com/CSLujunyu/
Spatio-Temporal-Matching-Network.

2 Our model

Before presenting the model, we first provide the
problem formulation. Suppose that we have a di-
alogue dataset {(D,C,R)i}Ni=1, we denotes D =
{d0, d1, ..., dm} as a conversation context with ut-
terances di and C = {c0, c1, ..., cn} as the next ut-
terance candidate set. R represents the correct re-
sponse ID in the corresponding candidate set. Our
goal is to learn a matching model between the di-

alog context D and the candidates ci which can
measure the matching degree and predict the best
matched response.

2.1 Representation Module

Given a dialog context D = {d0, d1, ..., dm} and
candidates C = {c0, c1, ..., cn}, we employ L lay-
ers of bidirectional GRUs (Bi-GRU) (Cho et al.,
2014) to extract sequential information in a sen-
tence. The representations we used are deep,
in the sense that they are a function of all of
the internal layers of the Bi-GRU (Devlin et al.,
2018; Peters et al., 2018a) We denote lth GRU
layer dialog and candidate representation as Hlµ =
{µl0, µl1, ..., µlm} and Hlγ = {γl0, γl1, ..., γln} re-
spectively.

2.2 Spatio-Temporal Matching block

An illustration of the matching block is shown in
Figure 3. We use attention mechanism to con-
struct local related features for every candidate.
In order to avoid the influence of gradient explo-
sion caused by large dot product, matching ma-
trices are constructed at each layer using scale-
attention (Vaswani et al., 2017), which is defined
as:

Mlµm,γn =
(µlm)

T
γln√

d
, (1)

where l ∈ [1, L], µlm ∈ Rd×nµ denotes mth turn
of dialog representation at lth GRU layer, γln ∈
Rd×nγ denotes nth candidate representation at lth
GRU layer, M lµm,γn ∈ R

nµ×nγ is constructed as

https://github.com/CSLujunyu/Spatio-Temporal-Matching-Network
https://github.com/CSLujunyu/Spatio-Temporal-Matching-Network


46

attention images, d is the dimension of word em-
bedding, nµ and nγ denotes the number of words
in dialog utterances and candidates respectively.

Figure 3: A close-up of the matching block

Moreover, in order to retain the natural tempo-
ral relationship of the matching matrices, we ag-
gregate them all into a 4D-cube by expanding in
time dimension. We call 4D-matching as spatio-
temporal features and define images of nth candi-
date as Q(n):

Q(n) = {Q(n)i,j,k}m×nµ×nγ , (2)

Q
(n)
i,j,k = {M

l
µi,γn [j, k]}

L
l=0, (3)

where Q(n) ∈ Rm×nµ×nγ×L, M lµi,γn [j, k] ∈ R
and Q(n)i,j,k ∈ R

L is a pixel in Q(n).
Motivated by C3D network (Tran et al., 2014),

it is natural to apply a 3D ConvNet to extract local
matching information from Q(n). The operation
of 3D convolution with max-pooling is the exten-
sion of typical 2D convolution, whose filters and
strides are 3D cubes. Our matching block has four
convolution layers and three pooling layers (First
two convolution layers are both immediately fol-
lowed by pooling layer, yet the last pooling layer
follows two continuous convolution layers). All
of 3D convolution filters are 3× 3× 3 with stride
1 × 1 × 1. With the intention of preserving the
temporal information in the early phase, 3D pool-
ing layers are set as 3× 3× 3 with stride 3× 3× 3
except for the first pooling layer which has kernel
size of 1× 3× 3 and stride 1× 3× 3.

One fully-connected layer is used to predict the
matching score between dialog context and poten-
tial responses. Finally, we compute softmax cross
entropy loss,

sn = Wfconv(Q
(n)) + b, (4)

where fconv is the 3D ConvNet we used, W and
b are learned parameters.

3 Experiments

3.1 Dataset

The ongoing DSTC series starts as an initiative
to provide a common testbed for the task of Di-
alog State Tracking, and the most recent event,
DSTC7 in 2018, mainly focused on end-to-end
systems (Williams et al., 2013; Yoshino et al.,
2019). We evaluate our model on two new datasets
that released by the NOESIS (DSTC7 Track1): (1)
the Ubuntu Corpus: Ubuntu IRC (Lowe et al.,
2015a) consists of almost one million two-person
conversations extracted from the Ubuntu chat logs
, used to receive technical support for various
Ubuntu-related problems. The newest version lies
in manually annotations with a large set of can-
didates (Kummerfeld et al., 2018). The train-
ing data includes over 100,000 complete conversa-
tions, and the test data contains 1,000 partial con-
versations. (2) the Advising Dataset: It collects
advisor dialogues for the purpose of guiding the
student to pick courses that fit not only their cur-
riculum, but also personal preferences about time,
difficulty, career path, etc. It provides 100,000 par-
tial conversations for training, obtained by cutting
500 conversations off randomly at different time
points. Each conversation has a minimum of 3
turns and up to 100 candidates.

3.2 Metrics

We use the same evaluation metrics as in previ-
ous works and the recommendation of the NOE-
SIS (Wu et al., 2017; Zhou et al., 2018; Yoshino
et al., 2019). Each comparison model is asked
to select k best-matched utterances from n avail-
able candidates. We calculate the recall of the
true positive responses among the k selected ones

and denote it as Rn@k =
∑k
i=0 yi∑n
i=0 yi

, where yi is the
binary label for each candidate. In addition, we
use MRR (Mean reciprocal rank) (Voorhees et al.,
1999; Radev et al., 2002) to evaluate the confident
ranking of the candidates returned by our model.

3.3 Experimental Setting

We consider at most 9 turns and 50 words for each
utterance and responses in our experiments. Word
embeddings are initialized by GloVe1(Pennington

1http://nlp.stanford.edu/data/glove.840B.300d.zip



47

Model R100@1 R100@10 MRR

Baseline 0.083 0.359 -
DAM 0.347 0.663 0.356

DAM+Fine-tune 0.364 0.664 0.443
DME 0.383 0.725 0.498

DME-SMN 0.455 0.761 0.558

STM(Transform) 0.490 0.764 0.588
STM(GRU) 0.503 0.783 0.597

STM(Ensemble) 0.521 0.797 0.616∗
STM(BERT) 0.548∗ 0.827∗ 0.614

Table 1: Experiment Result on the Ubuntu Corpus.

Model Advising 1 Advising 2

R100@10 MRR R100@10 MRR

Baseline 0.296 - - -
DAM 0.603 0.312 0.374 0.174

DAM+Fine-tune 0.622 0.333 0.416 0.192
DME 0.420 0.215 0.304 0.142

DME-SMN 0.570 0.335 0.388 0.183

STM(Transform) 0.590 0.320 0.404 0.182
STM(GRU) 0.654 0.380 0.466 0.220

STM(Ensemble) 0.662∗ 0.385∗ 0.502∗ 0.232∗

Table 2: Experiment Results on the Advising Dataset.

et al., 2014) and updated during training. We use
Adam (Kingma and Ba, 2014) as the optimizer, set
the initial learning rate is 0.001, and we employ
early-stopping(Caruana et al., 2001) as a regular-
ization strategy.

3.4 Comparison Methods

In this paper, we investigate the current state-of-
the-art model in response selection task. In order
to make it compatible to the task of NOESIS, we
have made some changes as following: (1) Base-
line The benchmark released by DSTC7 is an ex-
tension of the Dual LSTM Encoder model 2 (Lowe
et al., 2015b). (2) Dual Multi-turn Encoder Dif-
ferent from Baseline, we use a multi-turn encoder
to embed each utterance respectively and calcu-
late utterance-candidate matching scores using dot
product at the last hidden state of LSTM. (3) Se-
quential Matching Network We employ Sequen-
tial Matching Network (Wu et al., 2017) to mea-
sure the matching score of each candidate, and
then calculate categorical cross entropy loss across
all of them. We name it as DME-SMN in Ta-
ble 1, 2. (4) Deep Attention Matching Net-
work The DAM (Zhou et al., 2018) trained on
undersampling data (Chawla, 2009), which use a

2https://github.com/IBM/dstc7-noesis/tree/master/noesis-
tf

1:1 ratio between true responses and negative re-
sponses for training, is represented as DAM in Ta-
ble 1, 2. Furthermore, we also construct context-
related negative responses to train the model. We
observe that using only this context-related neg-
ative responses to train the model will result in
divergence. So this data is only used for fine-
tuning. In this way, DAM is firstly trained on un-
dersampling data then get fine-tuned with context-
related negative responses. We name this model as
DAM+Fine-tune in Table 1, 2.

3.5 Ablation Study

As it is shown in Table 1, we conduct an ablation
study on the testset of the Ubuntu Corpus, where
we aim to examine the effect of each part in our
proposed model.

Firstly, we verify the effectiveness of dual
multi-turn encoder by comparing Baseline and
DME in Table 1. Thanks to dual multi-turn en-
coder, DME achieves 0.725 at R100@10 which
is 0.366 better than the Baseline (Lowe et al.,
2015b).

Secondly, we study the ability of representation
module by testing LSTM, GRU and Transformer
with the default hyperparameter in Tensorflow. We
note that GRU is better for this task. After re-
moving spatio-temporal matching block, the per-
formance degrades significantly.

In order to verify the effectiveness of STM
block further, we design a DME-SMN which uses
2D convolution for extracting spatial attention in-
formation and employ GRU for modeling tempo-
ral information. The STM block makes a 10.54%
improvement at R100@1.

Next, we replace GRU with Transformer in
STM. Supposed the data has maximal m turns
and n candidates, the time complexity of cross-
attention (Zhou et al., 2018), O(mn), is much
higher than that of the Dual-Encoder based model,
O(m + n). Thus, cross-attention is an impracti-
cal operation when the candidate set is large. So
we remove cross-attention operations in DAM and
extend it with Dual-Encoder architecture. The re-
sult in Table 1 shows that using self-attention only
may not be enough for representation.

As BERT (Devlin et al., 2018) has been shown
to be a powerful feature extractor for various tasks,
we employ BERT as a feature-based approach
to generate ELMo-like pre-trained contextual rep-
resentations (Peters et al., 2018b).It succeed the



48

Figure 4: Attention feature across positive and negative
matching in the first layer.

highest results and outperforms other methods by
a significant margin.

3.6 Visualization
In order to demonstrate the effectiveness of spatio-
temporal information matching mechanism, we
visualize attention features across positive and
negative examples.

To clarify how our model identifies important
matching information between context and candi-
dates, we visualize the attention matching matri-
ces in Figure 4. The first row is positive match-
ing matrices and the sencond is negative match-
ing example. We denote the y-axis of Figure 4 as
response sentence and the x-axis as utterances in
context. Each colored grid represents the match-
ing degree or attention score between two words.
Deeper color represents better matching. Atten-
tion images in the first row are related to posi-
tive matching while those of the second row are
related to negative matching. Intuitively, We can
see that important words such as “vlc”, “wma” are
recognized and carried to match “drm” in correct
response. In contrast, the incorrect response has
no correlation and thus little matching spaces.

Note that our model can not only match word-
level information, but also can match segment-

Figure 5: Attention feature in different granularities.
Left picture represents the second layer matching ma-
trix for segment granularities, while right picture match
at the third layer.

level or sentence level information using 3D con-
volution. As it shows in Figure 5, the second layer
tends to concentrate on segment-level information
for which “wma patch” in utterance highly match
“the home page drm” and “nasty nasty standard
drm” in response. Furthermore, we find in our ex-
periment that third layer tends to focus on sentence
topic and more abstract meaning of the segments,
which achieve better performance. However, more
than three layers will destroy model ability in our
experiments.

4 Conclusion and Future Work

In this paper, we proposed an End-to-End spatio-
temporal matching model for response selection.
The model uses a dual stacked GRU or pre-trained
BERT to embed utterances and candidates respec-
tively and apply spatio-temporal matching block
to measure the matching degree of a pair of context
and candidate. Visualization of attention layers il-
lustrates that our model has the good interpretative
ability, and has the ability to pick out important
words and sentences.

In the future, we would like to explore the ef-
fectiveness of various attention methods to solve
indefinite choices task with interpretive features.

5 Acknowledgement

Junyu Lu, Chenbin Zhang and Zenglin Xu
was partially supported by a grant from Na-
tional Natural Science Foudation of China
(No.61572111), Startup fundings of UESTC
(Nos.A1098531023601041 and G05QNQR004),
and a Research Fund for the Central Universities
of China (No.ZYGX2016Z003).



49

References
Rafael E Banchs and Haizhou Li. 2012. Iris: a chat-

oriented dialogue system based on the vector space
model. In Proceedings of the ACL 2012 System
Demonstrations, pages 37–42. Association for Com-
putational Linguistics.

Rich Caruana, Steve Lawrence, and C Lee Giles. 2001.
Overfitting in neural nets: Backpropagation, conju-
gate gradient, and early stopping. pages 402–408.

Nitesh V Chawla. 2009. Data mining for imbalanced
datasets: An overview. In Data mining and knowl-
edge discovery handbook, pages 875–886. Springer.

Long Chen, Hanwang Zhang, Jun Xiao, Liqiang Nie,
Jian Shao, Wei Liu, and Tat-Seng Chua. 2017. Sca-
cnn: Spatial and channel-wise attention in convolu-
tional networks for image captioning. pages 5659–
5667.

Kyunghyun Cho, Bart Van Merriënboer, Dzmitry Bah-
danau, and Yoshua Bengio. 2014. On the properties
of neural machine translation: Encoder-decoder ap-
proaches. arXiv preprint arXiv:1409.1259.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805.

Rohit Girdhar and Deva Ramanan. 2017. Attentional
pooling for action recognition. Neural Information
Processing Systems (NIPS), pages 34–45.

Kensho Hara, Hirokatsu Kataoka, and Yutaka Satoh.
2018. Can spatiotemporal 3d cnns retrace the his-
tory of 2d cnns and imagenet? pages 6546–6555.

Shuiwang Ji, Wei Xu, Ming Yang, and Kai Yu. 2013.
3d convolutional neural networks for human action
recognition. IEEE transactions on pattern analysis
and machine intelligence, 35(1):221–231.

Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. arXiv preprint
arXiv:1412.6980.

Jonathan K Kummerfeld, Sai R Gouravajhala, Joseph
Peper, Vignesh Athreya, Chulaka Gunasekara,
Jatin Ganhotra, Siva Sankalp Patel, Lazaros Poly-
menakos, and Walter S Lasecki. 2018. Analyz-
ing assumptions in conversation disentanglement re-
search through the lens of a new dataset and model.
arXiv preprint arXiv:1810.11118.

Diane J Litman and Scott Silliman. 2004. Itspoke:
An intelligent tutoring spoken dialogue system. In
Demonstration papers at HLT-NAACL 2004, pages
5–8. Association for Computational Linguistics.

Ryan Lowe, Michael Noseworthy, Iulian V Serban,
Nicolas Angelard-Gontier, Yoshua Bengio, and
Joelle Pineau. 2017. Towards an automatic turing
test: Learning to evaluate dialogue responses. arXiv
preprint arXiv:1708.07149.

Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle
Pineau. 2015a. The ubuntu dialogue corpus: A large
dataset for research in unstructured multi-turn dia-
logue systems. CoRR, abs/1506.08909.

Ryan Lowe, Nissan Pow, Iulian V. Serban, and Joelle
Pineau. 2015b. The ubuntu dialogue corpus: A large
dataset for research in unstructured multi-turn dia-
logue systems. Proceedings of the SIGDIAL 2015
Conference, page 285294.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1532–
1543.

Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018a. Deep contextualized word rep-
resentations. arXiv preprint arXiv:1802.05365.

Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt
Gardner, Christopher Clark, Kenton Lee, and Luke
Zettlemoyer. 2018b. Deep contextualized word rep-
resentations. CoRR, abs/1802.05365.

Dragomir R Radev, Hong Qi, Harris Wu, and Weiguo
Fan. 2002. Evaluating web-based question answer-
ing systems. In LREC.

Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.
Neural responding machine for short-text conversa-
tion. arXiv preprint arXiv:1503.02364.

Du Tran, Lubomir D. Bourdev, Rob Fergus, Lorenzo
Torresani, and Manohar Paluri. 2014. C3D: generic
features for video analysis. CoRR, abs/1412.0767.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. CoRR, abs/1706.03762.

Ellen M Voorhees et al. 1999. The trec-8 question an-
swering track report. In Trec, volume 99, pages 77–
82. Citeseer.

Jason Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013. The dialog state track-
ing challenge. In Proceedings of the SIGDIAL 2013
Conference, pages 404–413.

Yu Wu, Wei Wu, Chen Xing, Zhoujun Li, and Ming
Zhou. 2017. Sequential matching network: A
new architecture for multi-turn response selection in
retrieval-based chatbots. Proceedings ofthe 55th An-
nual Meeting ofthe Association for Computational
Linguistics, pages 496–505.

Koichiro Yoshino, Chiori Hori, Julien Perez, Luis Fer-
nando D’Haro, Lazaros Polymenakos, R. Chu-
laka Gunasekara, Walter S. Lasecki, Jonathan K.
Kummerfeld, Michel Galley, Chris Brockett, Jian-
feng Gao, Bill Dolan, Xiang Gao, Huda AlAmri,
Tim K. Marks, Devi Parikh, and Dhruv Batra. 2019.

http://arxiv.org/abs/1506.08909
http://arxiv.org/abs/1506.08909
http://arxiv.org/abs/1506.08909
http://www.aclweb.org/anthology/D14-1162
http://www.aclweb.org/anthology/D14-1162
http://arxiv.org/abs/1802.05365
http://arxiv.org/abs/1802.05365
http://arxiv.org/abs/1412.0767
http://arxiv.org/abs/1412.0767
http://arxiv.org/abs/1706.03762
http://arxiv.org/abs/1706.03762


50

Dialog system technology challenge 7. CoRR,
abs/1901.03461.

Rui Zhang, Honglak Lee, Lazaros Polymenakos, and
Dragomir Radev. 2018. Addressee and response se-
lection in multi-party conversations with speaker in-
teraction rnns.

Xiangyang Zhou, Lu Li, Daxiang Dong, Yi Liu, Ying
Chen, Wayne Xin Zhao, Dianhai Yu, and Hua Wu.
2018. Multi-turn response selection for chatbots
with deep attention matching network. Proceed-
ings ofthe 56th Annual Meeting ofthe Association for
Computational Linguistics, pages 1–10.

http://arxiv.org/abs/1901.03461

