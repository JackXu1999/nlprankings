



















































Text Emotion Distribution Learning from Small Sample: A Meta-Learning Approach


Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing
and the 9th International Joint Conference on Natural Language Processing, pages 3957–3967,
Hong Kong, China, November 3–7, 2019. c©2019 Association for Computational Linguistics

3957

Text Emotion Distribution Learning from Small Sample:
A Meta-Learning Approach

Zhenjie Zhao Xiaojuan Ma
Department of Computer Science and Engineering
Hong Kong University of Science and Technology

Clear Water Bay, Hong Kong
{zzhaoao, mxj}@cse.ust.hk

Abstract

Text emotion distribution learning (EDL) aims
to develop models that can predict the inten-
sity values of a sentence across a set of emo-
tion categories. Existing methods based on
supervised learning require a large amount of
well-labelled training data, which is difficult
to obtain due to inconsistent perception of
fine-grained emotion intensity. In this paper,
we propose a meta-learning approach to learn
text emotion distributions from a small sam-
ple. Specifically, we propose to learn low-rank
sentence embeddings by tensor decomposition
to capture their contextual semantic similarity,
and use K-nearest neighbors (KNNs) of each
sentence in the embedding space to generate
sample clusters. We then train a meta-learner
that can adapt to new data with only a few
training samples on the clusters, and further fit
the meta-learner on KNNs of a testing sample
for EDL. In this way, we effectively augment
the learning ability of a model on the small
sample. To demonstrate the performance, we
compare the proposed approach with state-of-
the-art EDL methods on a widely used EDL
dataset: SemEval 2007 Task 14 (Strapparava
and Mihalcea, 2007). Results show the superi-
ority of our method on small-sample emotion
distribution learning.

1 Introduction

Analyzing emotions in text automatically is an im-
portant topic (Yadollahi et al., 2017) with widely
used applications such as classifying e-commerce
products reviews (Rao et al., 2016) and devel-
oping emotionally intelligent chatbots for health-
care (Fadhil and Gabrielli, 2017), to name a
few. Text emotion analysis aims to recognize
writers’ emotional states towards particular top-
ics or subjects (Yadollahi et al., 2017), and has
attracted considerable research efforts in the last
few decades (Canales and Martı́nez-Barco, 2014;

Abdul-Mageed and Ungar, 2017; Yu et al., 2018;
Zhang et al., 2018).

Existing works cast text emotion analysis into
three types of tasks: single label learning (SLL),
multi-label learning (MLL), and label distribution
learning (LDL). In SLL, one particular name in
an emotion category (referred as label in the fol-
lowing) is predicted (Abdul-Mageed and Ungar,
2017), e.g., joyful, angry, or sad. However, due
to the correlation among different emotions, one
sentence can potentially contain multiple differ-
ent emotions (Yu et al., 2018). Therefore, a more
practical way is to assign multiple labels to a sen-
tence (Yu et al., 2018), namely, MLL. Label dis-
tribution learning, which is called emotion distri-
bution learning (EDL) in emotion mining (Zhou
et al., 2016), goes a step further and assigns one in-
tensity value to each emotion, which is necessary
to encode fine-grained information for comparing
strength of different emotions, etc.

In general, there are three approaches to text
emotion analysis tasks: lexicon-based (Staiano
and Guerini, 2014), learning-based (Zhang et al.,
2018), and the combination of both methods (Mu-
dinas et al., 2012). In the lexicon-based case, one
needs to collect an emotion lexicon corpus, e.g.,
WordNet-Affect (Strapparava and Valitutti, 2004),
SentiWordNet (Esuli and Sebastiani, 2006), and
applies different counting methods to aggregate
the occurrences of words associated with various
emotions (Staiano and Guerini, 2014). Learning-
based methods, in contrast, mostly frame emo-
tion analysis as a supervised learning problem,
which requires annotated text data with emo-
tion labels and extraction of proper sentence fea-
tures. Learning-based approaches alone, or com-
bined with lexicon-based methods, usually pro-
duce state-of-the-art (SOTA) performance (Mud-
inas et al., 2012; Zhang et al., 2018), and thus are
widely used nowadays.



3958

However, learning-based methods usually de-
mand a large amount of annotated data to train
models, which has become one of the performance
bottlenecks. EDL in particular aims to decode
fine-grained composition and magnitude of emo-
tions in text, the human perception of which can be
highly subtle and personal (Volkova et al., 2010).
It is difficult, if not impossible, to collect a large-
scale emotion distribution dataset with consistent,
clean human labels. Therefore, developing tech-
niques to learn from a small sample is critical for
the practicality of emotion distribution analysis.

In this paper, based on meta-learning (Vilalta
and Drissi, 2002; Finn et al., 2017), we propose
an efficient approach to learn text emotion distri-
bution from a small sample. To make the most of
a small labeled dataset, we propose to use the K-
nearest semantically similar neighbors (KNNs) of
each training sample to cluster the training data,
and train a meta-learner that can adapt to new test-
ing data with only a few samples on the clusters.
We can then fit the meta-learner on KNNs of each
testing sample. Learning semantic similarity of
sentences usually requires a large amount of data
(Le and Mikolov, 2014). We propose to learn low-
rank embeddings of sentences by tensor decompo-
sition to capture their contextual semantic similar-
ity, which works well regardless of the size of doc-
uments (Hosseinimotlagh and Papalexakis, 2018).
We evaluate the proposed approach on a widely
used text emotion distribution dataset: SemEval
2007 Task 14 (Strapparava and Mihalcea, 2007),
and show that it outperforms the existing SOTA
methods for small sample EDLs.

The contributions of this paper are: 1) we pro-
pose a novel meta-learning framework to learn
text emotion distribution from a small sample; 2)
we propose to learn low-rank embeddings of sen-
tences by tensor decomposition to find semanti-
cally similar neighbors for training and adapting a
meta-learner.

2 Related Works

We briefly review three related areas that motivate
this work, including emotion distribution learning,
text representation learning, and learning from a
small sample.

2.1 Emotion Distribution Learning

Emotion distribution learning of text (Zhou et al.,
2016; Zhang et al., 2018) is a recently proposed

task that tries to predict the intensity values of
a sentence across a set of emotion categories.
Such information is important for understanding
the fine-grained emotion information (Zhou et al.,
2016; Zhang et al., 2018). For example, one sen-
tence can usually invoke multiple emotional states
with different levels, and existing approaches of
SLL and MLL are inadequate for capturing multi-
label, multi-intensity information. LDL is more
suitable for such scenarios. In general, LDL meth-
ods can be classified into three categories: prob-
lem transformation, algorithm adaption, and spe-
cialized algorithms (Geng and Ji, 2013). PT-
Bayes and PT-SVM are typical problem trans-
formation methods that transform the LDL prob-
lem into an SLL problem, and use Bayes clas-
sifier and SVM to predict label distribution, re-
spectively. AA-KNN and AA-BP are algorithm
adaption methods that extend K-nearest neigh-
bors (KNNs) and back-propagation (BP) neural
networks. SA-LDSVR, SA-IIS, SA-BFGS, SA-
CPNN are specialized LDL algorithms that di-
rectly parametrize and optimize LDL objectives
(Geng and Ji, 2013). In terms of EDL, two differ-
ent models have been proposed recently, includ-
ing a maximum entropy model (Zhou et al., 2016)
and a convolutional neural network model (Zhang
et al., 2018), and the latter one is the SOTA.

2.2 Text Representation Learning

Learning numerical representation of text is usu-
ally the first step for learning-based emotion
analysis, which can be categorized at two lev-
els: word/phrase and sentence/document. At the
word/phrase level, for example, Mikolov et al.
(2013) propose word2vec which uses a three-layer
neural network, i.e., the input layer, the projec-
tion layer, and the output layer, to learn word
vectors from a large corpora in an unsupervised
manner. The projection layer maps one-hot en-
coded input to a low-dimension vector, which is
used to predict a word in the output layer. The
learned word vectors of the projection layer are
shown to be an effective word representation. At
the sentence/document level, similar to word2vec,
doc2vec (Le and Mikolov, 2014) treats sentences
and context words in the same way in the input
layer, and uses a three-layer neural network to
learn the vector representation of sentences. Simi-
larly, the skip-thought vector method (Kiros et al.,
2015) uses sentences directly for prediction tasks,



3959

and ignores context words used in doc2vec. Re-
cent works show that using attention mechanism,
transformer in particular (Vaswani et al., 2017), is
an effective way to learn universal sentence repre-
sentation with unlabeled text, such as BERT (De-
vlin et al., 2019) and XLNet (Yang et al., 2019).
There are other ways to improve the discrimina-
tive ability of the learned features through super-
vised learning, such as task transfer methods like
InferSent (Conneau et al., 2017).

2.3 Learning from A Small Sample

The success of machine learning models, espe-
cially deep learning models, heavily depends on a
large amount of labeled data. But acquiring train-
ing data is usually difficult and expensive (John-
son et al., 2018). Therefore, considerable research
efforts on small sample learning are emerging re-
cently (Lake et al., 2015; Shu et al., 2018). There
are generally two approaches for learning from a
small sample (Shu et al., 2018): concept learn-
ing and experience learning. Concept learning
means analyzing the structure of example sam-
ples by imitating human abilities like imagina-
tion, synthesis, and analysis (Lake et al., 2015;
Shu et al., 2018). Experience learning means aug-
menting or transferring learning experience from
other data or models, including data augmentation,
model fine-tuning, model compression, and meta-
learning (Shu et al., 2018). Meta-learning in par-
ticular is an effective way of augmenting the ex-
perience learning ability (Thrun and Pratt, 1998;
Vilalta and Drissi, 2002; Finn et al., 2017).

2.3.1 Meta-Learning
Meta-learning aims to increase the learning per-
formance through experience sharing among tasks
(Thrun and Pratt, 1998; Vilalta and Drissi, 2002;
Finn et al., 2017). One kind of meta-learning is
to train a meta-learner to update the parameters or
rules of the learning models (Bengio et al., 1991).
However, the complexity of this approach is usu-
ally high (Bengio et al., 1991; Finn et al., 2017).
Another approach is to train a memory neural net-
work, such as recurrent neural networks (Santoro
et al., 2016), to keep a record of the different expe-
riences among different tasks. In particular, Finn
et al. (2017) find that it is possible to optimize a
learner to adapt new tasks quickly only by gradi-
ent descent. In this approach, no additional pa-
rameters are needed. Recently, researchers have
also extended this method to unsupervised learn-

ing (Hsu et al., 2019) and online learning scenarios
(Finn et al., 2019). Meta-learning has been used
for few-shot image recognition (Lee et al., 2019),
agent navigation (Finn et al., 2017), low-resource
machine translation (Gu et al., 2018), query gen-
eration (Huang et al., 2018), and so on.

Existing EDL methods are designed with tra-
ditional machine learning paradigms (Geng and
Ji, 2013; Zhou et al., 2016; Zhang et al., 2018),
which may not work well on a small sample. Due
to the difficulty of annotating emotion distribution
data, developing techniques of small sample EDLs
is thus critical for text emotion analysis. Trans-
ferring experience with pre-trained models (Shu
et al., 2018) can be an effective way to boost natu-
ral language tasks. But such methods may need an
additional large training corpora, and fine-tuning
models on specific domains is non-trivial (Le and
Mikolov, 2014). In this paper, we are interested in
how to only use the labeled data for small sample
EDLs (Shu et al., 2018).

3 Problem Formulation

3.1 Emotion Distribution Learning (EDL)

We denote one sample as (s,y), where s is a sen-
tence or document, y = (y1, y2, . . . , yC) is its
emotion distribution label, yj denotes the inten-
sity value of the j-th emotion, C is the number of
discrete emotions, and ∑Cj y

j = 1. For EDL, we
expect to train a model f ∶ S ↦ Y that can ac-
curately map any sentence s in semantic space S
to its entailed emotion distribution y in emotion
distribution space Y .

3.2 EDL from A Small Sample

Given a set of training samples Dtrain =
{(si,yi)}

M
i=1, we are interested in how to train

a model f that can predict emotion distribution
effectively on a set of testing samples Dtest =
{(si,yi)}

N
i=1, where M is the number of training

samples and is a small number (e.g., 50), N is the
number of testing samples.

For EDL from a small sample, we adopt the ex-
perience learning approach (Shu et al., 2018) by
considering: 1) how to augment learning ability on
a small number of training samples, and 2) how to
learn semantic similarity onDtrain∪Dtest so that we
can use K-nearest neighbors inDtrain to predict the
emotion distribution of a testing sample in Dtest.



3960

meta-learning

meta
learner

adapting

training sample (small) testing sample

...

training task 1

training task 2

training task 𝑀

K-nearest neighbors

...

...

...

Figure 1: Illustration diagram of the proposed EDL
method.

4 Method

As shown in Figure 1, to augment the learn-
ing ability on a small sample, we first partition
the training data by finding K-nearest neighbors
(KNNs) of each sample based on semantic simi-
larity, and treat each K samples as a cluster. We
then train a meta-learner that is optimized to adapt
to new data with only a few training samples on
the clusters. During testing, we fit the meta-learner
with KNNs of a testing sample, where KNNs are
found in the training data.

4.1 Meta-Learning Preliminary
A meta-learning algorithm consists of a set of
training tasks Ttrain = {Ti}Mi=1, a set of testing tasks
Ttest = {Ti}

N
i=1, and a model fθ

1, where M and N
are the numbers of the training and testing tasks
separately, and θ is the parameters of f . Each task
T consists of a set of training samples called sup-
porting set S and a set of testing samples called
querying set Q, namely, T = {S,Q}. The goal of
meta-learning is to train a learner fθ using Ttrain so
that given a new testing task T in Ttest, it can per-
form well on the query set Q of T by fine-tuning
it with only a few samples in the support set S.

4.2 EDL via Meta-Learning
We propose a meta-learning framework for EDL,
including task generation from a small sample,
meta-learner training, and meta-learner adaption
for predicting testing samples.

4.2.1 Task Generation
For each sample inDtrain, we first find its KNNs by
semantic similarity, and treat the K samples as a
training task. Therefore, samples in each task can
be overlapped, and we use this way to increase the
number of tasks. For each task, we randomly se-
lect K/2 samples as the support set, and use the

1To be consistent with the existing literature, we refer to
the model as the learner in the rest of the paper.

tensor 
decomposition

sentence tensor low-rank embedding

s

K-nearest neighbors

neighbor 
search

Figure 2: Tensor decomposition to find KNNs of each
sentence.

remaining ones as the query set, i.e., the sizes of
S and Q are both K/2. Therefore, for M samples
in Dtrain, we can generate M training tasks Ttrain.
The intuition is that semantically similar sentences
are more likely to have similar emotion distribu-
tion patterns.

Algorithm 1: Text EDL via Meta-Learning
Data: training sample Dtrain and testing

sample Dtest
Result: learner fθs for each sentence s in

Dtest
1 initialize hyper-parameters

α,β, γ,H,R,K,niter,L;

// Task Generation
2 calculate sentence embeddings C with

formula (1), and for each sample in Dtrain,
find its KNNs to get Ttrain;

// Meta-Learner Training
3 initialize the meta-learner f with parameter θ;
4 for iter in 1,2, . . . , niter do
5 sample L tasks from Ttrain randomly;
6 for l in 1,2, . . . , L do
7 θ′l ← θ − α▽θ LTl(S)(fθ)

8 end
9 θ ← θ − β ▽θ ∑lLTl(Q)(fθ′l);

10 end

// Adapting Meta-Learner
11 for each sentence s in Dtest do
12 find KNNs Ks of s in Dtrain;
13 θs ← θ −▽θLKs(fθ)

14 end

Low-rank embedding by tensor decomposition
Contextual patterns of words can be used to mea-
sure semantic similarity for emotion analysis (Sta-
iano and Guerini, 2014; Mikolov et al., 2013).
Traditional embedding approaches, e.g., doc2vec,
usually require a large amount of data (Le and



3961

Mikolov, 2014). We propose to use low-rank em-
beddings of sentences mined by tensor decompo-
sition, which can obtain text embeddings regard-
less of the corpus size (Hosseinimotlagh and Pa-
palexakis, 2018). As shown in Figure 2, con-
sidering D = Dtrain ∪ Dtest, we first build a vo-
cabulary for it, namely, w1,w2, . . . ,wV , where
V is the number of words. For each sentence
s in D, we count the word-word co-occurrence
in a small window H , and build a binary matrix
Vs ∈ [0,1]

V ×V . In particular, Vs(i, j) = 1 in-
dicates word wi and wj co-occurs in s within a
small window H at least once. In this way, we
can capture the semantic patterns of a sentence
in Vs. In addition, this approach can also deal
with negation issue to some extent, which is im-
portant for sentiment analysis (Reitan et al., 2015).
Because negation sentences usually have negation
words, they will have a different word-word co-
occurrence pattern with that of normal sentences,
which will result in different embeddings. There-
fore, the tensor decomposition method may put
sentences with and without negation words into
different clusters. Afterwards, we stack all Vs
as a three-dimensional tensor V ∈ [0,1]V ×V ×D,
where D = M + N . We adopt the CANDE-
COMP/PARAFAC tensor decomposition method
(Sidiropoulos et al., 2017) to find an approxima-
tion V̂ of V :

V̂ =
R

∑
r=1

wr ⊗wr ⊗ sr, (1)

such that the Frobenius norm ∣∣V̂ − V ∣∣F is min-
imal, where wr ∈ RV , sr ∈ RD, R is the rank,
and ⊗ is the outer product, namely, wr ⊗wr ⊗ sr
being a three-dimensional tensor, and wr ⊗wr ⊗
sr(i, j, k) = wr(i) ⋅ wr(j) ⋅ sr(k). We use both
training and testing datasets for embedding, which
follows the general practice of previous literature
(Zhou et al., 2016; Zhang et al., 2018). In such a
case, it is possible to infer a complete vocabulary
of the corpus by making use of both the training
and testing dataset. If some testing data are not
available when the tensor is built, there exist tensor
decomposition methods for dealing with stream-
ing data scenarios (Gujral et al., 2018), namely,
the testing data can be updated continuously over
time. Our framework can easily utilize such ad-
vanced methods to generalize to sentences with
out-of-vocabulary words.

With the tensor decomposition, we can find

low-rank embeddings of sentences that capture
the similarity of contextual patterns (Hosseini-
motlagh and Papalexakis, 2018). In particular,
C = [s1, s2, . . . , sR] ∈ RD×R, where the s-row
of C = [cT1 ,c

T
2 , . . . ,c

T
D]

T , cTs , is the embedding
vector of the sentence s. We measure the simi-
larity of two sentences i, j by Euclidean distance:

d(i, j) =
√

∑
R
r=1(ci(r) − cj(r))

2, where c(r) de-
notes the r-th element of c.

4.2.2 Meta-Learner Training
We can train a meta-learner on the generated Ttrain.

Learner. We use a Convolutional Neural Net-
work (CNN) model as the basic learner, which
has shown good performance on text classification
(Kim, 2014) and text emotion distribution learn-
ing (Zhang et al., 2018). The CNN learner has
the same architecture with (Zhang et al., 2018). In
particular, given the input sentence s, we first stack
a matrix X with the word vector of each word
(Mikolov et al., 2013). Then three convolution
layers with kernel sizes 3,4,5 are performed on X
separately, and we then concatenate them together.
A fully connected layer is then used, following
with a soft-max operation to get the final emotion
probability prediction. We use Kullback-Leibler
(K-L) divergence LK-L as the objective to measure
the distance of predicted distribution ŷ and the

true distribution ŷ: LK-L = ∑Ki=1
1
K ∑

C
j=1 y

j
i log

yji
ŷji

,

where K is the number of training samples. Sim-
ilarly to (Zhang et al., 2018), we also optimize
the classification accuracy of the dominant emo-
tion by a cross-entropy (CE) objective, which is
shown to improve EDL performance. In partic-
ular, LCE = −∑Ki=1

1
K ∑

C
j=1 1(y

j
i ) log ŷ

j
i , where

1(yj) = 1 if yj is the maximal value of y, other-
wise 1(yj) = 0. The final objective is a weighted
sum of LKL and LCE: L = γLK-L + (1 − γ)LCE,
where γ is the weight factor, 0 ≤ γ ≤ 1.

Training meta-learner. To train the learner fθ,
we optimize the parameters θ of the learner f such
that a small number of gradient steps on a new task
will produce maximally effective behavior on that
task, namely,

min
θ
∑

Ti∼Ttrain

LTi(Q)(fθ′i), (2)

where Ti is a randomly sampled task in Ttrain, θ′i is
the trained optimal parameters on task Ti. Ti(Q)
denotes that the loss is computed on the query set



3962

Q. Equation (3) is optimized via stochastic gradi-
ent descent (SGD),

θ ← θ − β(▽θ ∑
Ti∼Ttrain

LTi(Q)(fθ′i)), (3)

where β is the meta-learning rate. Similarly, SGD
is used to compute θ′i, θ

′
i ← θ − α▽θ LTi(S)(fθ),

where Ti(S) denotes that the loss is computed on
S, and α is the learning rate.

4.2.3 Adapting Meta-Learner
The meta-learner fθ is trained to adapt to new data
with only a few semantically similar training sam-
ples. Therefore, given a testing sample s, we first
find its K-nearest neighborsKs in the training data
Dtrain, and then adapt fθ on Ks by SGD:

θ ← θ − α▽θ LKs(fθ). (4)

Here we use the learning rate α to be consistent
with the meta-training procedure.

The overall algorithm is shown in Algorithm
1, where α is the learning rate, β is the meta-
learning rate, γ is the weight value of the distri-
bution and classification losses, H is the window
size for word-word co-occurrence counting, R is
the rank of tensor decomposition, K is the num-
ber of nearest neighbors, niter is the number of
meta-training iterations, and L is the number of
tasks for each round of meta-training.

5 Experiment

To evaluate the proposed approach for learning
emotion distribution from a small sample, we con-
duct intensive experiments on SemEval 2007 Task
14 (Strapparava and Mihalcea, 2007). To the best
of our knowledge, this is the only publicly avail-
able English dataset with emotion distributions la-
beled by humans.

5.1 Experiment Setup
5.1.1 Dataset
SemEval 2007 Task 14 contains 1250 sentences of
news headlines with 6 emotion intensities (anger,
disgust, fear, joy, sadness, and surprise) labeled by
humans. Each intensity value is a non-negative
value. We normalize the annotated scores to get
emotion distribution labels using the same pro-
cedure with Zhang et al. (2018). In particular,
given an original intensity tuple (l1, l2, . . . , l6), we
first calculate the sum of all values, l = ∑6k=1 lk,

and then normalize it to get a distribution as
(l1/l, l2/l, . . . , l6/l). If l = 0, then the distribu-
tion will be (1/6,1/6, . . . ,1/6). It is possible to
add another intensity value l7 denoting the overall
level of emotion to the original label; for example,
if l7 is 1, there is no emotion in the text, and if l7
is 0, there is strong emotions. Similar to l1 ∼ l6, l7
can be annotated manually. We can then normal-
ize (l1, l2, . . . , l7) to get a new distribution. In this
way, we can better model the cases of a sentence
expressing very little emotion overall. For sim-
plicity and fair comparison, we only use l1 ∼ l6 in
this paper.

5.1.2 Experiment Protocal
Because there is no publicly available small
dataset for text emotion distribution evaluation,
we follow existing practices (Hosseinimotlagh and
Papalexakis, 2018) to simulate a small training set
by randomly selecting 10% of the samples and us-
ing the remaining ones for testing. We run 10-fold
cross validation, and report the averaged results.

Baselines. We compare the proposed method
(denoted as EDL-Meta) with several baseline
methods, including the SOTA method EDL-CNN
(Zhang et al., 2018), LDL methods, and document
vectorization methods. EDL-CNN uses the ba-
sic learner of EDL-Meta, and can be seen as a
special case of EDL-Meta when K = 0. Sim-
ilar to Zhang et al. (2018), we also extract the
penultimate layer of EDL-CNN as features, and
fit several typical LDL methods: PT-Bayes, PT-
SVM, AA-KNN, AA-BP, SA-LDSVR, SA-IIS,
SA-BFGS, SA-CPNN for comparison. The ba-
sic principles of each method are briefly summa-
rized in subsection 2.1. In addition, we apply three
SOTA document vectorization methods – doc2vec
(Le and Mikolov, 2014), InferSent (Conneau et al.,
2017), and BERT (Devlin et al., 2019) – and use
the extracted vectors to train a linear regressor to
predict emotion distributions.

5.1.3 Evaluation Metrics
Evaluating the performance of distribution learn-
ing is challenging, because we need to measure the
prediction results of fine-grained intensity values.
In (Geng and Ji, 2013), the authors propose six
metrics, and suggest that each metric may reflect
certain aspects of an algorithm. A good algorithm
should perform well on most of them. The six met-
rics contain Euclidean↓, Sørensen↓, Squaredχ2↓,



3963

Method Euclidean↓ Sørensen↓ Squaredχ2↓ K-L↓ Fidelity↑ Intersection↑

PT-Bayes 0.4870 0.4889 0.6707 0.7574 0.7330 0.5111
PT-SVM 0.5748 0.5706 0.8578 1.1327 0.6639 0.4294
AA-KNN 0.4248 0.4054 0.5181 0.8325 0.7986 0.5946
AA-BP 0.4620 0.4468 0.5945 0.7410 0.7662 0.5532

SA-LDSVR 0.4336 0.4238 0.5301 0.5828 0.7927 0.5762
SA-IIS 0.4402 0.4305 0.5456 0.5983 0.7842 0.5695

SA-BFGS 0.8403 0.6909 1.1563 7.7697 0.5056 0.3091
SA-CPCNN 0.4779 0.4600 0.6108 0.7365 0.7660 0.5400

BERT 0.4498 0.4378 0.5620 0.6207 0.7770 0.5622
InferSent 0.4630 0.4518 0.5882 0.6488 0.7662 0.5482
doc2vec 0.4458 0.4334 0.5552 0.6133 0.7799 0.5666

EDL-CNN 0.4450 0.4345 0.5553 0.6105 0.7794 0.5655
EDL-Meta 0.3949 0.3747 0.4478 0.5148 0.8319 0.6253

Table 1: Evaluation results on SemEval 2007 Task 14.

D
is

ta
nc

e

Euclidean↓
√
∑

C
i=1(pi − qi)2

Sørensen↓ ∑
C
i=1 ∣pi−qi ∣

∑Ci=1(pi+qi)

Squaredχ2↓ ∑Ci=1
(pi−qi)2
pi+qi

K-L↓ ∑Ci=1 pi log
pi
qi

Si
m

ila
rl

y

Fidelity↑ ∑Ci=1
√
piqi

Intersection↑ ∑Ci=1 min(pi, qi)

Table 2: Metrics for evaluating the performance of
emotion distribution learning.

K-L↓, Fidelity↑, Intersection↑, and can be classi-
fied into two categories: distance metrics and sim-
ilarity metrics (Geng and Ji, 2013). Distance met-
rics measure the distance between the predicted
distribution and the true one, the smaller the better.
Similarity metrics measure the similarity between
the predicted distribution and the true one, the big-
ger the better. Here, ↑ means the bigger the bet-
ter, ↓ means the smaller the better. The formulas
for calculating all metrics are summarized in Table
2, where (q1, q2, . . . , qC) is the predicted distribu-
tion, (p1, p2, . . . , pC) is the true distribution, C is
the number of emotions.

5.1.4 Implementation
We use 300 dimension word vectors trained on
Google News from (Mikolov et al., 2013) as ini-
tial input. Because SemEval 2007 Task 14 is
mostly News headlines, the pre-trained word vec-
tors are closer to it. We implement our algo-
rithm by PyTorch 2. Owing to EDL-CNN not
being open-sourced, we also implement it by Py-
Torch. The implementation of doc2vec is adopted
from gemsim 3. BERT embedding (uncased base

2https://pytorch.org
3https://radimrehurek.com/gensim

model, without fine-tuning) is adopted from an
open-source implementation (Xiao, 2018). The
implementations of other methods are downloaded
from the original paper (Geng and Ji, 2013; Con-
neau et al., 2017). For EDL-CNN, we use the net-
work architecture in the original paper, and set the
learning rate 0.1, epoch number 25 (Kim, 2014).
In the same experiment setting with (Zhang et al.,
2018), namely, 90% training data and 10% test-
ing data of SemEval 2007, we can obtain 0.344
Euclidean↓, 0.330 Sørensen↓, 0.344 Squaredχ2↓,
0.437 K-L↓, 0.853 Fidelity↑, 0.670 Intersection↑,
which are slightly better than the results reported
in (Zhang et al., 2018). For fair comparison, we
use the default parameters of all other methods,
which are reported to get the best performance.
For EDL-Meta, we empirically set α = 0.01,
β = 0.1, L = 5, H = 5. γ is set to be 0.7 ac-
cording to (Zhang et al., 2018), and we do not
further tune it. 1000 epoches are used to train
the meta-learner for both datasets. To find opti-
mal K and R, we run a 5-fold cross validation
grid search, and set K = 20, R = 5. The alter-
nating least squares method is used to calculate
the tensor decomposition, and we use the imple-
mentation in the Matlab tensor toolbox 4. The k-
d tree method is used to find KNNs of a sample
efficiently. We run all experiments on a desktop
with Intel(R) Core(TM) i9-7900X CPU 3.30GHz,
64GB RAM, Nvidia GeForce GTX 1080 Ti (×2).

5.2 Results
The comparison results of SemEval 2007 Task 14
are shown in Table 1. We can see that EDL-Meta
shows better results than other methods on all met-
rics. In particular, EDL-Meta can usually outper-

4http://www.tensortoolbox.org

https://pytorch.org
https://radimrehurek.com/gensim
http://www.tensortoolbox.org


3964

Method Euclidean↓ Sørensen↓ Squaredχ2↓ K-L↓ Fidelity↑ Intersection↑

doc2vec 0.3987 0.3795 0.4563 0.5231 0.8279 0.6205
InferSent 0.3993 0.3799 0.4567 0.5228 0.8277 0.6201
random 0.3966 0.3763 0.4494 0.5179 0.8317 0.6237
tensor 0.3949 0.3747 0.4478 0.5148 0.8319 0.6253

Table 3: Comparison results of different embedding methods.

Meta. Adap. Euclidean↓ Sørensen↓ Squaredχ2↓ K-L↓ Fidelity↑ Intersection↑

No No 0.4450 0.4345 0.5553 0.6105 0.7794 0.5655
No Yes 0.4588 0.4489 0.5827 0.6403 0.7680 0.5511
Yes No 0.3954 0.3752 0.4482 0.5154 0.8318 0.6248
Yes Yes 0.3949 0.3747 0.4478 0.5148 0.8319 0.6253

Table 4: Comparison results of different combinations of training and adapting procedures.

form other methods by about 5% on most metrics.
Although EDL-CNN can perform well with more
training samples (Zhang et al., 2018), on the small
sample, its performance is not as stable as EDL-
Meta. Even simple KNN can get slightly better
results than EDL-CNN on most metrics. Likewise,
other methods cannot get stable results on all met-
rics. This indicates that EDL-Meta is more suit-
able for small sample EDLs.

5.3 Discussion
5.3.1 Low-rank Embedding
To investigate the effectiveness of the tensor de-
composition method, we use doc2vec (Le and
Mikolov, 2014) and InferSent (Conneau et al.,
2017) to train sentence vectors on D, and find
KNNs of a sample by cosine similarity, denoted as
doc2vec and InferSent, respectively. In addition,
we also use randomly selected K-neighbors to
train and test EDL-Meta, denoted as random. We
denote our tensor decomposition method as ten-
sor. The results are shown in Table 3. Compared
to doc2vec, InferSent, and random, our method
can get better results on all metrics. The doc2vec
and InferSent embedding methods show a slightly
lower performance, even worse than the random
version. doc2vec usually assumes a large pool of
training data (Le and Mikolov, 2014), while In-
ferSent also does not work well for transferring to
a task with a small training sample. The tensor
decomposition method is more suitable for small
sample learning.

5.3.2 Meta-Training and Adapting
To investigate the effect of the proposed meta-
training and adapting procedures, we conduct an-
other experiment. In particular, with the same ex-

EDL-CNN EDL-Meta

Figure 3: The performance of EDL-CNN and EDL-
Meta on different training percentages. The horizontal
axis denotes different training percentages, and the ver-
tical axis denotes the performance on different metrics.

periment setting, we replace the meta-training pro-
cedure (denoted as Meta.) with a normal batch
training (batch size 50) and the adaption proce-
dure (denoted as Adap.) with a normal evalua-
tion procedure, respectively. We can then get four
versions of EDL-Meta, namely, without Meta. +
without Adap., without Meta. + with Adap., with
Meta. + without Adap., and with Meta. + with
Adap. The first one is EDL-CNN in particular, and
the last one is the normal EDL-Meta. In this way,
we can further examine the importance of the pro-
posed meta-training and adapting procedures. The
results are shown in Table 4. We can see that with
both the meta-training and adapting procedures,
EDL-Meta performs more stably than other meth-
ods. In addition, the meta-training procedure plays
a crucial role on boosting the performance, as the
results of the third version are similar to the fourth
version. Finally, without meta-training, only using



3965

adapting is meaningless, as the performance of the
second version decreases a lot.

5.3.3 Label Percentage
In the same experiment setting, we further investi-
gate the influence of different training/testing par-
tition. We compare the performance of EDL-CNN
and EDL-Meta under different training/testing
partition. The results are shown in Figure 3. We
can find that on small training sample, there is a
clear gap between EDL-CNN and EDL-Meta. But
with more training sample (>50%), EDL-CNN
and EDL-Meta converge to similar results. There-
fore, it is likely that the learning ability of EDL-
Meta is limited by its basic learner. Further exper-
iments on different learners deserve to investigate.

6 Conclusion

In this paper, we propose an efficient meta-
learning approach to learn text emotion distribu-
tion from a small sample. In addition, to find the
K-nearest semantically similar neighbors, we pro-
pose to learn sentence embedding by tensor de-
composition. Experiments on SemEval 2007 Task
14 shows that the proposed approach outperforms
existing EDL methods on small sample emotion
distribution learning. We further investigate the
low-rank embedding method, the meta-training
procedure, and the adaption procedure. We find
that leveraging nearest semantically similar neigh-
bors is an effective way for small sample EDLs.
We also find that the meta-training procedure can
be a good alternative to the normal batch training
procedure, especially for small sample EDLs.

Acknowledgments

The authors would like to thank Lanqing Xue,
Zhenhui Peng, and Prof. Evangelos E. Papalexakis
for insightful discussions, as well as all anony-
mous reviewers for constructive comments. This
work is supported by the Research Grants Council
of the Hong Kong Special Administrative Region,
China under Grant No.: C6030-18G.

References
Muhammad Abdul-Mageed and Lyle Ungar. 2017.

EmoNet: Fine-grained emotion detection with gated
recurrent neural networks. In Proceedings of the
55th Annual Meeting of the Association for Com-
putational Linguistics, pages 718–728, Vancouver,
Canada. Association for Computational Linguistics.

Yoshua Bengio, Samy Bengio, and Jocelyn Cloutier.
1991. Learning a synaptic learning rule. In In-
ternational Joint Conference on Neural Networks
(IJCNN), page 969.

Lea Canales and Patricio Martı́nez-Barco. 2014. Emo-
tion detection from text: A survey. In Proceedings
of the Workshop on Natural Language Processing in
the 5th Information Systems Research Working Days
(JISIC), pages 37–43, Quito, Ecuador. Association
for Computational Linguistics.

Alexis Conneau, Douwe Kiela, Holger Schwenk, Loı̈c
Barrault, and Antoine Bordes. 2017. Supervised
learning of universal sentence representations from
natural language inference data. In Proceedings of
the 2017 Conference on Empirical Methods in Nat-
ural Language Processing, pages 670–680, Copen-
hagen, Denmark. Association for Computational
Linguistics.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
deep bidirectional transformers for language under-
standing. In Proceedings of the 2019 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, pages 4171–4186, Minneapolis, Min-
nesota. Association for Computational Linguistics.

Andrea Esuli and Fabrizio Sebastiani. 2006. SENTI-
WORDNET: A publicly available lexical resource
for opinion mining. In Proceedings of the Fifth In-
ternational Conference on Language Resources and
Evaluation (LREC’06), Genoa, Italy. European Lan-
guage Resources Association (ELRA).

Ahmed Fadhil and Silvia Gabrielli. 2017. Addressing
challenges in promoting healthy lifestyles: The AI-
chatbot approach. In Proceedings of the 11th EAI
International Conference on Pervasive Computing
Technologies for Healthcare, pages 261–265. ACM.

Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017.
Model-agnostic meta-learning for fast adaptation of
deep networks. In Proceedings of the 34th In-
ternational Conference on Machine Learning, vol-
ume 70 of Proceedings of Machine Learning Re-
search, pages 1126–1135, International Convention
Centre, Sydney, Australia. PMLR.

Chelsea Finn, Aravind Rajeswaran, Sham Kakade, and
Sergey Levine. 2019. Online meta-learning. In
Proceedings of the 36th International Conference
on Machine Learning, volume 97 of Proceedings
of Machine Learning Research, pages 1920–1930,
Long Beach, California, USA. PMLR.

Xin Geng and Rongzi Ji. 2013. Label distribution
learning. Proceedings of the 13th IEEE Inter-
national Conference on Data Mining Workshops,
pages 377–383.

Jiatao Gu, Yong Wang, Yun Chen, Victor O. K. Li,
and Kyunghyun Cho. 2018. Meta-learning for low-
resource neural machine translation. In Proceed-
ings of the 2018 Conference on Empirical Methods

https://doi.org/10.18653/v1/P17-1067
https://doi.org/10.18653/v1/P17-1067
https://doi.org/10.3115/v1/W14-6905
https://doi.org/10.3115/v1/W14-6905
https://doi.org/10.18653/v1/D17-1070
https://doi.org/10.18653/v1/D17-1070
https://doi.org/10.18653/v1/D17-1070
https://doi.org/10.18653/v1/N19-1423
https://doi.org/10.18653/v1/N19-1423
https://doi.org/10.18653/v1/N19-1423
http://www.lrec-conf.org/proceedings/lrec2006/pdf/384_pdf.pdf
http://www.lrec-conf.org/proceedings/lrec2006/pdf/384_pdf.pdf
http://www.lrec-conf.org/proceedings/lrec2006/pdf/384_pdf.pdf
https://doi.org/10.1145/3154862.3154914
https://doi.org/10.1145/3154862.3154914
https://doi.org/10.1145/3154862.3154914
http://proceedings.mlr.press/v70/finn17a.html
http://proceedings.mlr.press/v70/finn17a.html
http://proceedings.mlr.press/v97/finn19a.html
https://doi.org/10.1109/ICDMW.2013.19
https://doi.org/10.1109/ICDMW.2013.19
https://doi.org/10.18653/v1/D18-1398
https://doi.org/10.18653/v1/D18-1398


3966

in Natural Language Processing, pages 3622–3631,
Brussels, Belgium. Association for Computational
Linguistics.

Ekta Gujral, Ravdeep Pasricha, and Evangelos E. Pa-
palexakis. 2018. Sambaten: Sampling-based batch
incremental tensor decomposition. In Proceedings
of the 2018 SIAM International Conference on Data
Mining, pages 387–395.

Seyedmehdi Hosseinimotlagh and Evangelos E Pa-
palexakis. 2018. Unsupervised content-based iden-
tification of fake news articles with tensor decom-
position ensembles. In WSDM 2018 Workshop on
Misinformation and Misbehavior Mining on the Web
(MIS2).

Kyle Hsu, Sergey Levine, and Chelsea Finn. 2019. Un-
supervised learning via meta-learning. In Interna-
tional Conference on Learning Representations.

Po-Sen Huang, Chenglong Wang, Rishabh Singh,
Wen-tau Yih, and Xiaodong He. 2018. Natural
language to structured query generation via meta-
learning. In Proceedings of the 2018 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, pages 732–738, New Orleans, Louisiana.
Association for Computational Linguistics.

Mark Johnson, Peter Anderson, Mark Dras, and Mark
Steedman. 2018. Predicting accuracy on large
datasets from smaller pilot data. In Proceedings of
the 56th Annual Meeting of the Association for Com-
putational Linguistics, pages 450–455, Melbourne,
Australia. Association for Computational Linguis-
tics.

Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proceedings of the 2014
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1746–1751, Doha, Qatar.
Association for Computational Linguistics.

Ryan Kiros, Yukun Zhu, Ruslan R Salakhutdinov,
Richard Zemel, Raquel Urtasun, Antonio Torralba,
and Sanja Fidler. 2015. Skip-thought vectors. In
C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama,
and R. Garnett, editors, Advances in Neural Infor-
mation Processing Systems 28, pages 3294–3302.
Curran Associates, Inc.

Brenden M Lake, Ruslan Salakhutdinov, and Joshua B
Tenenbaum. 2015. Human-level concept learning
through probabilistic program induction. Science,
350(6266):1332–1338.

Quoc Le and Tomas Mikolov. 2014. Distributed repre-
sentations of sentences and documents. In Proceed-
ings of the 31st International Conference on Ma-
chine Learning, volume 32 of Proceedings of Ma-
chine Learning Research, pages 1188–1196, Bejing,
China. PMLR.

Kwonjoon Lee, Subhransu Maji, Avinash Ravichan-
dran, and Stefano Soatto. 2019. Meta-learning with
differentiable convex optimization. In The IEEE
Conference on Computer Vision and Pattern Recog-
nition (CVPR).

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their composition-
ality. In C. J. C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K. Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
26, pages 3111–3119. Curran Associates, Inc.

Andrius Mudinas, Dell Zhang, and Mark Levene. 2012.
Combining lexicon and learning based approaches
for concept-level sentiment analysis. In Proceedings
of the First International Workshop on Issues of Sen-
timent Discovery and Opinion Mining, WISDOM
’12, pages 5:1–5:8, New York, NY, USA. ACM.

Yanghui Rao, Haoran Xie, Jun Li, Fengmei Jin, Fu Lee
Wang, and Qing Li. 2016. Social emotion classifi-
cation of short text via topic-level maximum entropy
model. In Information & Management, volume 53,
pages 978 – 986.

Johan Reitan, Jørgen Faret, Björn Gambäck, and Lars
Bungum. 2015. Negation scope detection for twit-
ter sentiment analysis. In Proceedings of the 6th
Workshop on Computational Approaches to Subjec-
tivity, Sentiment and Social Media Analysis, pages
99–108, Lisboa, Portugal. Association for Compu-
tational Linguistics.

Adam Santoro, Sergey Bartunov, Matthew Botvinick,
Daan Wierstra, and Timothy Lillicrap. 2016. Meta-
learning with memory-augmented neural networks.
In Proceedings of the 33rd International Conference
on International Conference on Machine Learning -
Volume 48, ICML’16, pages 1842–1850. JMLR.org.

Jun Shu, Zongben Xu, and Deyu Meng. 2018. Small
sample learning in big data era. arXiv:1808.04572.

Nicholas D. Sidiropoulos, Lieven De Lathauwer, Xiao
Fu, Kejun Huang, Evangelos E. Papalexakis, and
Christos Faloutsos. 2017. Tensor decomposition
for signal processing and machine learning. IEEE
Trans. Signal Process., 65(13):3551–3582.

Jacopo Staiano and Marco Guerini. 2014. Depeche
mood: a lexicon for emotion analysis from crowd
annotated news. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics, pages 427–433, Baltimore, Maryland. As-
sociation for Computational Linguistics.

Carlo Strapparava and Rada Mihalcea. 2007. Semeval-
2007 task 14: Affective text. In Proceedings of
the 4th International Workshop on Semantic Eval-
uations, SemEval ’07, pages 70–74.

Carlo Strapparava and Alessandro Valitutti. 2004.
WordNet affect: an affective extension of Word-
Net. In Proceedings of the Fourth International

https://doi.org/10.1137/1.9781611975321.44
https://doi.org/10.1137/1.9781611975321.44
https://openreview.net/forum?id=r1My6sR9tX
https://openreview.net/forum?id=r1My6sR9tX
https://doi.org/10.18653/v1/N18-2115
https://doi.org/10.18653/v1/N18-2115
https://doi.org/10.18653/v1/N18-2115
https://www.aclweb.org/anthology/P18-2072
https://www.aclweb.org/anthology/P18-2072
https://doi.org/10.3115/v1/D14-1181
https://doi.org/10.3115/v1/D14-1181
http://papers.nips.cc/paper/5950-skip-thought-vectors.pdf
http://proceedings.mlr.press/v32/le14.html
http://proceedings.mlr.press/v32/le14.html
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
https://doi.org/10.1145/2346676.2346681
https://doi.org/10.1145/2346676.2346681
https://doi.org/https://doi.org/10.1016/j.im.2016.04.005
https://doi.org/https://doi.org/10.1016/j.im.2016.04.005
https://doi.org/https://doi.org/10.1016/j.im.2016.04.005
https://doi.org/10.18653/v1/W15-2914
https://doi.org/10.18653/v1/W15-2914
http://dl.acm.org/citation.cfm?id=3045390.3045585
http://dl.acm.org/citation.cfm?id=3045390.3045585
https://doi.org/10.1109/TSP.2017.2690524
https://doi.org/10.1109/TSP.2017.2690524
https://doi.org/10.3115/v1/P14-2070
https://doi.org/10.3115/v1/P14-2070
https://doi.org/10.3115/v1/P14-2070
http://www.lrec-conf.org/proceedings/lrec2004/pdf/369.pdf
http://www.lrec-conf.org/proceedings/lrec2004/pdf/369.pdf


3967

Conference on Language Resources and Evaluation
(LREC’04), Lisbon, Portugal. European Language
Resources Association (ELRA).

Sebastian Thrun and Lorien Pratt, editors. 1998.
Learning to Learn. Kluwer Academic Publishers,
Norwell, MA, USA.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In I. Guyon, U. V. Luxburg, S. Bengio,
H. Wallach, R. Fergus, S. Vishwanathan, and R. Gar-
nett, editors, Advances in Neural Information Pro-
cessing Systems 30, pages 5998–6008. Curran As-
sociates, Inc.

Ricardo Vilalta and Youssef Drissi. 2002. A perspec-
tive view and survey of meta-learning. Artificial In-
telligence Review, 18(2):77–95.

Ekaterina P. Volkova, Betty J. Mohler, Detmar Meur-
ers, Dale Gerdemann, and Heinrich H. Bülthoff.
2010. Emotional perception of fairy tales: Achiev-
ing agreement in emotion annotation of text. In
Proceedings of the NAACL HLT 2010 Workshop on
Computational Approaches to Analysis and Gener-
ation of Emotion in Text, CAAGET ’10, pages 98–
106, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.

Han Xiao. 2018. bert-as-service. https://github.com/
hanxiao/bert-as-service.

Ali Yadollahi, Ameneh Gholipour Shahraki, and Os-
mar R. Zaiane. 2017. Current state of text sentiment
analysis from opinion to emotion mining. ACM
Comput. Surv., 50(2):25:1–25:33.

Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Car-
bonell, Ruslan Salakhutdinov, and Quoc V Le.
2019. XLNet: Generalized autoregressive pretrain-
ing for language understanding. arXiv preprint
arXiv:1906.08237.

Jianfei Yu, Luis Marujo, Jing Jiang, Pradeep Karu-
turi, and William Brendel. 2018. Improving multi-
label emotion classification via sentiment classifica-
tion with dual attention transfer network. In Pro-
ceedings of the 2018 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1097–
1102, Brussels, Belgium. Association for Computa-
tional Linguistics.

Yuxiang Zhang, Jiamei Fu, Dongyu She, Ying Zhang,
Senzhang Wang, and Jufeng Yang. 2018. Text emo-
tion distribution learning via multi-task convolu-
tional neural network. In Proceedings of the Twenty-
Seventh International Joint Conference on Artificial
Intelligence, pages 4595–4601. International Joint
Conferences on Artificial Intelligence Organization.

Deyu Zhou, Xuan Zhang, Yin Zhou, Quan Zhao, and
Xin Geng. 2016. Emotion distribution learning from
texts. In Proceedings of the 2016 Conference on

Empirical Methods in Natural Language Process-
ing, pages 638–647, Austin, Texas. Association for
Computational Linguistics.

http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf
http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf
https://doi.org/10.1023/A:1019956318069
https://doi.org/10.1023/A:1019956318069
http://dl.acm.org/citation.cfm?id=1860631.1860643
http://dl.acm.org/citation.cfm?id=1860631.1860643
https://github.com/hanxiao/bert-as-service
https://github.com/hanxiao/bert-as-service
https://doi.org/10.1145/3057270
https://doi.org/10.1145/3057270
https://www.aclweb.org/anthology/D18-1137
https://www.aclweb.org/anthology/D18-1137
https://www.aclweb.org/anthology/D18-1137
https://doi.org/10.24963/ijcai.2018/639
https://doi.org/10.24963/ijcai.2018/639
https://doi.org/10.24963/ijcai.2018/639
https://doi.org/10.18653/v1/D16-1061
https://doi.org/10.18653/v1/D16-1061

