



















































Learning Interpretable Negation Rules via Weak Supervision at Document Level: A Reinforcement Learning Approach


Proceedings of NAACL-HLT 2019, pages 407–413
Minneapolis, Minnesota, June 2 - June 7, 2019. c©2019 Association for Computational Linguistics

407

Learning Interpretable Negation Rules via Weak Supervision at
Document Level: A Reinforcement Learning Approach

Nicolas Pröllochs
Oxford-Man Institute
University of Oxford

nicolas.prollochs@eng.ox.ac.uk

Stefan Feuerriegel
ETH Zurich

sfeuerriegel@ethz.ch

Dirk Neumann
University of Freiburg

dirk.neumann@is.uni-freiburg.de

Abstract

Negation scope detection is widely performed
as a supervised learning task which relies upon
negation labels at word level. This suffers
from two key drawbacks: (1) such granular an-
notations are costly and (2) highly subjective,
since, due to the absence of explicit linguistic
resolution rules, human annotators often dis-
agree in the perceived negation scopes. To
the best of our knowledge, our work presents
the first approach that eliminates the need for
word-level negation labels, replacing it in-
stead with document-level sentiment annota-
tions. For this, we present a novel strategy
for learning fully interpretable negation rules
via weak supervision: we apply reinforcement
learning to find a policy that reconstructs nega-
tion rules from sentiment predictions at docu-
ment level. Our experiments demonstrate that
our approach for weak supervision can effec-
tively learn negation rules. Furthermore, an
out-of-sample evaluation via sentiment analy-
sis reveals consistent improvements (of up to
4.66 %) over both a sentiment analysis with
(i) no negation handling and (ii) the use of
word-level annotations from humans. More-
over, the inferred negation rules are fully in-
terpretable.

1 Introduction

Negations are a frequently utilized linguistic tool
for expressing disapproval or framing negative
content with positive words. Neglecting nega-
tions can lead to false attributions (Morante et al.,
2008) and, moreover, impair accuracy when an-
alyzing natural language; e. g., in information re-
trieval (Cruz Dı́az et al., 2012; Rokach et al., 2008)
and especially in sentiment analysis (Cruz et al.,
2015; Wiegand et al., 2010). Hence, even simple

heuristics for identifying negation scopes can yield
substantial improvements in such cases (Jia et al.,
2009).

Negation scope detection is sometimes imple-
mented as unsupervised learning (e. g., Pröllochs
et al., 2016), while a better performance is com-
monly achieved via supervised learning (see our
supplements for a detailed overview): the resulting
models thus learn to identify negation scopes from
word-level annotations (e. g., Li and Lu, 2018; Re-
itan et al., 2015). We argue that this approach
suffers from inherent drawbacks. (1) Such gran-
ular annotations are costly and, especially at word
level, a considerable number of them is needed.
(2) Negation scope detection is highly subjec-
tive (Councill et al., 2010). Due to the absence
of explicit linguistic rules for resolutions, exist-
ing corpora often come with annotation guidelines
(Morante and Blanco, 2012; Morante and Daele-
mans, 2012). Yet there are considerable differ-
ences: some corpora were labeled in a way that
negation scopes consist of single text spans, while
others allowed disjoint spans (Fancellu et al.,
2017). More importantly, given the absence of
universal rules, human annotators largely disagree
in their perception of what words should be la-
beled as negated.

Motivational experiment. Since prevalent cor-
pora were labeled only by a single rater, we now
establish the severity of between-rater discrepan-
cies. For this, we carried out an initial analy-
sis of 500 sentences from movie reviews.1 Each
sentence contained at least one explicit negation
phrase from the list of Jia et al. (2009), such as
“not” or “no.” Two human raters were then asked

1Details are reported in our supplementary materials.



408

to annotate negation scopes. They could choose
an arbitrary selection of words and were not re-
stricted to a single subspan, as recommended by
Fancellu et al. (2017). The annotations resulted
in large differences: only 50.20 % of the words
were simultaneously labeled as “negated” by both
raters. Based on this experimental evidence, we
showcase there is no universal definition of nega-
tion scopes (rather, human annotations are likely
to be noisy or even error-prone) and thus highlight
the need for further research.

Contributions. To the best of our knowledge,
our work presents the first approach that elimi-
nates the need for word-level annotations of nega-
tion labels. Instead, we perform negation scope
detection merely by utilizing shallow annotations
at document level in the form of sentiment la-
bels (e. g., from user reviews). Our novel strat-
egy learns interpretable negation rules via weak
supervision: we apply reinforcement learning to
find a policy that reconstructs negation rules based
on sentiment prediction at document level (as op-
posed to conventional word-level annotations).

In our approach, a single document d comes
with a sentiment label yd. The document con-
sists of Nd words, wd,1, . . . , wd,Nd , where the
number of words can easily surpass several hun-
dreds. Based on the sentiment value, we then need
to make a decision (especially out-of-sample) for
each of the Nd words, whether or not it should be
negated. In this case, a single sentiment value is
outnumbered by potentially hundreds of negation
decisions, thus pinpointing to the difficulty of this
task. Formally, the goal is to learn individual la-
bels ad,i ∈ {Negated,¬Negated} for each word
wd,i. Rewards are the errors in sentiment predic-
tion at document level.

Strengths. Our approach exhibits several favor-
able features that overcome shortcomings found
in prior works. Among them, it eliminates the
need for manual word-level labels. It thus avoids
the detrimental influence of subjectivity and mis-
interpretation. Instead, our model is solely trained
on a document-level variable and can thus learn
domain-specific particularities of the given prose.
The inferred negation rules are fully interpretable
while documents can contain multiple instances
of negations with arbitrary complexity, sometimes
nested or consisting out of disjoint text spans. De-
spite facing several times more negation decisions
than sentiment labels, our experiments demon-

strate that this problem can be effectively learned
through reinforcement learning.

Evaluation. Given the considerable inconsis-
tencies in human annotations of negation scopes
and the lack of universal rules, we regard the
“true” negation scopes as unobservable. Hence,
we later compare the identified negation scopes
with those from rater 1 and 2 only as a sensitiv-
ity check because of the fact that both raters have
only 50.2 % overlap. Instead, we choose the fol-
lowing evaluation strategy. We concentrate on the
performance of negation scope detection as a sup-
porting tool in natural language processing where
its primary role is to facilitate more complex learn-
ing tasks such as sentiment analysis. Therefore,
we report the performance improvements in sen-
timent analysis resulting from our approach. For
a fair comparison, we use baselines that only rely
upon the same information as our weak supervi-
sion (and thus have no access to word-level nega-
tion labels). Our performance is even on par with
a supervised classifier that can exploit richer labels
during training.

2 Learning Negation Scope Detection via
Weak Supervision

Intuition. The choice of reinforcement learning
for weak supervision might not be obvious at first,
but, in fact, it is informed by theory: it imitates the
human reading process as stipulated by cognitive
reading theory (Just and Carpenter, 1980), where
readers iteratively process information word-by-
word.

States and actions. In each learning iteration,
the reinforcement learning agent observes the cur-
rent state si = (wi, ai−1) that we engineer as the
combination of the i-th wordwi in a document and
the previous action ai−1. This specification estab-
lishes a recurrent architecture whereby the previ-
ous negation can pass on to the next word. At the
same time, this allows for nested negations, as a
word can first introduce a negation scope and an-
other subsequent negation can potentially revert it.

After observing the current state, the agent
chooses an action at from of two possibilities:
(1) it can set the current word to negated or
(2) it can mark it as not negated. Hence, we ob-
tain the following set of possible actions A =
{Negated,¬Negated}. Based on the selected ac-
tion, the agent receives a reward, ri which up-
dates the knowledge in the state-action function



409

Q(si, ai). This state-action function is then used
to infer the best possible action ai in each state si,
i. e., the optimal policy π∗(si, ai).

Reward function. The reward ri depends upon
the correlation between a given a document-level
label (e. g., a rating in movie reviews) and the sen-
timent of a document. We predict the sentiment Sd
of document d using a widely-used sentiment rou-
tine based on the occurrences of positively- and
negatively-opinionated terms (see Taboada et al.,
2011). If a term is negated by the policy, the po-
larity of the corresponding term is inverted, i. e.,
positively opinionated terms are counted as nega-
tive and vice versa. In the following, S0d denotes
the document sentiment without considering nega-
tions; Sπd the sentiment when incorporating nega-
tions based on policy π.

When processing a document, we cannot actu-
ally compute the reward until we have processed
all words. Therefore, we set the reward before the
last word to c ≈ 0, i. e., ri = c for i = 1, . . . , Nd−
1. For the final word, the agent compares its per-
formance in predicting the document label based
on sentiment without considering negations S0d to
the sentiment when incorporating negations based
on the current policy π∗. The former is defined
by the absolute difference between the document
label yd and the predicted sentiment without nega-
tions S0d , whereas the latter is defined by the ab-
solute difference between yd and the adjusted sen-
timent using the current policy Sπd . Then the dif-
ference between these values returns the terminal
reward rNd . Thus the reward is

ri =

{
0, if ai = Neg and i < Nd,
c, if ai = ¬Neg and i < Nd,∣∣yd − S0d∣∣− |yd − Sπd | , if i = Nd,

with a constant c (we use c = 0.005) that adds
a small reward for default (i. e., non-negating) ac-
tions to avoid overfitting.
Q-learning. During the learning process2, the

agent then successively observes a sequence of
words in which it can select between exploring
new actions or taking the current optimal one.
This choice is made by ε-greedy selection accord-
ing to which the agent explores the environment
by selecting a random action with probability ε or,

2We use Watkin’s Q(λ) with eligibility traces; see Sutton
and Barto (1998) for details. At the beginning, we initialize
the action-value function Q(s, a) to zero for all states and
actions. This also controls our default action when encoun-
tering unknown states or out-of-vocabulary (OOV) words. In
such cases, the non-negated action is preferred.

alternatively, exploits the current knowledge with
probability 1− ε.

3 Experiments

Datasets. We use the following benchmark
datasets with document-level annotations from the
literature (cf. Hogenboom et al., 2011; Pröllochs
et al., 2016; Wiegand et al., 2010):

IMDb: movie reviews from the Internet Movie
Database archive, each annotated with an overall
rating at document level (Pang and Lee, 2005).

Airport: user reviews of airports from Skytrax,
each annotated with an overall rating at document
level (Pérezgonzález and Gilbey, 2011).

Ad hoc: financial announcements with com-
plex, domain-specific language (Pröllochs et al.,
2016), labeled with the daily abnormal return of
the corresponding stock.

Learning parameters. We perform 4000 learn-
ing iterations with a higher exploration rate as
given by the following parameters3: exploration
ε = 0.001, discount factor γ = 0 and learning rate
α = 0.005. In a second phase, we run 1000 itera-
tions for fine-tuning with exploration ε = 0.0001,
discount factor γ = 0 and learning rate α = 0.001.

Policy learning. For each dataset, the rein-
forcement learning process converges to a sta-
tionary policy that shows reward fluctuations be-
low 0.05 %. As part of a benchmark, we study
the mean squared error (MSE) between yd and
the predicted sentiment S0d when leaving nega-
tions untreated as our benchmark. For all datasets,
the in-sample MSE decreases substantially (see
Figure 1), demonstrating the effectiveness of our
learning approach. The reductions number to
14.93 % (IMDb), 16.77 % (airport), and 0.91 %
(ad hoc). The latter is a result of the considerably
more complex language in financial statements.

Performance in Sentiment Analysis. We use
10-fold cross validation to compare the out-of-
sample performance in sentiment analysis of rein-
forcement learning to benchmarks without word-
level labels from previous works. The bench-
marks consists of rules (Hogenboom et al., 2011;
Taboada et al., 2011), which search for the occur-
rence of specific cues based on pre-defined lists
and then invert the meaning of a fixed number of
surrounding words. Table 1 compares the out-of-
sample MSE between predicted sentiment and the

3Further details regarding the learning parameters are pro-
vided in the supplementary materials.



410

(a) IMDb

Benchmark (no negation handling)

0.80

0.85

0.90

0.95

1.00

0 1000 2000 3000 4000 5000
Iteration

M
S

E

(b) Airport

Benchmark (no negation handling)

0.6

0.7

0.8

0.9

0 1000 2000 3000 4000 5000
Iteration

M
S

E

(c) Ad hoc

Benchmark (no negation handling)

0.980

0.985

0.990

0.995

1.000

0 1000 2000 3000 4000 5000
Iteration

M
S

E

Figure 1: MSE between the document label and predicted sentiment across different learning iterations using
10-fold cross validation. Additional lines in black from smoothing.

document-level label:4

IMDb: Negating a fixed window of the next 4
words achieves the lowest error among all rules,
similar to Dadvar et al. (2011). This rule reduces
the MSE of the benchmark with no negation han-
dling by 1.05 %. Our approach works even more
accurately, and dominates all of the rules, reducing
the out-of-sample MSE by at least 4.60 %.

Airport: Our method decreases the MSE by
4.66 % compared to the best-performing rule
(negating a fixed window of the next 4 words).

Ad hoc: Even for complex financial language,
reinforcement learning exceeds this benchmark
method by 0.19 % in terms of out-of-sample MSE.

Altogether, our weak supervision improves sen-
timent analysis consistently across all datasets.5

Approach IMDb Airport Ad hoc

Benchmark: no negation handling 0.9133 0.7415 0.9958

Negating all subsequent words 0.9160 0.7312 0.9949
Negating the whole sentence 0.9339 0.7811 0.9961
Fixed window of 1 word 0.9082 0.7212 0.9950
Fixed window of 2 words 0.9052 0.7130 0.9943
Fixed window of 3 words 0.9047 0.7146 0.9943
Fixed window of 4 words 0.9038 0.7134 0.9942
Fixed window of 5 words 0.9039 0.7136 0.9942

Proposed reinforcement learning 0.8622 0.6798 0.9923
for weak supervision

Table 1: Out-of-sample MSE between sentiment Sπd
and the document label yd. Lowest error in bold.

Comparison to human raters. For reasons
of completeness, our supplements report the over-
lap with both human raters from our motivational
experiment, which is in the range of 18.8 % to

4We also experimented with performance comparisons in
a classification task, yet our approach also yields consistent
improvements in this evaluation.

5We also investigated the relationship between prediction
performance and text length, finding only minor effects.

25.2 %. However, these numbers should be treated
with caution, as we remind that there is no univer-
sal definition of negation scopes and even the two
human annotations reveal on 50.2 %. Moreover,
our approach was not learned towards reconstruct-
ing these human annotations, since we focused on
rules that achieve the greatest benefit in sentiment
analysis.

Comparison to word-level classifiers. We also
compared weak supervision against a supervised
HMM classifier from Pröllochs et al. (2016) that
draws upon granular word-level negation labels.
Here we report the sentiment analysis on IMDb in
order to be able to use the domain-specific nega-
tion labels from IMDb text snippets of our ini-
tial experiment. In comparison to our reinforce-
ment learning, the supervised classifier results in
a 5.79 % higher (and thus inferior) MSE. Yet our
weak supervision circumvents costly word-level
annotations.

Interpretability. Our method yields negation
rules that are fully interpretable: one simply has to
assess the state-action function Q(si, ai). Table 2
provides an example excerpt for the document
“this beautiful movie isn’t good but fantastic.”
The agent the starts by observing the first state
given by the combination of the first word w1 and
the previous action a0, i. e. s1 = (this,¬Negated).
According to the state-action table, the best ac-
tion for the agent is to set this state to not negated
(a1 = ¬Negated). This pattern continues un-
til it observes state s4 = (isn’t,¬Negated) in
which the policy implies to initiate a negation
scope (a4 = Negated). Subsequently, the negation
scope is forwarded until the agent observes s6 =
(but,Negated) in which it terminates the nega-
tion scope (a6 = ¬Negated). Finally, the agent
observes s7 = (fantastic,¬Negated) in which it
takes action a7 = ¬Negated.



411

State=(wi, ai−1) Negated ¬Negated π∗(si, ai)

(this,¬Negated) 0.0114 0.0502 ¬Negated
(beautiful,¬Negated) 0.0081 0.0779 ¬Negated
(movie,¬Negated) 0.0039 0.0506 ¬Negated
(isn’t,¬Negated) 0.0700 0.0456 Negated
(good,Negated) 0.0578 0.0322 Negated
(but,Negated) 0.0120 0.0365 ¬Negated
(fantastic,¬Negated) −0.0181 0.1708 ¬Negated

Table 2: Excerpt of state-action function Q(si, ai) ac-
tionsA = {Negated,¬Negated} and the learned policy
π∗ for IMDb reviews.

4 Related Work

State-of-the-art methods for detecting, handling
and interpreting negations can be grouped into dif-
ferent categories (cf. Pröllochs et al., 2015, 2016;
Rokach et al., 2008).

Rule-based approaches are among the most
common due to their ease of implementation and
solid out-of-the-box performance. These usu-
ally suppose a forward influence of negation cues
based on which they invert the meaning of the
whole sentence or a fixed number of subsequent
words (Hogenboom et al., 2011). Furthermore,
they can also incorporate syntactic information
in order to imitate subject and object (Padmaja
et al., 2014; Chowdhury and Lavelli, 2013). Nega-
tion rules have been found to work effectively
across different domains and rarely need fine-
tuning (Taboada et al., 2011). However, rule-based
approaches entail several drawbacks, as the list of
negations must be pre-defined and the selection
criterion according to which rule a rule is chosen
is usually random or determined via cross vali-
dation. In addition, rules cannot effectively cope
with implicit expressions or particular, domain-
specific characteristics.

Generative probabilistic models (e. g., hidden
Markov models or conditional random fields) can
partially overcome these shortcomings (Li and Lu,
2018; Reitan et al., 2015; Rokach et al., 2008),
such as the difficulty of recognizing implicit nega-
tions. These process narrative language word-by-
word and move between hidden states represent-
ing negated and non-negated parts. Such mod-
els can adapt to domain-specific language, but re-
quire more computational resources and rely upon
ex ante transition probabilities. Although vari-
ants based on unsupervised learning avoid the
need for any labels, practical applications reveal
inferior performance compared to supervised ap-
proaches (Pröllochs et al., 2015). The latter usu-

ally depend on manual labels at a granular level,
which are not only costly but suffer from subjec-
tive interpretations (Fancellu et al., 2017).

A third category of methods links the polar-
ity shift effect of negations more closely to sen-
timent analysis tasks at sentence or document
level. For example, text parts can be classified
into a polarity-unshifted part and a polarity-shifted
part according to certain rules (Li and Huang,
2009). Sentiment classification models are then
trained using both parts (Li et al., 2010). Alterna-
tively, rule-based algorithms can extract sentences
with inconsistent sentiment and omit them from
standard sentiment analysis procedures (Orimaye
et al., 2012). Reversely, antonym dictionaries have
been used to generate sentiment-inverted texts to
classify polarity in pairs (Xia et al., 2016). Al-
though such data expansion techniques usually en-
hance the performance of sentiment analysis, they
require either complex linguistic knowledge or ex-
tra human annotations (Xia et al., 2015).

Research gap. In contrast to these methods,
we propose a novel strategy for learning negation
rules via weak supervision. Our model uses re-
inforcement learning to reconstruct negation rules
based on an document-level variable and does not
require any kind of manual word-level labeling or
precoded linguistic patterns. It is able to recognize
explicit as well as implicit negations, while avoid-
ing the influence of subjective interpretations.

5 Conclusion

This paper proposes the first approach for nega-
tion scope detection based on weak supervision.
Our proposed reinforcement learning strategy cir-
cumvents the need for word-level annotations with
negation scopes, as it reconstructs negation rules
based on a document-level sentiment labels. Our
experiments show that our weak supervision is ef-
fective in negation scope detection; it yields con-
sistent improvements (of up to 4.66 %) over a sen-
timent analysis without negation handling.

Our works suggests important implications. We
are in line with growing literature (e. g., Fancellu
et al., 2017) that reports challenges in resolving
negation scopes through humans. Beyond prior
works, our experiment reveals between-rater in-
consistencies. While negation scope detection is
widely studied as an isolated task, it could be ben-
eficial when linking its evaluation more closely to
context-specific uses such as sentiment analysis.



412

References
Md Faisal Mahbub Chowdhury and Alberto Lavelli.

2013. Exploiting the scope of negations and
heterogeneous features for relation extraction: A
case study for drug-drug interaction extraction. In
NAACL-HLT, pages 765–771.

Isaac G. Councill, Ryan McDonald, and Leonid Ve-
likovich. 2010. What’s great and what’s not: Learn-
ing to classify the scope of negation for improved
sentiment analysis. In Workshop on Negation and
Speculation in Natural Language Processing, pages
51–59. ACL.

Noa P. Cruz, Maite Taboada, and Ruslan Mitkov. 2015.
A machine–learning approach to negation and spec-
ulation detection for sentiment analysis. Journal of
the Association for Information Science and Tech-
nology, 67(9):2118–2136.

Noa P. Cruz Dı́az, Maña López, Manuel J., Jac-
into Mata Vázquez, and Victoria Pachón Álvarez.
2012. A machine-learning approach to negation and
speculation detection in clinical texts. Journal of the
American Society for Information Science and Tech-
nology, 63(7):1398–1410.

Maral Dadvar, Claudia Hauff, and Franciska de Jong.
2011. Scope of negation detection in sentiment anal-
ysis. In Dutch-Belgian Information Retrieval Work-
shop, pages 16–20.

Federico Fancellu, Adam Lopez, Bonnie Webber, and
Hangfeng He. 2017. Detecting negation scope is
easy, except when it isn’t. In Conference of the Eu-
ropean Chapter of the ACL, pages 58–63. ACL.

Alexander Hogenboom, Paul van Iterson, Bas Heer-
schop, Flavius Frasincar, and Uzay Kaymak. 2011.
Determining negation scope and strength in senti-
ment analysis. In IEEE International Conference on
Systems, Man, and Cybernetics, pages 2589–2594.

Lifeng Jia, Clement Yu, and Weiyi Meng. 2009. The
effect of negation on sentiment analysis and retrieval
effectiveness. In CIKM, pages 1827–1830.

Marcel A Just and Patricia A Carpenter. 1980. A theory
of reading: From eye fixations to comprehension.
Psychological review, 87(4):329.

Hao Li and Wei Lu. 2018. Learning with structured
representations for negation scope extraction. In
Proceedings of the ACL, pages 533–539.

Shoushan Li and Chu-Ren Huang. 2009. Sentiment
classification considering negation and contrast tran-
sition. In Pacific Asia Conference on Language, In-
formation and Computation, pages 297–306. ACL.

Shoushan Li, Sophia Yat Mei Lee, Ying Chen, Chu-
Ren Huang, and Guodong Zhou. 2010. Senti-
ment classification and polarity shifting. In Inter-
national Conference on Computational Linguistics,
pages 635–643. ACL.

Roser Morante and Eduardo Blanco. 2012. Sem 2012
shared task: Resolving the scope and focus of nega-
tion. In Proceedings of the First Joint Conference
on Lexical and Computational Semantics (SemEval
’12), pages 265–274.

Roser Morante and Walter Daelemans. 2012.
Conandoyle-neg: Annotation of negation in
conan doyle stories. In Proceedings of the Eighth
International Conference on Language Resources
and Evaluation, Istanbul.

Roser Morante, Anthony Liekens, and Walter Daele-
mans. 2008. Learning the scope of negation in
biomedical texts. In EMNLP, pages 715–724.

Sylvester Olubolu Orimaye, Saadat M Alhashmi, and
Eu-Gene Siew. 2012. Buy it-don’t buy it: sentiment
classification on amazon reviews using sentence po-
larity shift. In Pacific Rim International Conference
on Artificial Intelligence, pages 386–399. Springer.

S. Padmaja, Sameen Fatima, and Sasidhar Bandu.
2014. Evaluating sentiment analysis methods and
identifying scope of negation in newspaper articles.
International Journal of Advanced Research in Arti-
ficial Intelligence, 3(11):1–6.

Bo Pang and Lillian Lee. 2005. Seeing stars: Exploit-
ing class relationships for sentiment categorization
with respect to rating scales. In Proceedings of the
ACL, pages 115–124.

Jose D. Pérezgonzález and Andrew Gilbey. 2011. Pre-
dicting skytrax airport rankings from customer re-
views. Journal of Airport Management, 5(4):335–
339.

Nicolas Pröllochs, Stefan Feuerriegel, and Dirk Neu-
mann. 2015. Enhancing sentiment analysis of finan-
cial news by detecting negation scopes. In HICSS,
pages 959–968.

Nicolas Pröllochs, Stefan Feuerriegel, and Dirk Neu-
mann. 2016. Negation scope detection in sentiment
analysis: Decision support for news-driven trading.
Decision Support Systems, 88:67–75.

Johan Reitan, Jørgen Faret, Björn Gambäck, and Lars
Bungum. 2015. Negation scope detection for twit-
ter sentiment analysis. In Workshop on Computa-
tional Approaches to Subjectivity, Sentiment and So-
cial Media Analysis, pages 99–108.

Lior Rokach, Roni Romano, and Oded Maimon. 2008.
Negation recognition in medical narrative reports.
Information Retrieval, 11(6):499–538.

Richard S. Sutton and Andrew G. Barto. 1998. Rein-
forcement Learning: An Introduction. MIT Press,
Cambridge, MA.

Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-based
methods for sentiment analysis. Computational Lin-
guistics, 37(2):267–307.



413

Michael Wiegand, Alexandra Balahur, Benjamin Roth,
Dietrich Klakow, and Andrés Montoyo. 2010. A
survey on the role of negation in sentiment analy-
sis. In Workshop on Negation and Speculation in
Natural Language Processing, pages 60–68. ACL.

Rui Xia, Feng Xu, Jianfei Yu, Yong Qi, and Erik Cam-
bria. 2016. Polarity shift detection, elimination and
ensemble: A three-stage model for document-level
sentiment analysis. Information Processing & Man-
agement, 52(1):36–45.

Rui Xia, Feng Xu, Chengqing Zong, Qianmu Li, Yong
Qi, and Tao Li. 2015. Dual sentiment analysis:
Considering two sides of one review. Transactions
on Knowledge and Data Engineering, 27(8):2120–
2133.


