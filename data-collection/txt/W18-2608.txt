



















































RECIPE: Applying Open Domain Question Answering to Privacy Policies


Proceedings of the Workshop on Machine Reading for Question Answering, pages 71–77
Melbourne, Australia, July 19, 2018. c©2018 Association for Computational Linguistics

71

RECIPE: Applying Open Domain Question Answering to Privacy Policies

Yan Shvartzshnaider
New York University and Princeton Univerity

yansh@nyu.edu

Ananth Balashankar
New York University

ananth@nyu.edu

Thomas Wies
New York University

wies@cs.nyu.edu

Lakshminarayanan Subramanian
New York University
lakshmi@cs.nyu.edu

Abstract

We describe our experiences in us-
ing an open domain question answering
model (Chen et al., 2017) to evaluate an
out-of-domain QA task of assisting in
analyzing privacy policies of companies.
Specifically, Relevant CI Parameters Ex-
tractor (RECIPE) seeks to answer ques-
tions posed by the theory of contextual
integrity (CI) regarding the information
flows described in the privacy statements.
These questions have a simple syntactic
structure and the answers are factoids or
descriptive in nature. The model achieved
an F1 score of 72.33, but we noticed that
combining the results of this model with a
neural dependency parser based approach
yields a significantly higher F1 score of
92.35 compared to manual annotations.
This indicates that future work which in-
corporates signals from parsing like NLP
tasks more explicitly can generalize better
on out-of-domain tasks.

1 Introduction

Open domain question answering approaches of-
fer a promising glimpse into a future in which ma-
chines are able to perform sophisticated cognitive
tasks on behalf of a human. Recent advances in
deep neural networks applied to reading compre-
hension and document retrieval (Chen et al., 2017;
Wang et al., 2017) have achieved competitive re-
sults for answering questions based on a large and
diverse corpus of documents. These models are
trained on Wikipedia text and are capable of an-
swering various factoid and descriptive questions.
Specifically, the distribution of the interrogative
words used, lexical and syntactic variations, rea-
soning across multiple sentences and ambiguous

statements in such Wikipedia datasets (Ryu et al.,
2014; Rajpurkar et al., 2016) results in a robust
QA model.

Motivated by their success, we set to apply one
such model (Chen et al., 2017) to evaluate an out-
of-domain QA task to assist in analysis and un-
derstanding of privacy policies. The text in pri-
vacy policies is notoriously cumbersome, confus-
ing and hard to comprehend even for legal ex-
perts (Reidenberg et al., 2015). So when it comes
to reading privacy policies, users often miss im-
portant information or skip reading them alto-
gether. Past efforts have applied NLP (Sathyendra
et al., 2017, 2016; Evans et al., 2017), Machine
Learning (Ammar et al., 2012) and crowdsourc-
ing (Wilson et al., 2016b) techniques to identify
important and relevant privacy statements. How-
ever, identifying paragraphs that mention sensitive
information in privacy policies only takes us half-
way because we still need to understand who col-
lects that information, who receives it, and under
what conditions the collection happens. To sup-
port this finer-grained analysis, we present a case
for using an machine comprehension model for
answering questions posed by the theory of con-
textual integrity (CI) (Nissenbaum, 2010).

To understand the privacy implications, the CI
theory (see Section 2) calls for answering to the
following questions: who are the actors (sender,
recipient, subject) involved in the information
flow? What are the type of information (at-
tribute), and condition (transmission principle) un-
der which information is exchanged? The an-
swers are used to formulate information flows (CI
flows) into a five element tuple (sender, attribute,
receiver, subject, transmission principle).

Unfortunately, because privacy policies are not
written with CI in mind, manually identifying CI
flows in text is a time consuming exercise. It re-
quires substantial cognitive effort to understand



72

and answer CI related questions. Automating this
task is not trivial either. The syntax of privacy
statements varies a lot, some relevant information
might not be specified at all. So, the answers are
not always obvious and cannot be identified using
a simple model. Even with the simple syntactic
structure of the questions, the trained model needs
to take into account the variations and complexity
in syntax and semantics used in privacy policies.

To help address these issues, we are design-
ing a Relevant CI Parameters Extractor (RECIPE)
that uses a pre-trained 3 layer bi-directional LSTM
reading comprehension (RC) model (Chen et al.,
2017). Our experiments show that, in itself, the
model achieved an F1 score of 72.33 for identify-
ing answers in the text. However, the results sig-
nificantly improved by combining the results from
the model and that of a neural dependency parser.
The combination of the two approaches yielded an
overall F1 score of 92.35 against the baseline of
six manually annotated privacy policies.

2 Contextual Integrity Primer

Questions underpinning the theory of Contextual
Integrity (CI) are used by many research efforts for
understanding privacy implications in a given con-
text. Legal and privacy scholars draw on CI to ex-
amine existing data sharing practices in companies
like Facebook (Hull et al., 2011) and Google (Zim-
mer, 2008) and to identify important contextual
elements behind users privacy expectations (Mar-
tin and Nissenbaum, 2016). In computer science,
CI has been used to build privacy compliance and
verification tools (Barth et al., 2006; Chowdhury
et al., 2013).

The CI theory defines privacy as appropriate
flow of information. The appropriateness is de-
termined by established norms in a given con-
text. CI offers a framework to capture the infor-
mation flow and contextual norms using a five ele-
ment tuple that specifies the following CI parame-
ters: (sender, attribute, receiver, subject, transmis-
sion principle). Therefore, answering the ques-
tions about who are the actors (sender, recipient,
subject) involved in the information flow, what
are the type of information (attribute), and con-
dition (transmission principle) of the information
exchange, is crucial for identifying potential pri-
vacy violations.

In our work, the answers to the questions are
highlighted in the text, as shown in Figure 1 to

Figure 1: Example of a Walmart privacy state-
ment. The coloring of the text identifies the CI
parameters.

assist consumers in understanding the information
flows described in the privacy policy. These anno-
tations can also help identify potentially confusing
or misleading statements, e.g., cases where one of
the five parameters such as transmission principle
or receiver is missing or ambiguous.

3 Related work

The problem of automatic parsing of privacy
policies was tackled by multiple efforts, as part
of the “Usable Privacy Project” (Sadeh et al.,
2013), which included training machine learning
models to identify paragraphs containing specific
data practices information (Wilson et al., 2016b),
identifying provision of choice statements, au-
tomatic extraction of the opt-out choice state-
ments (Sathyendra et al., 2016, 2017) and oth-
ers (Evans et al., 2017; Hosseini et al., 2016; Bha-
tia et al., 2016b). More recent work by Harkous
et al. (2018) looked at neural network classifiers
for annotation and support of free-form querying
of the privacy policy content.

Compared to these efforts, our work is the first
step towards bringing a formal analysis of pri-
vacy policies through the use of CI. We used de-
pendency parsing to extract CI parameters from
individual sentences, which was previously suc-
cessfully used for various privacy policy analy-
sis tasks. Bhatia and Breaux (2015) used depen-
dency types to construct an information type lex-
icon from manual human annotations and an en-
tity extractor based on part-of-speech tagging. In a
more recent work, Bhatia et al. (2016a) employed
typed dependency parsing to extract privacy goals
from privacy policies. In our work, we were able
to show that a machine reading comprehension
model (Chen et al., 2017; Hermann et al., 2015;
Seo et al., 2017), needs to additionally have the
capacity to capture the semantic relationships as-



73

sociated with dependency parsing structure from
the privacy policy text.

Furthermore, the problem of identifying CI pa-
rameters can be modeled as a sequence tagging
task using LSTMs combined with CRFs (Lample
et al., 2016; Ma and Hovy, 2016) to learn clas-
sification models for entity recognition and end-
to-end sequence labeling. However, training these
models requires large amounts of annotated data,
which in our case means hiring highly skilled (i.e.,
expensive) annotators to produce a high quality
corpus of CI-based annotated policies. In fact, our
work aims at reducing that effort.

4 Relevant CI Parameters Extractor
(RECIPE) using open-domain QA

In this section we describe our approach of for-
mulating the CI parameter extraction as an open-
domain QA task. Given a privacy statement
paragraph, such as shown in Figure 1, we pose
questions that correspond to each of the CI pa-
rameters, i.e.., what type of information be-
ing exchange (“technical information”), who is
the sender (“You”), receiver (“We”) and subject
(“your”) involved in the information exchange and
under what conditions (“when visiting websites or
using a mobile application service”)?

As in the example paragraph, some parameters
can be mentioned elsewhere, e.g., in the next sen-
tence. To identify CI parameters at a paragraph
level using global relationships across sentences,
we used a 3 layer bi-directional LSTM reading
comprehension (RC) model (Chen et al., 2017).
The model uses features of Glove word embed-
dings trained from 840B Web crawl data (Pen-
nington et al., 2014) and token features like pres-
ence of exact match with question’s tokens, parts
of speech, named entity relationship and term fre-
quency. We also align the question embedding
with the paragraph token embedding using soft
attention (Lee et al., 2016). During the predic-
tion phase, we perform two classification tasks to
predict the beginning and ending of the span of
the answer. The model is trained on the SQuAD
dataset (Rajpurkar et al., 2016) for machine com-
prehension (87k examples for training and 10k for
development) based on Wikipedia. Each question
in the dataset has an answer which is contained
within the paragraph. In our case, the answer span
detection is identical to the task of manually an-
notating CI parameters. In order to extract the 5

Parameter Type Question
Attribute What is the information?
Receiver Who is receiving the information?
Sender Who is sending the information?
Transmission Principle When is the information sent?
Subject Whose information is it?

Table 1: Questions asked for each contextual in-
tegrity parameter

parameters, we ask a fixed set of questions for a
given paragraph as can be seen in Table 1. The
top 5 answers from the reading comprehension
model are then used to evaluate the accuracy via
fuzzy string token match above a certain threshold
(>80%). We again manually validate if the an-
swers provided by the model match the manually
annotated answers semantically. For example dur-
ing extraction of “receiver” in the New York Times
policy, the model answered with the entity “New
York Times” whereas it was manually annotated as
“we”, which referred to NYT in the context. This
manual validation is required due to the ambiguity
prevalent in the privacy policy text and relying on
exact match can be misleading during evaluation.

In order to understand the limitations of this
model’s performance (discussed in Section 5), we
compared the results produced by dependency
parsing which is limited to identifying CI param-
eters at a single sentence level using local rela-
tionships. We discuss the dependency-parsing ap-
proach next.

Algorithm 1
paras← CI relevant paragraphs
sentences← segments.split(‘.’)
CIDP ← DependencyParser(sentences)
CIRC ← ReadingCompr(paras)
Return CIDP ∪ CIRC

4.1 Dependency parsing

We run a typed dependency parser (DP) on the text
of the policies by splitting the paragraph into indi-
vidual sentences and then parsing each sentence
using the Spacy I/O1 dependency parser. The li-
brary (Honnibal and Montani, 2018) achieves near
state of the art performance on most NLP tasks.2

We then match dependency types to specific CI
parameters. For example, in the sentence ”You

1https://spacy.io
2https://spacy.io/usage/facts-figures



74

may be asked to provide your personal informa-
tion anytime you are in contact with Apple or an
Apple affiliated company: The nominal subject
“you” and conjunct “Apple affiliated company”
are sender and receiver respectively, the direct ob-
ject “your personal information” is an attribute,
and the open clausal complement adverbial clause
modifier “anytime you are in contact with Apple
or an Apple affiliated company” is the transmis-
sion principle.

Table 2 shows all the mappings of dependency
types to CI parameters. For the sake of brevity,
we represent type dependencies as they are de-
fined in the Stanford Typed Dependency Man-
ual (De Marneffe and Manning). We then present
the options of the CI parameters as extracted by
the dependency parsers to the annotators, who
then validate them as explained in the previous
section, without having an option to modify the
text for the annotation.

CI Parameter Type Dependency types
Attribute dobj, parataxis, nsubjpass
Sender/Receiver nsubj, pronouns
Transmission Principle xcomp, ccomp, advcl, oprd
Subject poss, agent

Table 2: Mapping of dependency types corre-
sponding to CI parameters

In summary, in our approach we rely on depen-
dency parsing to extract CI parameters based on
the syntactic structure of a single sentence, and a
reading comprehension model to capture CI pa-
rameters based on the semantic understanding of
the larger scope. More specifically, the approach
consists of two rounds of extraction, as shown in
Algorithm 1, to return the union of the two sets
of parameters after manual validation assisted by
a fuzzy token match (Cohen, 2011) that uses Lev-
enshtein Distance to calculate the differences be-
tween sequences.

5 Evaluation

For our evaluation, we analyze the ensemble al-
gorithm against each of its sub-algorithms using
manually annotated policies as a baseline.

5.1 Dataset
We use OPP-115 Corpus (Wilson et al., 2016a)
that contains website privacy policies in natu-
ral text along side annotations (done by law stu-
dents) specifying the corresponding text data prac-

Parameter Type F1 score Validated
F1 score

Attribute 61.53 83.65
Receiver 48.57 75.00
Sender 37.70 56.55
Transmission Principle 52.20 67.29
Subject 25.00 26.56

Overall 49.20 72.33

Table 3: Validated F1 score of manually validated
reading comprehension based annotation

Parameter Type Valid (%) Validated F1 score
Attribute 23.73 84.39
Sender/Receiver 40.41 73.04
Subject 17.42 86.05
Transmission Principle 27.47 69.48

Overall 26.40 77.07

Table 4: F1 scores of dependency parsing based
annotation

tices. We rely on these labels to extract segments
within the privacy statement about information ex-
changes. Specifically, we chose segments related
to First Party Collection/Use, Third party shar-
ing/collection, Data Retention to extract CI pa-
rameters. We then manually annotated a total of
715 parameters (219 Attributes, 65 Subjects, 164
Transmission Principles, 124 Senders and 143 Re-
ceivers) from 6 privacy policies from Amazon,
Google, New York Times, The Atlantic, Bank of
America and Walmart. This forms the ground
truth of our evaluation.

5.2 Results and Discussion

Table 3 shows the F1 scores of the reading com-
prehension model alone. We see that subject, re-
ceiver and sender have relatively low F1 scores
and this is due to the absence of entities in the
paragraphs as they are usually referred to as pro-
nouns. We noticed that the reading comprehension
model outputs such pronoun answers only for 15%
of these parameters and prefers to answer with of-
ten incorrect entities for these questions.

Table 4 shows the results from using the depen-
dency parser on its own. Since dependency pars-
ing is restricted to a single sentence, it misses out
on some contextual information spread across sen-
tences as shown in Figure 1, leading to a loss in
accuracy, even after manual validation.

Table 5 compares the results from each algo-
rithm individually with the result achieved by en-
sembling the approaches. Exclusive contributions



75

Parameter DP only RC only DP ∩ RC DP ∪ RC
Attribute 12.98 16.34 67.31 96.63
Sender/Receiver 29.57 30.28 33.1 92.95
Transmission
Principle

20.75 23.27 44.02 88.05

Subject 57.14 19.05 7.14 83.33

Overall 24.24 23.81 44.30 92.35

Table 5: Validated F1 score by ensembling

by each of the individual models (“Parsing only”,
“RC only”) demonstrate how each model is able
to capture syntactic and semantic features respec-
tively, which the other could not. Column “DP ∩
RC” shows that many parameters are extracted by
both the approaches used to formulate CI parame-
ter extraction. This confirms that the task of CI pa-
rameter extraction is non-trivial and composes se-
mantic and syntactic relationship extraction within
it. Finally, “DP ∪ RC” achieves the highest F1
score, significantly improving over both of the
component scores individually.

Table 6 shows the number of incorrect answers
yielded by the hybrid approach, i.e., the answers
where neither RC nor DP performed well.

Parameter Incorrect (%)

Sender 4 (7.55 %)
Subject 7 (13.21 %)
Attribute 7 (13.21 %)
Receiver 16 (30.19 %)
Transmission Principle 19 (35.85 %)

Overall 53

Table 6: A summary of inaccurate labeling by the
emsebling approach. The percentage is out of total
number of invalid labels.

The inaccurate results for these answers can be
partially attributed to the fact that our approach
has to produce an answer (label) each time,
which in some cases is not explicitly stated in
the text. Furthermore, some paragraphs have a
complex syntactic structure, comprising very long
sentences glued together by semicolons. This
poses a challenge to both DP and RC, which rely
on the sentence structure and model trained on
syntactically proper sentences, respectively, to
identify the relevant parameters. Dealing with
such semantic and syntactic ambiguities while
correctly identifying relevant entities remains an
open research question.

6 Conclusion

In this paper we present our work towards design-
ing a Relevant CI Parameters Extractor (RECIPE)
that leverages an open domain QA model on Pri-
vacy Policies to answer questions posed by CI.
The theory of CI relies on identifying five param-
eters to reason about privacy violation. This is
done by asking questions about who are the actors
(sender, recipient, subject), what type of informa-
tion being conveyed and under what conditions in
an information flow.

This paper evaluates an open-domain QA model
to find answers to contextual integrity questions in
privacy policy texts, a complex task which is tra-
ditionally delegated to legal and privacy experts.
We perform an error analysis of the model on this
out-of-domain task and show that this error can be
reduced by combining the open domain QA model
with a neural dependency parser.

Through this paper, we hope to motivate the
community to incorporate signals from depen-
dency parsing like NLP tasks more explicitly in
solving complex tasks like open-domain QA for
generalizing on out-of-domain tasks.

7 Acknowledgments

We thank Schrasing Tong for his help in the ini-
tial stage of this work. This work is supported
by the National Science Foundation under grant
CCF-1350574.

References
Waleed Ammar, Shomir Wilson, Norman Sadeh, and

Noah A Smith. 2012. Automatic Categorization of
Privacy Policies: A Pilot Study. Carnegie Mellon
University Technial Report, (CMU-ISR-12-114).

Adam Barth, Anupam Datta, John C Mitchell, and He-
len Nissenbaum. 2006. Privacy and Contextual In-
tegrity: Framework and Applications. In IEEE Sym-
posium on Security and Privacy, pages 184–198.

Jaspreet Bhatia and Travis D Breaux. 2015. Towards
an Information Type Lexicon for Privacy Policies.
In IEEE Eighth International Workshop on Require-
ments Engineering and Law (RELAW), pages 19–24.

Jaspreet Bhatia, Travis D Breaux, and Florian Schaub.
2016a. Mining Privacy Goals from Privacy Policies
Using Hybridized Task Recomposition. In ACM
Transactions on Software Engineering and Method-
ology (TOSEM), pages 22:1–22:24.

Jaspreet Bhatia, Morgan C Evans, Sudarshan Wadkar,
and Travis D Breaux. 2016b. Automated Extraction



76

of Regulated Information Types using Hyponymy
Relations. In IEEE International Requirements En-
gineering Conference Workshops (REW), pages 19–
25.

Danqi Chen, Adam Fisch, Jason Weston, and Antoine
Bordes. 2017. Reading Wikipedia to Answer Open-
Domain Questions. In Association for Computa-
tional Linguistics (ACL).

Omar Chowdhury, Andreas Gampe, Jianwei Niu, Jef-
fery von Ronne, Jared Bennatt, Anupam Datta,
Limin Jia, and William H Winsborough. 2013. Pri-
vacy Promises That Can Be Kept: A Policy Analy-
sis Method with Application to the HIPAA Privacy
Rule. In Proceedings of the 18th ACM Symposium
on Access Control Models and Technologies (SAC-
MAT), pages 3–14.

A Cohen. 2011. FuzzyWuzzy: Fuzzy string
matching in python. https://github.com/
seatgeek/fuzzywuzzy.

Marie-Catherine De Marneffe and Christopher D
Manning. Stanford typed dependencies manual.
https://nlp.stanford.edu/software/
dependencies_manual.pdf.

Morgan C Evans, Jaspreet Bhatia, Sudarshan Wad-
kar, and Travis D Breaux. 2017. An Evaluation of
Constituency-based Hyponymy Extraction from Pri-
vacy Policies. In IEEE 25th International Require-
ments Engineering Conference (RE), pages 312–
321.

Hamza Harkous, Kassem Fawaz, Rémi Lebret, Florian
Schaub, Kang G Shin, and Karl Aberer. 2018. Poli-
sis: Automated Analysis and Presentation of Pri-
vacy Policies Using Deep Learning. arXiv preprint
arXiv:1802.02561.

Karl Moritz Hermann, Tomas Kocisky, Edward
Grefenstette, Lasse Espeholt, Will Kay, Mustafa Su-
leyman, and Phil Blunsom. 2015. Teaching Ma-
chines to Read and Comprehend. In Advances
in Neural Information Processing Systems (NIPS),
pages 1693–1701.

Matthew Honnibal and Ines Montani. 2018. spaCy 2:
Natural language understanding with Bloom embed-
dings, convolutional neural networks and incremen-
tal parsing. https://spacy.io.

Mitra Bokaei Hosseini, Sudarshan Wadkar, Travis D
Breaux, and Jianwei Niu. 2016. Lexical Similar-
ity of Information Type Hypernyms, Meronyms and
Synonyms in Privacy Policies. In AAAI Fall Sympo-
sium Series.

Gordon Hull, Heather Richter Lipford, and Celine
Latulipe. 2011. Contextual gaps: privacy issues
on facebook. Ethics and Information Technology,
13:289–302.

Guillaume Lample, Miguel Ballesteros, Sandeep Sub-
ramanian, Kazuya Kawakami, and Chris Dyer. 2016.
Neural Architectures for Named Entity Recognition.
CoRR, abs/1603.01360.

Kenton Lee, Tom Kwiatkowski, Ankur P. Parikh, and
Dipanjan Das. 2016. Learning recurrent span repre-
sentations for extractive question answering. CoRR,
abs/1611.01436.

Xuezhe Ma and Eduard H. Hovy. 2016. End-to-end
sequence labeling via bi-directional lstm-cnns-crf.
CoRR, abs/1603.01354.

Kirsten Martin and Helen Nissenbaum. 2016. Measur-
ing Privacy: An Empirical Test Using Context To
Expose Confounding Variables. Columbia Science
and Technology Law Review, 18:176.

Helen Nissenbaum. 2010. Privacy in context: Technol-
ogy, policy, and the integrity of social life. Stanford
University Press.

Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. Glove: Global vectors for
word representation. In Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 1532–
1543.

Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
Percy Liang. 2016. Squad: 100,000+ questions
for machine comprehension of text. arXiv preprint
arXiv:1606.05250.

Joel R Reidenberg, Travis Breaux, Lorrie Faith Cranor,
Brian French, Amanda Grannis, James T Graves,
Fei Liu, Aleecia McDonald, Thomas B Norton, and
Rohan Ramanath. 2015. Disagreeable Privacy Poli-
cies: Mismatches between Meaning and Users Un-
derstanding. Berkeley Tech. LJ, 30:39.

Pum-Mo Ryu, Myung-Gil Jang, and Hyun-Ki Kim.
2014. Open domain question answering using
Wikipedia-based knowledge model. Information
Processing & Management, 50(5):683–692.

Norman Sadeh, Alessandro Acquisti, Travis D Breaux,
Lorrie Faith Cranor, Aleecia M McDonald, Joel R
Reidenberg, Noah A Smith, Fei Liu, N Cameron
Russell, Florian Schaub, et al. 2013. The Usable
Privacy Policy Project. Technical report, CMU-ISR-
13-119, Carnegie Mellon University.

Kanthashree Mysore Sathyendra, Florian Schaub,
Shomir Wilson, and Norman Sadeh. 2016. Auto-
matic Extraction of Opt-Out Choices from Privacy
Policies. In AAAI Fall Symposium on Privacy and
Language Technologies.

Kanthashree Mysore Sathyendra, Shomir Wilson, Flo-
rian Schaub, Sebastian Zimmeck, and Norman
Sadeh. 2017. Identifying the provision of choices
in privacy policy text. In Conference on Empiri-
cal Methods in Natural Language Processing, pages
2764–2769.

https://github.com/seatgeek/fuzzywuzzy
https://github.com/seatgeek/fuzzywuzzy
https://nlp.stanford.edu/software/dependencies_manual.pdf
https://nlp.stanford.edu/software/dependencies_manual.pdf
https://spacy.io
http://arxiv.org/abs/1603.01360
http://arxiv.org/abs/1611.01436
http://arxiv.org/abs/1611.01436
http://arxiv.org/abs/1603.01354
http://arxiv.org/abs/1603.01354
http://www.aclweb.org/anthology/D14-1162
http://www.aclweb.org/anthology/D14-1162
https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf
https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf


77

Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and
Hannaneh Hajishirzi. 2017. Bidirectional Attention
Flow for Machine Comprehension. In 5th Inter-
national Conference on Learning Representations
(ICLR).

Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo
Wang, Tim Klinger, Wei Zhang, Shiyu Chang, Ger-
ald Tesauro, Bowen Zhou, and Jing Jiang. 2017.
R3: Reinforced Reader-Ranker for Open-Domain
Question Answering Question Answering. CoRR,
abs/1709.00023.

Shomir Wilson, Florian Schaub, Aswarth Abhilash
Dara, Frederick Liu, Sushain Cherivirala, Pe-
dro Giovanni Leon, Mads Schaarup Andersen, Se-
bastian Zimmeck, Kanthashree Mysore Sathyendra,
N Cameron Russell, et al. 2016a. The Creation and
Analysis of a Website Privacy Policy Corpus. In
54th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), vol-
ume 1, pages 1330–1340.

Shomir Wilson, Florian Schaub, Rohan Ramanath,
Norman Sadeh, Fei Liu, Noah A. Smith, and Fred-
erick Liu. 2016b. Crowdsourcing Annotations for
Websites’ Privacy Policies: Can It Really Work? In
25th International Conference on World Wide Web,
(WWW), pages 133–143.

Michael Zimmer. 2008. Privacy on Planet Google: Us-
ing the Theory of “Contextual Integrity” to Clarify
the Privacy Threats of Google’s Quest for the Per-
fect Search Engine. Journal of Business Technology
Law, 3:109.

http://arxiv.org/abs/1709.00023
http://arxiv.org/abs/1709.00023
https://doi.org/10.1145/2872427.2883035
https://doi.org/10.1145/2872427.2883035

