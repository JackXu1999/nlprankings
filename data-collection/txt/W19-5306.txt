



















































Machine Translation with parfda, Moses, kenlm, nplm, and PRO


Proceedings of the Fourth Conference on Machine Translation (WMT), Volume 2: Shared Task Papers (Day 1) pages 122–128
Florence, Italy, August 1-2, 2019. c©2019 Association for Computational Linguistics

122

Machine Translation with parfda, Moses, kenlm, nplm, and PRO

Ergun Biçici
ergun.bicici@boun.edu.tr

Electrical and Electronics Engineering Department, Boğaziçi University
orcid.org/0000-0002-2293-2031

Abstract

We build parfda Moses statistical machine
translation (SMT) models for most language
pairs in the news translation task. We experi-
ment with a hybrid approach using neural lan-
guage models integrated into Moses. We ob-
tain the constrained data statistics on the ma-
chine translation task, the coverage of the test
sets, and the upper bounds on the translation
results. We also contribute a new testsuite for
the German-English language pair and a new
automated key phrase extraction technique for
the evaluation of the testsuite translations.

1 Introduction

Parallel feature weight decay algorithms
(parfda) (Biçici, 2018) is an instance se-
lection tool we use to select training and language
model instances to build Moses (Koehn et al.,
2007) phrase-based machine translation (MT)
systems to translate the test sets in the news
translation task at WMT19 (Bojar et al., 2019).
The importance of parfda increase with the
increasing size of the parallel and monolingual
data available for building SMT systems. In
the light of last year’s evidence that shows that
parfda phrase-based SMT can obtain the 2nd
best results on a testsuite in the English-Turkish
language pair (Biçici, 2018) when generating the
translations of key phrases that are important for
conveying the meaning, we obtain phrase-based
Moses results and its extension with a neural
LM in addition to the n-gram based LM that we
use. We experiment with neural probabilistic LM
(NPLM) (Vaswani et al., 2013). We record the
statistics of the data and the resources used.

Our contributions are:

• a test suite for machine translation that is out
of the domain of news task to take the chance
of taking a closer look at the current status of

Figure 1: parfda Moses SMT workflow.

SMT technology used by the task participants
when translating 38 sentences about interna-
tional relations concerning cultural artifacts,

• parfdaMoses phrase-based MT results and
data statistics for the following translation di-
rections:

– English-Czech (en-cs)
– English-Finnish (en-fi), Finnish-English

(fi-en),
– English-German (en-de), German-

English (de-en),
– English-Kazakh (en-kk), Kazakh-

English (kk-en),
– English-Lithuanian (en-lt), Lithuanian-

English (lt-en),
– English-Russian (en-ru), Russian-

English (ru-en),

• upperbounds on the translation performance
using lowercased coverage to identify which
models used data in addition to the parallel
corpus.

The sections that follow discuss the instance se-
lection model (Section 2), the machine translation
model (Section 3), the testsuite used for evaluating
MT in en-de and de-en, and the results.

orcid.org/0000-0002-2293-2031


123

S → T Training Data LM DataData #word S (M) #word T (M) #sent (K) tcov #word (M) tcov
en-cs C 587.2 659.8 44436 0.758 1439.6 0.835
en-cs parfda 111.4 98.4 2474 0.693 371.3 0.779
en-de C 832.6 879.0 39959 0.792 4252.0 0.864
en-de parfda 139.0 130.7 2467 0.736 450.8 0.795
de-en C 879.0 832.6 39959 0.865 12382.8 0.92
de-en parfda 132.6 141.3 2441 0.827 487.8 0.871
en-fi C 96.2 125.3 5657 0.528 1598.9 0.746
en-fi parfda 73.9 56.1 2168 0.512 419.1 0.676
fi-en C 130.1 100.4 6254 0.783 12382.8 0.926
fi-en parfda 51.1 66.4 2021 0.771 416.8 0.869
en-kk C 1.6 1.9 204 0.262 173.5 0.576
en-kk parfda 1.9 1.5 202 0.242 175.0 0.576
kk-en C 1.9 1.6 204 0.591 12382.8 0.907
kk-en parfda 1.5 1.9 202 0.584 337.7 0.835
en-lt C 38.2 45.0 2191 0.532 1523.4 0.539
en-lt parfda 45.0 38.2 2191 0.532 310.7 0.539
lt-en C 45.0 38.2 2191 0.794 12382.8 0.933
lt-en parfda 34.1 40.5 1877 0.754 383.5 0.89
en-ru C 212.0 181.9 9296 0.738 11459.4 0.888
en-ru parfda 92.3 80.0 2260 0.713 469.0 0.803
ru-en C 181.7 211.8 9287 0.857 12382.8 0.937
ru-en parfda 78.2 90.5 2212 0.839 437.0 0.894

Table 1: Statistics for the training and LM corpora in the constrained (C) setting compared with the parfda
selected data. #words is in millions (M) and #sents in thousands (K). tcov is target 2-gram coverage.

scov tcov
1 2 3 4 5 1 2 3 4 5

en-cs 0.9762 0.8399 0.5686 0.2809 0.1085 0.9792 0.7557 0.3985 0.1646 0.0618
en-de 0.9673 0.8683 0.6288 0.3301 0.1296 0.96 0.7916 0.5102 0.2438 0.0898
en-fi 0.9535 0.779 0.4829 0.2122 0.0745 0.9009 0.5283 0.2337 0.0849 0.0229
en-kk 0.8399 0.4643 0.1623 0.0363 0.0075 0.7404 0.262 0.0648 0.0104 0.0017
en-lt 0.9519 0.7214 0.3896 0.1374 0.0355 0.909 0.5324 0.2125 0.0663 0.0156
en-ru 0.9743 0.8251 0.5362 0.2434 0.0813 0.9606 0.7384 0.4102 0.1794 0.0673

Table 2: Constrained training data lowercased source feature coverage (scov) and target feature coverage (tcov) of
the test set for n-grams.

2 Instance Selection with parfda

parfda parallelize feature decay algorithms
(FDA) (Biçici and Yuret, 2015), a class of instance
selection algorithms that decay feature weights,
for fast deployment of accurate SMT systems.
Figure 1 depicts parfda Moses SMT workflow.

We use the test set source sentences to select
the training data and the target side of the selected
training data to select the LM data. We decay the
weights for both the source features of the test set
and the target features that we already select to in-
crease the diversity. We select about 2.2 million
instances for training data and about 12 million
sentences for each LM data not including the se-
lected training set, which is added later. Table 1
shows size differences with the constrained dataset
(C).1 We use 3-grams to select training data and 2-
grams for LM data and split the hyphenated words

1Available at https://github.com/bicici/
parfdaWMT2019

using the “-a” option of the tokenizer used in
Moses (Sennrich et al., 2017). tcov lists the tar-
get coverage in terms of the 2-grams of the test
set. The maximum sentence length is set to 126.
Table 2 lists the lowercased coverage of the test set
by the constrained training data of WMT19.

3 Machine Translation with Moses,
kenlm and nplm, and PRO

We train 6-gram LM using kenlm (Heafield et al.,
2013). For word alignment, we use mgiza (Gao
and Vogel, 2008) where GIZA++ (Och and Ney,
2003) parameters set max-fertility to 10, the num-
ber of iterations to 7,5,5,5,7 for IBM models
1,2,3,4, and the HMM model, and learn 50 word
classes in three iterations with the mkcls tool dur-
ing training. We use “-mbr” option when de-
coding the test set.3 The development set con-

3As practiced in the parallel corpus filter-
ing task http://www.statmt.org/wmt19/

https://github.com/bicici/parfdaWMT2019
https://github.com/bicici/parfdaWMT2019
http://www.statmt.org/wmt19/parallel-corpus-filtering.html


124

BLEU de-en fi-en kk-en lt-en en-cs en-de en-fi en-kk en-lt
kenlm 0.309 0.202 0.105 0.225 0.152 0.235 0.127 0.029
nplm 0.292 0.18 0.215 0.142 0.119 0.029 0.073
bilingual nplm 0.102 0.03
kenlm + nplm 0.307 0.226 0.156 0.238 0.03 0.078
kenlm with hyphen splitting 0.3074 0.2024 0.0999 0.2245 0.1522 0.2395 0.1294 0.03 0.0828

Table 3: parfda BLEU cased results with different LM on text that is not hyphen splitted compared with after
hyphen splitting.

BLEU de-en fi-en kk-en lt-en ru-en en-cs en-de en-fi en-kk en-lt en-ru
parfda 0.3074 0.2024 0.0999 0.2245 0.3179 0.1522 0.2395 0.1294 0.03 0.0828 0.1846
topC 0.428 0.33 0.305 0.365 0.401 0.299 0.449 0.274 0.111 0.191 0.363

- parfda
avg diff 0.1405

Table 4: parfda results compared with the top results in WMT19 and their difference.2

tains up to 5000 sentences randomly sampled from
previous years’ development sets (2013-2018) and
remaining come from the development set for
WMT19. We obtain robust optimization results
using monotonically increasing n-best list size in
the beginning of tuning with pairwise ranking op-
timization (PRO) (Hopkins and May, 2011; Biçici,
2018). This allows us to find parameters whose
tuning score reach 1% close to the best tuning pa-
rameter set score in only 4 iterations but we still
run tuning for 21 iterations. Truecasing updates
the casing of words according to the most com-
mon form. We truecase the text before building
the SMT model as well as after decoding and then
detruecase before preparing the translation, which
provided better results than simply detruecasing
after decoding (Biçici, 2018).

We trained nplm LM in 10 epochs. We also ex-
perimented with bilingual nplm, which uses nplm
in a bilingual setting to use both the source and
the target context and builds a LM on the training
set (Devlin et al., 2014). Both nplm and bilingual
nplm can be used with Moses as a feature within
its configuration file.4 On average, results in Ta-
ble 3 shows that using only nplm decrease the
scores and improvements are obtained when both
nplm and kenlm are used. However, the gain
from splitting hyphenated words is more and it is
a less computationally demanding option. kenlm
takes about 20 minutes whereas building a single
nplm model took us 11.5 to 14.25 days or 1000
times longer and it takes about 56 GB space on
the disk.

parallel-corpus-filtering.html
4http://www.statmt.org/moses/?n=

FactoredTraining.BuildingLanguageModel#
ntoc32

parfda results at WMT19 are in Table 4 us-
ing BLEU over tokenized text where we compare
with the top constrained submissions (topC). All
top models use NMT in 2019 and most use back-
translations, which means that their tcov is upper
bounded by LM tcov. topC is 14.05 BLEU points
on average better than parfda in 2019 and the
difference was 12.88 in 2018.

4 Translation Upper Bounds with tcov

We obtain upper bounds on the translation perfor-
mance based on the target coverage (tcov) of n-
grams of the test set found in the selected parfda
training data using lowercased text. For a given
sentence T ′, the number of OOV tokens are iden-
tified:

OOV r = round((1− tcov) ∗ |T ′|) (1)

where |T ′| is the number of tokens in the sen-
tence. We obtain each bound using 500 such in-
stances and repeat for 10 times. tcov BLEU bound
is optimistic since it does not consider reorder-
ings in the translation or differences in sentence
length. Each plot in Figure 2 locates tcov BLEU
bound obtained from each n-gram and from n-
gram tcovs combined up to and including n and
� locates the parfda result and F locates the
top constrained result. Based on the distance be-
tween the top BLEU result and the bound, we can
obtain a sorting of the difficulty of the translation
directions in Table 5.

5 German-English Testsuite

We prepared a MT test suite that is out of the
domain of news translation task to take a closer

4We use the results from matrix.statmt.org.

http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/wmt19/parallel-corpus-filtering.html
http://www.statmt.org/moses/?n=FactoredTraining.BuildingLanguageModel#ntoc32
http://www.statmt.org/moses/?n=FactoredTraining.BuildingLanguageModel#ntoc32
http://www.statmt.org/moses/?n=FactoredTraining.BuildingLanguageModel#ntoc32
matrix.statmt.org


125

Figure 2: parfda results (�) and OOV r tcov BLEU upper bounds for kk and lt.

BLEU distance translation direction
0.0041 en-de
0.0092 en-kk
0.0277 en-ru
0.0296 en-fi
0.0372 de-en
0.0407 kk-en
0.0594 lt-en
0.0722 en-lt
0.0849 ru-en
0.0943 fi-en
0.1365 en-cs

Table 5: Difficulty of translation directions based on
the distance of the top result to the upper bound.

look at the current status of SMT technology used
by the task participants to translate 38 sentences
about international relations concerning cultural
artifacts in German and English. The sentences
and their translations are available at https:
//github.com/bicici/SMTData sourced
from the press releases of the Prussian Cultural
Heritage Foundation.5 The scores of participants
are in Table 10 in terms of BLEU (Papineni et al.,
2002) and F1 (Biçici, 2011) scores. However, such
automatic evaluation metrics treat the features or
n-grams equivalently or group them based on their
length, without knowledge about their frequency
in use or significance in conveying the meaning.

Word order in a sentence does not contain the
majority of information (Landauer, 2002) for vo-
cabulary size |V | ≥ n where n is the average
sentence length. For n = 25 words with |V | =
105 with equivalent representation using n = 10
phrases with |V | = 107 or using n = 50 BPE
tokens with |V | = 104 or using n = 125 chars

5http://www.preussischer-kulturbesitz.
de

bits % info.

w
or

d order log2 25! 83.7 16.8%
choice log2 10

125 415.2 83.2%
total log2 25!× 10125 498.9 100.0%

ph
ra

se order log2 10! 21.8 8.6%
choice log2 10

70 232.5 91.4%
total log2 10!× 1070 254.3 100.0%

B
PE

order log2 50! 214.2 24.4%
choice log2 10

200 664.4 75.6%
total log2 50!× 10200 878.6 100.0%

ch
ar

order log2 125! 695.2 80.7%
choice log2 10

50 166.1 19.3%
total log2 125!× 1050 861.3 100.0%

Table 6: Information contribution from granular parts
of a sentence.

with |V | = 102 have differring contribution to
the information of the sentence in bits from to-
ken order or choice (Table 6). If we use keyword
subsequences for F1 based evaluation, we would
cover about 91% of the information in a sentence
whereas if we include punctuation characters, they
will contribute at most 19.3%.

Key phrase identification is important since
when scores are averaged, important phrases that
are missing only decrease the score by 1|p|N|p|
for BLEU calculation for a phrase of length |p|
over N|p| phrases with length |p|. We extend our
evaluation of the testsuite translations using key-
words (Biçici, 2018).

We automate key phrase identification within a
reference set of N sentences by selecting among
NX candidate n-grams that:

• are representative and few

https://github.com/bicici/SMTData
https://github.com/bicici/SMTData
http://www.preussischer-kulturbesitz.de
http://www.preussischer-kulturbesitz.de


126

min XT (αXp · Xl ·
1

−βXc
+111NX )

s.t. Xd(X · L) ≥ 0.5 LN min. coverage
0 ≤ X ≤ 1
α = 1, β = 2

Variables:
X ∈ RNX phrase selection vector
Xp ∈ RNX phrase probability vector
Xc ∈ RNX phrase count vector
L ∈ RNX phrase length vector
LN ∈ RN sentence length vector
Xd ∈ RN×NX phrase distribution matrix

Table 7: Optimization constraints.

system F1 # match # in reference
online-B 0.869 63 82
Facebook FAIR 0.8531 61 82
NEU 0.8286 58 82
MLLP-UPV 0.8286 58 82
online-Y 0.8286 58 82
MSRA 0.8201 57 82
RWTH Aachen 0.8201 57 82
UCAM 0.8201 57 82
online-A 0.8029 55 82
online-G 0.7941 54 82
parfda 0.7761 52 82
PROMT NMT 0.7761 52 82
TartuNLP-c 0.7761 52 82
uedin 0.7761 52 82
dfki-nmt 0.7481 49 82
JHU 0.6557 40 82
online-X 0.4381 23 82

Table 8: de-en testsuite F1 scores with key phrases.

• cover significant portion of the text

• are frequent (Xc for counts of phrases)

• are less likely to be found (Xp for the proba-
bility of phrases)

and formulate the task as a linear program in Ta-
ble 7. We use up to 6-grams and set minimum cov-
erage of each sentence to 0.5. We removed some
stop words from the phrases: ’of’, ’the’, ’and’, ’of
the’, ’a’, ’an’ and replaced those parts with ’.*?’
and obtained regular expressions. The key phrases
we obtain are listed in Table 9. The key phrases
are used to evaluate using the F1 score (Table 10).
We plan to extend this work towards more objec-
tive key phrase evaluation methods.

6 Conclusion

We use parfda for building task specific MT
systems that use less computation overall and re-
lease our engineered data for training MT systems.

We also contribute a new testsuite for the German-
English language pair and a new automated key
phrase extraction technique for evaluation.

Acknowledgments

The research reported here received financial sup-
port from the Scientific and Technological Re-
search Council of Turkey (TÜBİTAK).

References
Ergun Biçici. 2011. The Regression Model of Machine

Translation. Ph.D. thesis, Koç University. Supervi-
sor: Deniz Yuret.

Ergun Biçici. 2018. Robust parfda statistical machine
translation results. In Third Conf. on Statistical Ma-
chine Translation (WMT18), Brussels, Belgium.

Ergun Biçici and Deniz Yuret. 2015. Optimizing in-
stance selection for statistical machine translation
with feature decay algorithms. IEEE/ACM Transac-
tions On Audio, Speech, and Language Processing
(TASLP), 23:339–350.

Ondřej Bojar, Christian Federmann, Mark Fishel,
Yvette Graham, Barry Haddow, Matthias Huck,
Philipp Koehn, Christof Monz, Mathias Müller, and
Matt Post. 2019. Findings of the 2019 conference on
machine translation (wmt19). In Proc. of the Fourth
Conf. on Machine Translation, Florence, Italy. As-
sociation for Computational Linguistics.

Jacob Devlin, Rabih Zbib, Zhongqiang Huang, Thomas
Lamar, Richard Schwartz, and John Makhoul. 2014.
Fast and robust neural network joint models for sta-
tistical machine translation. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
1370–1380, Baltimore, Maryland. Association for
Computational Linguistics.

Qin Gao and Stephan Vogel. 2008. Software Engineer-
ing, Testing, and Quality Assurance for Natural Lan-
guage Processing, chapter Parallel Implementations
of Word Alignment Tool.

Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modified
Kneser-Ney language model estimation. In 51st An-
nual Meeting of the Assoc. for Computational Lin-
guistics, pages 690–696, Sofia, Bulgaria.

Mark Hopkins and Jonathan May. 2011. Tuning as
ranking. In Conf. on Empirical Methods in Natural
Language Processing, pages 1352–1362.

Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open

https://doi.org/10.1109/TASLP.2014.2381882
https://doi.org/10.1109/TASLP.2014.2381882
https://doi.org/10.1109/TASLP.2014.2381882
https://doi.org/10.3115/v1/P14-1129
https://doi.org/10.3115/v1/P14-1129
http://www.aclweb.org/anthology/D11-1125
http://www.aclweb.org/anthology/D11-1125


127

source toolkit for statistical machine translation. In
45th Annual Meeting of the Assoc. for Computa-
tional Linguistics Companion Volume Demo and
Poster Sessions, pages 177–180.

Thomas K. Landauer. 2002. On the computational ba-
sis of learning and cognition: Arguments from LSA.
41:43–84.

Franz Josef Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1):19–51.

Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In 40th Annual
Meeting of the Assoc. for Computational Linguistics,
pages 311–318, Philadelphia, PA, USA.

Rico Sennrich, Alexandra Birch, Anna Currey, Ulrich
Germann, Barry Haddow, Kenneth Heafield, An-
tonio Valerio Miceli Barone, and Philip Williams.
2017. The university of edinburgh’s neural mt sys-
tems for wmt17. In Proceedings of the Second Con-
ference on Machine Translation, Volume 2: Shared
Task Papers, pages 389–399, Copenhagen, Den-
mark. Association for Computational Linguistics.

Ashish Vaswani, Yinggong Zhao, Victoria Fossum,
and David Chiang. 2013. Decoding with large-
scale neural language models improves translation.
In Proceedings of the 2013 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1387–1392, Seattle, Washington, USA. Association
for Computational Linguistics.

http://www.aclweb.org/anthology/W17-4739
http://www.aclweb.org/anthology/W17-4739
https://www.aclweb.org/anthology/D13-1140
https://www.aclweb.org/anthology/D13-1140


128

A de-en Testsuite Sentences

They live in seven communities
been granted by .*? community
Southwestern Alaska has been inhabited
Hermann Parzinger
speaking groups .*? Indians immigrated
Ethnological Museum
aim .*? building up
Chugach Alaska Corporation
objects
Chugach
exhibition module in
northwest coast
ethnographic observations than by tales
goods from Chenega Island
to protect people from danger
were therefore removed unlawfully from
indications are that
graves were opened solely for
Ethnological
are two broken masks
cultural heritage
Indians immigrated
items concerned are grave goods
origin .*? history
contacts with Europe existed since
Prince William Sound
grave goods identified in
color on these ones indicates
live in seven communities
Chugach people exist today
journey is .*? impressive
consent had been granted by
virtual presentation .*? all
proposal to this effect from
President
museum at
nineteenth century for
diplomatic note in support
it was decided to return
Corporation asked .*? Ethnological Museum
indigenous peoples
Memorandum .*? Understanding with
has been inhabited for thousands
American northwest coast
now be returning them to

Table 9: Key phrases for the de-en testsuite.

B
L

E
U

lc
B

L
E

U
F
1

lc
F
1

m
od

el
1

2
3

4
1

2
3

4
1

2
3

4
1

2
3

4

de-en

on
lin

e-
B

0.
69

76
0.

68
28

0.
60

42
0.

58
89

0.
54

0.
52

5
0.

48
92

0.
47

45
0.

64
19

0.
62

79
0.

57
56

0.
56

25
0.

52
64

0.
51

4
0.

48
65

0.
47

46
Fa

ce
bo

ok
FA

IR
0.

71
69

0.
70

73
0.

61
43

0.
60

37
0.

53
91

0.
52

79
0.

47
64

0.
46

4
0.

63
11

0.
62

28
0.

55
91

0.
55

05
0.

50
39

0.
49

48
0.

45
96

0.
45

04
R

W
T

H
A

ac
he

n
0.

70
05

0.
68

14
0.

58
89

0.
57

3
0.

51
32

0.
49

94
0.

45
17

0.
43

85
0.

61
35

0.
59

96
0.

54
16

0.
52

95
0.

48
76

0.
47

62
0.

44
58

0.
43

49
N

E
U

0.
70

72
0.

69
13

0.
59

71
0.

58
05

0.
51

95
0.

50
32

0.
45

63
0.

43
96

0.
61

29
0.

59
92

0.
54

01
0.

52
74

0.
48

52
0.

47
27

0.
44

16
0.

42
92

U
C

A
M

0.
69

75
0.

67
95

0.
59

43
0.

57
48

0.
51

68
0.

49
58

0.
45

13
0.

42
83

0.
61

27
0.

59
69

0.
53

89
0.

52
19

0.
48

06
0.

46
23

0.
43

46
0.

41
59

M
SR

A
0.

68
94

0.
67

46
0.

57
69

0.
56

4
0.

49
54

0.
48

44
0.

42
96

0.
41

96
0.

60
34

0.
59

42
0.

52
78

0.
51

96
0.

47
08

0.
46

32
0.

42
63

0.
41

93
on

lin
e-

A
0.

68
84

0.
66

51
0.

58
22

0.
55

59
0.

50
11

0.
47

28
0.

43
38

0.
40

36
0.

61
33

0.
58

79
0.

53
48

0.
50

92
0.

47
38

0.
44

81
0.

42
65

0.
40

07
JH

U
0.

70
67

0.
67

05
0.

59
23

0.
55

39
0.

50
84

0.
47

0.
44

11
0.

40
25

0.
60

27
0.

56
28

0.
52

31
0.

48
48

0.
46

34
0.

42
61

0.
41

73
0.

38
16

on
lin

e-
Y

0.
65

83
0.

64
14

0.
54

13
0.

52
5

0.
45

97
0.

44
4

0.
39

52
0.

37
97

0.
58

38
0.

56
82

0.
50

53
0.

49
11

0.
44

69
0.

43
33

0.
40

17
0.

38
84

M
L

L
P-

U
PV

0.
68

72
0.

66
71

0.
56

66
0.

54
28

0.
47

94
0.

45
62

0.
41

06
0.

38
84

0.
58

88
0.

56
7

0.
50

67
0.

48
61

0.
44

7
0.

42
75

0.
40

12
0.

38
29

df
ki

-n
m

t
0.

68
64

0.
65

03
0.

57
23

0.
53

12
0.

49
02

0.
44

42
0.

42
33

0.
37

37
0.

59
15

0.
54

63
0.

51
33

0.
46

75
0.

45
45

0.
40

82
0.

40
85

0.
36

2
ue

di
n

0.
64

93
0.

63
04

0.
53

09
0.

51
16

0.
45

09
0.

43
03

0.
38

62
0.

36
46

0.
57

51
0.

55
85

0.
49

45
0.

47
75

0.
43

44
0.

41
73

0.
38

88
0.

37
18

on
lin

e-
G

0.
65

36
0.

62
81

0.
52

69
0.

50
08

0.
44

29
0.

41
61

0.
38

09
0.

35
45

0.
56

42
0.

53
5

0.
48

46
0.

45
6

0.
42

84
0.

40
05

0.
38

49
0.

35
71

PR
O

M
T

N
M

T
0.

65
65

0.
63

74
0.

52
89

0.
50

74
0.

43
74

0.
41

53
0.

36
42

0.
34

3
0.

55
29

0.
53

29
0.

47
04

0.
45

12
0.

40
94

0.
39

18
0.

36
17

0.
34

55
Ta

rt
uN

L
P-

c
0.

62
95

0.
61

37
0.

50
64

0.
49

11
0.

41
86

0.
40

39
0.

34
79

0.
33

39
0.

53
71

0.
52

28
0.

45
5

0.
44

2
0.

39
41

0.
38

2
0.

34
72

0.
33

64
pa

rf
da

0.
60

96
0.

59
69

0.
46

42
0.

45
21

0.
36

86
0.

35
91

0.
29

94
0.

29
31

0.
51

5
0.

50
21

0.
42

64
0.

41
59

0.
36

58
0.

35
79

0.
32

18
0.

31
53

on
lin

e-
X

0.
63

16
0.

56
7

0.
48

37
0.

40
52

0.
38

28
0.

29
97

0.
30

31
0.

22
22

0.
51

49
0.

43
62

0.
42

53
0.

34
64

0.
36

01
0.

28
49

0.
31

13
0.

24
13

Table 10: Testsuite BLEU and F1 results.


