



















































WSD-games: a Game-Theoretic Algorithm for Unsupervised Word Sense Disambiguation


Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 329–334,
Denver, Colorado, June 4-5, 2015. c©2015 Association for Computational Linguistics

WSD-games: a Game-Theoretic Algorithm for Unsupervised Word Sense
Disambiguation

Rocco Tripodi Marcello Pelillo
Ca’ Foscari University of Venice

Via Torino 155
30172 Venezia, Italy

{rocco.tripodi, pelillo}@unive.it

Abstract

In this paper we present an unsupervised ap-
proach to word sense disambiguation based on
evolutionary game theory. In our algorithm
each word to be disambiguated is represented
as a node on a graph and each sense as a class.
The algorithm performs a consistent class as-
signment of senses according to the similarity
information of each word with the others, so
that similar words are constrained to similar
classes. The dynamics of the system are for-
mulated in terms of a non-cooperative multi-
player game, where the players are the data
points to decide their class memberships and
equilibria correspond to consistent labeling of
the data.

1 Introduction

Word sense disambiguation (WSD) is the task to
identify the intended sense of a word in a compu-
tational manner based on the context in which it
appears (Navigli, 2009). It has been studied since
the beginning of NLP (Weaver, 1955) and also to-
day it is a central topic of this discipline. Many
algorithms have been proposed during the years,
based on supervised (Zhong and Ng, 2010; Tratz
et al., 2007), semi-supervised (Pham et al., 2005)
and unsupervised (Mihalcea, 2005; McCarthy et al.,
2007) learning models. Nowadays, even if super-
vised methods perform better in general domains,
unsupervised and semi-supervised models are gain-
ing attention from the research community with per-
formances close to the state of the art (Ponzetto and
Navigli, 2010). In particular Knowledge-based and

graph based algorithms are emerging as interesting
ways to face the problem (Agirre et al., 2009; Sinha
and Mihalcea, 2007). The peculiarities of those al-
gorithms are that they do not require any corpus evi-
dence and use only the structural properties of a lex-
ical database to perform the disambiguation task.

An unsupervised algorithm which has been im-
plemented in different ways by the community (Mi-
halcea et al., 2004; Haveliwala, 2002; Agirre et al.,
2014; De Cao et al., 2010) is the PageRank (Page
et al., 1999). This algorithm is similar in spirit to
ours but we instead of using the graph to compute
the most important nodes (senses) in it, we use the
network to model the geometry of the data and the
interactions among the data points. In our system
the nodes of the graph are interpreted as players, in
the game theoretic sense (see Section 2), which play
a game in order to maximize their utility. The con-
cept of utility has been used in different ways in the
game theory (GT) literature and in general it refers
to the satisfaction that a player derives from the out-
come of a game (Szabó and Fath, 2007). From our
point of view increasing the utility of a word means
increasing the textual coherence, in a distributional
semantics perspective (Firth, 1957). In fact, in our
framework a word always tries to chose a sense close
to the senses which the other words in the text are
likely to choose.

The starting point of our research is based on the
assumption that the meaning of a sentence emerges
from the interaction of the components which are in-
volved in it. In our study we tried to model this inter-
action and to develop a system in which it is possible
to map lexical items onto concepts. For this reason

329



we decided to use a powerful tool, derived from Evo-
lutionary Game Theory (EGT): the non-cooperative
games (see Section 2). EGT and GT have been used
in different ways to study the language use (Pietari-
nen, 2007; Skyrms, 2010) and evolution (Nowak et
al., 2001) but as far as we know, our is the first at-
tempt to use it in a specific NLP task. This choice
is motivated by the fact that GT models are able
to perform a consistent labeling of the data (Hum-
mel and Zucker, 1983; Pelillo, 1997), taking into ac-
count the contextual information. These features are
of great importance for an unsupervised algorithm
which tries to perform a WSD task, because them
can be obtained without any supervision and help
the system to adapt to different contextual domains.

2 Game Theory

In this section we briefly introduce some concepts
of GT and EGT, for detailed analysis of these top-
ics we refer to (Weibull, 1997; Leyton-Brown and
Shoham, 2008; Sandholm, 2010).

GT provides predictive power in interactive deci-
sion situations. It has been introduced by Von Neu-
mann and Morgenstern (1944) and in its normal
form representation (which is the one we will use
in our algorithm) it consists in: a finite set of play-
ers I = (1, .., n), a set of pure strategies for each
player Si = (s1, ..., sn) and an utility function ui :
S1×...×Sn → R which associates strategies to pay-
offs. The utility function depends on the combina-
tion of two strategies played together, not just on the
strategy of a single player. An important assumption
in GT is that the players are rational and try to maxi-
mize the value of ui; furthermore in non-cooperative
games the players choose their strategies indepen-
dently. A strategy s∗i is said to be dominant if and
only if ui(s∗i , s−i) > ui(si, s−i), ∀s−i ∈ S−i. As
an example we can consider the famous Prisoner’s
Dilemma (in Table 1) where the strategy confess is
a dominant strategy for both players and this strategy
combination is the Nash equilibrium of the game.
Nash equilibria are those strategy profiles which are
best response to the strategy of the co-player and no
player has the incentive to unilaterally deviate from
his strategy, because there is no way to do better.

1 \ 2 confess don’t confess
confess -5,-5 0,-6
don’t confess -6,0 -1,-1

Table 1: The Prisoner’s Dilemma.

2.1 Evolutionary Game Theory
EGT has been introduce by Smith and Price (1973)
overcoming some limitations of traditional GT such
as the hyper-rationality imposed on the players, in
fact in real life situations the players choose a strat-
egy according to heuristics or social norms (Szabó
and Fath, 2007). Another important aspect of EGT
is the introduction of an inductive learning process,
in which the agents play the game repeatedly with
their neighborhood, updating their believes on the
state of the game and choosing their strategy accord-
ingly. The strategy space of each player is defined
as a probability distribution over its pure strategies.
It is represented as a vector xi = (xi1, . . . , xim)
where m is the number of pure strategies and each
component xih denotes the probability that player i
choose its hth pure strategy. The strategy space lies
on the m-dimensional standard simplex ∆m where:∑m

h=1 xih = 1 and xih ≥ 0 for all h. The ex-
pected payoff of a pure strategy eh in a single game
is u(eh, x) = eh · Ax where A is the m×m payoff
matrix. The average payoff of all the player strate-
gies is u(x, x) =

∑
h∈S xhu(e

h, x). In order to find
the Nash equilibria of the game it is used the repli-
cator dynamic equation (Taylor and Jonker, 1978)

ẋ = [u(eh, x)− u(x, x)] · xh ∀h ∈ S (1)
which allows better than average strategies (best
replies) to grow. As in (Erdem and Pelillo, 2012)
we used the discrete time version of the replicator
dynamic equation:

xh(t+ 1) = xh(t)
u(eh, x)
u(x, x)

∀h ∈ S (2)

where at each time step t the players update their
strategies until the system converges and the Nash
equilibria are found.

3 WSD Games

In this section we will show how we created the data
necessary for our framework and how the games are
played.

330



3.1 Graph Construction

We model the geometry of the data as a graph,
with nodes corresponding to the words to be disam-
biguated, denoted by I = {ij}Nj=1, where ij corre-
sponds to the j-th word and N is the number of tar-
get words in a specific text. From I we construct a
N ×N similarity matrixW where each element wij
is the similarity value assigned for the words i and
j. W can be exploited as an useful tool for graph-
based algorithms since it is treatable as weighted ad-
jacency matrix of a weighted graph.

A crucial factor for the graph construction is the
choice of the similarity measure, sim(·, ·) → R
to weights the edges of the graph. For our ex-
periments we used similarity measures which com-
pute the strength of co-occurrence between any two
words ii and ij

wij = sim(ii, ij) ∀i, j ∈ I : i 6= j (3)

Specifically we used the modified Dice coheffi-
cient (mDice) (Dice, 1945), the pointwise mu-
tual information (PMI) (Church and Hanks, 1990)
and the log likelihood ratio (D2) (Dunning, 1993)
These measure have been calculate using the Google
Web1T corpus (Brants and Franz, 2006), a large col-
lection of n-grams (with a window of max 5 words)
occurring in one terabyte of Web documents as col-
lected by Google.

At this point we have the similarity graph W ,
we recall that we will use this matrix in order to
allow the words to play the games only with sim-
ilar words. The higher the similarity among two
words, the higher the reciprocal influence and the
possibility that they belong to a similar class. For
this reason, at first we smooth the data in W and
then choose only the most significant js for each
j ∈ W . The first point is solved using a gaussian
kernel on W , wij = exp (−w

2
ij

2σ2
), where σ is the

kernel width parameter; the second point is solved
applying a k − nearest neighbor algorithm to W ,
which allows us to remove the edges which are less
significant for each i ∈ I . In our experiments we
used σ = 0.5 and k = 25. Moreover, this opera-
tion reduces the computational cost of the algorithm,
which will focus only on relevant similarities.

3.2 The Strategy Space

In order to create the strategy space of the game,
we first use WordNet (Mallery, 1995) to collect the
sense inventories Mi = 1, . . . ,m of each word,
wherem is the number of synsets associated to word
i. Then we set all the sense inventories and obtain
the list of all possible senses, C = 1, . . . , c.

We can now define the strategy space S of the
game in matrix form as:

si1 si2 · · · sic
...

... · · · ...
sn1 sn2 · · · snc

where each row corresponds to the strategy space of
a player and each column corresponds to a sense.
Formally it is a c-dimensional space ∆c and each
mixed strategy profile lives in the mixed strategy
space of the game, given by the Cartesian product
Θ = ×i∈I∆i.

At this point the strategy space can be initialized
with the following formula in order to follow the
constraints described in Section 2.1

sij =

{
|Mi|−1, if sense j is in Mi.
0, otherwise.

(4)

for all i ∈ I and j ∈ S.
3.3 The Payoff Matrix

We encoded the payoff matrix of a WSD game as
a sense similarity matrix among all the senses in
the strategy spaces of the game. In this way the
higher the similarity among two sense candidates,
the higher the incentive for a player to chose that
sense, and play the strategy associated to it.

The c × c sense similarity matrix Z is defined as
follows:

zij = ssim(si, sj) ∀i, j ∈ C : i 6= j (5)

In our experiments we used the GlossV ector mea-
sure (Patwardhan and Pedersen, 2006) in order to
compute the semantic relatedness ssim(·, ·). This
measure calculates the cosine similarity among two
second order context vectors. Each vector is ob-
tained from a WordNet super-glosse, which is the
gloss of a synset plus the glosses of the synsets re-
lated to it.

331



run sim P R F1 math med. gen.
1 PMI 57.4 48.9 52.8 47.4 56.3 53.5
2 mDice 58.8 50.0 54.1 48.5 58.4 53.5
3 D2 53.5 45.4 49.1 43.4 54.4 46.7

Table 2: The results of the WSD-games team at SemEval-
2015 task 13. Precision, Recall and F1 in all domains and
F1 in specific domains.

From Z we can obtain the partial semantic simi-
larity matrix for each pair of player, Zij = m × n,
where m and n are the senses of i and j in Z.

In a previous work (Tripodi et al., 2015) we did
not use this information, instead we used labeled
data points to propagate the class membership in-
formation over the graph. In this new version the
use of the semantic information made the algorithm
completely unsupervised.

3.4 System Dynamics
Now that we have the topology of the data W , the
strategy space of the game S and the payoff matrix
Z we can compute the Nash equilibria of the game
according to equation (2). So in each iteration of
the system each player gain its payoffs according to
equation (6) which allows each payoff to be propor-
tional to the similarity (wij) and to the affinity that
player j has to the hs strategy of player i.

ui(eh, x) =
∑
j∈Ni

((wijZij)xj)h (6)

When the system converges each player chooses the
strategy with the highest value.

4 Results and Analysis

The dataset proposed by the organizers of SemEval-
2015 Task 13 (Moro and Navigli, 2015) consists of
five texts from three different domains: math and
computer, biomedical and general. The english cor-
pus is composed of 1426 instances to disambiguate
and 1262 of them have been used in the evalua-
tion. For our experiments we used only the instances
whose lemma has an entry in WordNet 3.0 without
looking up multi-words or trying to link the enti-
ties to other sources such as Wikipedia or BabelNet
(Navigli and Ponzetto, 2012)

We submitted three runs for our system with 1227
single words disambiguated for each run. The only

difference for each run is the similarity measure that
we used to construct the graph W . For run-1 we
used the PMI measure, for run-2 the mDice coef-
ficient and for run-3 the D2. As we expected from
previous experiments on similar datasets, the best
results have been achieved using the mDice coef-
ficient (see Table 2). We obtained low recall values
for all our runs and this because we did not search
multi-words and did not use other sources of infor-
mation for the named entities, in fact the number of
named entities is limited in WordNet.

Looking more closely at the results, we noticed
that we obtained a very low precision (48.5%) in the
math and computer domain and this because even if
the lexical entry of certain instances (eg. in text2:
tab, dialog, script) have an entry in WordNet, their
intended meaning is not present; it can only be ac-
cessible to those systems which use BabelNet to col-
lect the sense inventories. This unexpected problem
affects the performances of the system because even
if those instances will not be considered in the eval-
uation, they have been used by other instances in our
system to play the disambiguation games, compro-
mising the dynamics of the system.

5 Conclusions and Future Works

We have presented an unsupervised system for WSD
based on EGT which takes into account contextual
similarity and semantic similarity information in or-
der to perform a consistent labeling of the data. Its
performances are below those of supervised systems
and are comparable with unsupervised and semi-
supervised systems even if on the Semeval-2015
task 13 dataset we did not use other source of infor-
mation except WordNet, did not search multi-words
and did not aspect that the intended meaning of some
instances is not present in WordNet.

As future work we are planning to do a detailed
evaluation of the system in order to find the most
appropriate measures to use and to incorporate in
the framework other sources of information like Ba-
belNet. Furthermore we are also thinking to test
the system as supervised and semi-supervised, im-
plementing a new initialization of the strategy space
and to test new graph construction techniques.

332



References

Eneko Agirre, Oier Lopez De Lacalle, Aitor Soroa, and
Informatika Fakultatea. 2009. Knowledge-based
WSD and Specific Domains: Performing Better than
Generic Supervised WSD. In IJCAI, pages 1501–
1506.

Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa.
2014. Random Walks for Knowledge-Based Word
Sense Disambiguation. Computational Linguistics,
40(1):57–84.

Thorsten Brants and Alex Franz. 2006. {Web 1T 5-gram
Version 1}.

Kenneth Ward Church and Patrick Hanks. 1990. Word
Association Norms, Mutual Information, and Lexicog-
raphy. Computational linguistics, 16(1):22–29.

Diego De Cao, Roberto Basili, Matteo Luciani,
Francesco Mesiano, and Riccardo Rossi. 2010. Ro-
bust and Efficient PageRank for Word Sense Disam-
biguation. In Proceedings of the 2010 Workshop on
Graph-based Methods for Natural Language Process-
ing, pages 24–32.

Lee R. Dice. 1945. Measures of the amount of ecologic
association between species. Ecology, 26(3):297–302.

Ted Dunning. 1993. Accurate Methods for the Statistics
of Surprise and Coincidence. Computational linguis-
tics, 19(1):61–74.

Aykut Erdem and Marcello Pelillo. 2012. Graph Trans-
duction as a Noncooperative Game. Neural Computa-
tion, 24(3):700-723.

John R. Firth. 1957. A Synopsis of Linguistic The-
ory 1930-1955. Studies in linguistic analysis. Oxford:
Blackwell.

Taher H. Haveliwala. 2002. Topic-Sensitive PageRank.
In Proceedings of the 11th international conference on
World Wide Web, pages 517–526.

Robert A. Hummel and Steven W. Zucker. 1983. On the
Foundations of Relaxation Labeling Processes. Pat-
tern Analysis and Machine Intelligence, IEEE Trans-
actions on, (3):267–287.

Kevin Leyton-Brown and Yoav Shoham. 2008. Essen-
tials of Game Theory: A Concise Multidisciplinary
Introduction. Synthesis Lectures on Artificial Intelli-
gence and Machine Learning, 2(1):1–88.

John C. Mallery. 1995. WordNet: a Lexical Database for
English. Communications of the ACM, 38(11):39-41.

Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2007. Unsupervised Acquisition of Pre-
dominant Word Senses. Computational Linguistics,
33(4):553–590.

Rada Mihalcea, Paul Tarau, and Elizabeth Figa. 2004.
PageRank on Semantic Networks, with Application to
Word Sense Disambiguation. In Proceedings of the

20th international conference on Computational Lin-
guistics, page 1126.

Rada Mihalcea. 2005. Unsupervised Large-Vocabulary
Word Sense Disambiguation with Graph-Based Algo-
rithms for Sequence Data Labeling. In Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Processing,
pages 411–418.

Andrea Moro and Roberto Navigli. 2015. SemEval-2015
Task 13: Multilingual All-Words Sense Disambigua-
tion and Entity Linking. In Proceedings of SemEval-
2015.

Roberto Navigli and Simone Paolo Ponzetto. 2012. Ba-
belNet: The Automatic Construction, Evaluation and
Application of a Wide-Coverage Multilingual Seman-
tic Network. Artificial Intelligence, 193:217–250.

Roberto Navigli. 2009. Word Sense Disambiguation: A
Survey. ACM Computing Surveys (CSUR), 41(2):10.

Martin A. Nowak, Natalia L. Komarova, and Partha
Niyogi. 2001. Evolution of Universal Grammar. Sci-
ence, 291(5501):114–118.

Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry
Winograd. 1999. The PageRank Citation Ranking:
Bringing Order to the Web.

Siddharth Patwardhan and Ted Pedersen. 2006. Us-
ing WordNet-Based Context Vectors to Estimate the
Semantic Relatedness of Concepts. In Proceedings
of the EACL 2006 Workshop Making Sense of Sense-
Bringing Computational Linguistics and Psycholin-
guistics Together, volume 1501, pages 1–8.

Marcello Pelillo. 1997. The Dynamics of Nonlinear Re-
laxation Labeling Processes. Journal of Mathematical
Imaging and Vision, 7(4):309–323.

Thanh Phong Pham, Hwee Tou Ng, and Wee Sun
Lee. 2005. Word Sense Disambiguation with Semi-
Supervised Learning. In Proceedings of the National
Conference on Artificial Intelligence, volume 20, page
1093.

Ahti-Veikko Pietarinen. 2007. Game theory and linguis-
tic meaning.

Simone Paolo Ponzetto and Roberto Navigli. 2010.
Knowledge-Rich Word Sense Disambiguation Rival-
ing Supervised Systems. In Proceedings of the 48th
annual meeting of the association for computational
linguistics, pages 1522–1531.

William H. Sandholm. 2010. Population games and evo-
lutionary dynamics.

Ravi Som Sinha and Rada Mihalcea. 2007. Unsuper-
vised Graph-based Word Sense Disambiguation Using
Measures of Word Semantic Similarity. In ICSC, vol-
ume 7, pages 363–369.

Brian Skyrms. 2010. Signals: Evolution, learning, and
information.

333



John M. Smith and George R. Price. 1973. The Logic of
Animal Conflict. Nature, 246:15.

György Szabó and Gabor Fath. 2007. Evolutionary
Games on Graphs. Physics Reports, 446(4):97-216.

Peter D. Taylor and Leo B. Jonker. 1978. Evolutionary
Stable Strategies and Game Dynamics. Mathematical
biosciences, 40(1):145–156.

Stephen Tratz, Antonio Sanfilippo, Michelle Gregory,
Alan Chappell, Christian Posse, and Paul Whitney.
2007. PNNL: A Supervised Maximum Entropy Ap-
proach to Word Sense Disambiguation. In Proceed-
ings of the 4th International Workshop on Semantic
Evaluations, pages 264–267.

Rocco Tripodi, Marcello Pelillo, and Rodolfo Delmonte.
2015. An Evolutionary Game Theoretic Approach
to Word Sense Disambiguation. In Proceedings of
NLPCS 2014.

John Von Neumann and Oskar Morgenstern. 1944. The-
ory of Games and Economic Behavior (60th Anniver-
sary Commemorative Edition).

Warren Weaver. 1955. Translation. Machine translation
of languages, 14:15-23.

Jörgen W. Weibull. 1997. Evolutionary game theory.
Zhi Zhong and Hwee Tou Ng. 2010. It Makes Sense: A

Wide-Coverage Word Sense Disambiguation System
for Free Text. In Proceedings of the ACL 2010 System
Demonstrations, pages 78–83.

334


