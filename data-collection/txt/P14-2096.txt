



















































Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation


Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 586–591,
Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics

Cross-language and Cross-encyclopedia Article Linking Using
Mixed-language Topic Model and Hypernym Translation

Yu-Chun Wang
Department of CSIE

National Taiwan University
Taipei, Taiwan

d97023@csie.ntu.edu.tw

Chun-Kai Wu
Department of CSIE

National Tsinghua University
Hsinchu, Taiwan

s102065512@m102.
nthu.edu.tw

Richard Tzong-Han Tsai∗
Department of CSIE

National Central University
Chungli, Taiwan

thtsai@csie.ncu.edu.tw

Abstract

Creating cross-language article links
among different online encyclopedias is
now an important task in the unification
of multilingual knowledge bases. In this
paper, we propose a cross-language article
linking method using a mixed-language
topic model and hypernym translation
features based on an SVM model to link
English Wikipedia and Chinese Baidu
Baike, the most widely used Wiki-like
encyclopedia in China. To evaluate our
approach, we compile a data set from the
top 500 Baidu Baike articles and their
corresponding English Wiki articles. The
evaluation results show that our approach
achieves 80.95% in MRR and 87.46%
in recall. Our method does not heavily
depend on linguistic characteristics and
can be easily extended to generate cross-
language article links among different
online encyclopedias in other languages.

1 Introduction

Online encyclopedias are among the most fre-
quently used Internet services today. One of
the largest and best known online encyclopedias
is Wikipedia. Wikipedia has many language ver-
sions, and articles in one language contain hyper-
links to corresponding pages in other languages.
However, the coverage of different language ver-
sions of Wikipedia is very inconsistent. Table 1
shows the statistics of inter-language link pages
in the English and Chinese editions in February
2014. The total number of Chinese articles is
about one-quarter of English ones, and only 2.3%
of English articles have inter-language links to
their Chinese versions.

∗corresponding author

Articles Inter-language Links Ratio
zh 755,628 zh2en 486,086 64.3%
en 4,470,246 en2zh 106,729 2.3%

Table 1: Inter-Language Links in Wikipedia

However, there are alternatives to Wikipedia for
some languages. In China, for example Baidu
Baike and Hudong are the largest encyclopedia
sites, containing more than 6.2 and 7 million Chi-
nese articles respectively. Similarly, in Korea,
Naver Knowledge Encyclopedia has a large pres-
ence.

Since alternative encyclopedias like Baidu
Baike are larger (by article count) and growing
faster than the Chinese Wikipedia, it is worth-
while to investigate creating cross-language links
among different online encyclopedias. Several
works have focused on creating cross-language
links between Wikipedia language versions (Oh
et al., 2008; Sorg and Cimiano, 2008) or find-
ing a cross-language link for each entity mention
in a Wikipedia article, namely Cross-Language
Link Discovery (CLLD) (Tang et al., 2013; Mc-
Namee et al., 2011). These works were able to
exploit the link structure and metadata common
to all Wikipedia language versions. However,
when linking between different online encyclope-
dia platforms this is more difficult as many of these
structural features are different or not shared. To
date, little research has been done into linking be-
tween encyclopedias on different platforms.

Title translation is an effective and widely used
method of creating cross-language links between
encyclopedia articles. (Wang et al., 2012; Adafre
and de Rijke, 2005) However, title translation
alone is not always sufficient. In some cases, for
example, the titles of corresponding articles in dif-
ferent languages do not even match. Other meth-
ods must be used along with title translation to cre-
ate a more robust linking tool.

586



In this paper, we propose a method compris-
ing title and hypernym translation and mixed-
language topic model methods to select and link
related articles between the English Wikipedia and
Baidu Baike online encyclopedias. We also com-
pile a suitable dataset from the above two ency-
clopedias to evaluate the linking accuracy of our
method.

2 Method

Cross-language article linking between different
encyclopedias can be formulated as follows: For
each encyclopedia K, a collection of human-
written articles, can be defined as K = {ai}ni=1,
where ai is an article in K and n is the size of
K. Article linking can then be defined as fol-
lows: Given two encyclopedia K1 and K2, cross-
language article linking is the task of finding the
corresponding equivalent article aj from encyclo-
pedia K2 for each article ai from encyclopedia
K1. Equivalent articles are articles that describe
the same topic in different languages.

Our approach to cross-language article linking
comprises two stages: candidate selection, which
produces a list of candidate articles, and candidate
ranking, which ranks that list.

2.1 Candidate Selection
Since knowledge bases (KB) may contain millions
of articles, comparison between all possible pairs
in two knowledge bases is time-consuming and
sometimes impractical. To avoid brute-force com-
parison, we first select plausible candidate articles
on which to focus our efforts. To extract possible
candidates, two similarity calculation methods are
carried out: title matching and title similarity.

2.1.1 Title Matching
In our title matching method, we formulate can-
didate selection as an English-Chinese cross-
language information retrieval (CLIR) problem
(Schönhofen et al., 2008), in which every English
article’s title is treated as a query and all the arti-
cles in the Chinese encyclopedia are treated as the
documents. We employ the two main CLIR meth-
ods: query translation and document translation.

In query translation, we translate the title of ev-
ery English article into Chinese and then use these
translated titles as queries to retrieve articles from
the Chinese encyclopedia. In document transla-
tion, we translate the contents of the entire Chinese
encyclopedia into English and then search them

using the original English titles. The top 100 re-
sults for the query-translation and the top 100 re-
sults for document-translation steps are unionized.
The resulting list contains our title-matching can-
didates.

For the query- and document-translation steps,
we use the Lucene search engine with similar-
ity scores calculated by the Okapi BM25 ranking
function (Beaulieu et al., 1997). We separate all
words in the translated and original English article
titles with the “OR” operator before submission to
the search engine. For all E-C and C-E translation
tasks, we use Google Translate.

2.1.2 Title Similarity
In the title similarity method, every Chinese arti-
cle title is represented as a vector, and each dis-
tinct character in all these titles is a dimension of
all vectors. The title of each English article is
translated into Chinese and represented as a vec-
tor. Then, cosine similarity between this vector
and the vector of each Chinese title is measured as
title similarity.

2.2 Candidate Ranking

The second stage of our approach is to score
each viable candidate using a supervised learning
method, and then sort all candidates in order of
score from high to low as final output.

Each article xi in KB K1 can be
represented by a feature vector xi =
(f1(xi), f2(xi), . . . , fn(xi)). Also, we have
yj = (f1(yj), f2(yj), . . . , fn(yj)) for a candidate
article yj in KB K2. Then, individual feature
functions Fk(xi, yj) are based on the feature
properties of both article ai and aj . The top pre-
dicted corresponding article yj in the knowledge
base K2 for an input article xi in K1 should
receive a higher score than any other entity in
K2, am ∈ K2,m 6= j. We use the support
vector machine (SVM) approach to determine the
probability of each pair (xi,yj) being equivalent.
Our SVM model’s features are described below.

Title Matching and Title Similarity Feature
(Baseline)
We use the results of title matching and title sim-
ilarity from the candidate selection stage as two
features for the candidate ranking stage. The sim-
ilarity values generated by title matching and title
similarity are used directly as real value features
in the SVM model.

587



Mixed-language Topic Model Feature (MTM)
For a linked English-Chinese article pair, the dis-
tribution of words used in each usually shows
some convergence. The two semantically corre-
sponding articles often have many related terms,
which results in clusters of specific words. If two
articles do not describe the same topic, the distri-
bution of terms is often scattered. (Misra et al.,
2008) Thus, the distribution of terms is good mea-
surement of article similarity.

Because the number of all possible words is too
large, we adopt a topic model to gather the words
into some latent topics. For this feature, we use
the Latent Dirichlet Allocation (LDA) (Blei et al.,
2003). LDA can be seen as a typical probabilistic
approach to latent topic computation. Each topic
is represented by a distribution of words, and each
word has a probability score used to measure its
contribution to the topic. To train the LDA model,
the pair English and Chinese articles are concate-
nated into a single document. English and Chinese
terms are all regarded as terms of the same lan-
guage and the LDA topic model, namely mixed-
language topic model, generates both English and
Chinese terms for each latent topic. Then, for each
English article and Chinese candidate pair in test-
ing, the LDA model provides the distribution of
the latent topics. Next, we can use entropy to mea-
sure the distribution of topics. The entropy of the
estimated topic distribution of a related article is
expected to be lower than that of an unrelated ar-
ticle. We can calculate the entropy of the distribu-
tion as a value for SVM. The entropy is defined as
follows:

H = −
T∑

j=1

~θdj log ~θdj

where T is the number of latent topics, θdj is the
topic distribution of a given topic j.

Hypernym Translation Feature (HT)
The first sentence of an encyclopedia article usu-
ally contains the title of the article. It may also
contain a hypernym that defines the category of
the article. For example, the first sentence of the
“iPad” article in the English Wikipedia begins,
“iPad is a line of tablet computers designed and
marketed by Apple Inc. . .” In this sentence, the
term “tablet computers” is the hypernym of iPad.
These extracted hypernyms can be treated as arti-
cle categories. Therefore, articles containing the
same hypernym are likely to belong to the same

category.
In this study, we only carry out title hypernym

extraction on the first sentences of English articles
due to the looser syntactic structure of Chinese. To
generate dependency parse trees for the sentences,
we adopt the Stanford Dependency Parser. Then,
we manually designed seven patterns to extract hy-
pernyms from the parse tree structures. To demon-
strate this idea, let us take the English article “The
Hunger Games” for example. The first sentence of
this article is “The Hunger Games is a 2008 young
adult novel by American writer Suzanne Collins.”
Since article titles may be named entities or com-
pound nouns, the dependency parser may mislabel
them and thus output an incorrect parse tree. To
avoid this problem, we first replace all instances of
an article’s title in the first sentence with pronouns.
For example, the previous sentence is rewritten as
“It is a 2008 young adult novel by American writer
Suzanne Collins.” Then, the dependency parser
generates the following parse tree:

novel

It is a 2008 young adult collins
nsubj cop det num amod nn prep_by

suzanne writer American
nn nnamod

Next, we apply our predefined syntactic patterns
to extract the hypernym. (Hearst, 1992) If any pat-
tern matches the structure of the dependency parse
tree, the hypernym can be extracted. In the above
example, the following pattern is matched:

NN

It is NN
nsubj cop nn

[target]

In this pattern, the rightmost leaf is the hyper-
nym target. Thus, we can extract the hypernym
“novel” from the previous example. The term
“novel” is the extracted hypernym of the English
article “The Hunger Games”.

After extracting the hypernym of the English ar-
ticle, the hypernym is translated into Chinese. The
value of this feature in the SVM model is calcu-
lated as follows:

Fhypernym(h) = log count(translated(h))

where h is the hypernym, translated(h) is the
Chinese translation of the term h.

English Title Occurrence Feature (ETO)
In a Baidu Baike article, the first sentence may
contain a parenthetical translation of the main ti-
tle. For example, the first sentence of the Chinese

588



article on San Francisco is “旧金山（San Fran-
cisco），又译‘圣弗朗西斯科’、‘三藩市’。”.
We regard the appearance of the English title in
the first sentence of a Baidu Baike article as a bi-
nary feature: If the English title appears in the first
sentence, the value of this feature is 1; otherwise,
the value is 0.

3 Evalutaion

3.1 Evaluation Dataset

In order to evaluate the performance of cross-
language article linking between English Wikiep-
dia and Chinese Baidu Baike, we compile
an English-Chinese evaluation dataset from
Wikipedia and Baidu Baike online encyclopedias.
First, our spider crawls the entire contents of En-
glish Wikipedia and Chinese Baidu Baike. Since
the two encyclopedias’ article formats differ, we
copy the information in each article (title, content,
category, etc.) into a standardized XML structure.
In order to generate the gold standard evalua-
tion sets of correct English and Chinese article
pairs, we automatically collect English-Chinese
inter-language links from Wikipedia. For pairs
that have both English and Chinese articles, the
Chinese article title is regarded as the translation
of the English one. Next, we check if there is a
Chinese article in Baidu Baike with exactly the
same title as the one in Chinese Wikipedia. If
so, the corresponding English Wikipedia article
and the Baidu Baike article are paired in the gold
standard.

To evaluate the performance of our method on
linking different types of encyclopedia articles, we
compile a set containing the most popular articles.
We select the top 500 English-Chinese article pairs
with the highest page view counts in Baidu Baike.
This set represents the articles people in China are
most interested in.

Because our approach uses an SVM model, the
data set should be split into training and test sets.
For statistical generality, each data set is randomly
split 4:1 (training:test) 30 times. The final evalua-
tion results are calculated as the mean of the aver-
age of these 30 evaluation sets.

3.2 Evaluation Metrics

To measure the quality of cross-language entity
linking, we use the following three metrics. For
each English article queries, ten output Baidu
Baike candidates are generated in a ranked list. To

define the metrics, we use following notations: N
is the number of English query; ri,j is j-th correct
Chinese article for i-th English query; ci,k is k-th
candiate the system output for i-th English query.

Top-k Accuracy (ACC)
ACC measures the correctness of the first candi-
date in the candidate list. ACC = 1 means that all
top candidates are correctly linked (i.e. they match
one of the references), and ACC = 0 means that
none of the top candidates is correct.

ACC =
1
N

N∑
i=1

{
1 if ∃ri,j : ri,j = ci,k
0 otherwise

}

Mean Reciprocal Rank (MRR)
Traditional MRR measures any correct answer
produced by the system from among the candi-
dates. 1/MRR approximates the average rank of
the correct transliteration. An MRR closer to 1 im-
plies that the correct answer usually appears close
to the top of the n-best lists.

RRi =

{
minj 1j if ∃ri,j , ci,k : ri,j = ci,k
0 otherwise

}
MRR = 1N

∑N
i=1RRi

Recall
Recall is the fraction of the retrieved articles that
are relevant to the given query. Recall is used to
measure the performance of the candidate selec-
tion method. If the candidate selection method can
actually select the correct Chinese candidate, the
recall will be high.

Recall =
|relevant articles| ∩ |retrieved articles|

|relevant articles|
3.3 Evaluation Results
The overall results of our method achieves 80.95%
in MRR and 87.46% in recall. Figure 1 shows the
top-k ACC from the top 1 to 5. These results show
that our method is very effective in linking articles
in English Wikipedia to those in Baidu Baike.

In order to show the benefits of each feature
used in the SVM model, we conduct a experiment
to test the performance of different feature combi-
nations. Because title similarity of the articles is a
widely used method, we choose English and Chi-
nese title similarity as the baseline. Then, another
feature is added to each configuration until all the
features have been added. Table 2 shows the final
results of different feature combinations.

589



0.76	  

0.839	  

0.858	  
0.869	   0.87	  

0.7	  

0.72	  

0.74	  

0.76	  

0.78	  

0.8	  

0.82	  

0.84	  

0.86	  

0.88	  

1	   2	   3	   4	   5	  

TopK	  

Figure 1: Top-k Accuracy

Level Configuration MRR
0 Baseline (BL) 0.6559

1
BL + MTM∗1 0.6967†

BL + HT∗2 0.6975†

BL + ETO∗3 0.6981†

2
BL + MTM + HT 0.7703†

BL + MTM + ETO 0.7558†

BL + HT + ETO 0.7682†

3 BL + MTM + HT + ETO 0.8095†

∗1MTM: mix-language topic model
∗2HT: hypernym translation
∗3ETO: English title occurrence
† This config. outperforms the best config. in last level with

statistically significant difference.

Table 2: MRRs of Feature Combinations

In the results, we can observe that mix-language
topic model, hypernym, and English title oc-
curence features all noticeably improve the perfor-
mance. Combining two of these three feature has
more improvement and the combination of all the
features achieves the best.

4 Discussion

Although our method can effectively generate
cross-language links with high accuracy, some
correct candidates are not ranked number one. Af-
ter examining the results, we can divide errors into
several categories:

The first kind of error is due to large literal dif-
ferences between the English and Chinese titles.
For example, for the English article “Nero”, our
approach ranks the Chinese candidate “尼禄王”
(“King Nero”) as number one, instead of the cor-
rect answer “尼禄·克劳狄乌斯·德鲁苏斯·日耳
曼尼库斯” (the number two candidate). The title
of the correct Chinese article is the full name of
the Roman Emperor Nero (Nero Claudius Drusus

Germanicus). The false positive “尼禄王” is a his-
torical novel about the life of the Emperor Nero.
Because of the large difference in title lengths, the
value of the title similarity feature between the En-
glish article “Nero” and the corresponding Chi-
nese article is low. Such length differences may
cause the SVM model to rank the correct answer
lower when the difference of other features are not
so significant because the contents of the Chinese
candidates are similar.

The second error type is caused by articles that
have duplicates in Baidu Baike. For example, for
the English article “Jensen Ackles”, our approach
generates a link to the Chinese article “Jensen”
in Baidu Baike. However, there is another Baidu
article “詹森·阿克斯” (“Jensen Ackles”). These
two articles both describe the actor Jensen Ackles.
In this case, our approach still generates a correct
link, although it is not the one in the gold standard.

The third error type is translation errors. For ex-
ample, the English article “Raccoon” is linked to
the Baidu article “狸” (raccoon dog), though the
correct one is “浣熊” (raccoon). The reason is that
Google Translate provides the translation “狸” in-
stead of “浣熊”.

5 Conclusion

Cross-language article linking is the task of creat-
ing links between online encyclopedia articles in
different languages that describe the same content.
We propose a method based on article hypernym
and topic model to link English Wikipedia articles
to corresponding Chinese Baidu Baike articles.
Our method comprises two stages: candidate se-
lection and candidate ranking. We formulate can-
didate selection as a cross-language information
retrieval task based on the title similarity between
English and Chinese articles. In candidate rank-
ing, we employ several features of the articles in
our SVM model. To evaluate our method, we com-
pile a dataset from English Wikipedia and Baidu
Baike, containing the 500 most popular Baidu ar-
ticles. Evaluation results of our method show an
MRR of up to 80.95% and a recall of 87.46%. This
shows that our method is effective in generating
cross-language links between English Wikipedia
and Baidu Baike with high accuracy. Our method
does not heavily depend on linguistic characteris-
tics and can be easily extended to generate cross-
language article links among different encyclope-
dias in other languages.

590



References
Sisay Fissaha Adafre and Maarten de Rijke. 2005.

Discovering missing links in wikipedia. In Proceed-
ings of the 3rd international workshop on Link dis-
covery (LinkKDD ’05).

M. Beaulieu, M. Gatford, X. Huang, S. Robertson,
S. Walker, and P. Williams. 1997. Okapi at TREC-
5. In Proceedings of the fifth Text REtrieval Confer-
ence (TREC-5), pages 143–166.

David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning Research, 3(4-5):993–1022.

Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th conference on Computational linguistics,
volume 2.

Paul McNamee, James Mayfield, Dawn Lawrie, Dou-
glas W Oard, and David S Doermann. 2011. Cross-
language entity linking. In Proceedings of Interna-
tional Joint Con-ference on Natural Language Pro-
cessing (IJCNLP), pages 255–263.

Hemant Misra, Olivier Cappe, and François Yvon.
2008. Using lda to detect semantically incoherent
documents. In Proceedings of the Twelfth Confer-
ence on Computational Natural Language Learning
(CoNLL ’08).

Jong-Hoon Oh, Daisuke Kawahara, Kiyotaka Uchi-
moto, Jun’ichi Kazama, and Kentaro Torisawa.
2008. Enriching multilingual language re-
sources by discovering missing cross-language
links in wikipedia. In Proceedings of the 2008
IEEE/WIC/ACM International Conference on Web
Intelligence and Intelligent Agent Technology, vol-
ume 1, pages 322–328.

Pèter Schönhofen, Andràs Benczùr, Istvàn Bı̀rò, and
Kàroly Csalogàny. 2008. Cross-language retrieval
with wikipedia. Advances in Multilingual and
Multimodal Information Retrieval, Lecture Notes in
Computer Science, 5152:72–79.

Philipp Sorg and Philipp Cimiano. 2008. Enrich-
ing the crosslingual link structure of wikipedia-a
classification-based approach. In Proceedings of the
AAAI 2008 Workshop on Wikipedia and Artifical In-
telligence, pages 49–54.

Ling-Xiang Tang, In-Su Kang, Fuminori Kimura, Yi-
Hsun Lee, Andrew Trotman, Shlomo Geva, and Yue
Xu. 2013. Overview of the ntcir-10 cross-lingual
link discovery task. In Proceedings of the Tenth NT-
CIR Workshop Meeting.

Zhichun Wang, Juanzi Li, Zhigang Wang, and Jie Tang.
2012. Cross-lingual knowledge linking across wiki
knowledge bases. In Proceedings of the 21st in-
ternational conference on World Wide Web (WWW
’12).

591


