



















































Proceedings of the...


D S Sharma, R Sangal and A K Singh. Proc. of the 13th Intl. Conference on Natural Language Processing, pages 10–19,
Varanasi, India. December 2016. c©2016 NLP Association of India (NLPAI)

Can SMT and RBMT Improve each other’s Performance?- An
Experiment with English-Hindi Translation

Debajyoty Banik, Sukanta Sen, Asif Ekbal, Pushpak Bhattacharyya
Department of Computer Science and Engineering

Indian Institute of Technology Patna
{debajyoty.pcs13,sukanta.pcs15,asif,pb}@iitp.ac.in

Abstract

Rule-based machine translation
(RBMT) and Statistical machine
translation (SMT) are two well-known
approaches for translation which have
their own benefits. System archi-
tecture of SMT often complements
RBMT, and the vice-versa. In this
paper, we propose an effective method
of serial coupling where we attempt to
build a hybrid model that exploits the
benefits of both the architectures. The
first part of coupling is used to obtain
good lexical selection and robustness,
second part is used to improve syntax
and the final one is designed to com-
bine other modules along with the best
phrase reordering. Our experiments
on a English-Hindi product domain
dataset show the effectiveness of the
proposed approach with improvement
in BLEU score.

1 Introduction
Machine translation is a well-established
paradigm in Artificial Intelligence and Natural
Language Processing (NLP) which is getting
more and more attention to improve the qual-
ity (Callison-Burch and Koehn, 2005; Koehn
and Monz, 2006). Statistical machine trans-
lation (SMT) and rule-based machine trans-
lation (RBMT) are two well-known methods
for translating sentences from one to the other
language. But, each of these paradigms has its
own strengths and weaknesses. While SMT is
good for translation disambiguation, RBMT
is robust for morphology handling. There is
no systematic study involving less-resourced
languages, where the coupling of SMT and

RBMT has been shown to achieve better per-
formance. In our current research we attempt
to provide a systematic and principled way to
combine both SMT and RBMT for translat-
ing product related catalogs from English to
Hindi. We consider English-Hindi scenario as
an ideal platform as Hindi is a morphologically
very rich language compared to English. The
key contributions of our research are summa-
rized as follows:
(i). Proposal of an effective hybrid system
that exploits the advantages of both SMT and
RBMT.
(ii). Developing a system for translating prod-
uct catalogues from English to Hindi, which is
itself a difficult and challenging task due to the
nature of the domain. The data is often mixed,
comprising of very short sentences (even the
phrases) and the long sentences. To the best
of our knowledge, for such a domain, there is
no work involving Indian languages.Below we
describe SMT and RBMT very briefly.

1.1 Statistical Machine Translation
(SMT)

Statistical machine translation (SMT) systems
are considered to be good at capturing knowl-
edge of the domain from a large amount of
parallel data. This has robustness in resolv-
ing ambiguities and other related issues. SMT
provides good translation output based on
statistics and maximum likelihood expectation
(Koehn et al., 2003a):

ebest = argmaxeP (e|f)
= argmaxe[P (f |e)PLM (e)]

where f and e are the source and target lan-
guages, respectively. PLM (e) and P (f |e) are
the language and translation model, respec-
tively. The best output translation is denoted10



by ebest. Language model corresponds to the
n-gram probability. The translation probabil-
ity P (f |e) is modeled as,

P (f−I1 |e−I1 ) =
I∏

i=1

ϕ(f̄i|ēi)d(starti−endi−1−1)

ϕ is phrase translation probability and d(.)
is distortion probability.

starti−endi–1−1, which is the argument of
d(.) is a function of i, whereas starti and
endi−1 are the starting positions of the trans-
lation of ith phrase and end position of the
(i − 1)th phrase of e in f. In the above equa-
tion, it is well defined that most probable
phrases present in training corpora will be cho-
sen as the translated output. This could be
useful in handling ambiguity at the transla-
tion level. The work reported in (Dakwale
and Monz, 2016) focuses on improving the
performance of a SMT system. Along with
the translation model authors allow the re-
estimation of reordering models to improve ac-
curacy of translated sentences. The authors
in their work reported in (Carpuat and Wu,
2007) show how word sense disambiguation
helps to improve the performance of a SMT
system. Literature shows that there are few
systems available for English-Indian language
machine translation (Ramanathan et al., 2008;
Rama and Gali, 2009; Pal et al., 2010; Ra-
manathan et al., 2009).

1.2 Rule-based Machine Translation
(RBMT)

Rule-based system generates target sentence
with the help of linguistic knowledge. Hence,
there is a high chance that translated sentence
is grammatically well-formed.There are sev-
eral steps required to build linguistic rules for
translation. Robustness of a rule-based sys-
tem greatly depends on the quality of rules
devised. A set of sound rules ensures to build
a good accurate system. Generally, the steps
can be divided into three sub parts:

1. Analysis
2. Transfer
3. Generation

Analysis step consists of pre-processing, mor-
phological analysis, chunking, and pruning.
Transfer step consists of lexical transfer,
transliteration, and WSD. Finally, generation

step consists of genderization, vibhakti com-
putation, TAM computation, agreement com-
puting, word generator and sentence gener-
ator. The agreement computing can be ac-
complished with three sub steps: intra-chunk,
inter-chunk and default agreement computing.
In (Dave et al., 2001) authors have proposed
an inter-lingua based English–Hindi machine
translation system. In (Poornima et al., 2011),
authors have described how to simplify En-
glish to Hindi translation using a rule-based
approach. AnglaHindi is one of the very pop-
ular English-Hindi rule-based translation tools
proposed in (Sinha and Jain, 2003). Multilin-
gual machine aided translation for English to
Indian languages has been developed in (Sinha
et al., 1995). Apertium is an open source
rule-based machine translation tool proposed
in (Forcada et al., 2011). Rule-based approach
for machine translation has been proposed
with respect to Indian language (Dwivedi and
Sukhadeve, 2010).

1.3 Hybrid Machine Translation

A hybrid model of machine translation can be
developed using the strengths of both SMT
and RBMT. In this paper, we develop a hy-
brid model to exploit the benefits of disam-
biguation, linguistic rules, and structural is-
sues. Knowledge of coupling is very useful
to build hybrid model of machine translation.
There are different types of coupling, viz. se-
rial coupling and Parallel coupling. In serial
coupling, SMT and RBMT are processed one
after another in sequence. In parallel cou-
pling, models are processed in parallel to build
a hybrid model. In Indian languages, few hy-
brid models have been proposed as in(Dwivedi
and Sukhadeve, 2010; Aswani and Gaizauskas,
2005).

The rest of the paper is structured as fol-
lows. We present a brief review of the existing
works in Section 2. Motivations and various
characteristic features have been discussed in
Section 3. We describe our proposed method
in Section 4. Experiential setup and results
are discussed in Section 5. Finally, we con-
clude in Section 6.11



2 Related work
In rule-based MT, various linguistic rules are
defined and combined in (Arnold, 1994). Sta-
tistical machine translation models have re-
sulted from the word-based models (Brown
et al., 1990). This has become so popular
because of its robustness in translation only
with the parallel corpora. As both of this ap-
proaches have their own advantages and dis-
advantages, there is a trend nowadays to build
a hybrid model by combining both SMT and
RBMT (Costa-Jussa and Fonollosa, 2015).
Various architectures of hybrid model have
been compared in (Thurmair, 2009). Among
the various existing architectures, serial cou-
pling and parallel coupling are the most popu-
lar (Ahsan et al., 2010).Rule-based approach
along with post-processed SMT outputs are
described in (Simard et al., 2007). A review for
hybrid MT is available in (Xuan et al., 2012).
In (Eisele et al., 2008), authors proposed an
architecture to build a hybrid machine trans-
lation engine by following a parallel coupling
method. They merged phrase tables of gen-
eral training data of SMT and the output of
RBMT. However, they did not consider the
source and target language ordering charac-
teristics. In this paper, we combine both SMT
and RBMT in order to exploit advantages of
both the translation strategies.

3 Necessity for Combining SMT
and RBMT

In this work we propose a hybrid architecture
for translating English documents into Hindi.
Both of these languages are very popular.
English is an international language, whereas
Hindi is one of the very popular languages.
Hindi is the official language in India and
in terms number of native speakers it ranks
fourth in the world.Linguistic characteristics
of English and Hindi are not similar and their
differences are listed below:

• Hindi is a relatively morphologically
richer language compared to English.

• Word orders are not same for English and
Hindi. Subject-Object-Verb (SOV) is the
standard way to represent Hindi whereas
SVO ordering is followed for English.

• Hindi uses postposition whereas English
uses preposition.

• Hindi uses pre-modifiers, whereas English
uses post-modifiers.

SMT and RBMT can not solve the problems as
mentioned above independently.So, main fo-
cus of our current work is to develop a hy-
brid system combining both SMT and RBMT
which can efficiently solve the problems.In ad-
dition to combining these two methods we also
introduce reordering to improve the transla-
tion quality. Our main motivation was to
make use of the strength of SMT (better in
handling translation ambiguities) and RBMT
(better for dealing with rich morphology)

3.1 Morphology
As already mentioned Hindi is a morpholog-
ically richer language compared to English.
Morphology plays an important role in the
translation quality of English-Hindi. Let us
consider the examples: case: ए (e – plural
direct) or ओं (on – plural oblique) is used as
plural-marker for ”boy”. But in the case of
”girl” याँ (on) is used for plural direct, and ओं
(on) is used for plural oblique.

Singular direct:
E: The boy is going.
H: लड़का जा रहा ह।ै
HT: Ladka ja raha hai.
E: The girl is going.
H: लड़क जा रह ह।ै
HT: Ladki ja rahi hai.

Plural direct:
E: The boys are going.
H: लड़के जा रहे ह।
HT: Ladke ja rahe hain.
E: The girls are going.
H: लड़ कयाँ जा रह ह।
HT: Ladkiya ja rahi hae.

Singular oblique:
E: I have seen a boy.
H: म ने एक लड़के को देखा।
HT: Main ne ek ladke ko dekha.
E: I have seen a girl.
H: म ने एक लड़क को देखा।
HT: Main ne ek ladki ko dekha.

12



plural oblique:
E: I have seen five boys.
H: म ने पाचँ लड़क को देखा।
HT: Main ne paanch ladkon ko dekha.
E: I have seen five girls.
H: म ने पाचँ लड़ कय को देखा।
HT: Main ne paanch ladkiyon ko dekha.

Tense: Tenses are directed by the verbs.
For example, एगा (aega) and एगी (aegi) denote
future connotation in singular form for mascu-
line gender and feminine gender, respectively.
आएगा (ayega), आएगी (ayegee). एगंे (aenge)
and एगंी (aengi) denote future tense in plural
form for masculine and feminine geneder,
respectively. Here we show the few usages:
Singular form in future tense:-

E: The boy will come.
H: लड़का आएगा ।
HT: ladka ayenga
E: The girl will come.
H: लड़क आएगी ।
HT: ladki ayegi

Plural form in future tense:-
E: Boys will come.
H: लड़के आएगंे ।
HT: ladke ayenge.
E: Girls will come.
H: लड़ कयाँ आएगंी ।
HT: ladkiyan ayengi.

The above examples describe how morphol-
ogy influences the structure and meaning of
the language. A root word can appear in dif-
ferent forms in different sentences depending
upon tense, number or gender. Such kinds of
diversities can not be handled properly by a
SMT system because of lack of data or enough
grammatical evidences. This can, however, be
handled efficiently in a RBMT system due to
the richness of linguistic rules that it embeds.
It is very important to have all the morpho-
logical forms and case structures along with
their equivalent representations in the target
language. Under this scenario, hybridization
of SMT and RBMT is a more preferred ap-
proach.

3.2 Data Sparsity
While translating from English to Hindi we
encounter with the problems of data sparsity

due to the variations in morphology and case
marking in source and target language pairs.

From the examples shown in the previous
subsection, it is seen that same word may ap-
pear in different positions of a sentence, often
followed or preceded by different words, due to
varying morphological properties such as case,
gender and number information. For exam-
ple, the English word ‘girl‘ can be translated to
लड़क (ladki), लड़ कयाँ (ladkiyan), लड़ कय (lad-
kiyon) etc. in Hindi based on case and num-
ber information. Even though both लड़ कयाँ
(ladkiyan) and लड़ कय (ladkiyon) are in plu-
ral forms, they convey differnt meanings based
on the context. The word लड़ कय (ladkiyon)
is placed with case markers, but लड़ कयाँ (lad-
kiyan) is used without it. The word ‘Child‘
can be ब ा (bachcha) and ब े ने (bachche ne)
in singular form in direct and oblique cases,
respectively. Here, ने is followed by ब (bach-
chon), but if ब यो ने (bachchon) ne) does not
occur in corpora then it can not be translated.
Such problems can be resolved using proper

linguistic knowledge, which is the strength of
a rule-based system.In statistical approach, sys-
tem is modeled using a probabilistic method
that retrieves the target phrase based on maxi-
mum likelihood estimates. Hence, this may not
be possible to resolve the issues using a SMT
system. In contrast, RBMT has the power to
deal with such situation that incorporates proper
grammatical knowledge.

3.3 Ambiguity

Ambiguity is a very common problem in
machine translation. Ambiguities can appear
in many different forms. For example, the
following sentence has ambiguities at the
various levels:

E: I went with my friend Washington to
the bank to withdraw some money, but was
disappointed to find it closed.
Bank may be verb or noun-Part of speech

ambiguity.
Washington may be a person name or place-

Named entity ambiguity.
Bank may be placed for the borders of

a water body or financial transaction- Sense
ambiguity.
The word `it` has to be disambiguated to13



understand its proper reference-Discourse/co-
reference ambiguity.
It is not understood who was disappointed

for the closure of bank (Pro-drop ambiguity).

3.3.1 Semantic Role Ambiguity

Let us consider the following example sen-
tence:

H: मझुे आपको मठाई िखलानी पड़ेगी
HT: Mujhe aapko mithae khilani padegee.

In this sentence, it is not properly dis-
closed who will feed the sweets (to/by me or
to/by you). Thus, English sentence for the
above Hindi sentence may take any of the
following forms:

E1: I have to feed you sweets.
E2: You have to feed me sweets.

3.3.2 Lexical Ambiguity

We discuss the problem of lexical ambiguity
with respect to the following example sentence.
E: I will go to the bank for walking today.

Here, bank may be a financial institu-
tion or the shore of a river or sea. It is
difficult to interpret exact meaning of bank.
Context plays an important role in interpreting
the current sense. Here, bank is used in the
context of walk. Hence, there is a greater
chance that it denotes the `bank of river`'
instead of `financial institution`. Use of
proverbs complicates translation further.
E: An empty vessel sounds much.
H: थोथा चना बाजे घना. / अधजल गगर

छलकत जाय.
HT: Thotha chana baaje ghana./ adhajal

gagaree chhalkat jai.
Its actual meaning should be िजसको कम ान
होता है वो दखावा करने के लए अ धक बोलता ह.ै
(jisko kam gyan hota hai wo dikhava karne
ke liye adhik bolta hai.)

All of the above mentioned issues can
not be efficiently handled by statistical or
rule-based approach independently. Some of
the issues are better handled by a RBMT
approach whereas some are better handled by
a SMT system. In this paper we develop a
hybrid model by combining the benefits of
both rules and statistics.

3.4 Ordering
We further study the effect of ordering in our
proposed model. Ordering can be considered as
a basic structure of any language. Different lan-
guages have different structure patterns at sen-
tence which can be achieve after merging PoS.
For example, English uses subject-verb-object
(SVO) whereas Hindi uses subject-object-verb
(SOV). These structural differences of language
pair can be the vital cause of affecting the ac-
curacy. So, we shall incorporate the concept of
ordering along with SMT and RBMT to build
the hybrid model.

4 Proposed MT Model: A
Multi-Engine Translation System

We propose a novel architecture that improves
translation quality by combining the benefits
of both SMT and RBMT. We also devise a
mechanism to further improve the performance
by integrating the concept of reordering at
the source side. This architecture is trying
to combine the best parts from multiple
hypothesis to achieve maximum advantages of
different MT engines and remove the pitfall of
the translated texts so that the quality of the
translated text could be improved. Translation
models are combined in such a way that
the overall performance is improved over
the individual models. In literature it was
also shown that an effective combination of
different complimentary models could be more
useful (Rayner and Carter, 1997; Eisele et al.,
2008).
Combining multiple models of machine

translations is not an easy task because of
the following facts: RBMT is linguistically
richer than SMT; RBMT can produce different
word orders in the target sentence compared
to SMT; and there may have different word
orders for the SMT and RBMT outputs. After
using linguistic rules at the source side of the
test set, we combine the outputs obtained to
the training set, and generate new hypothesis
to build a better phrase table. Finally, we use
argmax computation of SMT decoder to find
the best possible sequence. A combined
model can not produce expected output if the
individual component models are not strong
enough. Word ordering plays an important
role to improve the quality of translation, es-14



Figure 1: Architecture for multi-engine MT driven by a SMT decoder

pecially for the pair of languages where source
language is relatively less-rich compared to the
target. Our source language, which is English,
follows a Subject-Verb-Object (SVO) fashion
whereas Hindi follows a Subject-Object-Verb
(SOV) ordering scheme. At first we extract
syntactic information of the source language.
The syntactic order of source sentence is
converted to the syntactic order of target
language. The source language sentences
are pre-processed following the set of trans-
formation rules as detailed in (Rao et al., 2000).

SSmV VmOOmCm → C ′mS′mS′O′mO′V ′mV ′
where,
S: Subject
V : Verb
O: Object
X ′: Hindi corresponding constituent, where X
is S, V, or O Xm: modifier of X
Cm: Clause modifier

Pre-ordering alters the English SVO order to
Hindi SOV order, and post-modifiers generate
the pre-modifiers. Our prepossessing module
performs this by parsing English sentence and
applying the reordering rules on the parse tree
to generate the representations in the target
side. After pre-ordering of source sentences,
we combine the RBMT and SMT based mod-
els.After pre-ordering of training and tuning
corpora we also do the same for the test set.
Alignment was done using the hypothesis of

RBMT.Beam search algorithm of SMT decoder
is used to obtain the best target sentence. De-
tailed architecture of the proposed technique is
shown in Figure 1. In this figure, lower por-
tion represents different modules and resources
used in the RBMT model, whereas the upper
portion represents the SMT model. Because of
this effective combination we obtain a model
that produces target sentences of better quali-
ties compared to either RBMT or SMT with
respect to morphology and disambiguation (at
the level of lexical and structural).

Sets Number of sentences
Training Set 111,586
Tune Set 602
Test Set 5,640

Table 1: Datasets statistics

5 Data Set, Experiential setup,
Result and analysis

5.1 Data Set
In this paper we develop a hybridized transla-
tion model for translating product catalogs from
English to Hindi.The training corpus consists of
111,586 English-Hindi parallel sentences. Tune
and test sets comprise of 602 and 5,640 sen-
tences, respectively. Brief statistics of training,
tune and test sets are shown in Table 4. The
domain is, itself, very challenging due to the
mixing of various types of sentences. There15



Approach BLEU Score
Baseline (Phrase-based SMT) 45.66
RBMT 5.34
SMT & RBMT 46.66
Our Approach 50.71
Improvement from Baseline 11.06%
Improvement from SMT & RBMT 8.67%

Table 2: Results of different models

are sentences of varying lengths consisting of
minimum of 3 tokens to the maximum of 80
tokens. Average length of the sentences is
approximately 10. In one of our experiments
we distributed the sentences into short and long
sets, containing less than 5 and more than equal
to 5 sentences, respectively. Training, tuning
and evaluation were then carried out, which
reveals that performance deteriorates due to the
reduction in size. Hence, we mix all kinds of
sentences for training, and then tune and test.
5.2 Experiential Setup
We use the pre-order tool developed at CFILT
lab. (Dwivedi and Sukhadeve, 2010) We use
Moses 1 setup for SMT related experiments.
The model is tuned using a tuning set. We
use ANUSAARAKA (Ramanathan et al., 2008)
rule-based system for translation. Phrase tables
are generated by training SMT model on the
parallel corpora of English-Hindi. The RBMT
system is evaluated on the test data. The
outputs produced by this model are used as
the silver standard data. The SMT model is
trained on this silver standard data to produce
a phrase table. The phrase table, thus obtained,
is added to the phrase table generated using
the original training data. Secondly, the silver
standard parallel corpora is added to the original
training corpora and a new parallel corpora is
generated. The SMT model is again built on
this new data-set. This generated model is used
to evaluate the test set thereafter.
5.3 Results and Analysis
We report the experimental results in Table
4. Accuracy is calculated using the standard
evaluation metric called BLEU (Papineni et
al., 2002). A baseline model (Phrase-based
SMT model) is developed by training Moses

1http://www.statmt.org/moses/

with default parameter settings (Koehn et al.,
2003b). We achieve a BLEU score of 45.66.
Our proposed hybrid model attains a BLEU
score of 46.66, which is 2.19% higher com-
pared to the baseline model. When re-ordering
is performed at the source side, we obtain
the BLEU score of 50.71, which is nearly
8.68% higher compared to the hybrid model
(without re-ordering) . This is 11.06% higher
compared to the baseline phrase-based model.
Generated outputs of the proposed model
are better in various respects like structure,
morphology etc. With the following examples,
we describe how the proposed model can be
used to improve the performance over SMT or
RBMT model. Here ST, SMT, AMT, HMT,
and PMT denote source sentence, SMT output,
RBMT output, output of the hybrid model
and output of the proposed system, respectively.

a. SMT output is incomplete while PMT
output is complete and better than SMT output.
ST: All applicable shipping fees and custom

duties up to customers address are included in
the price
SMT: डल वर तक लागू सभी कःटम और शु क

जोड़े जा चकेु ह इस दाम म
HT: Delivary tak lagu sabhi custom aur

shulk joden ja chuke hain is daam mein
PMT: डल वर तक लागू सभी कःटम और शु क

माहक के घर तक श पगं के मू य म शा मल ह
HT: Delivery tak lagu sabhi custom aur

shulk grahak ke ghar tak shipping ke mullya
mein samil hain
AMT: सब माहक जहाँ तक क शु क और

रवाज काय जहाज से भेजता हुआ लागू होना पते
मू य म सि म लत हुए गये ह
HT: Sab grahakon jahan tak ki shulk aur

rivaz karya jahaz se bhejta hua lagu hona pate
mulya mein sammilithue gaye hain

16



b. PMT output is a reordered version of
SMT which is an exact translation. Hence,
this is better compared to the others. Also
PMT retrieves proper phrase to generate better
quality. ST: Add loads of flirty colours to
your wardrobe!
SMT: म शोख रंग को शा मल कर अपनी

अलमार
HT: mein shokh rangon ko shamiln karen

apni almaree
PMT: अपनी अलमार म शोख रंग को शा मल

कर
HT:apni almaree mein shokh rangon ko

shamil karen
AMT: आपक अलमार को इँकबाज र के

बहुत जो डए!
HT:aapki almaree ko ishqbaaz radgon ko

bahut jodiye

c. PMT is capable to select better sen-
tence of generated translated output by both of
the systems. AMT is better than SMT. PMT
produces quite simliar output as AMT. Hence,
the overall quality will improve.
ST: A classy way to hang your clothes
SMT: एक उ म दज के तर का अपने कपड़े िसफ

लटका कर
HT Ek utam darje ke tareeka apne kapde

sirf latka kar
PMT: एक वशेष एवं उ तम माग आपके व

लटकाने का
HT: Ek vishesh evam uchchtam marg apke

vastra latkane ka.
AMT: एक वशेष एवं उ तम माग आपके व

लटकाने का
HT: Ek vishesh evam uchchtam marg apke

vastra latkane ka.

d. PMT output is better because it is
in correct syntax order (ends in verb).
ST: 11 Diamonds provides lifetime manu-

facturing & exchange warranty
SMT: ूदान करता है 11 ह रे और ए सचज

वारंट जीवन भर नमाण
HT: Pradan karta hai 11 hire or exchange

warranty jeevan bhar nirman
PMT: 11 डायमडं आजीवन नमाता और ए सचज

वांरट देता है
HT: 11 diamond aajeevan nirmata aur

exchange warranty deta hai

AMT: 11 डाइम ज जीवन-काल उ पादन और
अदला बदला अ धकार देता है
HT: Diamond jeevan-kaal utpadan aur adla
badla adhikar deta hai

It is out-of-scope to compare the existing
English-Hindi MT systems (as mentioned in
the related section) as none of the techniques
was evaluated on the product catalogue domain.
Since the domain as well as the training and
test data are different, we can not directly
compare our proposed system with the others.
It is also to be noted that none of the existing
systems makes use of an infrastructure like
ours. The multi-engine MT model proposed in
(Eisele et al., 2008) can not be compared as
this was not evaluated for the language pair
and domain that we attempted.

6 Conclusion

In this paper we have proposed a hybrid model
to study whether RBMT and SMT can improve
each other's efficiency. We use an effective
method of serial coupling where we have com-
bined both SMT and RBMT. The first part of
coupling has been used to obtain good lexical
selection and robustness, second part has been
used to improve syntax and the final one has
been designed to combine other modules along
with source-side phrase reordering. Our ex-
periments on a English-Hindi product domain
dataset show the effectiveness of the proposed
approach with improvement in BLEU score. In
future we would like to evaluate the proposed
model on other domains, and study hierarchical
SMT model for the product catalogues domain.

References
Arafat Ahsan, Prasanth Kolachina, Sudheer Ko-

lachina, Dipti Misra Sharma, and Rajeev San-
gal. 2010. Coupling statistical machine transla-
tion with rule-based transfer and generation. In
Proceedings of the 9th Conference of the Asso-
ciation for Machine Translation in the Americas.

Doug Arnold. 1994. Machine translation: an intro-
ductory guide. Blackwell Publisher.

Niraj Aswani and Robert Gaizauskas. 2005. A
hybrid approach to align sentences and words
in english-hindi parallel corpora. In Proceedings17



of the ACL Workshop on Building and Us-
ing Parallel Texts, pages 57--64. Association for
Computational Linguistics.

Peter F Brown, John Cocke, Stephen A Della Pietra,
Vincent J Della Pietra, Fredrick Jelinek, John D
Lafferty, Robert L Mercer, and Paul S Roossin.
1990. A statistical approach to machine transla-
tion. Computational linguistics, 16(2):79--85.

Chris Callison-Burch and Philipp Koehn. 2005. In-
troduction to statistical machine translation. Lan-
guage, 1:1.

Marine Carpuat and Dekai Wu. 2007. Improving
statistical machine translation using word sense
disambiguation. In EMNLP-CoNLL, volume 7,
pages 61--72.

Marta R Costa-Jussa and José AR Fonollosa. 2015.
Latest trends in hybrid machine translation and
its applications. Computer Speech & Language,
32(1):3--10.

Praveen Dakwale and Christof Monz. 2016. Im-
proving statistical machine translation perfor-
mance by oracle-bleu model re-estimation. In
The 54th Annual Meeting of the Association for
Computational Linguistics, page 38.

Shachi Dave, Jignashu Parikh, and Pushpak Bhat-
tacharyya. 2001. Interlingua-based english--hindi
machine translation and language divergence. Ma-
chine Translation, 16(4):251--304.

Sanjay K Dwivedi and Pramod P Sukhadeve. 2010.
Machine translation system in indian perspectives.
Journal of computer science, 6(10):1111.

Andreas Eisele, Christian Federmann, Hans Uszko-
reit, Hervé Saint-Amand, Martin Kay, Michael
Jellinghaus, Sabine Hunsicker, Teresa Herrmann,
and Yu Chen. 2008. Hybrid architectures for
multi-engine machine translation. Proceedings of
Translating and the Computer, 30.

Mikel L Forcada, Mireia Ginestí-Rosell, Jacob Nord-
falk, Jim O’Regan, Sergio Ortiz-Rojas, Juan An-
tonio Pérez-Ortiz, Felipe Sánchez-Martínez, Gema
Ramírez-Sánchez, and Francis M Tyers. 2011.
Apertium: a free/open-source platform for rule-
based machine translation. Machine translation,
25(2):127--144.

Philipp Koehn and Christof Monz. 2006. Shared
task: Exploiting parallel texts for statistical ma-
chine translation. In Proceedings of the NAACL
2006 workshop on statistical machine translation,
New York City (June 2006).

Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003a. Statistical phrase-based translation. In
Proceedings of the 2003 Conference of the
North American Chapter of the Association for
Computational Linguistics on Human Language
Technology-Volume 1, pages 48--54. Association
for Computational Linguistics.

Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003b. Statistical phrase-based translation. In
Proceedings of the 2003 Conference of the
North American Chapter of the Association for
Computational Linguistics on Human Language
Technology-Volume 1, pages 48--54. Association
for Computational Linguistics.

Santanu Pal, Sudip Kumar Naskar, Pavel Pecina,
Sivaji Bandyopadhyay, and Andy Way. 2010.
Handling named entities and compound verbs in
phrase-based statistical machine translation. As-
sociation for Computational Linguistics.

Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. Bleu: a method for au-
tomatic evaluation of machine translation. In
Proceedings of the 40th annual meeting on asso-
ciation for computational linguistics, pages 311--
318. Association for Computational Linguistics.

C Poornima, V Dhanalakshmi, KM Anand, and
KP Soman. 2011. Rule based sentence simpli-
fication for english to tamil machine translation
system. International Journal of Computer Appli-
cations, 25(8):38--42.

Taraka Rama and Karthik Gali. 2009. Modeling
machine transliteration as a phrase based statisti-
cal machine translation problem. In Proceedings
of the 2009 Named Entities Workshop: Shared
Task on Transliteration, pages 124--127. Associ-
ation for Computational Linguistics.

Ananthakrishnan Ramanathan, Jayprasad Hegde,
Ritesh M Shah, Pushpak Bhattacharyya, and
M Sasikumar. 2008. Simple syntactic and mor-
phological processing can help english-hindi sta-
tistical machine translation. In IJCNLP, pages
513--520.

Ananthakrishnan Ramanathan, Hansraj Choudhary,
Avishek Ghosh, and Pushpak Bhattacharyya.
2009. Case markers and morphology: addressing
the crux of the fluency problem in english-hindi
smt. In Proceedings of the Joint Conference
of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Nat-
ural Language Processing of the AFNLP: Vol-
ume 2-Volume 2, pages 800--808. Association
for Computational Linguistics.

Durgesh Rao, Kavitha Mohanraj, Jayprasad Hegde,
Vivek Mehta, and Parag Mahadane. 2000. A
practiced framework for syntactic transfer of
compound-complex sentences for english-hindi
machine translation. In Knowledge Based Com-
puter Systems: Proceedings of the International
Conference: KBCS--2000, page 343. Allied Pub-
lishers.

Manny Rayner and David Carter. 1997. Hybrid lan-
guage processing in the spoken language transla-
tor. In Acoustics, Speech, and Signal Processing,
1997. ICASSP-97., 1997 IEEE International Con-
ference on, volume 1, pages 107--110. IEEE.18



Michel Simard, Nicola Ueffing, Pierre Isabelle, and
Roland Kuhn. 2007. Rule-based translation with
statistical phrase-based post-editing. In Proceed-
ings of the Second Workshop on Statistical Ma-
chine Translation, pages 203--206. Association
for Computational Linguistics.

RMK Sinha and A Jain. 2003. Anglahindi: an
english to hindi machine-aided translation system.
MT Summit IX, New Orleans, USA, pages 494-
-497.

RMK Sinha, K Sivaraman, A Agrawal, R Jain,
R Srivastava, and A Jain. 1995. Anglabharti: a
multilingual machine aided translation project on
translation from english to indian languages. In
Systems, Man and Cybernetics, 1995. Intelligent
Systems for the 21st Century., IEEE Interna-
tional Conference on, volume 2, pages 1609--
1614. IEEE.

Gregor Thurmair. 2009. Comparing different archi-
tectures of hybrid machine translation systems. In
Proceedings of MT Summit XII, Ottawa (2009).

HW Xuan, W Li, and GY Tang. 2012. An
advanced review of hybrid machine translation
(hmt). Procedia Engineering, 29:3017--3022.

19


