



















































Bilingual Active Learning for Relation Classification via Pseudo Parallel Corpora


Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 582–592,
Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics

Bilingual Active Learning for Relation Classification via Pseudo Paral-
lel Corpora 

 
Longhua Qian    Haotian Hui   Ya’nan Hu   Guodong Zhou*   Qiaoming Zhu 

Natural Language Processing Lab 
School of Computer Science and Technology, Soochow University 

1 Shizi Street, Suzhou, China 215006 
{qianlonghua,20134227019,20114227025,gdzhou,qmzhu}@suda.edu.cn 

 
  

 

Abstract 

Active learning (AL) has been proven ef-
fective to reduce human annotation ef-
forts in NLP. However, previous studies 
on AL are limited to applications in a 
single language. This paper proposes a 
bilingual active learning paradigm for re-
lation classification, where the unlabeled 
instances are first jointly chosen in terms 
of their prediction uncertainty scores in 
two languages and then manually labeled 
by an oracle. Instead of using a parallel 
corpus, labeled and unlabeled instances 
in one language are translated into ones 
in the other language and all instances in 
both languages are then fed into a bilin-
gual active learning engine as pseudo 
parallel corpora. Experimental results on 
the ACE RDC 2005 Chinese and English 
corpora show that bilingual active learn-
ing for relation classification signifi-
cantly outperforms monolingual active 
learning. 

1 Introduction 
Semantic relation extraction between named en-
tities (aka. entity relation extraction or more con-
cisely relation extraction) is an important subtask 
of Information Extraction (IE) as well as Natural 
Language Processing (NLP). With its aim to 
identify and classify the semantic relationship 
between two entities (ACE 2002-2007), relation 
extraction is of great significance to many NLP 
applications, such as question answering, infor-
mation fusion, social network construction, and 
knowledge mining and population etc. 

                                                 
* Corresponding author 

In the literature, the mainstream research on 
relation extraction adopts statistical machine 
learning methods, which can be grouped into 
supervised learning (Zelenko et al., 2003; Culotta 
and Soresen, 2004; Zhou et al., 2005; Zhang et 
al., 2006; Qian et al., 2008; Chan and Roth, 
2011), semi-supervised learning (Zhang et al., 
2004; Chen et al., 2006; Zhou et al., 2008; Qian 
et al., 2010) and unsupervised learning (Hase-
gawa et al., 2004; Zhang et al., 2005) in terms of 
the amount of labeled training data they need. 
Usually the extraction performance depends 
heavily on the quality and quantity of the labeled 
data, however, the manual annotation of a large-
scale corpus is labor-intensive and time-
consuming. In the last decade researchers have 
turned to another effective learning paradigm--
active learning (AL), which, given a small num-
ber of labeled instances and a large number of 
unlabeled instances, selects the most informative 
unlabeled instances to be manually annotated and 
add them into the training data in an iterative 
fashion. Essentially active learning attempts to 
decrease the quantity of labeled instances by en-
hancing their quality, gauged by their informa-
tiveness to the learner. Since its emergence, ac-
tive learning has been successfully applied to 
many tasks in NLP (Engelson and Dagan, 1996; 
Hwa, 2004; Tomanek et al., 2007; Settles and 
Craven, 2008).  

It is trivial to validate, as we will do later in 
this paper, that active learning can also alleviate 
the annotation burden for relation extraction in 
one language while retaining the extraction per-
formance. However, there are cases when we 
may exploit relation extraction in multiple lan-
guages and there are corpora with relation in-
stances annotated for more than one language, 
such as the ACE RDC 2005 English and Chinese 
corpora. Hu et al. (2013) shows that supervised 
relation extraction in one language (e.g. Chinese) 

582



can be enhanced by relation instances translated 
from another language (e.g. English). This dem-
onstrates that there is some complementariness 
between relation instances in two languages, par-
ticularly when the training data is scarce. One 
natural question is: Can this characteristic be 
made full use of so that active learning can 
maximally benefit relation extraction in two lan-
guages? To the best of our knowledge, so far the 
issue of joint active learning in two languages 
has yet been addressed. Moreover, the success of 
joint bilingual learning may lend itself to many 
inherent multilingual NLP tasks such as POS 
tagging (Yarowsky and Ngai, 2001), name entity 
recognition (Yarowsky et al., 2001), sentiment 
analysis (Wan, 2009), and semantic role labeling 
(Sebastian and Lapata, 2009) etc. 

This paper proposes a bilingual active learn-
ing (BAL) paradigm to relation classification 
with a small number of labeled relation instances 
and a large number of unlabeled instances in two 
languages (non-parallel). Instead of using a par-
allel corpus which should have entity/relation 
alignment information and is thus difficult to 
obtain, this paper employs an off-the-shelf ma-
chine translator to translate both labeled and 
unlabeled instances from one language into the 
other language, forming pseudo parallel corpora. 
These translated instances along with the original 
instances are then fed into a bilingual active 
learning engine. Findings obtained from experi-
ments with relation classification on the ACE 
2005 corpora show that this kind of pseudo-
parallel corpora can significantly improve the 
classification performance for both languages in 
a BAL framework. 

The rest of the paper is organized as follows. 
Section 2 reviews the previous work on relation 
extraction while Section 3 describes our baseline 
systems. Section 4 elaborates on the bilingual 
active learning paradigm and Section 5 discusses 
the experimental results. Finally conclusions and 
directions for future work are presented in Sec-
tion 6. 

2 Related Work 
While there are many studies in monolingual 
relation extraction, there are only a few on multi-
lingual relation extraction in the literature. 

Monolingual relation extraction: A wide 
range of studies on relation extraction focus on 
monolingual resources. As far as representation 
of relation instances is concerned, there are fea-
ture-based methods (Zhao et al., 2004; Zhou et 

al., 2005; Chan and Roth, 2011) and kernel-
based methods (Zelenko et al., 2003; Zhang et al., 
2006; Qian et al., 2008), mainly for the English 
language. Both methods are also widely used in 
relation extraction in other languages, such as 
those in Chinese relation extraction (Che et al., 
2005; Li et al., 2008; Yu et al., 2010). 

Multilingual relation extraction: There are 
only two studies related to multilingual relation 
extraction. Kim et al. (2010) propose a cross-
lingual annotation projection approach which 
uses parallel corpora to acquire a relation detec-
tor on the target language. However, the map-
ping of two entities involved in a relation in-
stance may leads to errors. Therefore, Kim and 
Lee (2012) further employ a graph-based semi-
supervised learning method, namely Label 
Propagation (LP), to indirectly propagate labels 
from the source language to the target language 
in an iterative fashion. Both studies transfer rela-
tion annotations via parallel corpora from the 
resource-rich language (English) to the resource-
poor language (Korean), but not vice versa. 
Based on a small number of labeled instances 
and a large number of unlabeled instances in 
both languages, our method differs from theirs in 
that we adopt a bilingual active learning para-
digm via machine translation and improve the 
performance for both languages simultaneously. 

Active Learning in NLP: Active learning 
has become an active research topic due to its 
potential to significantly reduce the amount of 
labeled training data while achieving comparable 
performance with supervised learning. It has 
been successfully applied to many NLP applica-
tions, such as POS tagging (Engelson and Dagan, 
1996; Ringger et al., 2007), word sense disam-
biguation (Chan and Ng, 2007; Zhu and Hovy, 
2007), sentiment detection (Brew et al., 2010; Li 
et al., 2012), syntactical parsing (Hwa, 2004; 
Osborne and Baldridge, 2004), and named entity 
recognition (Shen et al., 2004; Tomanek et al., 
2007; Tomanek and Hahn, 2009) etc.  

Different from these AL studies on a single 
task, Reichart et al. (2008) introduce a multi-task 
active learning (MTAL) paradigm, where unla-
beled instances are selected for two annotation 
tasks (i.e. named entity and syntactic parse tree). 
They demonstrate that MTAL in the same lan-
guage outperforms one-sided and random selec-
tion AL. From a different perspective, we pro-
pose an active learning framework for the same 
task, but across two different languages. 

Another related study (Haffari and Sarkar, 
2009) deals with active learning for multilingual 

583



machine translation, which make use of multilin-
gual corpora to decrease human annotation ef-
forts by selecting highly informative sentences 
for a newly added language in multilingual paral-
lel corpora. While machine translation inherently 
deals with multilingual parallel corpora, our task 
focuses on relation extraction by pseudo parallel 
corpora in two languages. 

3 Baseline Systems 
This section first introduces the fundamental su-
pervised learning method, and then describes a 
baseline active learning algorithm. 

3.1 Supervised Learning 
We adopt the feature-based method for funda-
mental supervised relation classification, rather 
than the tree kernel-based method, since active 
learning needs a large number of iterations and 
the kernel-based method usually performs much 
slower than the feature-based one. Following is a 
list of our used features, much similar to Zhou et 
al. (2005): 
a) Lexical features of entities and their contexts 

WM1: bag-of-words in the 1st entity mention 
HM1: headword of M1 
WM2: bag-of-words in the 2nd entity mention 
HM2: headword of M2 
HM12: combination of HM1 and HM2 
WBNULL: when no word in between 
WBFL: the only one word in between 
WBF: the first word in between when at least 

two words in between 
WBL: the last word in between when at least 

two words in between 
WBO: other words in between except the first 

and last words when at least three words in 
between 

b) Entity type 
ET12: combination of entity types 
EST12: combination of entity subtypes 
EC12: combination of entity classes 

c) Mention level 
ML12: combination of entity mention levels 
MT12: combination of LDC mention types 

d) Overlap 
#WB: number of other mentions in between 
#MB: number of words in between 

M1>M2 or M1<M2: flag indicating whether 
M2/M1 is included in M1/M2. 

3.2 Active Learning Algorithm 
We use a pool-based active learning procedure 
with uncertainty sampling (Scheffer et al., 2001; 

Culotta and McCallum, 2005; Kim et al., 2006) 
for both Chinese and English relation classifica-
tion as illustrated in Fig. 1. During iterations a 
batch of unlabeled instances are chosen in terms 
of their informativeness to the current classifier, 
labeled by an oracle and in turn added into the 
labeled data to retrain the classifier. Due to our 
focus on the effectiveness of bilingual active 
learning on relation classification, we only use 
uncertainty sampling without incorporating more 
complex measures, such as diversity and repre-
sentativeness (Settles and Craven, 2008), and 
leave them for future work. 

Input: 
- L, labeled data set 
- U, unlabeled data set 
- n, batch size

Output:
- SVM, classifier 

Repeat:
    1. Train a single classifier SVM on L

2. Run the classifier on U
3. Find at most n instances in U that the classifier 

has the highest prediction uncertainty
    4. Have these instances labeled by an oracle

5. Add them into L
Until: certain number of instances are labeled or 
certain performance is reached

Algorithm uncertainty-based active learning

Figure 1. Pool-based active learning with uncer-
tainty sampling 

Since the SVMLIB package used in this paper 
can output probabilities assigned to the class la-
bels on an instance, we have three uncertainty 
metrics readily available, i.e., least confidence 
(LC), margin (M) and entropy (E). The NER 
experimental results on multiple corpora (Settles 
and Craven, 2008) show that there is no single 
clear winner among these three metrics. This 
conclusion is also validated by our preliminary 
experiments on the task of active learning rela-
tion extraction, thus we adopt the LC metric for 
simplicity. Specifically, with a sequence of K 
probabilities for a relation instance at some itera-
tion, denoted as {p1,p2,…pK} in the descending 
order, the LC metric of the relation instance can 
be simply picked as the first one, i.e. 

1pH
LC =     (1) 

Where K denotes the total number of relation 
classes. Note that this metric actually reflects 
prediction reliability (i.e. reverse uncertainty) 
rather than uncertainty in order to facilitate joint 

584



confidence calculation for two languages (cf. 
§4.4). Intuitively, the smaller the HLC is, the less 
confident the prediction is. 

4 Bilingual Active Learning for Rela-
tion Classification 

In this section, we elaborate on the bilingual ac-
tive learning for relation extraction. 

4.1 Problem Definition 
With Chinese and English (designated as c and e) 
as two languages used in our study, this paper 
intends to address the task of bilingual relation 
classification, i.e., assigning relation labels to 
candidate instances that have semantic relation-
ships. Suppose we have a small number of la-
beled instances in both languages, denoted as Lc 
and Le (non-parallel) respectively, and a large 
number of unlabeled instances in both languages, 
denoted as Uc and Ue (non-parallel). The test in-
stances in both languages are represented as Tc 
and Te. In order to take full advantage of bilin-
gual resources, we translate both labeled and 
unlabeled instances in one language to ones in 
the other language as follows: 

Lc  Let 
Uc  Uet 
Le  Lct 
Ue  Lct 

The objective is to learn SVM classifiers in 
both languages, denoted as SVMc and SVMe re-
spectively, in a BAL fashion to improve their 
classification performance. 

4.2 Bilingual Active Learning Framework 
Currently, AL is widely used in NLP tasks in a 
single language, i.e., during iterations unlabeled 
instances least confident only in one language 
are picked and manually labeled to augment the 
training data. The only exception is AL for ma-
chine translation (Haffari et al., 2009; Haffari 
and Sarkar, 2009), whose purpose is to select the 
most informative sentences in the source lan-
guage to be manually translated into the target 
language. Previous studies (Reichart et al., 2008; 
Haffari and Sarkar, 2009) show that multi-task 
active learning (MTAL) can yield promising 
overall results, no matter whether they are two 
different tasks or the task of machine translation 
on multiple language pairs. If a specific NLP 
task on two languages, such as relation classifi-
cation, can be regarded as two tasks, it is reason-
able to argue that these two tasks can benefit 

each other when jointly performed in the BAL 
framework. Yet, to our knowledge, this issue 
remains unexplored. 

An important issue for bilingual learning is 
how to obtain two language views for relation 
instances from multilingual resources. There are 
three solutions to this problem, i.e. parallel cor-
pora (Lu et al., 2011), translated corpora (aka. 
pseudo parallel corpora) (Wan 2009), and bilin-
gual lexicons (Oh et al., 2009). We adopt the one 
with pseudo parallel corpora, using the machine 
translation method to generate instances from 
one language to the other in the BAL paradigm, 
as depicted in Fig. 2. 

English View

Labeled 
Chinese Instances 

(Lc)

Labeled Translated 
English Instances 

(Let)

Labeled 
English Instances (Le)

Labeled Translated 
Chinese Instances 

(Lct)

Machine 
Translation

Machine 
Translation

Unlabeled 
Chinese Instances 

(Uc)

Unlabeled 
Translated Chinese 

Instances (Uct)

Unlabeled Translated
 English Instances (Uet)

Unlabeled 
English Instances 

(Ue)

Machine 
Translation

Machine 
Translation

Chinese View

Bilingual 
active learning

Test
Chinese Instances 

(Tc)

Test
English Instances 

(Te)

 
Figure 2. Framework of bilingual active learning 

In order to make full use of pseudo parallel 
corpora, translated labeled and unlabeled in-
stances are augmented in the following two ways: 

 For labeled Chinese instances (Lc) and Eng-
lish instances (Le), their translated counter-
parts (Let and Lct), along with their labels, are 
directly added into the labeled instances in the 
other language; 

 For unlabeled Chinese instances (Uc) and 
English instances (Ue), during an active learn-
ing iteration the top n unlabeled instances in 
Uc and Uet which are least confidently jointly 

585



predicted by SVMc and SVMe are labeled by 
an oracle and added to Lc and Le respectively. 
(cf. §4.4) 

4.3 Instance Projection via MT 
Among the several off-the-shelf machine transla-
tion services, we select the Google Translator1 
because of its high quality and easy accessibility. 
Both the mentions of relation instances and the 
mentions of two involved entities are first trans-
lated into the other language via machine transla-
tion. Then, two entities in the original instance 
are aligned with their counterparts in the trans-
lated instance in order to form an aligned bilin-
gual relation instance pair. 

Instance translation 
All the positive instances in the ACE 2005 Chi-
nese and English corpora are translated to an-
other language respectively, i.e. Chinese to Eng-
lish and vice versa. The relation instance is rep-
resented as the word sequence between two enti-
ties. This word sequence, rather than the whole 
sentence, is then translated to another language 
by the Google Translator. The reason is that, al-
though this sequence loses partial contextual in-
formation of the relation instance, its translation 
quality is supposed to be better. Our preliminary 
experiments indicate that the addition of contex-
tual information fail to benefit the task. After 
translation, word segmentation is performed on 
Chinese instances translated from English while 
tokenization is needed for translated English in-
stances. 

Entity alignment 
The objective of entity alignment is to build a 
mapping from the entities in the original in-
stances to the entities in the translated instances. 
Put in another way, entity alignment automati-
cally marks the entity mentions in the translated 
instance, thereby the feature vector correspond-
ing to the translated instance can be constructed. 
Entity alignment is vital in cross-language rela-
tion extraction whose difficulty lies in the fact 
that the same entity mention as an isolated phrase 
and as an integral phrase in the relation instance 
can be translated to different phrases. For exam-
ple, the Chinese entity mention “官员” (officer) 
is translated to “officer” in isolation, it is, how-
ever, translated to “officials” when in the relation 
instance “叙利亚 官员” (Syrian officials). 

                                                 
1 http://translate.google.com 

Input:
- Me, entity mention in English
- Re, relation instance in English
- Mct, translation of Me in Chinese
- Rc, translation of Re in Chinese
- L, a lexicon consisting of entries like (ei, ci, pi), 

where pi is the translation probability from ei to ci
- α, probability threshold

Output:
- Mc, the counterpart of Me in Rc

Steps:
1. If Mct can be exactly found in Rc, then return 

Mct
2. If the rightmost part of Mct can be found in Rc, 

then this part can be returned
3. For very word we in Me,

a) If there exists a word wc in Rc and (we, wc, p) 
in L and p>α, then (we, wc) is a match of two words

b) Return a successive sequence of matching 
words wc

4. Return null

Algorithm entity alignment

 Figure 3. Entity alignment algorithm 

Therefore, we devise some heuristics to align 
entity mentions between Chinese and English. 
The basic idea is that the word sequence in one 
mention successively matches the word sequence 
in the other mention. Take entity alignment from 
English to Chinese as an example, given entity 
mention Me in relation instance Re in English and 
their respective translations Mct and Rc in Chi-
nese, the objective of entity alignment is to find 
Mc, the counterpart of Me in Rc. The procedure of 
entity alignment algorithm can be described in 
Fig. 3. 

In the algorithm, the probability threshold α is 
empirically set to 0.002 where the precision and 
recall of entity alignment are balanced. Our lexi-
con is derived from the FBIS parallel corpus 
(#LDC2003E14), which is widely used in ma-
chine translation between English and Chinese. It 
should be noted that the process of relation trans-
lation and entity alignment are far from perfec-
tion, leading to reduction in the number of in-
stances being mapping to the other language, i.e. 

|Lc| > |Let| 
|Uc| > |Uet| 
|Le| > |Lct| 
|Ue| > |Lct| 

4.4 Bilingual Active Learning Algorithm 
The basic idea of our BAL paradigm is that, 
while unlabeled instances uncertain in one lan-

586



guage are informative to the learner in that lan-
guage, unlabeled instances jointly uncertain in 
both languages are informative to the learners in 
both languages, thus potentially improving clas-
sification performance for both languages more 
than their individual active learners do.  This 
idea is embodied in the BAL algorithm in Fig. 4, 
where n is the batch size, i.e., the number of in-
stances selected, labeled and augmented at each 
iteration. 

Figure 4. Bilingual active learning algorithm 

The key point of this algorithm lies in Step 5 
and Step 6, where unlabeled instances from Uc 
and Ue are selected and labeled respectively. 
Take Chinese for an example, when gauging the 
prediction uncertainty for an unlabeled instance 
in Uc, not only its own uncertainty measure Hc 
predicted by SVMc is considered, but also the 
uncertainty measure Het for its translation coun-
terpart in Uet, which is predicted by SVMe, is con-
sidered. Generally, in order to jointly consider 

these two measures, there are three methods to 
compute their means, namely, arithmetic mean, 
geometric mean and harmonic mean. Preliminary 
experiments show that among these three means, 
there is no single winner, so we simply take the 
geometric mean defined as follows:  

etcg HHH *=    (2) 

Considering that we adopt the LC measure as 
the uncertainty score, when an instance in Uc 
can’t find its translation counterpart in Uet due to 
translation error or entity alignment failure, Het is 
set to 1, i.e. the maximum. Since the bigger H is, 
the more confident the prediction is, the less 
likely the instance will be chosen, in this way we 
discourage the unlabeled instances without trans-
lation counterparts. 

5 Experimentation 
We have systematically evaluated our BAL para-
digm on the relation classification task using 
ACE RDC 2005 RDC Chinese and English cor-
pora. 

5.1 Experimental Settings 
Corpora and Preprocessing 

We use the ACE 2005 RDC Chinese and English 
corpora as the benchmark data (hereafter we re-
fer to them as the Chinese corpus (ACE2005c) 
and the English corpus (ACE2005e) respec-
tively). Both corpora have the same en-
tity/relation hierarchies, which define 7 entity 
types, 6 major relation types. However, the Chi-
nese corpus contains 633 documents and 9,147 
positive relation instances while the English cor-
pus only contains 498 files and 6,253 positive 
instances. Therefore, in order to balance the cor-
pus scale to fairly evaluate bilingual active learn-
ing impact on relation classification, we ran-
domly select 458 Chinese files and thus get 
6,268 positive instances, comparable to the Eng-
lish corpus. 

Preprocessing steps for both corpora include 
sentence splitting and tokenization (word seg-
mentation for Chinese using ICTCLAS2). Then, 
positive relation mentions with word sequences 
between two entities and their feature vectors are 
extracted from sentences while negative relation 
mentions are simply discarded because we focus 
on the task of relation classification. After entity 
and relation mentions in one language are trans-

                                                 
2 http://ictclas.org/ 

587



lated into the other language using the Google 
translator, entity alignment is performed between 
relation mentions and their translations. Finally 
4,747 Chinese relation mentions are successfully 
translated and aligned from English and vice 
versa, 4,936 English relation mentions are trans-
lated and aligned from Chinese. 

SVMLIB (Chang and Lin, 2011) is selected as 
our classifier since it supports multi-class classi-
fication. The training parameters C (SVM) is set 
to 2.4 according to our previous work on relation 
extraction (Qian et al., 2010). Relation classifica-
tion performance is evaluated using the standard 
Precision (P), Recall (R) and their harmonic av-
erage (F1) as well as deficiency measure (cf. lat-
ter in this section.). Overall performance scores 
are averaged over 10 runs. For each run, 1/40 
and 1/5 randomly selected instances are used as 
the training and test set respectively while the 
remaining instances are used as the unlabeled set 
for further labeling during active learning itera-
tions. 

Methods for Comparison 

For fair comparison, two baseline methods of 
supervised learning are included to augment their 
training sets with labeled instances during itera-
tions. However, these labeled instances are cho-
sen randomly from the corpus. 

SL-MO (Supervised Learning with monolin-
gual labeled instances): only the monolingual 
labeled instances are fed to the SVM classifiers 
for both Chinese and English relation classifica-
tion respectively. The initial training data only 
contain Lc and Le for Chinese and English respec-
tively.  

SL-CR (Supervised Learning with cross-
lingual labeled instances): in addition to mono-
lingual labeled instances (SL-MO), the training 
data for supervised learning contain labeled in-
stances translated from the other language. That 
is, the initial training data contain Lc and Lct for 
Chinese, or Le and Let for English. More impor-
tant, at each iteration not only the labeled in-
stances are added to the training data of its own 
language, but their translated instances are also 
added to the training data of the other language. 

AL-MO (Active Learning with monolingual 
instances): labeled and unlabeled data for active 
learning only contain monolingual instances. No 
translated instances are involved. That is, the 
data contain Lc and Uc for Chinese, or Le and Ue 
for English respectively. This is the normal ac-
tive learning method applied to a single language. 

AL-CR (Active Learning with cross-lingual 
instances): both the manually labeled instances 
and their translated ones are added to the respec-
tive training data. The initial training data con-
tain Lc and Lct for Chinese, or Le and Let for Eng-
lish. At each iteration, the n least confidently 
classified instances in Uc and Ue are labeled and 
added to the Chinese/English training data re-
spectively. Their translated instances in Uet and 
Uct are also added to the English/Chinese training 
data respectively. 

AL-BI (Active Learning with bilingual la-
beled and unlabeled instances): similar to AL-
CR with the exception that the unlabeled in-
stances are chosen not by uncertainty scores in 
one language, but by the joint uncertainty scores 
in two languages. (cf. §4.4) 

Evaluation Metric 

Although learning curves are often used to evalu-
ate the performance for active learning, it is pref-
erable to quantitatively compare various active 
learning methods using a statistical metric defi-
ciency (Schein and Ungar, 2007) defined as: 

∑
∑

=

=

−

−
= n

i in

n

i in
n

REFFREFF

ALFREFF
REFALdef

1

1

))()((

))()((
),(     (3) 

Where n is the number of iterations involved in 
active learning and Fi is the F1-score of relation 
classification at the ith iteration. REF is the base-
line active learning method and AL is an im-
proved variant of REF, such as AL-CR or AL-
BI. Essentially this deficiency metric measures 
the degree to which REF outperforms AL. Thus, 
smaller deficiency value (i.e. <1.0) indicates AL 
outperforms REF while a larger value (i.e. >1.0) 
indicates AL underperforms REF. 

5.2 Experimental Results and Analysis 
Comparison of overall deficiency 

Table 1 compares the deficiency scores of rela-
tion classification on the Chinese (ACE2005c) 
and English corpora (ACE2005e) for various 
learning methods, i.e., SL-CR, AL-MO, AL-CR 
and AL-BI. Particularly, SL-MO is used as the 
baseline system against which deficiency scores 
for other methods are computed. The batch size n 
is set to 100 and iterations stop after all the unla-
beled instances have run out of. Deficiency 
scores are averaged over 10 runs and the best 
ones are highlighted in bold font. Each run has a 
different test set and a different seed set. 

588



 
 (a) Chinese      (b) English 

Figure 5. Deficiency comparison for different batch sizes 

 
(a) Chinese      (b) English 

Figure 6. Learning curves for different methods 
 
The table shows that among the three active 

learning methods, bilingual active learning (AL-
BI) achieves the best performance for both Chi-
nese and English relation classification. This 
demonstrates that, bilingual active learning with 
jointly selecting the unlabeled instances can not 
only enhance relation classification for its own 
language, but also help relation classification for 
the other language due to the complementary 
nature of relation instances between Chinese and 
English. 

Corpora SL-CR AL-MO AL-CR AL-BI

ACE2005c 0.934 0.383 0.323 0.254
ACE2005e 0.779 0.405 0.298 0.160

Table 1. Deficiency comparison of different 
methods 

The table also shows the consistent utility of 
cross-lingual information for relation classifica-
tion for both languages. When cross-lingual in-
formation is augmented, SL-CR outperforms 
SL-MO and AL-CR outperforms AL-MO. 

Comparison of different batch sizes 

Figure 5(a) and 5(b) illustrate the deficiency 
scores for four learning methods (SL-CR, AL-

MO, AL-CR and AL-BI) against the SL-MO 
method with different batch sizes (n), where pre-
fixes “C” and “E” denote Chinese and English 
respectively. The horizontal axes denote the 
range of n (<=1000) while the vertical ones de-
note the deficiency scores. 

The figures show that the deficiency scores 
for three active learning methods run virtually 
parallel with each other while they increase mo-
notonously with the batch size n. This suggests 
that for both Chinese and English AL-BI consis-
tently performs best against other methods across 
a wide range of batch sizes, though the overall 
advantage of three active learning methods gen-
erally diminish. 

Comparison of learning curves 

In order to gain an intuition into how the per-
formance evolves when the labeled instances are 
added into the training data during iterations, we 
depict the learning curves for various learning 
methods on the Chinese and English corpora in 
Fig. 6(a) and 6(b) respectively. The horizontal 
axes denote learning iterations while the vertical 
ones denote F1-scores. For simplicity of illustra-
tion the F1-scores are collected from one of the 
10 runs. 

75

77

79

81

83

85

87

89

91

93

95

0 2 4 6 8

1
0

1
2

1
4

1
6

1
8

2
0

2
2

2
4

2
6

2
8

3
0

3
2

3
4

3
6

3
8

4
0

4
2

4
4

4
6

4
8

C-SL-MO

C-SL-CR

C-AL-MO

C-AL-CR

C-AL-BI

75

77

79

81

83

85

87

89

91

93

0 2 4 6 8

1
0

1
2

1
4

1
6

1
8

2
0

2
2

2
4

2
6

2
8

3
0

3
2

3
4

3
6

3
8

4
0

4
2

4
4

4
6

4
8

E-SL-MO
E-SL-CR
E-AL-MO
E-AL-CR
E-AL-BI

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1.0

100 200 300 400 500 600 700 800 900 1000

C-SL-CR

C-AL-MO

C-AL-CR

C-AL-BI

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

100 200 300 400 500 600 700 800 900 1000

E-SL-CR

E-AL-MO

E-AL-CR

E-AL-BI

589



The figures clearly demonstrate the perform-
ance difference for both languages among five 
methods at the beginning of iterations while F1-
scores converge at the end of iterations. Particu-
larly at the very outset, AL-BI outperforms other 
methods, quickly jumps to a very high point 
comparable to its best performance. However, 
after the 10th iteration the performance scores for 
the three AL variants tend to show trivial differ-
ence probably because most highly informative 
instances have already been added to the training 
data. 

Comparison of annotation scale 

In order to better compare BAL with other AL 
methods Figure 7 zooms out partial data on three 
AL methods in Fig. 6 and rescale the data for 
AL-MO, where “C” and “E” denote Chinese and 
English respectively. Likewise, the vertical axis 
denotes F1-scores while the horizontal axis de-
notes the number of instances labeled for AL-
CR and AL-BI. However, for AL-MO that num-
ber is doubled. This figure tries to answer the 
question: to label n respective instances in both 
languages for BAL or to labeled 2n instances in 
just one language for monolingual AL, can the 
former rival the latter? 

80

82

84

86

88

90

92

94

100 200 300 400 500 600 700 800 900 1000

C-AL-MO (2n)
C-AL-CR
C-AL-BI
E-AL-MO (2n)
E-AL-CR
E-AL-BI

 
Figure 7. Comparison of annotation scale among 
three AL methods 

The figure shows that for both Chinese and 
English, when the number of instances (n) to be 
labeled is no greater than 400, AL-BI with n in-
stances can achieve comparable performance 
with AL-MO with 2n instances. It implies that 
when the labeled instances are limited, labeling 
instances, half in one language and half in the 
other for BAL, is competitive against labeling 
the same total number of instances in just one 
language for monolingual AL, not to mention 
that the former can generate two relation extrac-
tors on two languages. 

6 Conclusion 
This paper proposes a bilingual active learning 
paradigm for Chinese and English relation classi-
fication. Given a small number of relation in-
stances and a large number of unlabeled relation 
instances in both languages, we translate both the 
labeled and unlabeled instances in one language 
to the other as pseudo parallel corpora. After en-
tity alignment, these labeled and unlabeled in-
stances in both languages are fed into a bilingual 
active learning engine. Experiments with the task 
of relation classification on the ACE RDC 2005 
Chinese and English corpora show that bilingual 
active learning can significantly outperforms 
monolingual active learning for both Chinese and 
English simultaneously. Moreover, we demon-
strate that BAL across two languages can com-
pete against monolingual AL when the annota-
tion scale is limited, though the overall number 
of labeled instances remains the same. 

For future work, on one hand, we plan to 
combine uncertainty sampling with diversity and 
informativeness measures; on the other hand, we 
intend to combine BAL with semi-supervised 
learning to further reduce human annotation ef-
forts. 

Acknowledgments 
This research is supported by Grants 61373096, 
61305088, 61273320, and 61331011 under the 
National Natural Science Foundation of China; 
Project 2012AA011102 under the “863” Na-
tional High-Tech Research and Development of 
China; Grant 11KJA520003 under the Education 
Bureau of Jiangsu, China. We would like to 
thank the excellent and insightful comments 
from the three anonymous reviewers. Thanks 
also go to my colleague Dr. Shoushan Li for his 
helpful suggestions. 

Reference 
ACE. 2002-2007. Automatic Content Extraction. 

http://www.ldc.upenn.edu/Projects/ACE/ 

A. Brew, D. Greene, and P. Cunningham. 2010. Using 
crowdsourcing and active learning to track senti-
ment in online media. ECAI’2010: 145–150. 

Y.S. Chan and D. Roth. 2011. Exploiting Syntactico-
Semantic Structures for Relation Extraction. 
ACL’2011: 551-560 

Y.S. Chan and H.T. Ng. 2007. Domain adaptation 
with active learning for word sense disambiguation. 
ACL’2007. 

590



C.C. Chang and C.J. Lin. 2011. LIBSVM: a library 
for support vector machines. ACM Transactions on 
Intelligent Systems and Technology, 2(27):1-27. 

W.X. Che, T. Liu, and S. Li. 2005. Automatic Extrac-
tion of Entity Relation (in Chinese). Journal of 
Chinese Information Processing, 19(2): 1-6. 

J.X. Chen, D.H. Ji, and C. L. Tan. 2006. Relation Ex-
traction using Label Propagation-based Semi-
supervised Learning. ACL/COLING’2006: 129-136. 

A. Culotta and J. Sorensen. 2004. Dependency tree 
kernels for relation extraction. ACL’2004: 423-439.  

A. Culotta and A. McCallum. 2005. Reducing label-
ing effort for stuctured prediction tasks. AAAI’2005: 
746–751. 

S. P. Engelson and I. Dagan. 1996. Minimizing man-
ual annotation cost in supervised training from cor-
pora. ACL’1996: 319–326. 

G. Haffari, M. Roy, and A. Sarkar. 2009. Active 
learning for statistical phrase-based machine trans-
lation. NAACL’2009: 415–423. 

G. Haffari and A. Sarkar. 2009. Active learning for 
multilingual statistical machine translation. 
ACL/IJCNLP’2009: 181–189. 

T. Hasegawa, S. Sekine, and R. Grishman. 2004. Dis-
covering Relations among Named Entities from 
Large Corpora. ACL’2004. 

Y.N. Hu, J.G. Shu, L.H. Qian, and Q.M. Qiao. 2013. 
Cross-lingual Relation Extraction based on Ma-
chine Translation (in Chinese). Journal of Chinese 
Information Processing, 27(5): 191-197. 

R. Hwa. 2004. Sample selection for statistical parsing. 
Computational Linguistics, 30(3): 253–276. 

S. Kim, M. Jeong, J. Lee, and G.G. Lee. 2010. A 
Cross-lingual Annotation Projection Approach for 
Relation Detection. COLING’2010: 564-571. 

S. Kim and G.G. Lee. 2012. A Graph-based Cross-
lingual Projection Approach for Weakly Super-
vised Relation Extraction. ACL’2012: 48-53. 

S. Kim, Y. Song, K. Kim, J.W. Cha, and G.G. Lee. 
2006. MMR-based active machine learning for bio 
named entity recognition. HLT-NAACL’2006: 69–
72. 

W.J. Li, P. Zhang, F.R. Wei, Y.X. Hou, and Q. Lu. 
2008. A Novel Feature-based Approach to Chinese 
Entity Relation Extraction. ACL’2008: 89-92. 

S.S. Li, S.F. Ju, G.D. Zhou, and X.J. Li. 2012. Active 
learning for imbalanced sentiment classifica-
tion. EMNLP-CoNLL’2012: 139-148. 

B. Lu, C.H. Tan, C. Cardie, and B.K. Tsou. 2011. 
Joint Bilingual Sentiment Classification with 
Unlabeled Parallel Corpora. ACL’2011: 320-330. 

J. Oh, K. Uchimoto, and K. Torisawa. 2009.  Bilin-
gual Co-Training for Monolingual Hyponymy-
Relation Acquisition. ACL’2009: 432-440. 

M. Osborne and J. Baldridge. 2004. Ensemble based 
active learning for parse selection. HLT-NAACL’ 
2004: 89–96. 

L.H. Qian, G.D. Zhou, F. Kong, and Q.M. Zhu. 2010. 
Clustering-based Stratified Seed Sampling for 
Semi-Supervised Relation Classification. 
EMNLP2010: 346-355. 

L.H. Qian, G.D. Zhou, Q.M. Zhu, and P.D. Qian. 
2008. Exploiting constituent dependencies for tree 
kernel-based semantic relation extraction. COL-
ING’2008: 697-704.  

R. Reichart, K. Tomanek, U. Hahn, and A. Rappoport. 
2008. Multi-task active learning for linguistic an-
notations. ACL’2008: 861-869. 

E. Ringger, P. McClanahan, R. Haertel, G. Busby, M. 
Carmen, J. Carroll, K. Seppi, and D. Lonsdale. 
2007. Active learning for part-of-speech tagging: 
Accelerating corpus annotation. In Proceedings of 
the Linguistic Annotation Workshop at ACL’2007: 
101–108. 

T. Scheffer, C. Decomain, and S. Wrobel. 2001. Ac-
tive hidden Markov models for information extrac-
tion. In Proceedings of the International Confer-
ence on Advances in Intelligent Data Analysis 
(CAIDA), pages 309–318. 

A. I. Schein and L. H. Ungar. 2007. Active learning 
for logistic regression: an evaluation. Machine 
Learning, 68(3): 235-265. 

P. Sebastian and M. Lapata. 2009. Cross-lingual an-
notation projection of semantic roles. Journal of 
Artificial Intelligence Research, 36(1): 307-340. 

B. Settles and M. Craven. 2008. An Analysis of Ac-
tive Learning Strategies for Sequence Labeling 
Tasks. EMNLP’2008: 1070–1079. 

D. Shen, J. Zhang, J. Su, G.D. Zhou and C.-L. Tan. 
2004. Multi-criteria-based active learning for 
named entity recognition. ACL’2004. 

K. Tomanek and U. Hahn. 2009. Semi-Supervised 
Active Learning for Sequence Labeling. ACL-
IJCNLP’2009: 1039-1047. 

K. Tomanek, J. Wermter, and U. Hahn. 2007. An ap-
proach to text corpus construction which cuts an-
notation costs and maintains reusability of anno-
tated data. EMNLP-CoNLL’2007: 486–495. 

X.J. Wan. 2009. Co-Training for Cross-Lingual Sen-
timent Classification. ACL-AFNLP’2009: 235-243. 

D. Yarowsky and G. Ngai. 2001. Inducing multilin-
gual POS taggers and NP bracketers via robust pro-
jection across aligned corpora. NAACL’2001: 1-8. 

591



D. Yarowsky, G. Ngai, and R. Wicentorski. 2001. 
Inducing multilingual text analysis tools via robust 
projection across aligned corpora. HLT’2001:1-8. 

H.H. Yu, L.H. Qian, G.D. Zhou, and Q.M. Zhu. 2010. 
Chinese Semantic Relation Extraction based on 
Unified Syntactic and Entity Semantic Tree (in 
Chinese). Journal of Chinese Information Process-
ing, 24(5): 17-23. 

D. Zelenko, C. Aone, and A. Richardella. 2003. Ker-
nel Methods for Relation Extraction. Journal of 
Machine Learning Research, 3: 1083-1106. 

Z. Zhang. 2004. Weakly-supervised relation classifi-
cation for Information Extraction. CIKM’2004. 

M. Zhang, J. Su, D. M. Wang, G. D. Zhou, and C. L. 
Tan. 2005. Discovering Relations between Named 
Entities from a Large Raw Corpus Using Tree 
Similarity-Based Clustering. IJCNLP’2005: 378-
389.  

M. Zhang, J. Zhang, J. Su, and G.D. Zhou. 2006. A 
Composite Kernel to Extract Relations between 
Entities with both Flat and Structured Features. 
ACL/COLING’2006: 825-832.  

S.B. Zhao and R. Grishman. 2005. Extracting rela-
tions with integrated information using kernel 
methods.  ACL’2005: 419-426. 

G.D. Zhou, J.H. Li, L.H. Qian, and Q.M. Zhu. 2008. 
Semi-Supervised Learning for Relation Extraction. 
IJCNLP’2008: 32-38. 

G.D. Zhou, J. Su, J. Zhang, and M. Zhang. 2005. Ex-
ploring various knowledge in relation extraction. 
ACL’2005: 427-434.  

J.B. Zhu and E. Hovy. 2007. Active learning for word 
sense disambiguation with methods for addressing 
the class imbalance problem. EMNLP-
CoNLL’2007: 783-790. 

592


