










































Diagnosing Causes of Reading Difficulty using Bayesian Networks


International Joint Conference on Natural Language Processing, pages 1383–1391,
Nagoya, Japan, 14-18 October 2013.

Diagnosing Causes of Reading Difficulty using Bayesian Networks

Pascual Martı́nez-Gómez
The University of Tokyo

National Institute of Informatics
pascual@nii.ac.jp

Akiko Aizawa
The University of Tokyo

National Institute of Informatics
aizawa@nii.ac.jp

Abstract

There is a need of matching text diffi-
culty to the expected reading skill of the
audience. Readability measures were de-
veloped with this objective in mind, first
by psycholinguists, and more recently, by
practitioners of natural language process-
ing. A common strategy was to extract
linguistic features that are good predic-
tors of readability, and then train discrim-
inative classification or regression models
that correlate well with human judgment.
But correlation does not imply causality,
which is a necessary property to explain
why documents are not readable. Our ob-
jective is to provide mechanisms for text
producers to adjust the readability of their
content. We propose the use of generative
models to diagnose causes of reading dif-
ficulty, and bring closer the realization of
automatic readability optimization.

1 Introduction

Educational institutions, government agencies and
some private companies have a special interest in
authoring documents for a certain audience, but
it is expensive to involve expert linguists to as-
sess the readability of every document they pro-
duce. The first psycholinguistic studies developed
readability formulas for grading purposes, based
on surface linguistic features. Those formulas, de-
spite of their simplicity, performed well and were
widely used by editors to grade reading material
for young readers. However, content producers
might be tempted to adapt their manuscripts by
tweaking the text features present in readability
formulas, without gaining (or even degrading) real
readability (Davison and Kantor, 1982).

Recently, the application of statistical models
to linguistic problems proved successful, and am-

bitious tasks in automatic document transforma-
tion such as text summarization or machine trans-
lation became a hot topic in computational linguis-
tics. Readability optimization is one of such docu-
ment transformation problems. Recent studies on
readability embrace machine learning techniques
to recognize readability with an even higher accu-
racy. The common approach consists in extracting
as many features as possible, and then training a
classifier or a regression model using human an-
notated texts to predict a readability score given
the observation of the linguistic features.

Those discriminative models correlate well with
human judgment, but fail at explaining why a doc-
ument is not readable. We call readability diagno-
sis the automatic discovery of the causes that lead
to (un)readability, and we believe it is an essential
step for readability optimization.

We propose the use of Bayesian causal net-
works to perform readability diagnosis. That is,
given a document, the objective of our Bayesian
network is to recognize the specific parts of the
document that are difficult to read. Bayesian
networks are a type of generative model, where
the joint probability distribution is constructed by
making certain independence assumptions. Their
main advantage is that they allow to query the
model regarding any linguistic variable, general-
izing the functionality of traditional models.

In the next section we briefly introduce for-
mer work by psycholinguists and recent work by
practitioners on natural language processing. We
describe our application of Bayesian networks to
readability diagnosis in Section 3 and summarize
the capabilities of the model. Corpora, baseline
system description and results are presented in
Section 4, where we assess to what extent our gen-
erative model predicts cognitive evidence. Point-
ers to future work and applications that would ben-
efit from our results can be found in Section 5, fol-
lowed by our conclusions in Section 6.

1383



2 Related Work

Readability formulas have been the subject of in-
vestigation long before the existence of current
natural language processing techniques. Although
sophisticated methods could have been developed,
there was an emphasis on easy-to-compute formu-
las, where the readability score of a text is com-
puted as a function of its linguistic features.

The Flesch-Kincaid formula (Flesch, 1948;
Kincaid et al., 1975) was probably the first in gain-
ing wide recognition among publishers. This for-
mula is a linear combination of two variables1, as:

rscore = 0.39×ASL+11.8×ASW−15.59 (1)

where ASL is the average number of words per
sentence, and ASW is the average number of syl-
lables per word. Despite of its simplicity, ASL
and ASW are very discriminative linguistic fea-
tures when assessing readability and this formula
correlates surprisingly well with human judgment.

The search for more discriminative linguistic
features continued, and Mc Laughlin (1969) found
that the number of polysyllabic words in a certain
amount of text is also a good predictor of reading
difficulty. The rationale behind such a linguistic
feature could be that the required lexical process-
ing is higher when the word is longer, or that long
words tend to be more infrequent and difficult to
read (Rayner and Duffy, 1986). This work was fol-
lowed by others (Fry, 1990) that counted the num-
ber of words in the text that were contained in the
vocabulary of specific word lists. The use of word
lists introduced a new dimension in readability,
since it was possible to design hand-crafted lists
that could not only account for lexical frequency,
but also for semantic complexity.

Building on the idea of lexical frequency and
counting on large amounts of text data, the use of
word lists was generalized into unigram language
models (Si and Callan, 2001), which increased the
correlation with human judgment on readability.

Linguistic features of different nature were also
explored, and grammatical features are an exam-
ple of them (Heilman et al., 2007). Those features
alone were found not to be as discriminant as the
lexical ones, but performed well in combination
with them. However, the effects were not additive,
which suggests that variables correlated with each

1We will use the term variables interchangeably with lin-
guistic features.

other to a certain extent. This was also noted in
some other works (Petersen and Ostendorf, 2009),
where syntactic features were also used, in combi-
nation with higher order n-gram language models.

Automatic text transformation for readability
optimization is a task that naturally follows for-
mer readability studies and the large scale need
of producing content for specific audiences. Au-
thors in (Carroll et al., 1999; Devlin et al., 1999;
Siddharthan, 2003) approached the problem using
rules for syntactic transformation, anaphora sub-
stitutions and vocabulary simplifications, but those
rules were not experimentally tested for their tar-
get readers. Williams and Reiter (2005) did test
their transformation rules, but they were limited to
assess the effects of their set of rules, which had a
low coverage. Other authors (Aluı́sio et al., 2010;
François and Fairon, 2012) integrated readability
scores in authoring systems, to assist text simplifi-
cation rather than fully automating it.

Previous work has concentrated on finding lin-
guistic features that are good predictors of read-
ability, and building discriminative models that
best correlate with human judgment. But those
models can only indicate whether a piece of text is
readable or not, and fail in explaining the causes.
In view of (semi-)automatic text simplification
and readability optimization, we propose Bayesian
causal networks as a generative model for read-
ability. In this approach, readability is modeled as
a factored joint probability distribution over lex-
ical, part of speech, syntactic, semantic and dis-
course features. This provides an interpretable
model to gain linguistic insight about what fea-
tures impact most on readability in a specific doc-
ument and to understand how that text should
be transformed to increase readability even under
human-imposed constraints.

3 Methodology

3.1 Discriminative and Generative Models

Previous work on readability assessment has fo-
cused on the development of discriminative mod-
els. Those discriminative models are functions φ
that map instantiations ` of a set of linguistic fea-
tures L to a readability score r ∈ R, φ : L →
R. In this work, examples of linguistic features
are “proportion of verbs to words”, or “maximum
number of active lexical chains” in a given text,
and their instantiations are their actual values for
that text. If we normalize the readability measure

1384



so that it assigns 1 to the whole space of possible
feature instantiations, we can regard the readabil-
ity score as a probabilistic measure, and without
loss of generalization, reformulate the problem as:

r̂ = argmax
r

Pr (r | `), (2)

where we have to find the readability score r with
maximum probability, given the instantiation ` of
the set of linguistic features L .

In this approach, the probability on all possi-
ble reading score assignments is well defined, but
there is no attempt to model the probability of the
instantiations ` of linguistic features L . As it has
been reported in related work, most explanatory
effects on readability do not add up across all lin-
guistic features. This suggests that linguistic fea-
tures interact with each other and have mixed ef-
fects on readability prediction. There have been
ablation and correlation studies to bring light on
those feature interactions (Kate et al., 2010), but
they were limited to a few feature combinations
and no attempts were done to study causal rela-
tionships or other conditional independencies.

To attain diagnosis capabilities, we propose the
use of Bayesian causal networks as an example of
generative models Pr(r, `), where the readability
score and the linguistic features are modeled to-
gether using a joint probability distribution. There
are, however, some challenges associated to this
model that are described below.

3.2 Independence Assumptions

To preserve generality, we will regard joint proba-
bility distributions as tables, where every row de-
fines the probability of a discrete value assignment
to all linguistic features and the readability score.
The number of parameters to be estimated in the
model is proportional to the number of possible
assignments, which is exponential with the num-
ber of linguistic features. A simple approach is
to consider the readability to be dependent on all
features, but all features independent from each
other. The joint probability distribution can be
consequently defined as:

Pr(r,L ) = Pr(r, l1, . . . , lm)

≈ p(r | l1, . . . , lm) · p(l1) · · · p(lm),
(3)

where p(li) are the priors for every linguistic fea-
ture li, and the conditional probability distribution

p(r | l1, . . . , lm) models the non-linear relation-
ship between linguistic features and the readability
score. The graphical representation of this model
can be found in Figure 1a, where the gray circles
are observed linguistic features, and edges encode
probabilistic influence (or dependency). Due to
the simplicity of this network, the number of de-
pendencies in p(r | l1, . . . , lm) is large, which re-
quires to estimate millions of parameters if there
are more than twenty linguistic features.

In order to reduce the number of parameters
without reducing the number of linguistic features,
we will introduce language constructs in the form
of hidden variables and set structural dependencies
between the linguistic features and these language
constructs. Guided by basic linguistic knowledge,
we will detect sets of inter-dependent linguistic
features and group them to a language construct
consistent with the linguistic theory.

Examples of language constructs are the lexical
difficulty Lex, the syntactic difficulty Syn, or the
semantic difficulty Sem. Those variables cannot
be directly measured in a text (because they are not
well defined), but are rather unknown functions of
some other linguistic features, such as the length
of a word (in characters or syllables), the amount
of uppercase letters (e.g. in acronyms) or the pres-
ence of digits (e.g. protein names in biology). The
graphical representation that introduces language
constructs as hidden variables can be found in Fig-
ure 1b. Those hidden variables are typically intro-
duced in joint probabilistic models as:

Pr(r,L ) = Pr(r, l1, . . . , lm)

=
∑
Lex

∑
Syn

∑
Sem

Pr(r,Lex,Syn,Sem, l1, . . . , lm)

(4)

By inspecting Figure 1b, we can observe that
readability score r is independent from observable
linguistic features li given the language constructs
Lex, Syn and Sem. Thus, we can rewrite Equa-
tion 4 to factorize over the graph in Figure 1b as:

Pr(r, l1, . . . , lm)

≈
∑
Lex

∑
Syn

∑
Sem

p(r | Lex,Syn,Sem)

· p(Lex | l1, . . . , li) · p(Syn | li+1, . . . , lj)
· p(Sem | lj+1, . . . , lm) · p(l1) · · · p(lm)

(5)

where l1, . . . , li are inter-dependent lexical fea-
tures that somehow influence the lexical difficulty,

1385



r

...li...l1 lj ... lm

(a) Simple Bayesian network, where the readability score r
depends on all linguistic features li. The number of param-
eters makes the estimation problem intractable.

r

Syn SemLex

...l1 li ...li+1 lj ...lj+1 lm

(b) Structured Bayesian network that introduces language con-
structs (Lex, Syn and Sem) as hidden variables (white el-
lipses), with the purpose of reducing the dependencies of the
readability score r from the rest of the linguistic features.

Figure 1: Graphical representations of causal net-
works. Arrows denote probabilistic influence.

li+1, . . . , lj are syntactic features that influence
syntactic difficulty, and the remaining are seman-
tic features. Now the readability score r depends
only on a small set of language constructs, which
dramatically reduces the amount of parameters.

3.3 Estimating Parameter Values
Hidden variables and independency assumptions
are often necessary to reduce the number of pa-
rameters that need to be estimated, specially when
there are many variables or there is a limited
amount of training data. In the factor graph of Fig-
ure 2, there is a conditional probability distribu-
tion (CPD) Pr(v | Pav) modeling the probability
of every linguistic feature v given its parents Pav
in the graph2. In this work, we make no assump-
tions on how a variable is related to its parents and
we model this unknown relationship using non-
parametric CPDs. The drawback is that we need
to discretize the values of the linguistic variables
and that the number of parameters3 increases ex-
ponentially with the number of parent variables.

The estimation of the parameter values can be
carried out using standard techniques that aim at
optimizing the likelihood over the training data
in presence of hidden variables. In this work,

2If a variable v has no parents, then its CPD is p(v).
3The term “non-parametric” might be misleading, since

this type of CPDs have many parameters.

we used the Expectation-Maximization (EM) al-
gorithm (Dempster et al., 1977) for that purpose.

3.4 Querying the Model

Estimating the joint probability distribution
Pr(r, `) has its advantages, since it gives us
complete knowledge about the problem. In order
to interpret the model, we can perform some
insightful queries involving any variable.
Marginal Maximum a Posteriori is used to
find the most probable value assignment to some
linguistic features given some evidence. This
query can mimic the functionality of discrimina-
tive models, where the objective is to find the most
probable readability score r̂ given the linguistic
evidence `0, in presence of language constructs L:

MAP(r̂ | `0) = argmax
r

∑
L

p(r,L | `0) (6)

where the conditional probability distribution
p(r,L | `0) can be found by using the Bayes rule:

p(r,L | `0) = p(r,L, `
0)

p(`0)
(7)

Another application of marginal MAP queries is
to gain linguistic insight about what character-
izes unreadable texts. This insight could be ob-
tained by querying the model in the opposite di-
rection, i.e. MAP(ˆ̀ | r0), where we want to
obtain the most plausible linguistic instantiation ˆ̀
given a certain readability level r0. More com-
plex queries can be similarly performed by condi-
tioning the marginal MAP. For instance, the query
MAP(ˆ̀ | Lexhigh, rgood) would result in the most
plausible values of linguistic features that have a
high lexical difficulty but a good readability.
Sensitivity analysis allows us to understand how
sensitive a certain variable is to some observed lin-
guistic features. In our study, we are interested
in understanding what individual or combination
of observable linguistic features influence most in
the readability of a particular text. A common ap-
proach (Kjærulff and Madsen, 2007) is to compute
the distance d between the joint probability distri-
bution with different instantiations of the linguistic
features under study.

4 Experiments

We first describe the data that we used to train
our systems, and the data grounded on cognitive

1386



effort that we used for validation. Then, we de-
scribe the full set of linguistic features and our
baseline systems. Finally, we assess to what ex-
tent our Bayesian causal network is able to predict
the specific parts of the documents that are diffi-
cult to read, and compare it to other systems.

4.1 Corpora

To estimate the parameters of the Bayesian causal
network and our baseline systems, we opted to use
texts from three corpora, namely Wikipedia Sim-
ple4, Wikipedia English5, and PubMed6.

Wikipedia has been a valuable resource for the
development of text transformation methods, such
as summarization (Biadsy et al., 2008), or machine
translation (Smith et al., 2010), among others.
Wikipedia Simple is a relatively new version of
the Wikipedia English, where articles are written
in simple English7. Wikipedia English does not re-
quire any specific writing style other than clarity,
precision and completeness. Finally, PubMed cor-
pus is a large collection of academic biomedical
articles, where readability is often sacrificed for
precision and completeness. We assume that these
three corpora have different expected readabilities
(high, intermediate and low, respectively), and we
use them as readability annotations at document
level. Some linguistic features considered in our
work are sensitive to text length (i.e. number of
active lexical chains or average coreference dis-
tance). For this reason, we collected only abstracts
from Wikipedia Simple that contain 10, 11 or 12
sentences, and randomly sampled from Wikipedia
English and PubMed the same amount of long ab-
stracts with the same text length distribution as
Wikipedia Simple, totaling in 8, 856 abstracts.

Our hypothesis is that Bayesian causal networks
are capable of recognizing specific parts of docu-
ments that make texts difficult to read. To test our
hypothesis, we need documents with readability
annotations at sub-document level. But such fine-
grained annotations are difficult to obtain even for
expert linguists because there are many linguistic
variables involved in the annotation decisions.

In this work, we indirectly annotate the reading
difficulty of every part of the text using an esti-
mation of the expected cognitive effort required

4http://simple.wikipedia.org/
5http://en.wikipedia.org/
6http://www.ncbi.nlm.nih.gov/pubmed/
7Guidelines to write in simple English are proposed in

Wikipedia Simple, but are not strictly enforced.

to understand that part of the text. There are
several methods that have been proposed to mea-
sure moment-to-moment cognitive effort, such as
functional magnetic resonance imaging (fMRI) to
quantify activations of certain brain areas, or mea-
surements in pupil size changes. However, those
methods have difficulties in aligning cognitive ef-
fort spatially and temporally to segments in a text,
and we opted to measure fixation time on indi-
vidual words due to its relative simplicity. Thus,
we work under the assumption that higher cogni-
tive effort is reflected as longer fixation durations,
since parts of the text that are difficult to read re-
quire longer cognitive processing time.

On the text side, we characterize a part of a
text by a quantification of its linguistic features at
word level. Let fi,j be the quantification of lin-
guistic feature i at word wj . As an example, lin-
guistic feature “is noun”, fnoun,j = 1 if wj is a
noun. Non-binary linguistic features can be sim-
ilarly quantified in the range [0, 1] dividing their
value by the maximum possible value. For fea-
tures not defined at word level (e.g. “sentence
length”), the feature quantification of words in the
span are all equal to the quantification of the span.

In order to estimate fixation time Ti induced by
every linguistic feature i, we accumulate fixation
durations on words scaled by the quantification of
every linguistic feature at those words, and nor-
malize it by the total amount of fixation durations
and total amount of feature quantification. For-
mally, let tj be the total amount of fixation dura-
tion on word wj . Then, fixation time Ti caused by
linguistic feature i can be computed as:

Ti =

∑
j tj · fi,j

(
∑

j tj) · (
∑

j fi,j)
(8)

We collected fixation durations on every word
using the eye-tracker Tobii TX300, and used a
text-gaze aligner (Martı́nez-Gómez et al., 2012)
to correct the systematic errors introduced by the
eye-tracker. There were 40 subjects participating
in our study, and only the 20% of eye-tracking
sessions with highest signal quality were selected
for this study. Most subjects were non-native En-
glish speakers linked to academia, with varying
language skills and background knowledge. They
were asked to carefully read 2 documents on 3 top-
ics (6 documents in total), about economics, nutri-
tion and astronomy, and answer detailed question-
naires to assess their understanding. The average

1387



Readability

LexicalDifficultyPOSSemanticDifficulty SyntacticDifficultyDiscourse

NamedEntity

AllUppercase ContainsUppercase

WordLengthPerplexity NumbersVerbs

Nouns

Prepositions

MaxDependencyDensityDependencyDistance

TerminalNodeRatio

SentenceLength FigureOfMerit

AcademicGeneral

HeightHypernym

OutVocabulary

DistanceCoreference

NumLexChainDiscourseConnectors

Passive

Figure 2: Graphical representation of our Bayesian causal network. Observable linguistic features are
represented by white ellipses. Language constructs introduced as hidden variables are represented by
gray ellipses. Directed edges indicate the direction of causality, and encode probabilistic influence.

duration of the reading and question-answering
session was 1 hour, and every subject was com-
pensated with the equivalent to 20 US dollars in
cash at the end of the session. Documents con-
tained 22.5 sentences and 469 words on average.

The objective of the Bayesian causal network
will be to predict cognitive effort caused by each
linguistic feature, and it will be compared to the
results obtained by using discriminative methods.

4.2 Feature Set

Figure 2 shows the 22 linguistic features (gray
ellipses) that were used in this work, the 5 lan-
guage constructs that were introduced as hidden
variables (white ellipses), and their probabilistic
relationships (directed edges). The linguistic fea-
tures that appear as ancestors of lexical difficulty
and Part of Speech (POS) correspond to their av-
erage at token level (i.e. in the case of “Numbers”,
the percentage of tokens that are numbers).

Named entities were extracted using the NLTK
toolkit (Bird et al., 2009), word lengths (in syl-
lables) were computed by averaging the num-
ber of stresses in the CMU pronunciation dictio-
nary (Weide, 1998). The perplexity was computed
using Google 5-grams (Brants and Franz, 2006)
with deleted interpolation tuned on a tokenized
and non-lowercased separate subset of represen-
tative sentences from all three corpora. The per-
centage of prepositions, nouns and verbs was com-
puted using the NLTK POS tagger.

Following the work in (Hudson, 1995) we con-
sidered the maximum dependency density and av-
erage distance between dependents as linguistic
features that influence syntactic difficulty, com-
puted using a dependency parser (Klein and Man-
ning, 2003). Terminal node to non-terminal node

ratio is another typical phrase-based measure of
syntactic difficulty, and it was computed using an
HPSG parser (Miyao and Tsujii, 2008). The figure
of merit, as given by the same parser, is a function
of the lexical probability rules that are triggered
during the automatic parsing, and somehow repre-
sents the parsing surprise.

Height of hypernyms were computed as the
average distance between token lemmas to the
most abstract term in WordNet (Fellbaum, 2010)
and measures how specific terms are. “Gen-
eral”, “Academic” and “OutVocabulary” features
denote the average number of words appearing
in the General Word Service List (West and Jef-
fery, 1953), in the Academic Word List (Coxhead,
1998), or in none of them.

The average distance between mentions and
their referents, and the maximum number of ac-
tive lexical chains were computed using a corefer-
ence resolution system (Raghunathan et al., 2010)
in a similar fashion to how the average dependency
distance and maximum dependency density were
computed to measure syntactic difficulty. Finally,
the average number of passive clauses was com-
puted using the output of the HPSG parser, and the
percentage of tokens that are discourse connectors
was measured checking the occurrence of every
token in a hand-crafted list of 279 connectors.

4.3 Baseline

Using our Bayesian network, we computed the
importance of each linguistic feature for every
document as the sensitivity of the network condi-
tioned on the observation of the rest of the vari-
ables. We compared our system to two baselines.
The first baseline, raw features, measures the
importance of linguistic features (across the cor-

1388



-0.7

-0.4

-0.1

0.2

0.5

1 2 3 4 5 6

C
o

rr
e

la
ti

o
n

s 

Documents 

Correlations between model predictions 
and estimated cognitive effort 

Bayesian

raw features

SVM

Figure 3: Correlations between predictions of fea-
ture impact on reading difficulty and the expected
cognitive effort introduced by such features. Con-
fidence intervals are computed at 95%.

pora) as the correlation between each linguistic
feature and the readability score. As a second
baseline, we chose SVM models due to their suc-
cess in readability studies (François and Fairon,
2012). We measured their sensitivity to each lin-
guistic feature, by observing the variations on the
SVM response due to variations in each linguistic
feature (Cortez, 2010), while holding the rest of
linguistic variables to their average values. This
baseline was built by training and tuning an SVM
with a gaussian kernel in a cross-validation setup.
Both baselines obtain quantifications of feature in-
fluence on readability independent of the docu-
ment instantiation. For SVM sensitivity analysis,
we also computed variability of SVM categorical
response to changes in the linguistic feature under
study while setting the rest of linguistic features
to the instantiations on each document. However,
there was a negligible variance in SVM response,
and results are not reported for that experiment.

Confidence intervals for all systems were ob-
tained by measuring prediction variability in 10
runs of random sampling with 90% of the data. All
linguistic features were discretized in two intervals
for the Bayesian network, except the readability
score, which had three states (one for each class).
This is an important loss of information for the
Bayesian network, but it was necessary for compu-
tational reasons. SVM and raw features base-
lines, however, used continuous values.

4.4 Results

Figure 3 shows correlations between predictions
of feature impact on reading difficulty and the

expected cognitive effort introduced by such fea-
tures. The x−axis corresponds to the identifier of
each document for which we have estimated cog-
nitive effort using the eye-tracker and the y−axis
corresponds to correlations with the systems. In-
tervals for every prediction at a 95% confidence
are displayed above and below each bar.

As it can be observed, raw features do
not capture meaningfully cognitive effort and their
correlations are close to zero, with a high confi-
dence (narrow confidence intervals). The quan-
tification on linguistic feature importance given
by the SVM sensitivity analysis is slightly nega-
tive with large confidence intervals, which sug-
gests that this type of analysis is not useful to pre-
dict reading difficulties in specific parts of the doc-
uments. The Bayesian causal network obtains
mild, but consistent and positive correlations with
the expected cognitive effort and its confidence in-
tervals show strong significance.

Table 1 shows the most influential linguistic fea-
tures on reading difficulty for documents 4 and
6. According to the cognitively-grounded reading
difficulty, lexical perplexity (surprise), the occur-
rence of named entities, out of vocabulary words,
passive clauses, academic words, nouns and ab-
straction (hypernyms) are the linguistic features
that required longer fixation times in order to un-
derstand those documents. The Bayesian network
ranked, on top 5, two and three of the most influ-
ential linguistic features for document 4 and 6.

5 Applications and Future Work

Bayesian causal networks for readability diagnosis
have an immediate application to authoring sys-
tems, where the inference engine automatically
detects text segments that make the text difficult to
read. For that purpose, the average quantification
of every linguistic feature has to be computed at
document level. Then, causal reasoning (Bayesian
sensitivity analysis) would be performed to find
linguistic features with highest impact on reading
difficulty for that specific document. Finally, in-
stantiations of such linguistic features at segment
level whose quantifications are above document
average would be flagged for edition. Authors
can then proceed to amend the text, or assert con-
straints. These constraints can take the form of
“I want to increase readability without sacrificing
the current lexical difficulty”. Such constraints can
be introduced using marginal MAPs as described

1389



Document 4 Cognitive effort Bayesian SVM raw features
feature 1 Nouns General Dependency density General
feature 2 Out Vocabulary Out Vocabulary General Out Vocabulary
feature 3 Passive Academic Contains uppercase Academic
feature 4 Academic Figure of Merit Dependency distance All uppercase
feature 5 Height Hypernym Named entities Verbs Figure of Merit
Document 6 Cognitive effort Bayesian SVM raw features
feature 1 Perplexity Named entities Dependency density General
feature 2 Named entities Academic General Out Vocabulary
feature 3 Out Vocabulary General Contains uppercase Academic
feature 4 Passive Perplexity Dependency distance All uppercase
feature 5 Academic Figure of Merit Verbs Figure of Merit

Table 1: List of 5 most influential linguistic features for documents 4 and 6, sorted in descending order.
The first column corresponds to the order given by cognitive effort. The rest of the columns correspond
to predictions of systems. The Bayesian network finds 2 and 3 out of the 5 most influential features in
documents 4 and 6. SVM and raw features provide constant estimations for all documents.

in Section 3.4. There are, however, features that
cannot be tweaked individually and would require
very complex user actions. Others are simply very
difficult to handle by humans, as in the case of the
terminal node to non-terminal node ratio.

In an automatic readability optimization setup,
a set of transformation actions could be applied
on a text, but discerning the most appropriate ac-
tion can be challenging. Bayesian networks could
be a solution to it, since they can infer the desir-
able configuration of linguistic values for a certain
readability level in a given document, and what ac-
tions would lead to the largest readability gain.

The remaining challenges when working with
non-parametric Bayesian networks are two. The
first one is the necessary loss of information that
occurs when discretizing features, and paramet-
ric models are possible solutions. Finding bet-
ter network topologies is also an interesting chal-
lenge that brings linguistic insights into readabil-
ity studies and increases the predictive power of
the model. One approach is to refine the net-
work using more thoughtful linguistic knowledge.
Another possibility is to automatically estimate
the optimal network topology driven by data, but
causal properties could be difficult to preserve.

We used indirect measurements of cognitive ef-
fort that rely on the computation of a normalized
fixation time on every linguistic feature. Fixa-
tion durations were recorded using a precise eye-
tracker, but data collection is rarely exempt of sys-
tematic errors and new methods to estimate cog-
nitive effort should account for this degraded cali-
bration. Moreover, certain aspects of cognitive ef-

fort might not be reflected by fixation times, and
other features of eye movements, such as regres-
sions or changes in pupil diameter can be valuable.

Since estimations of feature impact on readabil-
ity depends on each document, it was difficult to
compare our findings to prior work. Future in-
vestigations in readability diagnosis would benefit
from a combination of indirect measurements of
cognitive effort and readability annotations by lin-
guistic experts at sub-document level, that could
be shared within the research community.

6 Conclusions

Discriminative models are built to predict read-
ability and correlate well with human judgment.
Those models are good readability predictors, but
fail at explaining the causes of unreadability. With
the intention of assisting humans to optimize read-
ability or to fully automate it, we need methods
able to infer the causes of readability.

We have presented the application of Bayesian
causal networks to build generative readability
models. To reduce the number of dependencies
between linguistic features, we introduced lan-
guage constructs as hidden variables and estimated
the parameter values using the EM algorithm.

Using our proposed Bayesian causal network,
we measured the impact of every linguistic feature
in presence of all other variables, and compared
the prediction accuracy to grounded cognitive ef-
fort. Our method showed significant and positive
correlations with cognitive effort, suggesting that
it is able to capture linguistic features that cause
difficulties in reading for specific documents.

1390



References
S. Aluı́sio, L. Specia, C. Gasperin, and C. Scarton.

2010. Readability assessment for text simplifica-
tion. In Proc. of the NAACL HLT 2010 Fifth Work-
shop on Innovative Use of NLP for Building Educa-
tional Applications, pages 1–9. ACL.

F. Biadsy, J. Hirschberg, and E. Filatova. 2008. An un-
supervised approach to biography production using
Wikipedia. In Proc. of ACL-08: HLT, pages 807–
815.

S. Bird, E. Klein, and E. Loper. 2009. Natural Lan-
guage Processing with Python. O’Reilly Media Inc.

T. Brants and A. Franz. 2006. Web 1T 5-gram vers. 1.

J. Carroll, G. Minnen, D. Pearce, Y. Canning, S. De-
vlin, and J. Tait. 1999. Simplifying text for
language-impaired readers. In Proc. of EACL, vol-
ume 99, pages 269–270.

P. Cortez. 2010. Data mining with neural networks
and support vector machines using the r/rminer tool.
In Advances in Data Mining. Applications and The-
oretical Aspects, pages 572–583. Springer.

A. Coxhead. 1998. An academic word list, volume 18.
School of Linguistics and Applied Language Stud-
ies, Victoria University of Wellington.

A. Davison and R.N. Kantor. 1982. On the failure of
readability formulas to define readable texts: A case
study from adaptations. Reading Research Quar-
terly, pages 187–209.

A.P. Dempster, N.M. Laird, and D.B. Rubin. 1977.
Maximum likelihood from incomplete data via the
EM algorithm. Journal of Royal Statistical Society.

S. Devlin, J. Tail, Y. Canning, J. Carroll, G. Minnen,
and D. Pearce. 1999. The application of assis-
tive technology in facilitating the comprehension of
newspaper text by aphasic people. Assistive Tech-
nology on the Threshold of the New Millennium.

C. Fellbaum. 2010. WordNet. Theory and Appli-
cations of Ontology: Computer Applications, pages
231–243.

R. Flesch. 1948. A new readability yardstick. Journal
of applied psychology, 32(3):221.

T. François and C. Fairon. 2012. An AI readability
formula for French as a foreign language. In Proc. of
the 2012 Joint Conference on EMNLP and CoNLL,
pages 466–477. ACL.

E. Fry. 1990. A readability formula for short passages.
Journal of Reading, pages 594–597.

M. J. Heilman, K. Collins-Thompson, J. Callan, and
M. Eskenazi. 2007. Combining lexical and gram-
matical features to improve readability measures for
first and second language texts. In Proc. of NAACL
HLT, pages 460–467.

R.A. Hudson. 1995. Measuring syntactic difficulty.
Manuscript, University College, London.

R.J. Kate, X. Luo, S. Patwardhan, M. Franz, R. Flo-
rian, R.J. Mooney, S. Roukos, and C. Welty. 2010.
Learning to predict readability using diverse linguis-
tic features. In Proc. of the 23rd COLING, pages
546–554. ACL.

J.P. Kincaid, R. Fishburne, R.L. Rogers, and B.S.
Chissom. 1975. Derivation of new readability for-
mulas for navy enlisted personnel.

U. B. Kjærulff and A. L. Madsen. 2007. Bayesian Net-
works and Influence Diagrams. Information science
and statistics. Springer New York.

D. Klein and C. Manning. 2003. Accurate unlexical-
ized parsing. In Proc. of the 41st ACL, pages 423–
430. ACL.

P. Martı́nez-Gómez, C. Chen, T. Hara, Y. Kano, and
A. Aizawa. 2012. Image registration for text-gaze
alignment. In Proc. of the IUI’12, pages 257–260.

G.H. Mc Laughlin. 1969. SMOG grading-a new read-
ability formula. Journal of reading, pages 639–646.

Y. Miyao and J. Tsujii. 2008. Feature forest models
for probabilistic HPSG parsing. Computational Lin-
guistics, 34:35–80, March.

S.E. Petersen and M. Ostendorf. 2009. A ma-
chine learning approach to reading level assessment.
Computer Speech & Language, 23(1):89–106.

K. Raghunathan, H. Lee, S. Rangarajan, N. Chambers,
M. Surdeanu, D. Jurafsky, and C. Manning. 2010. A
multi-pass sieve for coreference resolution. In Proc.
of the 2010 on EMNLP, pages 492–501. ACL.

K. Rayner and S.A. Duffy. 1986. Lexical complex-
ity and fixation times in reading: Effects of word
frequency, verb complexity, and lexical ambiguity.
Memory & Cognition, 14(3):191–201.

L. Si and J. Callan. 2001. A statistical model for sci-
entific readability. In Proc. of the 10th CIKM, pages
574–576. ACL.

A. Siddharthan. 2003. Syntactic Simplification and
Text Cohesion. Ph.D. thesis, University of Cam-
bridge.

J.R. Smith, C. Quirk, and K. Toutanova. 2010. Ex-
tracting parallel sentences from comparable corpora
using document level alignment. In HLT: The 2010
NA-ACL, pages 403–411. ACL.

R.L. Weide. 1998. The CMU pronunciation dictio-
nary, release 0.6.

M. West and G.B. Jeffery. 1953. A general service list
of English words. Longmans, Green London.

S. Williams and E. Reiter. 2005. Generating readable
texts for readers with low basic skills. In Proc. of
the 10th European Workshop on Natural Language
Generation.

1391


