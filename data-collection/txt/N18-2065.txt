



















































Consistent CCG Parsing over Multiple Sentences for Improved Logical Reasoning


Proceedings of NAACL-HLT 2018, pages 407–412
New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics

Consistent CCG Parsing over Multiple Sentences
for Improved Logical Reasoning

Masashi Yoshikawa1
yoshikawa.masashi.yh8@is.naist.jp

Koji Mineshima2
mineshima.koji@ocha.ac.jp

Hiroshi Noji3
hiroshi.noji@aist.go.jp

Daisuke Bekki2
bekki@is.ocha.ac.jp

1Nara Institute of Science and Technology, Nara, Japan
2Ochanomizu University, Tokyo, Japan

3Artificial Intelligence Research Center, AIST, Tokyo, Japan

Abstract
In formal logic-based approaches to Recogniz-
ing Textual Entailment (RTE), a Combinatory
Categorial Grammar (CCG) parser is used to
parse input premises and hypotheses to obtain
their logical formulas. Here, it is important
that the parser processes the sentences consis-
tently; failing to recognize a similar syntactic
structure results in inconsistent predicate argu-
ment structures among them, in which case the
succeeding theorem proving is doomed to fail-
ure. In this work, we present a simple method
to extend an existing CCG parser to parse a set
of sentences consistently, which is achieved
with an inter-sentence modeling with Markov
Random Fields (MRF). When combined with
existing logic-based systems, our method al-
ways shows improvement in the RTE experi-
ments on English and Japanese languages.

1 Introduction

While today’s neural network-based syntactic
parsers (Dyer et al., 2016; Dozat and Manning,
2017; Yoshikawa et al., 2017) have proven suc-
cessful on sentence level modeling, it is still chal-
lenging to accurately process texts that go beyond
a single sentence (e.g. coreference resolution, dis-
course structure analysis). In this work we focus,
among others, on the consistent analysis of multi-
ple sentences in a document. This is as an impor-
tant problem in reasoning tasks as other document
analysis.

RTE is an elemental technology for semantic
analysis of multiple sentences, where, given a text
(T) and a hypothesis (H), a system determines if
T entails H. Existing methods based on formal
logic (Bos, 2008; Martı́nez-Gómez et al., 2017;
Abzianidze, 2017) obtain logical formulas for T
and H using an off-the-shelf CCG parser, and then
feed them to a theorem prover. The standard ap-
proach to mapping CCG trees onto logical formu-
las is to assign λ-terms to the words in a sentence

(a) An example semantic template:
V ⊢ S\NP : λF.(∃x.(F (x) ∧ ∃e.V (e, x)))

(b) T: A man is exercising
NP (S\NP)/(S\NP) S\NP

>
S\NP

<
S :

∃x.(man(x) ∧ ∃e.exercise(e, x))

H: There is a man exercising
NP S\NP/NP NP/N N /N N

...
S :

∃x.(man(x) ∧ exercise(x))

Figure 1: (a) An example semantic template for verbs
V that associates a CCG category S\NP with a λ-
term. (b) A logical formula of a sentence is obtained
at the root of a tree by composing λ-terms of all words
following CCG combinatory rules. In this Figure, hy-
pothesis H is wrongly parsed (See the text for details).

and combine them in a bottom-up fashion (Fig-
ure 1a). Here, when the parser fails to make con-
sistent analyses for T and H, the succeeding in-
ference component is also doomed to failure. In
Figure 1b, when the parser wrongly analyzes “man
exercising” in H as “man” modifying “exercising”,
the entailment relation cannot be established, due
to the different argument structures of exercise
in the resulting formulas.

While it is ideal to enhance the overall per-
formance of a parser, it is not cheaply obtain-
able. Additionally, neural network-based parsers
are susceptible to subtle changes in the input and
thus hard to inspect and modify its parameters to
change its prediction. Due to this, we cannot ex-
pect that a particular pair of words across multiple
sentences be always analyzed in a consistent man-
ner.

In this work, we solve the inconsistency prob-

407



lem above by adapting the inter-sentence model of
Rush et al. (2012) to CCG parsing. Their moti-
vation is to exploit the similarities among test sen-
tences to overcome situations where the amount of
the training data is scarce or its domain is differ-
ent from the test data. The method based on dual
decomposition tries to find parse trees for a set of
sentences that agree with an MRF, which encour-
ages the assignment of a similar structure to simi-
lar contexts.

In our approach, we aim to eliminate wrong
logical formulas such as in Figure 1 by reward-
ing consistent CCG parses across sentences. This,
in turn, is achieved by rewarding the consistent
assignment of categories to the terminals. This
works for CCG parsing, as its derivation is mostly
determined by the terminal categories. The key of
our approach is that by combining A* parsing of
Yoshikawa et al. (2017) with dual decomposition,
we can keep small the latency incurred by the use
of the iterative algorithm.

We conducted experiments using two state-
of-the-art logic-based systems (Martı́nez-Gómez
et al., 2017; Abzianidze, 2017) and two RTE
datasets for English and Japanese languages. Our
method always shows improvement compared to
the baselines.

2 Method

We describe our approach of modeling the
inter-consistencies among CCG trees Y =
⟨y1, . . . ,yN ⟩ for sentences X = ⟨x1, . . . ,xN ⟩
(§2.1), 1 A* parsing method for each yi (§2.2) and
joint decoding of the MRF and A* parsing using
dual decomposition (§2.3).

2.1 Document Consistencies with MRF

To model inter-consistencies among CCG parses,
we adapt the global MRF model of Rush et al.
(2012). See Figure 2 for an example MRF. Our
MRF encourages the assignment of similar cate-
gories to the words appearing in similar contexts.

Firstly we construct a graphical representation
of an MRF. For each context (unigram surface
form in the case of Figure 2) c ∈ C, we have a
set Wc of indices ⟨s, t⟩ that appear in c, where s is
a sentence index and t a word index on sentence

1 In this work, we focus on the inconsistency problem of
premises and hypotheses of RTE task, and thus X does not
contain sentences from any “training data”, as was done in
Rush et al. (2012). Exploiting external resources in the same
manner is also an interesting future direction.

H: There is no man exercising

T: A man is exercising

c3c2c1

Figure 2: An MRF graph is made up of cliques each
consisting of one context node (∈ C; circles) and word
nodes (∈ W ; rectangles) instantiating that context.
As such, each clique expresses the interdependencies
among words appearing across sentences.

s. Let W =
∪

c∈C Wc. We define an undirected
graph G = ⟨V,E⟩, whose vertices are V = C∪W
and edges E = {⟨w, c⟩ : c ∈ C,w ∈ Wc}. See
Figure 2 for an MRF graph constructed for an ex-
ample RTE problem.

We assign to each node in the graph a label
from a set of CCG categories T , so as to max-
imize the global consistency score g. By com-
bining g with local CCG parsing for each y, we
aim to obtain globally consistent trees Y (§2.3).
We define label assignment z to nodes in V as
z = ⟨z1, ..., z|W |, z′1, ..., z′|C|⟩ ∈ T |W | × T ′

|C|,
where T ′ = T ∪ {NULL}. In the following, zw
denotes the element in z at the index correspond-
ing to w ∈ W (similarly z′c for c ∈ C). Following
Rush et al. (2012), we allow NULL label for con-
text nodes. This works as a switch to “turn off”
the consistency constraints to the connected nodes.
Then, in the set Z(X) of all possible zs for X , we
look for z∗ = arg max

z∈Z(X)
g(z), where g(z) is2:

g(z) =
∑

w∈W
fw(zw) +

∑

(w,c)∈E
fw,c(zw, z

′
c).

To reward the consistent assignment of categories
among connected nodes, fw,c is defined as follow:

fw,c(zw, z
′
c) =





δ1 if zw = z′c
δ2 if simpl(zw) = simpl(z′c)
δ3 if z′c = NULL
0 otherwise,

where δ1 ≥ δ2 ≥ δ3 and simpl removes feature
values from a category (e.g. simpl(Sdcl\NP ) =
S\NP ). for fw, we use logPtag obtained by CCG

2 We omit unary terms fc for c ∈ C, as we set them 0.

408



parser (§2.2). We tune δis based on the RTE per-
formance on the development set.

Since the above MRF g(z) has a simple naı̈ve
Bayes structure, we can compute argmax using
dynamic programming.

2.2 A* CCG Parsing

To parse a sentence, we use the state-of-the-art
A* parsing method of Yoshikawa et al. (2017),
which treats a CCG tree y as a tuple ⟨c,h⟩ of cate-
gories c = ⟨c1, . . . , cM ⟩ and dependency structure
h = ⟨h1, . . . , hM ⟩, where each hi is a head index.
They model a tree with a locally factored model;
the probability of a CCG tree is the product of the
probabilities of the categories ptag and the depen-
dency heads pdep of all words in x:

p(y|x) =
∏

i∈[1,M ]
ptag(ci|x)

∏

i∈[1,M ]
pdep(hi|x).

Note that the most computationally heavy part of
their method is the calculation of Ptag|dep, which
needs to be done only once in our extension with
dual decomposition. The additional computational
cost of our method is rather small, as it depends
on the number of times to run A* algorithm on the
precomputed Ptag|dep, which is quite efficient.3

The probability P (Y |X) of parses Y for X un-
der this model is simply the product of all yis:

Y ∗ = arg max
Y ∈Y(X)

P (Y |X)

= arg max
Y ∈Y(X)

∑

yi∈Y
log p(yi|xi),

where Y(X) is the space of all possible parses for
X .

2.3 Dual Decomposition

To obtain CCG parses Y for sentences X that are
optimal in terms of both the global consistency
model (§2.1) and the local parsing model (§2.2),
we solve the following problem using dual decom-
position:

(Y ∗, z∗) = arg max
Y ∈Y(X),z∈Z(X)

P (Y |X) + g(z)

s.t. ∀⟨s, t⟩ ∈ W zs,t = cs,t,
3 The supertagger of depccg processes 54 sentences per

second while its A* decoder 2463 sentences per second. This
is measured on SICK test set consisting of 9854 sentences
using 2.20 GHz Intel Xeon CPUs with 16 cores.

Algorithm 1 Joint CCG parsing and global MRF
decoding

▷ J : a set of pairs of word nodes and categories in MRF
▷ α: step size (0.0 < α ≤ 1.0)
Let J = {⟨w, c⟩|w ∈W, c ∈ T }
Let 1c(z) = 1 if z equals to c else 0
u
(1)
w,c ← 0 ∀⟨w, c⟩ ∈ J

for k = 1, . . . ,K do
z(k) ← arg max

z∈Z(X)
g(z) +

∑

⟨w,c⟩∈J
u
(k)
w,c1c(zw)

Y (k) ← arg max
Y ∈Y(X)

P (Y |X)−
∑

⟨w,c⟩∈J
u
(k)
w,c1c(cw)

if z(k)w = c(k)w for all w ∈W then
return ⟨z(k), Y (k)⟩

u
(k+1)
w,c ← u(k)w,c+α(1c(z(k)w )−1c(c(k)w )) ∀⟨w, c⟩ ∈ J

return ⟨z(K), Y (K)⟩

where cs,t is the category assigned on t’th word in
ys. The condition in the equation states that the
decoded Y ∗ and z∗ must agree in the category as-
signment to word nodes in the MRF. Alg. 1 shows
the pseudocode for dual decomposition applied to
our method. Note that all the decoding subprob-
lems can be kept intact even when added the La-
grangian multiplier u of dual decomposition.

3 Experiments

3.1 Experimental Settings

English In English experiment, we test the per-
formance of ccg2lambda (Martı́nez-Gómez et al.,
2017) and LangPro (Abzianidze, 2017) on SICK
dataset (Marelli et al., 2014)4. As mentioned ear-
lier, these systems try to prove whether T en-
tails H, by applying a theorem prover to the log-
ical formulas converted from the CCG trees. We
report results for ccg2lambda with the default
settings (with SPSA abduction; Martı́nez-Gómez
et al. (2017)) and results for two versions of Lang-
Pro, one which is described in Abzianidze (2015)
(henceforth we refer to it as LangPro15) and the
other in Abzianidze (2017) (LangPro17).5 Briefly,
the difference between the two versions is that
LangPro17 is more robust to parse errors. See
the paper for the detail. For the CCG parser in
§2.2, we use depccg6 with an MRF in §2.1. We

4 We also conducted experiments on FraCaS
dataset (Cooper et al., 1996). For ccg2lambda, we found no
improvements in RTE performance with our MRF, while for
LangPro, we found that MRF guides to solve additional two
problems.

5 We report the scores for LangPro improved from the
reviewed version, which we obtained from the author through
the personal communication after the acceptance.

6https://github.com/masashi-y/depccg

409



Method Accuracy Precision Recall
LangPro15 (Abzianidze, 2015)
EasyCCG 79.05 98.00 52.67
depccg 80.37 97.94 55.81
depccg + MRF 80.88 97.91 57.03

LangPro17 (Abzianidze, 2017)
EasyCCG 81.04 97.47 57.69
depccg 81.53 97.51 58.81
depccg + MRF 81.61 97.52 59.00

ccg2lambda (Martı́nez-Gómez et al., 2017)
EasyCCG 81.59 97.73 58.48
depccg 81.95 97.19 59.98
depccg + MRF 82.86 97.14 62.18

Table 1: RTE results on test section of SICK

compare our results with depccg without the MRF
and baselines reported in the above papers that use
EasyCCG (Lewis and Steedman, 2014).

In MRF, a context node is constructed when
two or more words from both T and H share
the same surface form. Exceptionally, some
pairs of categories are allowed to be aligned with
score δ1: a pair of noun modifier (N/N ) and
verb tense (Sng\NP ), which are categories for
present participles, and a pair of nominal modi-
fier (N/N ) and noun (N ). In the experiment us-
ing ccg2lambda the pairs of categories of tran-
sitive and intransitive verbs, ((SX\NP )/NP ,
SX\NP ) and ((SX\NP )/PP , SX\NP ), for any
feature X are also allowed with δ1.

For the hyperparamters, we conducted grid
search over [0.0, 0.1, . . . , 0.9] for each δi in the
MRF s.t. δ1 ≥ δ2 ≥ δ3 and found that δ1 =
0.9, δ2 = 0.1, δ3 = 0.0 works the best on SICK
trial set. We set α = 0.0002 and K = 500 in
Alg. 1. We decay α by 0.9 in every iteration.

Japanese In Japanese experiment, we eval-
uate ccg2lambda’s performance on JSeM
dataset (Kawazoe et al., 2017). To construct an
MRF graph, we processed RTE problems with
kuromoji7 and made a context node for a noun
or a verb followed by an adverb. The reason
why we use bigram POS tag-based context is
that the graph construction based on the surface
form has resulted in poor RTE performance, by
overgenerating MRF constraints. This may be
due to the fact that Japanese sentences are usually
tokenized into smaller units. We used depccg and
the same hyperparameters as English experiment.

7http://www.atilika.org/

Method Accuracy Precision Recall
jigg 75.0 92.7 65.4
depccg 67.87 88.34 56.77
depccg + MRF 71.31 88.88 62.24

Table 2: RTE results using ccg2lambda on JSeM

3.2 Results and Error Analysis
We show the results on SICK in Table 1. Our MRF
consistently contributes to the improvement of the
accuracies for both ccg2lambda and LangPro. We
observe the same tendency in the scores for all sys-
tems; with MRF, both the accuracy and recall for
the systems moderately improve and the systems
using depccg have higher recall and lower preci-
sion compared to the ones with EasyCCG (with
LangPro17 it marks higher precision as well).

In SICK, there are many instances of the con-
struction shown in Figure 1 (“There is no man ex-
ercising”, “There is no dog barking”, etc.), whose
correct reading is that the last verb (e.g. exer-
cising) is a present participle modifying a noun
(e.g. man). EasyCCG and default depccg wrongly
parse the last phrase (man exercising) as N/N N ,
where man modifies exercising. Our method cor-
rectly predicts N Sng\NP , by utilizing the paired
sentence (e.g. “A man is exercising”), in which the
role of exercising is less ambiguous.

Given that the strength of LangPro17 is its ro-
bustness to parse errors such as PP-attachment, the
larger gain in the accuracy for LangPro15 (roughly
0.5 versus 0.1 point up) indicates that our method
is also robust in handling well-known difficult
parsing problems. The example (a) in Table 3 is a
case of coordinate construction. Baseline depccg
wrongly coordinates crocheting with a noun sofa,
while our method successfully resolves the correct
coordinate structure by assigning Sng\NP to the
word (hence attaching it to sitting). Example (b) is
one of the cases of PP-attachment that our method
successfully resolved. Our method relocates the
two PPs in T in their correct places. As in the
example in Figure 1, our method corrects cases
like (a) and (b) by using the structure of the less
ambiguous counterpart as a guide. In the case of
(c), the existing parsers misclassify outdoors in T
as a noun and turns the verb run into a transitive
verb. With our method, intransitive verb run in H
works as a soft constraint on the verb in T and cor-
rects its structure successfully. However, there are
some cases where using only surface forms as a
cue forces the assignment of categories which is

410



Sentences

(a)
T: The girl is sitting on the couch and is [Sng\NP crocheting]
H: The girl is sitting on the sofa and crocheting
crocheting: 7 N ; 3 Sng\NP

(b)

T: A veteran is showing different things from a war to some people
H: Different things [(NP\NP )/NP from] a war are being shown [((S\NP )\(S\NP ))/NP to] some people by a veteran
from: 7 ((S\NP )\(S\NP ))/NP ; 3 (NP\NP )/NP
to: 7 (NP\NP )/NP ; 3 ((S\NP )\(S\NP ))/NP

(c)
T: A few man in a competition are [Sng\NP running] outside
H: A few man in a competition are running outdoors
running: 7 (Sng\NP )/NP ; 3Sng\NP

(d)
T: A man is [(Sng\NP )/NP eating] some food
H: The person is eating
eating: 3 Sng\NP ; 7 (Sng\NP )/NP

Table 3: Example parse results in SICK test set. (a), (b), (c) With the global MRF model, words in bold font
previously assigned a wrong category (7) have been assigned a correct one (3). (d) is a case where the MRF is too
strict and leads to the wrong assignment.

consistent but not desirable. In example (d), eat is
used as a transitive verb in T and as an intransitive
verb in H; thus it should have different categories.

We show the results on JSeM in Table 2. The
RTE performance for Japanese language has im-
proved consistently across all the scores when we
add an MRF. However all the scores with depccg
(with or without MRF) lag behind the scores re-
ported in Mineshima et al. (2016), which uses a
CCG parser implemented in Jigg (Noji and Miyao,
2016). We hypothesize that this is due to the fact
that the previous work created the semantic tem-
plates for this language by analyzing parse outputs
by Jigg and this resulted in a kind of “overfitting”
in the templates.

In the above experiments, our method worked
well, mainly due to the fact that the sentences in
these datasets have comparably simple structure.
However, in other datasets, there are naturally
more complex cases as in Table 3 (d), where we
want different syntactic analyses for occurences of
words with the same surface form. We can counter
these cases by simply extending the definition of
“context” by N-grams or the use of POS tag as
we did in the Japanese experiment. Developing a
machine learning-based method that selects which
contexts to use and set δis automatically is also an
important future work.

4 Conclusion and Future Work

In this work, by modeling the inter-consistencies
of multiple sentences in CCG parsing, we have
successfully improved the performance of the for-
mal logic-based methods to RTE. Still, there can

be pairs of words in more complex RTE problems
that should not have the same category but that
our method wrongly force them to. This is mainly
due to the fact that we hand-tuned rules to con-
struct context nodes. In future work, we extend
the method so that it learns when to set an MRF
constraint.

Acknowledgments

First of all, we thank the three anonymous re-
viewers for their insightful comments. We are
also grateful to Lasha Abzianidze for conducting
in-depth experiments and for detailed discussion
about LangPro. This work was supported by JST
CREST Grant Number JPMJCR1301, Japan.

References
Lasha Abzianidze. 2015. A tableau prover for natural

logic and language. In Proceedings of the 2015 Con-
ference on Empirical Methods in Natural Language
Processing. Association for Computational Linguis-
tics, Lisbon, Portugal, pages 2492–2502. http:
//aclweb.org/anthology/D15-1296.

Lasha Abzianidze. 2017. LangPro: Natural Language
Theorem Prover. In Proceedings of the 2017 Con-
ference on Empirical Methods in Natural Language
Processing: System Demonstrations. Association
for Computational Linguistics, Copenhagen, Den-
mark, pages 115–120. http://www.aclweb.
org/anthology/D17-2020.

Johan Bos. 2008. Wide-coverage Semantic Anal-
ysis with Boxer. In Proceedings of the 2008
Conference on Semantics in Text Processing.
Association for Computational Linguistics, Strouds-
burg, PA, USA, STEP ’08, pages 277–286.

411



http://dl.acm.org/citation.cfm?id=
1626481.1626503.

Robin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox,
Josef Van Genabith, Jan Jaspars, Hans Kamp, David
Milward, Manfred Pinkal, Massimo Poesio, Steve
Pulman, Ted Briscoe, Holger Maier, and Karsten
Konrad. 1996. FraCaS: A Framework for Compu-
tational Semantics. Deliverable D16.

Timothy Dozat and Christopher D. Manning. 2017.
Deep Biaffine Attention for Neural Dependency
Parsing. In Proc. of ICLR https://arxiv.
org/abs/1611.01734.

Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros,
and Noah A. Smith. 2016. Recurrent Neu-
ral Network Grammars. In Proceedings of the
2016 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies. Association
for Computational Linguistics, San Diego, Cali-
fornia, pages 199–209. http://www.aclweb.
org/anthology/N16-1024.

Ai Kawazoe, Ribeka Tanaka, Koji Mineshima, and
Daisuke Bekki. 2017. An inference problem set for
evaluating semantic theories and semantic process-
ing systems for japanese. In Mihoko Otake, Set-
suya Kurahashi, Yuiko Ota, Ken Satoh, and Daisuke
Bekki, editors, New Frontiers in Artificial Intel-
ligence: JSAI-isAI 2015 Workshops, LENLS, JU-
RISIN, AAA, HAT-MASH, TSDAA, ASD-HR, and
SKL, Kanagawa, Japan, November 16-18, 2015, Re-
vised Selected Papers. Springer International Pub-
lishing, Cham, pages 58–65. https://doi.
org/10.1007/978-3-319-50953-2_5.

Mike Lewis and Mark Steedman. 2014. A* CCG Pars-
ing with a Supertag-factored Model. In Proceed-
ings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP).
Association for Computational Linguistics, pages
990–1000. https://doi.org/10.3115/v1/
D14-1107.

Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella bernardi, and Roberto Zampar-
elli. 2014. A SICK cure for the evaluation of compo-
sitional distributional semantic models. In Nicoletta
Calzolari, Khalid Choukri, Thierry Declerck,
Hrafn Loftsson, Bente Maegaard, Joseph Mariani,
Asuncion Moreno, Jan Odijk, and Stelios Piperidis,
editors, Proceedings of the Ninth International
Conference on Language Resources and Evaluation
(LREC’14). European Language Resources Associ-
ation (ELRA), Reykjavik, Iceland, pages 216–223.
ACL Anthology Identifier: L14-1314. http:
//www.lrec-conf.org/proceedings/
lrec2014/pdf/363_Paper.pdf.

Pascual Martı́nez-Gómez, Koji Mineshima, Yusuke
Miyao, and Daisuke Bekki. 2017. On-demand In-
jection of Lexical Knowledge for Recognising Tex-
tual Entailment. In Proceedings of the 15th Con-

ference of the European Chapter of the Associa-
tion for Computational Linguistics: Volume 1, Long
Papers. Association for Computational Linguistics,
Valencia, Spain, pages 710–720. http://www.
aclweb.org/anthology/E17-1067.

Koji Mineshima, Ribeka Tanaka, Pascual Martı́nez-
Gómez, Yusuke Miyao, and Daisuke Bekki. 2016.
Building compositional semantics and higher-order
inference system for a wide-coverage Japanese CCG
parser. In Proceedings of the 2016 Conference
on Empirical Methods in Natural Language Pro-
cessing. Association for Computational Linguis-
tics, Austin, Texas, pages 2236–2242. https:
//aclweb.org/anthology/D16-1242.

Hiroshi Noji and Yusuke Miyao. 2016. Jigg: A
Framework for an Easy Natural Language Process-
ing Pipeline. In Proceedings of ACL-2016 Sys-
tem Demonstrations. Association for Computational
Linguistics, pages 103–108. https://doi.
org/10.18653/v1/P16-4018.

Alexander Rush, Roi Reichart, Michael Collins,
and Amir Globerson. 2012. Improved Pars-
ing and POS Tagging Using Inter-Sentence Con-
sistency Constraints. In Proceedings of the
2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computa-
tional Natural Language Learning. Association
for Computational Linguistics, Jeju Island, Korea,
pages 1434–1444. http://www.aclweb.org/
anthology/D12-1131.

Masashi Yoshikawa, Hiroshi Noji, and Yuji Mat-
sumoto. 2017. A* CCG Parsing with a Supertag and
Dependency Factored Model. In Proceedings of the
55th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers). As-
sociation for Computational Linguistics, Vancou-
ver, Canada, pages 277–287. http://aclweb.
org/anthology/P17-1026.

412


