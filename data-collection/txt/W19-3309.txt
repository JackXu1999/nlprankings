



















































Meta-Semantic Representation for Early Detection of Alzheimer's Disease


Proceedings of the First International Workshop on Designing Meaning Representations, pages 82–91
Florence, Italy, August 1st, 2019 c©2019 Association for Computational Linguistics

82

Meta-Semantic Representation for Early Detection of Alzheimer’s Disease

Jinho D. Choi
Computer Science
Emory University
Atlanta, GA, USA
jchoi31@emory.edu

Mengmei Li
Computer Science
Emory University
Atlanta, GA, USA
kate.li@emory.edu

Felicia Goldstein
Neurology

Emory University
Atlanta, GA, USA
fgoldst@emory.edu

Ihab Hajjar
Neurology

Emory University
Atlanta, GA, USA
ihajjar@emory.edu

Abstract
This paper presents a new task-oriented mean-
ing representation called meta-semantics, that
is designed to detect patients with early symp-
toms of Alzheimer’s disease by analyzing their
language beyond a syntactic or semantic level.
Meta-semantic representation consists of three
parts, entities, predicate argument structures,
and discourse attributes, that derive rich knowl-
edge graphs. For this study, 50 controls and 50
patients with mild cognitive impairment (MCI)
are selected, and meta-semantic representation
is annotated on their speeches transcribed in
text. Inter-annotator agreement scores of 88%,
82%, and 89% are achieved for the three types
of annotation, respectively. Five analyses are
made using this annotation, depicting clear dis-
tinctions between the control and MCI groups.
Finally, a neural model is trained on features
extracted from those analyses to classify MCI
patients from normal controls, showing a high
accuracy of 82% that is very promising.

1 Introduction

Our understanding of Alzheimers disease (AD) has
evolved over the last few decades. Most notably is
the discovery that AD has long latent preclinical
and mild cognitive impairment (MCI) stages (Karr
et al., 2018; Steenland et al., 2018). These stages
are the focus of many prevention and therapeutic
interventions. A key limitation in identifying these
pre-dementia stages for clinical trial recruitment
is the need for expensive or invasive testing like
positron emission tomography or obtaining cere-
brospinal fluid (CSF) analyses. Traditional cogni-
tive testing is time-consuming and can be biased
by literacy and test-taking skills (Fyffe et al., 2011).
Recent advances in natural language processing
(NLP) offer the unique opportunity to explore pre-
viously undetectable changes in the cognitive pro-
cess of semantics that can be automated in clinical
artificial intelligence (Beam and Kohane, 2016).

Limited prior studies have suggested the feasibil-
ity of detecting AD by analyzing language varia-
tions. One approach includes linguistically moti-
vated analysis extracting lexical, grammatical, and
syntactic features to detect language deficits in AD
patients (Fraser et al., 2016; Orimaye et al., 2017).
The other approach involves deep learning models
to extract features from languages used by AD pa-
tients (Orimaye et al., 2016; Karlekar et al., 2018).
The limitations of these studies are that most were
developed based on dementia cases, so their ability
to detect pre-dementia is still unknown. The impact
of these methods is the highest in the cases where
traditional cognitive measures are unable to clarify
the patients cognitive status. Hence, we focus on
these early MCI stages in this study.

We suggest a new meaning representation called
meta-semantics that derives a knowledge graph re-
flecting semantic, pragmatic, and discourse aspects
of language spoken by MCI patients. The objective
of this representation is not to design yet another
structure to capture more information but to sense
aspects beyond the syntax and semantic level that
are essential for the early detection of MCI patients.
We hypothesize that patients in the pre-dementia
stage do not necessarily make so much of grammat-
ical mistakes compared to normal people but often
have difficulties in elaborating or articulating their
thoughts in language. To verify our hypothesis, we
collect speeches from 50 normal controls and 50
MCI patients that standardized cognition tests fail
to distinguish (Section 2), annotate meta-semantic
representation on the transcripts of those speeches
(Section 3), make several analyses to comprehend
linguistic differences between the control and the
MCI groups (Section 4), then develop a neural net-
work model to detect MCI patients from normal
controls (Section 5). To the best of our knowledge,
this is the first time that a dedicated meaning repre-
sentation is proposed for the detection of MCI.



83

2 Data Preparation

We analyzed data from 100 subjects collected as
part of the B-SHARP, Brain, Stress, Hypertension,
and Aging Research Program.1 50 cognitively nor-
mal controls and 50 patients with mild cognitive im-
pairment (MCI) were selected based on neuropsy-
chological and clinical assessments performed by a
trained physician and a neuropsychologist. The two
groups were matched on overall cognitive scores to
examine how well our new meta-semantic indices
would perform in the setting where standardized
tests such as the Montreal Cognitive Assessment
(Nasreddine et al., 2005) and the Boston Naming
Test (Kaplan et al., 1983) failed to distinguish them.
Table 1 shows demographics and clinical features
of the control and the MCI groups.

Type Control MCI P-value
Age 65.6 (±6.80) 66.0 (±8.38) 0.809
Race 54%; 44% 58%; 42% 0.840
Sex 62% 60% 1.000

Education 54% 56% 1.000
MoCA 24.2 (±2.15) 23.9 (±2.00) 0.502
BNT 14.0 (±1.43) 13.8 (±1.23) 0.550
CDR 0.01 (±0.07) 0.43 (±0.18) <0.001
FAQ 1.00 (±1.62) 1.71 (±2.57) 0.103

Table 1: Demographics and clinical features of the two
groups. Age: avg-years, Race: % African American;
% Non-Hispanic Caucasian, Sex: % female, Education:
% Bachelor’s or above, MoCA (Montreal Cognitive
Assessment): avg-score, BNT (Boston Naming Test):
avg-score, CDR (Clinical Dementia Rating): avg-score,
FAQ (Function Assessment Questionnaire): avg-score.
The p-values are evaluated by the t-test except for race,
sex, and education which are evaluated by the χ2 test.

No significant group differences were found in age,
race, sex, or education between these two groups.
The MCI group performed significantly worse on
the Clinical Dementia Rating (Morris, 1994), but
did not differ as much on the Function Assessment
Questionnaire (Pfeffer et al., 1982) assessing in-
strumental activities of daily living.

2.1 Speech Task Protocol

We conducted a speech task protocol that evaluated
subjects’ language abilities on 1) natural speech, 2)
fluency, and 3) picture description, and collected au-
dio recordings for all three tasks from each subject.
For this study, the audio recordings from the third
task, picture description, were used to demonstrate

1B-SHARP: http://medicine.emory.edu/bsharp

the effectiveness of the meta-semantics analysis on
detecting MCI. All subjects were shown the picture
in Figure 1, The Circus Procession, copyrighted by
McLoughlin Brothers as part of the Juvenile Col-
lection, and given the same instruction to describe
the picture for one minute. Visual abilities of the
subjects were confirmed before recording.

Figure 1: The image of “The Circus Procession” used
for the picture description task.

2.2 Transcription

Audio recordings for the picture description task
(Section 2.1) from the 100 subjects in Table 1 were
automatically transcribed by the online tool, Temi,2

then manually corrected. Table 3 shows transcripts
from a normal control and an MCI patient whose
MoCA scores are matched to 29 (out of 30 points).
For the annotation of meta-semantic representa-
tion in Section 3, all transcripts were tokenized by
the open-source NLP toolkit called ELIT.3 Table 2
shows general statistics of these transcripts from
the output automatically generated by the part-of-
speech tagger and the dependency parser in ELIT.

Type Control MCI P-value
T 174.32 (±40.14) 175.04 (±48.01) 0.936
S 11.34 (±3.08) 11.22 (±3.73) 0.862
N 36.32 (±8.62) 38.06 (±12.25) 0.418
V 27.10 (±7.44) 24.50 (±6.93) 0.077
C 7.74 (±4.25) 7.54 (±4.42) 0.820

RN 2.36 (±1.82) 1.64 (±1.67) 0.044
CM 4.52 (±2.74) 4.30 (±2.15) 0.659

Table 2: Statistics of transcripts from the two groups.
The avg-count and the stdev are reported for each field.
T: tokens, S: sentences, N: nouns, V: verbs, C: con-
juncts, RN: relative clauses and non-finite modifiers,
CM: clausal modifiers or complements. The p-values
are evaluated by the t-test.

2Temi: https://www.temi.com
3ELIT: https://github.com/elitcloud/elit

http://medicine.emory.edu/bsharp
https://www.temi.com
https://github.com/elitcloud/elit


84

Control MCI
This is a what looks like a circus poster. The title is the Circus
Procession. There’s an off color green background. On the left-
hand side is elephant in a costume peddling a tricycle, operating
a tricycle. On the right side is another elephant with holding a
fan. He’s dressed in an outfit with a hat and a cane. There are
two people in the background and they could be either men or
women. And then there are three, I’ll take that back. And then
the foreground is a clown in a white suit with red trim. It was
copyrighted in 1988 by the McLoughlin Brothers, New York
or NY. Um, there’s a black border. Um, the, there are shadows
represented by some brown color at the bottom.

It’s a circus poster. Going left to right is an elephant standing
on its side legs, and a, um, vest, a tie and a red Tuxedo coat,
and um yellow cap with a black band holding what appears to
be a fan in its trunk. The elephant has glasses and a cane. Um,
the top, says the Circus Procession. To the left of the elephant
is a clown in a white and red costume with red and black paint
on his face, red hair or shoes. And there appear to be three like
soldiers, um gray suits, yellow trim, um, um, red hair. To the
left of them, there’s another elephant, riding a bicycle. This
elephant has pants to red bicycle. He’s got a regular coat of his
and a red bow tie.

Table 3: Transcripts from a normal control and an MCI patient whose MoCA scores are 29 points.

No significant group differences were found in text-
level counts (tokens and sentences), grammatical
categories (nouns and verbs), or syntactic structures
(conjuncts, clausal modifiers or complements), ex-
cept for the relative clauses and non-finite modifiers
whose p-value is less than 0.05. The MCI group
used notably a fewer number of verbs although the
difference to the control group was not significant.

3 Meta-Semantic Representation

We organized a team of two undergraduate students
in Linguistics to annotate meta-semantic represen-
tation on the transcripts from Section 2.2 such that
every transcript was annotated by two people and
adjudicated by an expert. The web-based annota-
tion tool called BRAT was used for this annotation
(Stenetorp et al., 2012), where the entire content of
each transcript was displayed at a time. Figure 2
shows a screenshot of our annotation interface us-
ing BRAT on the control example in Table 3.

Figure 2: A screenshot of our annotation interface us-
ing the web-based tool BRAT on the first five sentences
of the control example in Table 3.

Meta-semantic representation involves three types
of annotation, entities (Section 3.1), predicate argu-
ment structures (Section 3.2), discourse attributes
(Section 3.3), as well as few other miscellaneous
components (Section 3.4). The following sections
give a brief overview of our annotation guidelines.

3.1 Entities
To analyze which and how objects in the picture are
described by individual subjects, every object men-
tioned in the transcript is identified as either a pre-
defined entity or an unknown entity. All nominals
including pronouns, proper nouns, common nouns,
and noun phrases are considered potential mentions.
Table 4 shows the list of 50 predefined entities that
are frequently mentioned in the transcripts.

Main Entity Sub Entities

Picture
Background, Border, Copyright,
Parade, Shadow, Title

Elephant L
EL Beanie, EL Collar, EL Head,
EL Jacket, EL Pants, EL Tie,
EL Tricycle, EL Trunk

Elephant R

ER Fedora, ER Coat, ER Vest,
ER Cane, ER Fan, ER Glasses,
ER Head, ER Collar, ER Pants,
ER Tie, ER Hand, ER Feet,
ER Trunk, ER Hanky

Men
Man L, Man M, Man R, M Boots,
M Costume, M Cross, M Flag,
M Hat, M Plume, M Sword

Clown
CL Face, CL Hair, CL Head,
CL Pants, CL Ruffle, CL Shoes,
CL Suit

Table 4: Predefined entities, where the main entities in-
dicate the 5 conspicuous objects in Figure 1 and the sub
entities indicate objects that belong to the main entities.

In the example below, five mentions are found and
can be linked to four entities as follows:

An elephant1 is holding a fan2. To the leftside
of him3, another elephant4 is riding a tricycle5.

• {elephant1, him3} → Elephant R
(elephant on the right)

• {elephant4} → Elephant L
(elephant on the left)

• {fan2} → ER Fan
• {tricycle5} → EL Tricycle



85

poster

circus

the Circus  
Procession

PICTURE

elephant

TITLE BACKGROUND ELEPHANT_L

background

On the 
lefthand side

costume

peddling

tricycle

operating

tricycle

On the 
right side

holding

fanattr

off color green

attr
withloc

age
nt

agent
theme theme

more
ELEPHANT_R

elephant
loc

theme
age

nt

EL_JACKETNmod Nmod Xmod EL_TRICYCLE Xmod ER_FAN

Figure 3: Visualization of meta-semantic representation on the first 5 sentences of the control example in Table 3.

The entity Men is a group of three people includ-
ing Man L, Man M, and Man R (man on the left,
middle, and right) as its sub entities. Such a group
entity is defined because subjects regularly describe
them together as one unit. Picture often refers
to the types of the picture that subjects view it as
(e.g., poster in Figure 2). Special kinds of entities,
Title and Copyright, are also defined that are
annotated on the literals (e.g., the Circus Proces-
sion in Figure 2, McLoughlin Brothers, 1888, N.Y.)
to see if subjects indeed recognize them correctly.
Any object that is either ambiguous or not prede-
fined is annotated as an unknown entity.

It is worth mentioning that unlike mention an-
notation for coreference resolution in OntoNotes
(Pradhan et al., 2012) where whole noun phrases
are annotated as mentions, function words such as
articles or determiners and modifiers such as ad-
verbs or adjectives are not considered part of men-
tions in our annotation, which is similar to abstract
meaning representation (Banarescu et al., 2013).
Such abstraction is more suitable for spoken data
where the usage of these function words and modi-
fiers is not so consistent.

3.2 Predicate Argument Structures

To analyze semantics of the entities as well as their
relations to one another, predicate argument struc-
tures are annotated. Note that meta-semantic repre-
sentation is entity-centric such that expressions that
do not describe the picture are discarded from the
annotation (e.g., When I was young, circus came to
my town all the time). Such expressions do not help
analyzing subjects’ capabilities in describing the
picture although they can be used for other kinds
of analyses which we will explore in the future.

Following the latest guidelines of PropBank (Bo-
nial et al., 2017), both verbal predicates, excluding
auxiliary and modal verbs, and nominal predicates,
including eventive nouns and nouns from light-verb
constructions, are considered in our representation.

Once predicates are identified, arguments are an-
notated with the following thematic roles (in the
examples, predicates are in italic, arguments are in
brackets, and thematic roles are in subscripts):

• agent: Prototypical agents
e.g., An [elephant]agent is holding a fan.

• theme: Prototypical patients or themes
e.g., An elephant is holding a [fan]theme.

• dative: Recipients or beneficiaries e.g., The
soldier is bringing a flag to the [circus]dative.

• adv: Adverbial modifiers
e.g., That elephant is [actually]adv walking.

• dir: Directional modifiers
e.g., Feathers are coming out of the [hat]dir.

• loc: Locative modifiers e.g., The clown is danc-
ing in between the [elephants]loc.

• mnr: Locative modifiers
e.g., Soldiers are marching [proudly]mnr.

• prp: Purpose or clausal modifiers e.g., The
clown is dancing to [tease]prp the elephants.

• tmp: Temporal modifiers e.g., This seemed to
be a poster made in the early [1900s]tmp.

If an argument is a preposition phrase, the thematic
role is annotated on the preposition object such that
in the example above, only the head noun [hat] is
annotated as dir instead of the entire preposition
phrase “out of the hat”.4 As shown in the prp
example, a predicate can be an argument of another
predicate. Note that modifiers do not need to be
arguments of only predicates but entities as well
(e.g., the elephant on the [tricycle]loc, a poster from
way back in [1990s]tmp).

The choice of these thematic roles are observa-
tional to the transcripts. No instance of dative is
found in our dataset but the role is still kept in the
guidelines for future annotation.
4See the case relation in Section 3.4 for more details about
how prepositions are handled in our annotation.



86

3.3 Discourse Attributes
To analyze discourse aspects of the transcripts, six
labels and one relation are annotated as follows (in
the examples, attributes are indicated in brackets):

ambiguous Objects contextually ambiguous to
identify are annotated with this label. For example,
both [elephant] and [something] are annotated as
ambiguous because it is unclear which elephant
and object they refer to. Also, [blue] likely refers to
the vest of Elephant R but not specified in this
context; thus, it is also annotated as ambiguous.

That [elephant] is holding [something].
The elephant with [blue] on is walking.

opinion Descriptions subjective to that partic-
ular subject are annotated with this label. For ex-
ample, ‘red’ is considered an objective fact agreed
by most subjects whereas [fancy] is considered a
subjective opinion, not necessarily agreed by
others. Similarly, [like a millionaire] is considered
subject’s opinion about the elephant’s costume.

The ‘red ’tie with the [fancy] shirt.
That elephant is dressed up [like a millionaire].

emotion Expressions that carry subjects’ emo-
tions or their views on objects’ emotions are anno-
tated with this label.

That clown looks [happy].
The elephant makes me [sad].

certain Adverbials or modals that express cer-
tainty are annotated with this label.

Those people [must] be women.
This is [obviously] an old poster.

fuzzy Adverbials or modals that express fuzzi-
ness are annotated with this label.

The elephant carries [some kind of] balloon.
I am [not sure] if the elephant is marching.

emphasis Adverbials used for emphasis are an-
notated with this label.

That tricycle is [very] big.
That clown is [definitely] enjoying this.

more Additional descriptions from appositions
and repetitions from repairs are annotated with this
relation (in the examples, ones in the brackets have
more relations to the ones in italic):

There are elephants, two [elephants]more, here.
This is the Circus Profession, [Procession]more.
That one is holding an umbrella, or a [fan]more.

[elephants] is an apposition that adds more infor-
mation to elephants. [Procession] is a prototypical
repair case that fixes the prior mention of Profes-
sion. [fan] may not be considered a repair in some
analysis, but it is in ours because it attempts to fix
the earlier mention of umbrella in a speech setting.

3.4 Miscellaneous
Two additional modifiers, Nmod and Xmod are an-
notated. Nmod are modifiers of nominals that mod-
ify entities with the attr relation:

A [polka dot]attr dress.
Very [big]attr [red and yellow]attr pants.

Xmod are any other types of modifiers, mostly ad-
verbials and prepositions. If adverbials, they are an-
notated with the adv relation in Sec 3.2. If prepo-
sitions, they are annotated with the case relation:

There is a [seemingly]adv dancing clown.
Feathers are coming [out of]case the hat.

Finally, possessions of entities are annotated with
the with relation regardless of verbs such as have
or get for the consistency across different structures.
In both of the following sentences, [jacket] has the
with relation to the elephant.

The elephant with a blue [jacket]with.
The elephant has a blue [jacket]with.

4 Meta-Semantic Analysis

Given the annotation in Section 3, several analyses
are made to observe how effective meta-semantic is
to distinguish the control (C) and MCI (M ) groups.

4.1 Entity Coverage Analysis
We anticipate that most subjects in C andM would
recognize the main entities whereas a fewer number
of sub entities would be commonly recognized by
M than C. For each entity ei, that is the i’th entity
in Table 4, two counts cci and c

m
i are measured such

that they are the numbers of subjects in C and M
whose transcripts include at least one mention of ei.
For instance, the entity e7 = Title is mentioned
by cc7 = 37 subjects in C and c

m
7 = 40 subjects in

M in our annotation.
Figure 4 shows how many entities are commonly

mentioned by each percentage range of the sub-
jects in C and M . For example, six entities are
commonly mentioned by 55∼75% of the subjects
in C whereas only three entities are commonly
mentioned by the same range of the subjects in M .
These percentage ranges are analyzed as follows:



87

0

2

4

6

8

10

12

14

15 - 35% 35 - 55% 55 - 75% 75 - 100%

N
um

be
r 

of
 E

nt
iti

es

Subject Percentage Range

Control MCI

Figure 4: Entity coverage analysis.

High range (75∼100%) No significant group
difference is found between C and M . 5 entities,
Elephant R, Elephant L, EL Tricycle,
Clown, and Men, are commonly mentioned by
C, whereas 6 entities (all of above + Title) are
commonly mentioned by M in this range.

Mid range (35∼75%) Subjects in M start not
recognizing certain entities recognized by subjects
in C in this range. 14 entities are commonly men-
tioned by C whereas 10 entities are mentioned by
M . When the range is fine-grained to 45∼75%, the
difference becomes even more significant such that
10 entities are commonly mentioned by C whereas
only 5 entities are mentioned by M in that range.

Low range (15∼35%) Similar to the high range,
no significant difference is found between the two
groups. 11 and 13 entities are commonly recog-
nized by C and M , respectively in this range.

For the whole range of 15∼75%, the plot from C
can be well fitted to a linear line withR2 = 0.9524,
whereas the one from M cannot, resulting signif-
icantly lower R2 = 0.5924. The plot from M
rather shows an inverted Gaussian distribution, im-
plying that the majority of M tends not to mention
about entities that are not immediately conspicuous
which is not necessarily the case for subjects in C.

4.2 Entity Focus Analysis
This analysis shows which entities are more fre-
quently mentioned (focused) by what subject group.
For each entity ei and its counts cci and c

m
i in Sec-

tion 4.1, the proportions pci and p
m
i are measured

such that pci = c
c
i/|C| and pmi = c

m
i /|M |, where

|C| = |M | = 50 (Table 1). Then, the relative dif-
ference dri for the i’th entity is measured as follow:

dri =
pci − pmi

max(pci , p
m
i )

Thus, if dri is greater than 0, ei is more commonly
mentioned by C; otherwise, it is by M . Figure 4
shows the entities that are significantly more men-
tioned by C (blue) and M (red), where |d|ri ≥ 0.2.
6 entities, CL Pants, M Boots, ER Glasses,
EL Collar, ER Trunk, M Flag, EL Pants,
ER Vest, and EL Jacket, are noticeably more
mentioned by C, whereas only 2 entities, EL Tie
and EL Hat, are byM , which are focused on those
two small parts of the left elephant. Additionally,
M mentions more about the Background, which
is not a specific object but an abstract environment.

 

Figure 5: Entity focus analysis. Entities focused by C
and M are colored in blue and red, respectively.

4.3 Entity Density Analysis

This analysis shows the proportion of the descrip-
tion used for each object in the transcript. Meta-
semantic representation forms a graph comprising
many isolated subgraphs. In Figure 3, there are 5
subgraphs, where the largest subgraph has 7 ver-
tices (the one with Elephant L) and the smallest
subgraph has only 1 vertex (the one with Title).

R² = 0.9312

R² = 0.9206

0
2
4
6
8

10
12
14
16
18
20

1 2 3 4 5 6 7 8 9 10 11 12 13

S
iz

e

Rank

Control
MCI
Linear (Control)
Expon. (MCI)

Figure 6: Plots of size lists derived from meta-semantic
representation annotated on the control and MCI exam-
ples in Table 3, where x and y axises are ranked indices
and sizes of the subgraphs, respectively.



88

Let Gt be a graph derived from meta-semantic rep-
resentation annotated on the t’th transcript. Gt can
be represented by a list of its subgraphs sorted in
descending order with respect to their sizes such
that Gt = [gt1, . . . , g

t
k] where |gi| ≥ |gj | for all

0 < i < j ≤ k. The size of a subgraph is deter-
mined by the number of vertices. For the graph in
Figure 3, G = [g1, . . . , g5] such that |G| = k = 5,
|g1| = 7, and |g5| = 1. Given Gt, the size list Lt
can be derived such that Lt = [|gt1|, . . . , |g|tk]. Fig-
ure 6 shows plots of the size lists from the graphs
derived by meta-semantic representation annotated
on the control and MCI examples in Table 3. The
control plot can be well-fitted to a linear line with
R2 = 0.9312, whereas the MCI plot is better fitted
to an exponential curve with R2 = 0.9206.

SSEd Control MCI P-value
d = 1 12.10 (±12.37) 17.50 (±22.43) 0.1394
d = 2 5.18 (±4.81) 7.08 (±7.54) 0.1370
d = 3 3.03 (±2.44) 4.01 (±3.83) 0.1278
d = 4 2.36 (±2.14) 2.55 (±2.12) 0.6661
d = 5 1.89 (±1.78) 1.78 (±1.54) 0.7391

Table 5: The average sums of squared errors by fitting
each size list to degrees 1-5 of polynomial functions.

Table 5 shows the average sums of squared errors
SSEd by fitting each size list Lt = [lt1, . . . , l

t
k] to

polynomial functions fd(x) of degrees d = [1, .., 5]
where n = 50 for both C and M :

SSEd =
1

n

n∑
t=1

|Lt|∑
i=1

(fd(i)− lti)2

The control plots fit to lower degree functions more
reliably than the MCI plots, although not statisti-
cally significant, implying that subjects in C dis-
tribute their time more evenly to describe different
entities than subjects in M who tend to spend most
of their time to describe a couple of entities but not
so much for the rest of the entities.

4.4 Predicate Argument Analysis
Figure 7 shows the average percentages of predi-
cates and their thematic arguments annotated on the
transcripts. Subjects in C generally form sentences
with more predicate argument structures although
the differences are not statistically significant. Not
enough instances of the modifiers (e.g., mnr, loc)
are found to make a meaningful analysis for those
roles. Although predicate argument structures may
not appear useful, these structures make it possible

to perform the entity density analysis in Section 4.3
and potentially other types of analyses, which we
will conduct in the future.

0

2

4

6

8

10

12

predicate agent theme mnr loc adv dir

%
 p

er
 T

ra
ns

cr
ip

t

Predicates and Thematic Roles

Control MCI

Figure 7: Predicate argument analysis.

4.5 Discourse Attribute Analysis
Figure 8 shows the average percentages of dis-
course attributes. Notice that M makes over twice
more ambiguousmentions thanC, implying that
MCI patients do not elaborate as well. Moreover,
M makes more fuzzy expressions and frequently
uses more relations to repair, which makes their
speeches less articulated. On the other hand, C
makes more subjective opinion and certain
expressions with emphasis, which makes their
speeches sound more confident. These are essen-
tial features to distinguish M from C, makes this
analysis more “meta-semantics”.

0

0.01

0.02

0.03

0.04

0.05

0.06

0.07

ambiguous opinion emotion certain fuzzy emphasis more

%
 p

er
 T

ra
ns

cr
ip

t

Discourse Attributes

Control MCI

Figure 8: Discourse attribute analysis.

5 Experiments

5.1 Inter-Annotator Agreement
The annotation guidelines summarized in Section 3
are established through multiple rounds of double
annotation and adjudication. During the final round,
the entity annotation, the predicate argument anno-
tation, and the discourse attribute annotation reach
the F1 scores of 88%, 82%, and 89% respectively
for the inter-annotator agreement, which yield high-
quality data ready for training statistical models.



89

5.2 Data Split

The 100 transcripts from Section 2 are split into 5
folds where each fold contains 10 transcripts from
the control group and another 10 transcripts from
the MCI group (so the total of 20 transcripts). To
evaluate our model that takes a transcript annotated
with meta-semantic representation as input and pre-
dicts whether or not it is from the MCI group, 5-
fold cross validation is used, which is suitable for
experimenting with such a small dataset.

5.3 Features

For each transcript, three types of features are ex-
tracted from the meta-semantic analysis in Sec-
tion 4 for the classifications of Control vs. MCI:

• Entity Types: A vector e ∈ R1×|E| is created
where |E| = 50 is the total number of predefined
entities in Table 4, and each dimension i of e
represents the occurrence of the corresponding
entity such that ei = 1 if the i’th entity appears
in the transcript; otherwise, ei = 0.

• Entity Densities: A vector d ∈ R1×|P | is cre-
ated where P = {1, 2, 3} (|P | = 3) consisting
of degrees used for the entity density analysis in
Section 4.3 (in this case, the polynomial func-
tions with degrees 1, 2, and 3 are used) such that
di is the sum of the squared error measured by
comparing the size list L of this transcript to the
fitted polynomial function of the degree i.

• Labels: A vector b ∈ R1×|N | is created where
N contains counts of predicates, thematic roles,
and discourse attributes in Sections 3.2 and 3.3
(|N | = 16) such that bi is the count of the corre-
sponding component in the transcript.

5.4 Classification

The feature vector x = e ⊕ d ⊕ b is created by
concatenating e, d, and b, and gets fed into a clas-
sifier. Figure 9 illustrates the feed-forward neural
network used for the classification between the con-
trol and the MCI groups. Let the size of the feature
vector x be s = |E| + |P | + |L|. Then, the input
vector x ∈ R1×s is multiplied by the weight matrix
W0 ∈ Rs×d0 and generates the first hidden vector
h1 = x·W0. The hidden vector h1 ∈ R1×d0 is mul-
tiplied by another weight matrix W1 ∈ Rd0×d1 and
generates the second hidden vector h2 = h1 ·W1.
Finally, h2 ∈ R1×d1 is multiplied by the last weight
matrix W2 ∈ Rd1×d2 where d2 is the number of

classes to be predicted, and generates the output
vector y = h2 ·W2 ∈ R1×d2 . In our case, the sizes
of the hidden vectors are d0 = 200 and d1 = 100,
and the size of the output vector is d2 = 2. Note
that we have experimented with simpler networks
comprising only one or no hidden layer, but the one
with two hidden layers shows the best results.

x

h1

h2

y

W0

W1

W2

Figure 9: Feed-forward neural network used for the
classification of the control vs. MCI group.

The two dimensions ym and yc in the output vec-
tor are optimized for the likelihoods of the subject
being control or MCI, respectively. The average
of 82% accuracy is achieved by the 5-fold cross-
validation (Section 5.2) with this model. Consid-
ering these are subjects that the standardized tests
such as MoCA or Boston Naming Test could not
distinguish (Table 1), this result is very promising.

6 Related Work

Reilly et al. (2010) found that neurodegenerative
disorders could deteriorate nerve cells controlling
cognitive, speech and language processes. Verma
and Howard (2012) reported that language impair-
ment in AD could affect verbal fluency and naming,
that requires integrity of semantic concepts, before
breaking down in other facets of the brain. Tillas
(2015) showed that linguistic clues captured from
verbal utterances could indicate symptoms of AD.

Toledo et al. (2018) investigated the significance
of lexical and syntactic features from verbal narra-
tives of AD patients by performing several statisti-
cal tests based on 121 elderly participants consist-
ing of 60 patients with AD and 61 control subjects.
In this work, immediate word repetitions, word re-
visions, and coordination structures could be used
to distinguish patients with AD from the control
group. Mueller et al. (2018) recently found that
AD patients often depicted less informative dis-
course, greater impairment in global coherence,
greater modularization, and inferior narrative struc-
ture compared to the normal control group.



90

References
Laura Banarescu, Claire Bonial, Shu Cai, Madalina

Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract Meaning Representation
for Sembanking. In Proceedings of the 7th Linguis-
tic Annotation Workshop and Interoperability with
Discourse, LAW-ID’13, pages 178–186.

A. L. Beam and I. S. Kohane. 2016. Translating Arti-
ficial Intelligence Into Clinical Care. Journal of the
American Medical Association, 316(22):2368–2369.

Claire Bonial, Kathryn Conger, Jena D. Hwang,
Aous Mansouri, Yahya Aseri, Julia Bonn, Timothy
O’Gorman, and Martha Palmer. 2017. Current Di-
rections in English and Arabic PropBank. In Nancy
Ide and James Pustejovsky, editors, Handbook of
Linguistic Annotation, pages 737–769. Springer.

Kathleen C. Fraser, Jed A. Meltzer, and Frank Rudz-
icz. 2016. Linguistic Features Identify Alzheimer’s
Disease in Narrative Speech. Journal of Alzheimer’s
Disease, 49(2):407–422.

Denise C. Fyffe, Shubhabrata Mukherjee, Lisa L.
Barnes, Jennifer J. Manly, David A. Bennett, and
Paul K. Crane. 2011. Explaining Differences
in Episodic Memory Performance among Older
African Americans and Whites: The Roles of Fac-
tors Related to Cognitive Reserve and Test Bias.
Journal of the International Neuropsychological So-
ciety, 17(4):625–638.

Edith Kaplan, Harold Goodglass, and Sandra Wein-
traub. 1983. The Boston Naming Test. Philadelphia:
Lea and Febiger.

Sweta Karlekar, Tong Niu, and Mohit Bansal. 2018.
Detecting Linguistic Characteristics of Alzheimer’s
Dementia by Interpreting Neural Models. In Pro-
ceedings of the Conference of the North American
Chapter of the Association for Computational Lin-
guistics, NAACL’18, pages 701–707.

Justin E. Karr, Raquel B. Graham, Scott M. Hofer, and
Graciela Muniz-Terrera. 2018. When does cognitive
decline begin? A systematic review of change point
studies on accelerated decline in cognitive and neu-
rological outcomes preceding mild cognitive impair-
ment, dementia, and death. Psychology and Aging,
33(2):195–218.

John C. Morris. 1994. The Clinical Dementia Rating
(CDR): current version and scoring rules. Neurol-
ogy, 43(11):2412–2414.

Kimberly Diggle Mueller, Bruce P. Hermann, Jonilda
Mecollari, and Lyn Turkstra. 2018. Connected
speech and language in mild cognitive impairment
and Alzheimer’s disease: A review of picture de-
scription tasks. Journal of Clinical and Experimen-
tal Neuropsychology, 40(1):917–939.

Ziad S. Nasreddine, Natalie A. Phillips, Valérie
Bédirian, Simon Charbonneau, Victor Whitehead,
Isabelle Collin, Jeffrey L. Cummings, and Howard
Chertkow. 2005. The Montreal Cognitive Assess-
ment, MoCA: a brief screening tool for mild cogni-
tive impairment. Journal of the American Geriatrics
Society, 53(4):695–699.

Sylvester O. Orimaye, Jojo S-M. Wong, Karen J.
Golden, Chee P. Wong, and Ireneous N. Soyiri. 2017.
Predicting probable Alzheimer’s disease using lin-
guistic deficits and biomarkers. BMC Bioinformat-
ics, 18(34).

Sylvester Olubolu Orimaye, Jojo Sze-Meng Wong, and
Judyanne Sharmini Gilbert Fernandez. 2016. Deep-
Deep Neural Network Language Models for Predict-
ing Mild Cognitive Impairment. In Proceedings of
the Workshop on Advances in Bioinformatics and Ar-
tificial Intelligence: Bridging the Gap.

R. I. Pfeffer, T. T. Kurosaki, C.H. Jr. Harrah, J. M.
Chance, and S. Filos. 1982. Measurement of Func-
tional Activities in Older Adults in the Community.
Journal of Gerontology, 37(3):323–329.

Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,
Olga Uryupina, and Yuchen Zhang. 2012. CoNLL-
2012 Shared Task: Modeling Multilingual Unre-
stricted Coreference in OntoNotes. In Proceedings
of the Sixteenth Conference on Computational Nat-
ural Language Learning: Shared Task, CoNLL’12,
pages 1–40.

Jamie Reilly, Amy Rodriguez, Martine Lamy, and Jean
Neils-Strunjas. 2010. Cognition, Language, and
Clinical Pathological Features of Non-Alzheimer’s
Dementias: An Overview. Journal of Communica-
tion Disorders, 43(5):438–452.

Kyle Steenland, Liping Zhao, Samantha E. John, Feli-
cia C. Goldstein, Allan Levey, and Alvaro Alonso.
2018. A ‘Framingham-like’ Algorithm for Predict-
ing 4-Year Risk of Progression to Amnestic Mild
Cognitive Impairment or Alzheimer’s Disease Using
Multidomain Information. Journal of Alzheimer’s
Disease, 63(4):1383–1393.

Pontus Stenetorp, Sampo Pyysalo, Goran Topić,
Tomoko Ohta, Sophia Ananiadou, and Jun’ichi Tsu-
jii. 2012. brat: a Web-based Tool for NLP-Assisted
Text Annotation. In Proceedings of the Demonstra-
tions at the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics,
EACL’12, pages 102–107.

Alexandros Tillas. 2015. Language as Grist to the Mill
of Cognition. Cognitive Processing, 16(3):219–243.

Cı́ntia Matsuda Toledo, Sandra M. Aluisio, Lean-
dro Borges dos Santos, Sonia Maria Dozzi Brucki,
Eduardo Sturzeneker Trés, Maira Okada de Oliveira,
and Letı́cia Lessa Mansura. 2018. Analysis of
macrolinguistic aspects of narratives from individu-
als with Alzheimer’s disease, mild cognitive impair-
ment, and no cognitive impairment. Alzheimer’s De-
mentia, 10:31–40.

https://www.aclweb.org/anthology/N18-2110
https://www.aclweb.org/anthology/N18-2110
https://www.aclweb.org/anthology/E12-2021
https://www.aclweb.org/anthology/E12-2021


91

Myank Verma and Robert J. Howard. 2012. Se-
mantic memory and language dysfunction in early
Alzheimer’s disease: a review. International Jour-
nal of Geriatric Psychiatry, 27(12):1209–1217.


