



















































Multitask Parsing Across Semantic Representations


Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 373–385
Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics

373

Multitask Parsing Across Semantic Representations

Daniel Hershcovich1,2 Omri Abend2
1The Edmond and Lily Safra Center for Brain Sciences

2School of Computer Science and Engineering
Hebrew University of Jerusalem

{danielh,oabend,arir}@cs.huji.ac.il

Ari Rappoport2

Abstract

The ability to consolidate information of
different types is at the core of intelli-
gence, and has tremendous practical value
in allowing learning for one task to benefit
from generalizations learned for others. In
this paper we tackle the challenging task of
improving semantic parsing performance,
taking UCCA parsing as a test case, and
AMR, SDP and Universal Dependencies
(UD) parsing as auxiliary tasks. We ex-
periment on three languages, using a uni-
form transition-based system and learning
architecture for all parsing tasks. Despite
notable conceptual, formal and domain
differences, we show that multitask learn-
ing significantly improves UCCA parsing
in both in-domain and out-of-domain set-
tings. Our code is publicly available.1

1 Introduction

Semantic parsing has arguably yet to reach its
full potential in terms of its contribution to down-
stream linguistic tasks, partially due to the limited
amount of semantically annotated training data.
This shortage is more pronounced in languages
other than English, and less researched domains.

Indeed, recent work in semantic parsing has tar-
geted, among others, Abstract Meaning Represen-
tation (AMR; Banarescu et al., 2013), bilexical Se-
mantic Dependencies (SDP; Oepen et al., 2016)
and Universal Conceptual Cognitive Annotation
(UCCA; Abend and Rappoport, 2013). While
these schemes are formally different and focus on
different distinctions, much of their semantic con-
tent is shared (Abend and Rappoport, 2017).

Multitask learning (MTL; Caruana, 1997) al-
lows exploiting the overlap between tasks to ef-

1http://github.com/danielhers/tupa

fectively extend the training data, and has greatly
advanced with neural networks and representation
learning (see §2). We build on these ideas and pro-
pose a general transition-based DAG parser, able
to parse UCCA, AMR, SDP and UD (Nivre et al.,
2016). We train the parser using MTL to obtain
significant improvements on UCCA parsing over
single-task training in (1) in-domain and (2) out-
of-domain settings in English; (3) an in-domain
setting in German; and (4) an in-domain setting in
French, where training data is scarce.

The novelty of this work is in proposing a gen-
eral parsing and learning architecture, able to ac-
commodate such widely different parsing tasks,
and in leveraging it to show benefits from learn-
ing them jointly.

2 Related Work

MTL has been used over the years for NLP tasks
with varying degrees of similarity, examples in-
cluding joint classification of different arguments
in semantic role labeling (Toutanova et al., 2005),
and joint parsing and named entity recognition
(Finkel and Manning, 2009). Similar ideas, of
parameter sharing across models trained with dif-
ferent datasets, can be found in studies of do-
main adaptation (Blitzer et al., 2006; Daume III,
2007; Ziser and Reichart, 2017). For parsing,
domain adaptation has been applied successfully
in parser combination and co-training (McClosky
et al., 2010; Baucom et al., 2013).

Neural MTL has mostly been effective in tack-
ling formally similar tasks (Søgaard and Gold-
berg, 2016), including multilingual syntactic de-
pendency parsing (Ammar et al., 2016; Guo et al.,
2016), as well as multilingual (Duong et al., 2017),
and cross-domain semantic parsing (Herzig and
Berant, 2017; Fan et al., 2017).

Sharing parameters with a low-level task has

http://github.com/danielhers/tupa


374

shown great benefit for transition-based syntactic
parsing, when jointly training with POS tagging
(Bohnet and Nivre, 2012; Zhang and Weiss, 2016),
and with lexical analysis (Constant and Nivre,
2016; More, 2016). Recent work has achieved
state-of-the-art results in multiple NLP tasks by
jointly learning the tasks forming the NLP stan-
dard pipeline using a single neural model (Col-
lobert et al., 2011; Hashimoto et al., 2017), thereby
avoiding cascading errors, common in pipelines.

Much effort has been devoted to joint learn-
ing of syntactic and semantic parsing, including
two CoNLL shared tasks (Surdeanu et al., 2008;
Hajič et al., 2009). Despite their conceptual and
practical appeal, such joint models rarely outper-
form the pipeline approach (Lluı́s and Màrquez,
2008; Henderson et al., 2013; Lewis et al., 2015;
Swayamdipta et al., 2016, 2017).

Peng et al. (2017a) performed MTL for SDP
in a closely related setting to ours. They tackled
three tasks, annotated over the same text and shar-
ing the same formal structures (bilexical DAGs),
with considerable edge overlap, but differing in
target representations (see §3). For all tasks, they
reported an increase of 0.5-1 labeled F1 points.
Recently, Peng et al. (2018) applied a similar ap-
proach to joint frame-semantic parsing and seman-
tic dependency parsing, using disjoint datasets,
and reported further improvements.

3 Tackled Parsing Tasks

In this section, we outline the parsing tasks we ad-
dress. We focus on representations that produce
full-sentence analyses, i.e., produce a graph cov-
ering all (content) words in the text, or the lexical
concepts they evoke. This contrasts with “shal-
low” semantic parsing, primarily semantic role la-
beling (SRL; Gildea and Jurafsky, 2002; Palmer
et al., 2005), which targets argument structure phe-
nomena using flat structures. We consider four
formalisms: UCCA, AMR, SDP and Universal
Dependencies. Figure 1 presents one sentence an-
notated in each scheme.

Universal Conceptual Cognitive Annotation.
UCCA (Abend and Rappoport, 2013) is a seman-
tic representation whose main design principles
are ease of annotation, cross-linguistic applicabil-
ity, and a modular architecture. UCCA represents
the semantics of linguistic utterances as directed
acyclic graphs (DAGs), where terminal (childless)
nodes correspond to the text tokens, and non-

After

L

graduation
P

H

,U

John
A

moved
P

to
R

Paris
C

A

H

A

LR

LA

LA

(a) UCCA

move-01

after

graduate-01

op1

time

person

name

”John”

op1
nam

e
A

R
G

0

city

name

”Paris”

op1
nam

e

ARG2

ARG
0

(b) AMR

After graduation , John moved to Paris

ARG2 ARG1

ARG1 top ARG2

ARG1 ARG2

(c) DM

After graduation , John moved to Paris

case punct nsubj

obl

case

root
obl

(d) UD

Figure 1: Example graph for each task. Figure 1a presents
a UCCA graph. The dashed edge is remote, while the blue
node and its outgoing edges represent inter-Scene linkage.
Pre-terminal nodes and edges are omitted for brevity. Fig-
ure 1b presents an AMR graph. Text tokens are not part of
the graph, and must be matched to concepts and constants by
alignment. Variables are represented by their concepts. Fig-
ure 1c presents a DM semantic dependency graph, containing
multiple roots: “After”, “moved” and “to”, of which “moved”
is marked as top. Punctuation tokens are excluded from SDP
graphs. Figure 1d presents a UD tree. Edge labels express
syntactic relations.

terminal nodes to semantic units that participate in
some super-ordinate relation. Edges are labeled,
indicating the role of a child in the relation the par-
ent represents. Nodes and edges belong to one of
several layers, each corresponding to a “module”
of semantic distinctions. UCCA’s foundational
layer (the only layer for which annotated data ex-
ists) mostly covers predicate-argument structure,
semantic heads and inter-Scene relations.

UCCA distinguishes primary edges, corre-
sponding to explicit relations, from remote edges



375

(appear dashed in Figure 1a) that allow for a unit
to participate in several super-ordinate relations.
Primary edges form a tree in each layer, whereas
remote edges enable reentrancy, forming a DAG.

Abstract Meaning Representation. AMR (Ba-
narescu et al., 2013) is a semantic representation
that encodes information about named entities, ar-
gument structure, semantic roles, word sense and
co-reference. AMRs are rooted directed graphs,
in which both nodes and edges are labeled. Most
AMRs are DAGs, although cycles are permitted.

AMR differs from the other schemes we con-
sider in that it does not anchor its graphs in the
words of the sentence (Figure 1b). Instead, AMR
graphs connect variables, concepts (from a pre-
defined set) and constants (which may be strings
or numbers). Still, most AMR nodes are alignable
to text tokens, a tendency used by AMR parsers,
which align a subset of the graph nodes to a subset
of the text tokens (concept identification). In this
work, we use pre-aligned AMR graphs.

Despite the brief period since its inception,
AMR has been targeted by a number of works,
notably in two SemEval shared tasks (May, 2016;
May and Priyadarshi, 2017). To tackle its vari-
ety of distinctions and unrestricted graph struc-
ture, AMR parsers often use specialized meth-
ods. Graph-based parsers construct AMRs by
identifying concepts and scoring edges between
them, either in a pipeline fashion (Flanigan et al.,
2014; Artzi et al., 2015; Pust et al., 2015; Foland
and Martin, 2017), or jointly (Zhou et al., 2016).
Another line of work trains machine translation
models to convert strings into linearized AMRs
(Barzdins and Gosko, 2016; Peng et al., 2017b;
Konstas et al., 2017; Buys and Blunsom, 2017b).
Transition-based AMR parsers either use depen-
dency trees as pre-processing, then mapping them
into AMRs (Wang et al., 2015a,b, 2016; Goodman
et al., 2016), or use a transition system tailored to
AMR parsing (Damonte et al., 2017; Ballesteros
and Al-Onaizan, 2017). We differ from the above
approaches in addressing AMR parsing using the
same general DAG parser used for other schemes.

Semantic Dependency Parsing. SDP uses a set
of related representations, targeted in two recent
SemEval shared tasks (Oepen et al., 2014, 2015),
and extended by Oepen et al. (2016). They cor-
respond to four semantic representation schemes,
referred to as DM, PAS, PSD and CCD, represent-

ing predicate-argument relations between content
words in a sentence. All are based on semantic for-
malisms converted into bilexical dependencies—
directed graphs whose nodes are text tokens.
Edges are labeled, encoding semantic relations be-
tween the tokens. Non-content tokens, such as
punctuation, are left out of the analysis (see Fig-
ure 1c). Graphs containing cycles have been re-
moved from the SDP datasets.

We use one of the representations from the
SemEval shared tasks: DM (DELPH-IN MRS),
converted from DeepBank (Flickinger et al.,
2012), a corpus of hand-corrected parses from
LinGO ERG (Copestake and Flickinger, 2000), an
HPSG (Pollard and Sag, 1994) using Minimal Re-
cursion Semantics (Copestake et al., 2005).

Universal Dependencies. UD (Nivre et al.,
2016, 2017) has quickly become the dominant de-
pendency scheme for syntactic annotation in many
languages, aiming for cross-linguistically consis-
tent and coarse-grained treebank annotation. For-
mally, UD uses bilexical trees, with edge labels
representing syntactic relations between words.

We use UD as an auxiliary task, inspired by pre-
vious work on joint syntactic and semantic parsing
(see §2). In order to reach comparable analyses
cross-linguistically, UD often ends up in annota-
tion that is similar to the common practice in se-
mantic treebanks, such as linking content words to
content words wherever possible. Using UD fur-
ther allows conducting experiments on languages
other than English, for which AMR and SDP an-
notated data is not available (§7).

In addition to basic UD trees, we use the en-
hanced++ UD graphs available for English, which
are generated by the Stanford CoreNLP convert-
ers (Schuster and Manning, 2016).2 These include
additional and augmented relations between con-
tent words, partially overlapping with the notion
of remote edges in UCCA: in the case of control
verbs, for example, a direct relation is added in
enhanced++ UD between the subordinated verb
and its controller, which is similar to the seman-
tic schemes’ treatment of this construction.

4 General Transition-based DAG Parser

All schemes considered in this work exhibit reen-
trancy and discontinuity (or non-projectivity), to
varying degrees. In addition, UCCA and AMR

2http://github.com/stanfordnlp/CoreNLP

http://github.com/stanfordnlp/CoreNLP


376

contain non-terminal nodes. To parse these
graphs, we extend TUPA (Hershcovich et al.,
2017), a transition-based parser originally devel-
oped for UCCA, as it supports all these structural
properties. TUPA’s transition system can yield any
labeled DAG whose terminals are anchored in the
text tokens. To support parsing into AMR, which
uses graphs that are not anchored in the tokens,
we take advantage of existing alignments of the
graphs with the text tokens during training (§5).

First used for projective syntactic depen-
dency tree parsing (Nivre, 2003), transition-based
parsers have since been generalized to parse
into many other graph families, such as (dis-
continuous) constituency trees (e.g., Zhang and
Clark, 2009; Maier and Lichte, 2016), and DAGs
(e.g., Sagae and Tsujii, 2008; Du et al., 2015).
Transition-based parsers apply transitions incre-
mentally to an internal state defined by a buffer B
of remaining tokens and nodes, a stack S of unre-
solved nodes, and a labeled graph G of constructed
nodes and edges. When a terminal state is reached,
the graph G is the final output. A classifier is used
at each step to select the next transition, based on
features that encode the current state.

4.1 TUPA’s Transition Set

Given a sequence of tokens w1, . . . , wn, we pre-
dict a rooted graph G whose terminals are the to-
kens. Parsing starts with the root node on the
stack, and the input tokens in the buffer.

The TUPA transition set includes the standard
SHIFT and REDUCE operations, NODEX for cre-
ating a new non-terminal node and an X-labeled
edge, LEFT-EDGEX and RIGHT-EDGEX to create
a new primary X-labeled edge, LEFT-REMOTEX
and RIGHT-REMOTEX to create a new remote
X-labeled edge, SWAP to handle discontinuous
nodes, and FINISH to mark the state as terminal.

Although UCCA contains nodes without any
text tokens as descendants (called implicit units),
these nodes are infrequent and only cover 0.5% of
non-terminal nodes. For this reason we follow pre-
vious work (Hershcovich et al., 2017) and discard
implicit units from the training and evaluation, and
so do not include transitions for creating them.

In AMR, implicit units are considerably more
common, as any unaligned concept with no
aligned descendents is implicit (about 6% of the
nodes). Implicit AMR nodes usually result from
alignment errors, or from abstract concepts which

Parser state

S

,

B

John moved to Paris .

G

After

L

graduation

P

H

Classifier

BiLSTM

Embeddings

After graduation to Paris. . .

MLP

transition

softmax

Figure 2: Illustration of the TUPA model, adapted from Her-
shcovich et al. (2017). Top: parser state. Bottom: BiLTSM
architecture.

have no explicit realization in the text (Buys and
Blunsom, 2017a). We ignore implicit nodes when
training on AMR as well. TUPA also does not sup-
port node labels, which are ubiquitous in AMR but
absent in UCCA structures (only edges are labeled
in UCCA). We therefore only produce edge labels
and not node labels when training on AMR.

4.2 Transition Classifier

To predict the next transition at each step, we use
a BiLSTM with embeddings as inputs, followed
by an MLP and a softmax layer for classification
(Kiperwasser and Goldberg, 2016). The model
is illustrated in Figure 2. Inference is performed
greedily, and training is done with an oracle that
yields the set of all optimal transitions at a given
state (those that lead to a state from which the gold
graph is still reachable). Out of this set, the ac-
tual transition performed in training is the one with
the highest score given by the classifier, which is
trained to maximize the sum of log-likelihoods of
all optimal transitions at each step.

Features. We use the original TUPA features,
representing the words, POS tags, syntactic depen-
dency relations, and previously predicted edge la-
bels for nodes in specific locations in the parser
state. In addition, for each token we use embed-
dings representing the one-character prefix, three-
character suffix, shape (capturing orthographic



377

After

L

graduation
P

H

,U

John
A

moved
P

to
R

Paris
C

A

H

A

(a) UCCA

moved

After

graduation

op

time

John

nam
e

A
R

G
0

Paris

nam
e

ARG2

ARG
0

(b) AMR

Afterggraduation ,

root

g John

A
RG

1

movedg

head

tog Parisg

root

top

he
ad

A
R

G
2

ARG1 AR
G1

he
ad

ARG2

A
R

G
2

(c) DM

Afterg

ca
se

graduation
head

obl

,g Johng movedgtog

ca
se

Parisg

head

obl

pu
nc

t nsubj

head

(d) UD

Figure 3: Graphs from Figure 1, after conversion to the uni-
fied DAG format (with pre-terminals omitted: each terminal
drawn in place of its parent). Figure 3a presents a converted
UCCA graph. Linkage nodes and edges are removed, but
the original graph is otherwise preserved. Figure 3b presents
a converted AMR graph, with text tokens added according
to the alignments. Numeric suffixes of op relations are re-
moved, and names collapsed. Figure 3c presents a converted
SDP graph (in the DM representation), with intermediate
non-terminal head nodes introduced. In case of reentrancy,
an arbitrary reentrant edge is marked as remote. Figure 3d
presents a converted UD graph. As in SDP, intermediate non-
terminals and head edges are introduced. While converted
UD graphs form trees, enhanced++ UD graphs may not.

features, e.g., “Xxxx”), and named entity type,3

all provided by spaCy (Honnibal and Montani,
2018).4 To the learned word vectors, we concate-
nate the 250K most frequent word vectors from

3See Supplementary Material for a full listing of features.
4http://spacy.io

fastText (Bojanowski et al., 2017),5 pre-trained
over Wikipedia and updated during training.

Constraints. As each annotation scheme has
different constraints on the allowed graph struc-
tures, we apply these constraints separately for
each task. During training and parsing, the rele-
vant constraint set rules out some of the transitions
according to the parser state. Some constraints
are task-specific, others are generic. For exam-
ple, in UCCA, a terminal may only have one par-
ent. In AMR, a concept corresponding to a Prop-
Bank frame may only have the core arguments de-
fined for the frame as children. An example of
a generic constraint is that stack nodes that have
been swapped should not be swapped again.6

5 Unified DAG Format

To apply our parser to the four target tasks (§3), we
convert them into a unified DAG format, which is
inclusive enough to allow representing any of the
schemes with very little loss of information.7

The format consists of a rooted DAG, where the
tokens are the terminal nodes. As in the UCCA
format, edges are labeled (but not nodes), and are
divided into primary and remote edges, where the
primary edges form a tree (all nodes have at most
one primary parent, and the root has none). Re-
mote edges enable reentrancy, and thus together
with primary edges form a DAG. Figure 3 shows
examples for converted graphs. Converting UCCA
into the unified format consists simply of remov-
ing linkage nodes and edges (see Figure 3a), which
were also discarded by Hershcovich et al. (2017).

Converting bilexical dependencies. To convert
DM and UD into the unified DAG format, we add
a pre-terminal for each token, and attach the pre-
terminals according to the original dependency
edges: traversing the tree from the root down, for
each head token we create a non-terminal parent
with the edge label head, and add the node’s de-
pendents as children of the created non-terminal
node (see Figures 3c and 3d). Since DM allows
multiple roots, we form a single root node, whose

5http://fasttext.cc
6 To implement this constraint, we define a swap index for

each node, assigned when the node is created. At initializa-
tion, only the root node and terminals exist. We assign the
root a swap index of 0, and for each terminal, its position in
the text (starting at 1). Whenever a node is created as a result
of a NODE transition, its swap index is the arithmetic mean
of the swap indices of the stack top and buffer head.

7See Supplementary Material for more conversion details.

http://spacy.io
http://fasttext.cc


378

Parser state
. . .

Classifier

Task-specific BiLSTM Shared BiLSTM

Shared embeddings

After graduation to Paris. . .

Task-specific MLP

transition

softmax

Figure 4: MTL model. Token representations are computed
both by a task-specific and a shared BiLSTM. Their outputs
are concatenated with the parser state embedding, identical to
Figure 2, and fed into the task-specific MLP for selecting the
next transition. Shared parameters are shown in blue.

children are the original roots. The added edges
are labeled root, where top nodes are labeled top
instead. In case of reentrancy, an arbitrary parent
is marked as primary, and the rest as remote (de-
noted as dashed edges in Figure 3).

Converting AMR. In the conversion from
AMR, node labels are dropped. Since alignments
are not part of the AMR graph (see Figure 3b), we
use automatic alignments (see §7), and attach each
node with an edge to each of its aligned terminals.

Named entities in AMR are represented as a
subgraph, whose name-labeled root has a child for
each token in the name (see the two name nodes in
Figure 1b). We collapse this subgraph into a single
node whose children are the name tokens.

6 Multitask Transition-based Parsing

Now that the same model can be applied to dif-
ferent tasks, we can train it in a multitask setting.
The fairly small training set available for UCCA
(see §7) makes MTL particularly appealing, and
we focus on it in this paper, treating AMR, DM
and UD parsing as auxiliary tasks.

Following previous work, we share only some
of the parameters (Klerke et al., 2016; Søgaard and
Goldberg, 2016; Bollmann and Søgaard, 2016;
Plank, 2016; Braud et al., 2016; Martı́nez Alonso
and Plank, 2017; Peng et al., 2017a, 2018), leaving
task-specific sub-networks as well. Concretely, we
keep the BiLSTM used by TUPA for the main task
(UCCA parsing), add a BiLSTM that is shared

across all tasks, and replicate the MLP (feedfor-
ward sub-network) for each task. The BiLSTM
outputs (concatenated for the main task) are fed
into the task-specific MLP (see Figure 4). Feature
embeddings are shared across tasks.

Unlabeled parsing for auxiliary tasks. To sim-
plify the auxiliary tasks and facilitate generaliza-
tion (Bingel and Søgaard, 2017), we perform un-
labeled parsing for AMR, DM and UD, while still
predicting edge labels in UCCA parsing. To sup-
port unlabeled parsing, we simply remove all la-
bels from the EDGE, REMOTE and NODE tran-
sitions output by the oracle. This results in a
much smaller number of transitions the classifier
has to select from (no more than 10, as opposed
to 45 in labeled UCCA parsing), allowing us to
use no BiLSTMs and fewer dimensions and layers
for task-specific MLPs of auxiliary tasks (see §7).
This limited capacity forces the network to use the
shared parameters for all tasks, increasing gener-
alization (Martı́nez Alonso and Plank, 2017).

7 Experimental Setup

We here detail a range of experiments to assess
the value of MTL to UCCA parsing, training the
parser in single-task and multitask settings, and
evaluating its performance on the UCCA test sets
in both in-domain and out-of-domain settings.

Data. For UCCA, we use v1.2 of the English
Wikipedia corpus (Wiki; Abend and Rappoport,
2013), with the standard train/dev/test split (see
Table 1), and the Twenty Thousand Leagues Under
the Sea corpora (20K; Sulem et al., 2015), anno-
tated in English, French and German.8 For English
and French we use 20K v1.0, a small parallel cor-
pus comprising the first five chapters of the book.
As in previous work (Hershcovich et al., 2017),
we use the English part only as an out-of-domain
test set. We train and test on the French part using
the standard split, as well as the German corpus
(v0.9), which is a pre-release and still contains a
considerable amount of noisy annotation. Tuning
is performed on the respective development sets.

For AMR, we use LDC2017T10, identical to
the dataset targeted in SemEval 2017 (May and
Priyadarshi, 2017).9 For SDP, we use the DM
representation from the SDP 2016 dataset (Oepen

8http://github.com/huji-nlp/ucca-corpora
9http://catalog.ldc.upenn.edu/LDC2017T10

http://github.com/huji-nlp/ucca-corpora
http://catalog.ldc.upenn.edu/LDC2017T10


379

English French German
# tokens # sentences # tokens # sentences # tokens # sentences

train dev test train dev test train dev test train dev test train dev test train dev test
UCCA
Wiki 128444 14676 15313 4268 454 503
20K 12339 506 10047 1558 1324 413 67 67 79894 10059 42366 3429 561 2164
AMR 648950 36521
DM 765025 33964
UD 458277 17062 899163 32347 268145 13814

Table 1: Number of tokens and sentences in the training, development and test sets we use for each corpus and language.

et al., 2016).10 For Universal Dependencies,
we use all English, French and German tree-
banks from UD v2.1 (Nivre et al., 2017).11 We
use the enhanced++ UD representation (Schuster
and Manning, 2016) in our English experiments,
henceforth referred to as UD++. We use only the
AMR, DM and UD training sets from standard
splits.

While UCCA is annotated over Wikipedia and
over a literary corpus, the domains for AMR, DM
and UD are blogs, news, emails, reviews, and
Q&A. This domain difference between training
and test is particularly challenging (see §9). Un-
fortunately, none of the other schemes have avail-
able annotation over Wikipedia text.

Settings. We explore the following settings: (1)
in-domain setting in English, training and test-
ing on Wiki; (2) out-of-domain setting in English,
training on Wiki and testing on 20K; (3) French in-
domain setting, where available training dataset is
small, training and testing on 20K; (4) German in-
domain setting on 20K, with somewhat noisy an-
notation. For MTL experiments, we use unlabeled
AMR, DM and UD++ parsing as auxiliary tasks in
English, and unlabeled UD parsing in French and
German.12 We also report baseline results training
only the UCCA training sets.

Training. We create a unified corpus for each
setting, shuffling all sentences from relevant
datasets together, but using only the UCCA devel-
opment set F1 score as the early stopping criterion.
In each training epoch, we use the same number of
examples from each task—the UCCA training set
size. Since training sets differ in size, we sample
this many sentences from each one. The model is
implemented using DyNet (Neubig et al., 2017).13

10http://sdp.delph-in.net/osdp-12.tgz
11http://hdl.handle.net/11234/1-2515
12We did not use AMR, DM or UD++ in French and Ger-

man, as these are only available in English.
13http://dynet.io

Multitask
Hyperparameter Single Main Aux Shared
Pre-trained word dim. 300 300
Learned word dim. 200 200
POS tag dim. 20 20
Dependency relation dim. 10 10
Named entity dim. 3 3
Punctuation dim. 1 1
Action dim. 3 3
Edge label dim. 20 20
MLP layers 2 2 1
MLP dimensions 50 50 50
BiLSTM layers 2 2 2
BiLSTM dimensions 500 300 300

Table 2: Hyperparameter settings. Middle column shows hy-
perparameters used for the single-task architecture, described
in §4.2, and right column for the multitask architecture, de-
scribed in §6. Main refers to parameters specific to the main
task—UCCA parsing (task-specific MLP and BiLSTM, and
edge label embedding), Aux to parameters specific to each
auxiliary task (task-specific MLP, but no edge label embed-
ding since the tasks are unlabeled), and Shared to parameters
shared among all tasks (shared BiLSTM and embeddings).

Hyperparameters. We initialize embeddings
randomly. We use dropout (Srivastava et al., 2014)
between MLP layers, and recurrent dropout (Gal
and Ghahramani, 2016) between BiLSTM layers,
both with p = 0.4. We also use word (α = 0.2),
tag (α = 0.2) and dependency relation (α = 0.5)
dropout (Kiperwasser and Goldberg, 2016).14 In
addition, we use a novel form of dropout, node
dropout: with a probability of 0.1 at each step,
all features associated with a single node in the
parser state are replaced with zero vectors. For op-
timization we use a minibatch size of 100, decay-
ing all weights by 10−5 at each update, and train
with stochastic gradient descent for N epochs
with a learning rate of 0.1, followed by AMS-
Grad (Sashank J. Reddi, 2018) for N epochs with
α = 0.001, β1 = 0.9 and β2 = 0.999. We use
N = 50 for English and German, and N = 400
for French. We found this training strategy better
than using only one of the optimization methods,

14In training, the embedding for a feature value w is re-
placed with a zero vector with a probability of α

#(w)+α
,

where #(w) is the number of occurrences of w observed.

http://sdp.delph-in.net/osdp-12.tgz
http://hdl.handle.net/11234/1-2515
http://dynet.io


380

Primary Remote
LP LR LF LP LR LF

English (in-domain)
HAR17 74.4 72.7 73.5 47.4 51.6 49.4
Single 74.4 72.9 73.6 53 50 51.5
AMR 74.7 72.8 73.7 48.7? 51.1 49.9
DM 75.7? 73.9? 74.8? 54.9 53 53.9
UD++ 75? 73.2 74.1? 49 52.7 50.8
AMR + DM 75.6? 73.9? 74.7? 49.9 53 51.4
AMR + UD++ 74.9 72.7 73.8 47.1 50 48.5
DM + UD++ 75.9? 73.9? 74.9? 48 54.8 51.2
All 75.6? 73.1 74.4? 50.9 53.2 52

Table 3: Labeled precision, recall and F1 (in %) for primary
and remote edges, on the Wiki test set. ? indicates signifi-
cantly better than Single. HAR17: Hershcovich et al. (2017).

Primary Remote
LP LR LF LP LR LF

English (out-of-domain)
HAR17 68.7 68.5 68.6 38.6 18.8 25.3
Single 69 69 69 41.2 19.8 26.7
AMR 69.5 69.5 69.5 42.9 20.2 27.5
DM 70.7? 70.7? 70.7? 42.7 18.6 25.9
UD++ 69.6 69.8? 69.7 41.4 22 28.7
AMR + DM 70.7? 70.2? 70.5? 45.8 19.4 27.3
AMR + UD++ 70.2? 69.9? 70? 45.1 21.8 29.4
DM + UD++ 70.8? 70.3? 70.6? 41.6 21.6 28.4
All 71.2? 70.9? 71? 45.1 22 29.6
French (in-domain)
Single 68.2 67 67.6 26 9.4 13.9
UD 70.3 70? 70.1? 43.8 13.2 20.3
German (in-domain)
Single 73.3 71.7 72.5 57.1 17.7 27.1
UD 73.7? 72.6? 73.2? 61.8 24.9? 35.5?

Table 4: Labeled precision, recall and F1 (in %) for primary
and remote edges, on the 20K test sets. ? indicates signifi-
cantly better than Single. HAR17: Hershcovich et al. (2017).

similar to findings by Keskar and Socher (2017).
We select the epoch with the best average labeled
F1 score on the UCCA development set. Other
hyperparameter settings are listed in Table 2.

Evaluation. We evaluate on UCCA using la-
beled precision, recall and F1 on primary and
remote edges, following previous work (Hersh-
covich et al., 2017). Edges in predicted and
gold graphs are matched by terminal yield and
label. Significance testing of improvements over
the single-task model is done by the bootstrap test
(Berg-Kirkpatrick et al., 2012), with p < 0.05.

8 Results

Table 3 presents our results on the English in-
domain Wiki test set. MTL with all auxiliary tasks
and their combinations improves the primary F1
score over the single task baseline. In most set-
tings the improvement is statistically significant.
Using all auxiliary tasks contributed less than just

DM and UD++, the combination of which yielded
the best scores yet in in-domain UCCA parsing,
with 74.9% F1 on primary edges. Remote F1 is
improved in some settings, but due to the rela-
tively small number of remote edges (about 2%
of all edges), none of the differences is significant.
Note that our baseline single-task model (Single)
is slightly better than the current state-of-the-art
(HAR17; Hershcovich et al., 2017), due to the in-
corporation of additional features (see §4.2).

Table 4 presents our experimental results on the
20K corpora in the three languages. For English
out-of-domain, improvements from using MTL
are even more marked. Moreover, the improve-
ment is largely additive: the best model, using all
three auxiliary tasks (All), yields an error reduc-
tion of 2.9%. Again, the single-task baseline is
slightly better than HAR17.

The contribution of MTL is also apparent in
French and German in-domain parsing: 3.7% er-
ror reduction in French (having less than 10%
as much UCCA training data as English) and
1% in German, where the training set is com-
parable in size to the English one, but is noisier
(see §7). The best MTL models are significantly
better than single-task models, demonstrating that
even a small training set for the main task may
suffice, given enough auxiliary training data (as in
French).

9 Discussion

Quantifying the similarity between tasks.
Task similarity is an important factor in MTL suc-
cess (Bingel and Søgaard, 2017; Martı́nez Alonso
and Plank, 2017). In our case, the main and auxil-
iary tasks are annotated on different corpora from
different domains (§7), and the target representa-
tions vary both in form and in content.

To quantify the domain differences, we follow
Plank and van Noord (2011) and measure the L1
distance between word distributions in the English
training sets and 20K test set (Table 5). All aux-
iliary training sets are more similar to 20K than
Wiki is, which may contribute to the benefits ob-
served on the English 20K test set.

As a measure of the formal similarity of the dif-
ferent schemes to UCCA, we use unlabeled F1
score evaluation on both primary and remote edges
(ignoring edge labels). To this end, we annotated
100 English sentences from Section 02 of the Penn
Treebank Wall Street Journal (PTB WSJ). Anno-



381

20K AMR DM UD
Wiki 1.047 0.895 0.913 0.843
20K 0.949 0.971 0.904
AMR 0.757 0.469
DM 0.754

Table 5: L1 distance between dataset word distributions,
quantifying domain differences in English (low is similar).

Primary Remote
UP UR UF UP UR UF

AMR 53.8 15.6 24.2 7.3 5.5 6.3
DM 65 49.2 56 7.4 65.9 13.3
UD++ 82.7 84.6 83.6 12.5 12.7 12.6

Table 6: Unlabeled F1 scores between the representations of
the same English sentences (from PTB WSJ), converted to
the unified DAG format, and annotated UCCA graphs.

tation was carried out by a single expert UCCA
annotator, and is publicly available.15 These sen-
tences had already been annotated by the AMR,
DM and PTB schemes,16 and we convert their an-
notation to the unified DAG format.

Unlabeled F1 scores between the UCCA graphs
and those converted from AMR, DM and UD++

are presented in Table 6. UD++ is highly over-
lapping with UCCA, while DM less so, and AMR
even less (cf. Figure 3).

Comparing the average improvements resulting
from adding each of the tasks as auxiliary (see §8),
we find AMR the least beneficial, UD++ second,
and DM the most beneficial, in both in-domain
and out-of-domain settings. This trend is weakly
correlated with the formal similarity between the
tasks (as expressed in Table 6), but weakly neg-
atively correlated with the word distribution simi-
larity scores (Table 5). We conclude that other fac-
tors should be taken into account to fully explain
this effect, and propose to address this in future
work through controlled experiments, where cor-
pora of the same domain are annotated with the
various formalisms and used as training data for
MTL.

AMR, SDP and UD parsing. Evaluating the
full MTL model (All) on the unlabeled auxiliary
tasks yielded 64.7% unlabeled Smatch F1 (Cai and
Knight, 2013) on the AMR development set, when
using oracle concept identification (since the aux-
iliary model does not predict node labels), 27.2%
unlabeled F1 on the DM development set, and

15http://github.com/danielhers/wsj
16We convert the PTB format to UD++ v1 using Stan-

ford CoreNLP, and then to UD v2 using Udapi: http:
//github.com/udapi/udapi-python.

4.9% UAS on the UD development set. These
poor results reflect the fact that model selection
was based on the score on the UCCA development
set, and that the model parameters dedicated to
auxiliary tasks were very limited (to encourage us-
ing the shared parameters). However, preliminary
experiments using our approach produced promis-
ing results on each of the tasks’ respective English
development sets, when treated as a single task:
67.1% labeled Smatch F1 on AMR (adding a tran-
sition for implicit nodes and classifier for node la-
bels), 79.1% labeled F1 on DM, and 80.1% LAS
F1 on UD. For comparison, the best results on
these datasets are 70.7%, 91.2% and 82.2%, re-
spectively (Foland and Martin, 2017; Peng et al.,
2018; Dozat et al., 2017).

10 Conclusion

We demonstrate that semantic parsers can leverage
a range of semantically and syntactically anno-
tated data, to improve their performance. Our ex-
periments show that MTL improves UCCA pars-
ing, using AMR, DM and UD parsing as auxil-
iaries. We propose a unified DAG representation,
construct protocols for converting these schemes
into the unified format, and generalize a transition-
based DAG parser to support all these tasks, allow-
ing it to be jointly trained on them.

While we focus on UCCA in this work, our
parser is capable of parsing any scheme that can
be represented in the unified DAG format, and pre-
liminary results on AMR, DM and UD are promis-
ing (see §9). Future work will investigate whether
a single algorithm and architecture can be com-
petitive on all of these parsing tasks, an important
step towards a joint many-task model for semantic
parsing.

Acknowledgments

This work was supported by the Israel Science
Foundation (grant no. 929/17), by the HUJI Cy-
ber Security Research Center in conjunction with
the Israel National Cyber Bureau in the Prime
Minister’s Office, and by the Intel Collaborative
Research Institute for Computational Intelligence
(ICRI-CI). The first author was supported by a fel-
lowship from the Edmond and Lily Safra Center
for Brain Sciences. We thank Roi Reichart, Rotem
Dror and the anonymous reviewers for their help-
ful comments.

http://github.com/danielhers/wsj
http://github.com/udapi/udapi-python
http://github.com/udapi/udapi-python


382

References
Omri Abend and Ari Rappoport. 2013. Universal Con-

ceptual Cognitive Annotation (UCCA). In Proc. of
ACL, pages 228–238.

Omri Abend and Ari Rappoport. 2017. The state of
the art in semantic representation. In Proc. of ACL,
pages 77–89.

Waleed Ammar, George Mulcaire, Miguel Ballesteros,
Chris Dyer, and Noah Smith. 2016. Many lan-
guages, one parser. TACL, 4:431–444.

Yoav Artzi, Kenton Lee, and Luke Zettlemoyer. 2015.
Broad-coverage CCG semantic parsing with AMR.
In Proc. of EMNLP, pages 1699–1710.

Miguel Ballesteros and Yaser Al-Onaizan. 2017. AMR
parsing using stack-LSTMs. In Proc. of EMNLP,
pages 1269–1275.

Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Martha Palmer, and Nathan Schneider.
2013. Abstract Meaning Representation for sem-
banking. In Proc. of the Linguistic Annotation
Workshop.

Guntis Barzdins and Didzis Gosko. 2016. RIGA
at SemEval-2016 task 8: Impact of Smatch ex-
tensions and character-level neural translation on
AMR parsing accuracy. In Proc. of SemEval, pages
1143–1147.

Eric Baucom, Levi King, and Sandra Kübler. 2013.
Domain adaptation for parsing. In Proc. of RANLP,
pages 56–64.

Taylor Berg-Kirkpatrick, David Burkett, and Dan
Klein. 2012. An empirical investigation of statistical
significance in NLP. In Proc. of EMNLP-CoNLL,
pages 995–1005.

Joachim Bingel and Anders Søgaard. 2017. Identify-
ing beneficial task relations for multi-task learning
in deep neural networks. In Proc. of EACL, pages
164–169.

John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In Proc. of EMNLP, pages 120–128.

Bernd Bohnet and Joakim Nivre. 2012. A transition-
based system for joint part-of-speech tagging and la-
beled non-projective dependency parsing. In Proc.
of EMNLP-CoNLL, pages 1455–1465.

Piotr Bojanowski, Edouard Grave, Armand Joulin, and
Tomas Mikolov. 2017. Enriching word vectors with
subword information. TACL, 5:135–146.

Marcel Bollmann and Anders Søgaard. 2016. Im-
proving historical spelling normalization with bi-
directional lstms and multi-task learning. In Proc.
of COLING, pages 131–139.

Chloé Braud, Barbara Plank, and Anders Søgaard.
2016. Multi-view and multi-task training of RST
discourse parsers. In Proc. of COLING, pages
1903–1913.

Jan Buys and Phil Blunsom. 2017a. Oxford at
SemEval-2017 task 9: Neural AMR parsing with
pointer-augmented attention. In Proc. of SemEval,
pages 914–919.

Jan Buys and Phil Blunsom. 2017b. Robust incremen-
tal neural semantic graph parsing. In Proc. of ACL,
pages 1215–1226.

Shu Cai and Kevin Knight. 2013. Smatch: an evalua-
tion metric for semantic feature structures. In Proc.
of ACL, pages 748–752.

Rich Caruana. 1997. Multitask Learning. Machine
Learning, 28(1):41–75.

Ronan Collobert, Jason Weston, Léon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. J. Mach. Learn. Res., 12:2493–2537.

Matthieu Constant and Joakim Nivre. 2016. A
transition-based system for joint lexical and syntac-
tic analysis. In Proc. of ACL, pages 161–171.

Ann Copestake and Dan Flickinger. 2000. An
open source grammar development environment and
broad-coverage English grammar using HPSG. In
Proc. of LREC, pages 591–600.

Ann Copestake, Dan Flickinger, Carl Pollard, and
Ivan A. Sag. 2005. Minimal recursion semantics:
An introduction. Research on Language and Com-
putation, 3(2):281–332.

Marco Damonte, Shay B. Cohen, and Giorgio Satta.
2017. An incremental parser for Abstract Meaning
Representation. In Proc. of EACL.

Hal Daume III. 2007. Frustratingly easy domain adap-
tation. In Proc. of ACL, pages 256–263.

Timothy Dozat, Peng Qi, and Christopher D. Manning.
2017. Stanford’s graph-based neural dependency
parser at the conll 2017 shared task. In Proc. of
CoNLL, pages 20–30.

Yantao Du, Fan Zhang, Xun Zhang, Weiwei Sun, and
Xiaojun Wan. 2015. Peking: Building semantic de-
pendency graphs with a hybrid parser. In Proc. of
SemEval, pages 927–931.

Long Duong, Hadi Afshar, Dominique Estival, Glen
Pink, Philip Cohen, and Mark Johnson. 2017. Mul-
tilingual semantic parsing and code-switching. In
Proc. of CoNLL, pages 379–389.

Xing Fan, Emilio Monti, Lambert Mathias, and Markus
Dreyer. 2017. Transfer learning for neural seman-
tic parsing. In Proc. of Workshop on Representation
Learning for NLP, pages 48–56.

http://aclweb.org/anthology/P13-1023
http://aclweb.org/anthology/P13-1023
https://doi.org/10.18653/v1/P17-1008
https://doi.org/10.18653/v1/P17-1008
http://www.aclweb.org/anthology/Q16-1031
http://www.aclweb.org/anthology/Q16-1031
http://aclweb.org/anthology/D15-1198
http://aclweb.org/anthology/D17-1130
http://aclweb.org/anthology/D17-1130
http://aclweb.org/anthology/W13-2322
http://aclweb.org/anthology/W13-2322
https://doi.org/10.18653/v1/S16-1176
https://doi.org/10.18653/v1/S16-1176
https://doi.org/10.18653/v1/S16-1176
https://doi.org/10.18653/v1/S16-1176
http://www.aclweb.org/anthology/R13-1008
http://www.aclweb.org/anthology/D12-1091
http://www.aclweb.org/anthology/D12-1091
http://www.aclweb.org/anthology/E17-2026
http://www.aclweb.org/anthology/E17-2026
http://www.aclweb.org/anthology/E17-2026
http://www.aclweb.org/anthology/W06-1615
http://www.aclweb.org/anthology/W06-1615
http://www.aclweb.org/anthology/D12-1133
http://www.aclweb.org/anthology/D12-1133
http://www.aclweb.org/anthology/D12-1133
http://aclweb.org/anthology/Q17-1010
http://aclweb.org/anthology/Q17-1010
http://www.aclweb.org/anthology/C16-1013
http://www.aclweb.org/anthology/C16-1013
http://www.aclweb.org/anthology/C16-1013
http://www.aclweb.org/anthology/C16-1179
http://www.aclweb.org/anthology/C16-1179
https://doi.org/10.18653/v1/S17-2157
https://doi.org/10.18653/v1/S17-2157
https://doi.org/10.18653/v1/S17-2157
https://doi.org/10.18653/v1/P17-1112
https://doi.org/10.18653/v1/P17-1112
http://www.aclweb.org/anthology/P13-2131
http://www.aclweb.org/anthology/P13-2131
https://doi.org/10.1023/A:1007379606734
http://dl.acm.org/citation.cfm?id=1953048.2078186
http://dl.acm.org/citation.cfm?id=1953048.2078186
http://aclweb.org/anthology/P16-1016
http://aclweb.org/anthology/P16-1016
http://aclweb.org/anthology/P16-1016
https://www.cl.cam.ac.uk/~aac10/papers/lrec2000.pdf
https://www.cl.cam.ac.uk/~aac10/papers/lrec2000.pdf
https://www.cl.cam.ac.uk/~aac10/papers/lrec2000.pdf
https://doi.org/10.1007/s11168-006-6327-9
https://doi.org/10.1007/s11168-006-6327-9
http://homepages.inf.ed.ac.uk/scohen/eacl17amr.pdf
http://homepages.inf.ed.ac.uk/scohen/eacl17amr.pdf
http://www.aclweb.org/anthology/P07-1033
http://www.aclweb.org/anthology/P07-1033
https://doi.org/10.18653/v1/K17-3002
https://doi.org/10.18653/v1/K17-3002
http://aclweb.org/anthology/S15-2154
http://aclweb.org/anthology/S15-2154
https://doi.org/10.18653/v1/K17-1038
https://doi.org/10.18653/v1/K17-1038
http://aclweb.org/anthology/W17-2607
http://aclweb.org/anthology/W17-2607


383

Jenny Rose Finkel and Christopher D. Manning. 2009.
Joint parsing and named entity recognition. In Proc.
of NAACL-HLT, pages 326–334.

Jeffrey Flanigan, Sam Thomson, Jaime Carbonell,
Chris Dyer, and Noah A. Smith. 2014. A discrim-
inative graph-based parser for the Abstract Meaning
Representation. In Proc. of ACL, pages 1426–1436.

Daniel Flickinger, Yi Zhang, and Valia Kordoni. 2012.
DeepBank: A dynamically annotated treebank of the
Wall Street Journal. In Proc. of Workshop on Tree-
banks and Linguistic Theories, pages 85–96.

William Foland and James H. Martin. 2017. Abstract
Meaning Representation parsing using LSTM re-
current neural networks. In Proc. of ACL, pages
463–472.

Yarin Gal and Zoubin Ghahramani. 2016. A Theoreti-
cally Grounded Application of Dropout in Recurrent
Neural Networks. In D D Lee, M Sugiyama, U V
Luxburg, I Guyon, and R Garnett, editors, Advances
in Neural Information Processing Systems 29, pages
1019–1027. Curran Associates, Inc.

Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3).

James Goodman, Andreas Vlachos, and Jason Narad-
owsky. 2016. Noise reduction and targeted explo-
ration in imitation learning for Abstract Meaning
Representation parsing. In Proc. of ACL, pages
1–11.

Jiang Guo, Wanxiang Che, Haifeng Wang, and Ting
Liu. 2016. Exploiting multi-typed treebanks for
parsing with deep multi-task learning. CoRR,
abs/1606.01161.

Jan Hajič, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Antònia Martı́, Lluı́s
Màrquez, Adam Meyers, Joakim Nivre, Sebastian
Padó, Jan Štepánek, Pavel Straňák, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 shared task: Syntactic and semantic depen-
dencies in multiple languages. In Proc. of CoNLL,
pages 1–18.

Kazuma Hashimoto, caiming xiong, Yoshimasa Tsu-
ruoka, and Richard Socher. 2017. A joint many-task
model: Growing a neural network for multiple NLP
tasks. In Proc. of EMNLP, pages 1923–1933.

James Henderson, Paola Merlo, Ivan Titov, and
Gabriele Musillo. 2013. Multilingual joint pars-
ing of syntactic and semantic dependencies with a
latent variable model. Computational Linguistics,
39(4):949–998.

Daniel Hershcovich, Omri Abend, and Ari Rap-
poport. 2017. A transition-based directed acyclic
graph parser for UCCA. In Proc. of ACL, pages
1127–1138.

Jonathan Herzig and Jonathan Berant. 2017. Neural
semantic parsing over multiple knowledge-bases. In
Proc. of ACL, pages 623–628.

Matthew Honnibal and Ines Montani. 2018. spaCy 2:
Natural language understanding with Bloom embed-
dings, convolutional neural networks and incremen-
tal parsing. To appear.

Nitish Shirish Keskar and Richard Socher. 2017. Im-
proving generalization performance by switching
from Adam to SGD. CoRR, abs/1712.07628.

Eliyahu Kiperwasser and Yoav Goldberg. 2016. Sim-
ple and accurate dependency parsing using bidi-
rectional LSTM feature representations. TACL,
4:313–327.

Sigrid Klerke, Yoav Goldberg, and Anders Søgaard.
2016. Improving sentence compression by learn-
ing to predict gaze. In Proc. of NAACL-HLT, pages
1528–1533.

Ioannis Konstas, Srinivasan Iyer, Mark Yatskar, Yejin
Choi, and Luke Zettlemoyer. 2017. Neural AMR:
Sequence-to-sequence models for parsing and gen-
eration. In Proc. of ACL, pages 146–157.

Mike Lewis, Luheng He, and Luke Zettlemoyer. 2015.
Joint A* CCG parsing and semantic role labelling.
In Proc. of EMNLP, pages 1444–1454.

Xavier Lluı́s and Lluı́s Màrquez. 2008. A joint model
for parsing syntactic and semantic dependencies. In
Proc. of CoNLL, pages 188–192.

Wolfgang Maier and Timm Lichte. 2016. Discontinu-
ous parsing with continuous trees. In Proc. of Work-
shop on Discontinuous Structures in NLP, pages
47–57.

Héctor Martı́nez Alonso and Barbara Plank. 2017.
When is multitask learning effective? Semantic se-
quence prediction under varying data conditions. In
Proc. of EACL, pages 44–53.

Jonathan May. 2016. SemEval-2016 task 8: Meaning
representation parsing. In Proc. of SemEval, pages
1063–1073.

Jonathan May and Jay Priyadarshi. 2017. SemEval-
2017 task 9: Abstract Meaning Representation pars-
ing and generation. In Proc. of SemEval, pages
536–545.

David McClosky, Eugene Charniak, and Mark John-
son. 2010. Automatic domain adaptation for pars-
ing. In Proc. of NAACL-HLT, pages 28–36.

Amir More. 2016. Joint morpho-syntactic processing
of morphologically rich languages in a transition-
based framework. Master’s thesis, The Interdisci-
plinary Center, Herzliya.

http://www.aclweb.org/anthology/N09-1037
http://aclweb.org/anthology/P14-1134
http://aclweb.org/anthology/P14-1134
http://aclweb.org/anthology/P14-1134
https://www.dfki.de/lt/publication_show.php?id=6619
https://www.dfki.de/lt/publication_show.php?id=6619
https://doi.org/10.18653/v1/P17-1043
https://doi.org/10.18653/v1/P17-1043
https://doi.org/10.18653/v1/P17-1043
http://papers.nips.cc/paper/6241-a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.pdf
http://papers.nips.cc/paper/6241-a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.pdf
http://papers.nips.cc/paper/6241-a-theoretically-grounded-application-of-dropout-in-recurrent-neural-networks.pdf
http://www.aclweb.org/anthology/J02-3001
http://www.aclweb.org/anthology/J02-3001
http://aclweb.org/anthology/P16-1001
http://aclweb.org/anthology/P16-1001
http://aclweb.org/anthology/P16-1001
https://arxiv.org/abs/1606.01161
https://arxiv.org/abs/1606.01161
http://www.aclweb.org/anthology/W09-1201
http://www.aclweb.org/anthology/W09-1201
http://www.aclweb.org/anthology/W09-1201
http://aclweb.org/anthology/D17-1206
http://aclweb.org/anthology/D17-1206
http://aclweb.org/anthology/D17-1206
http://cognet.mit.edu/node/27348
http://cognet.mit.edu/node/27348
http://cognet.mit.edu/node/27348
http://aclweb.org/anthology/P17-1104
http://aclweb.org/anthology/P17-1104
http://aclweb.org/anthology/P17-2098
http://aclweb.org/anthology/P17-2098
https://arxiv.org/abs/1712.07628
https://arxiv.org/abs/1712.07628
https://arxiv.org/abs/1712.07628
https://transacl.org/ojs/index.php/tacl/article/view/885
https://transacl.org/ojs/index.php/tacl/article/view/885
https://transacl.org/ojs/index.php/tacl/article/view/885
https://doi.org/10.18653/v1/N16-1179
https://doi.org/10.18653/v1/N16-1179
https://doi.org/10.18653/v1/P17-1014
https://doi.org/10.18653/v1/P17-1014
https://doi.org/10.18653/v1/P17-1014
https://doi.org/10.18653/v1/D15-1169
http://www.aclweb.org/anthology/W08-2124
http://www.aclweb.org/anthology/W08-2124
http://aclweb.org/anthology/W16-0906
http://aclweb.org/anthology/W16-0906
http://www.aclweb.org/anthology/E17-1005
http://www.aclweb.org/anthology/E17-1005
https://doi.org/10.18653/v1/S16-1166
https://doi.org/10.18653/v1/S16-1166
https://doi.org/10.18653/v1/S17-2090
https://doi.org/10.18653/v1/S17-2090
https://doi.org/10.18653/v1/S17-2090
http://www.aclweb.org/anthology/N10-1004
http://www.aclweb.org/anthology/N10-1004
https://www.idc.ac.il/en/schools/cs/research/Documents/amir-mor-thesis.pdf
https://www.idc.ac.il/en/schools/cs/research/Documents/amir-mor-thesis.pdf
https://www.idc.ac.il/en/schools/cs/research/Documents/amir-mor-thesis.pdf


384

Graham Neubig, Chris Dyer, Yoav Goldberg, Austin
Matthews, Waleed Ammar, Antonios Anastasopou-
los, Miguel Ballesteros, David Chiang, Daniel
Clothiaux, Trevor Cohn, Kevin Duh, Manaal
Faruqui, Cynthia Gan, Dan Garrette, Yangfeng Ji,
Lingpeng Kong, Adhiguna Kuncoro, Gaurav Ku-
mar, Chaitanya Malaviya, Paul Michel, Yusuke
Oda, Matthew Richardson, Naomi Saphra, Swabha
Swayamdipta, and Pengcheng Yin. 2017. DyNet:
The dynamic neural network toolkit. CoRR,
abs/1701.03980.

Joakim Nivre. 2003. An efficient algorithm for projec-
tive dependency parsing. In Proc. of IWPT, pages
149–160.

Joakim Nivre, Željko Agić, Lars Ahrenberg, Lene
Antonsen, Maria Jesus Aranzabe, Masayuki Asa-
hara, Luma Ateyah, Mohammed Attia, Aitziber
Atutxa, Liesbeth Augustinus, Elena Badmaeva,
Miguel Ballesteros, Esha Banerjee, Sebastian Bank,
Verginica Barbu Mititelu, John Bauer, Kepa Ben-
goetxea, Riyaz Ahmad Bhat, Eckhard Bick, Victo-
ria Bobicev, Carl Börstell, Cristina Bosco, Gosse
Bouma, Sam Bowman, Aljoscha Burchardt, Marie
Candito, Gauthier Caron, Gülşen Cebirolu Ery-
iit, Giuseppe G. A. Celano, Savas Cetin, Fabri-
cio Chalub, Jinho Choi, Silvie Cinková, Çar
Çöltekin, Miriam Connor, Elizabeth Davidson,
Marie-Catherine de Marneffe, Valeria de Paiva,
Arantza Diaz de Ilarraza, Peter Dirix, Kaja Do-
brovoljc, Timothy Dozat, Kira Droganova, Puneet
Dwivedi, Marhaba Eli, Ali Elkahky, Tomaž Erjavec,
Richárd Farkas, Hector Fernandez Alcalde, Jennifer
Foster, Cláudia Freitas, Katarı́na Gajdošová, Daniel
Galbraith, Marcos Garcia, Moa Gärdenfors, Kim
Gerdes, Filip Ginter, Iakes Goenaga, Koldo Go-
jenola, Memduh Gökrmak, Yoav Goldberg, Xavier
Gómez Guinovart, Berta Gonzáles Saavedra, Ma-
tias Grioni, Normunds Grūzītis, Bruno Guillaume,
Nizar Habash, Jan Hajič, Jan Hajič jr., Linh Hà M,
Kim Harris, Dag Haug, Barbora Hladká, Jaroslava
Hlaváčová, Florinel Hociung, Petter Hohle, Radu
Ion, Elena Irimia, Tomáš Jelı́nek, Anders Jo-
hannsen, Fredrik Jørgensen, Hüner Kaşkara, Hi-
roshi Kanayama, Jenna Kanerva, Tolga Kayade-
len, Václava Kettnerová, Jesse Kirchner, Na-
talia Kotsyba, Simon Krek, Veronika Laippala,
Lorenzo Lambertino, Tatiana Lando, John Lee,
Phng Lê Hng, Alessandro Lenci, Saran Lertpra-
dit, Herman Leung, Cheuk Ying Li, Josie Li, Key-
ing Li, Nikola Ljubešić, Olga Loginova, Olga Lya-
shevskaya, Teresa Lynn, Vivien Macketanz, Aibek
Makazhanov, Michael Mandl, Christopher Man-
ning, Cătălina Mărănduc, David Mareček, Katrin
Marheinecke, Héctor Martı́nez Alonso, André Mar-
tins, Jan Mašek, Yuji Matsumoto, Ryan McDon-
ald, Gustavo Mendonça, Niko Miekka, Anna Mis-
silä, Cătălin Mititelu, Yusuke Miyao, Simonetta
Montemagni, Amir More, Laura Moreno Romero,
Shinsuke Mori, Bohdan Moskalevskyi, Kadri
Muischnek, Kaili Müürisep, Pinkey Nainwani,
Anna Nedoluzhko, Gunta Nešpore-Bērzkalne, Lng
Nguyn Th, Huyn Nguyn Th Minh, Vitaly Niko-

laev, Hanna Nurmi, Stina Ojala, Petya Osen-
ova, Robert Östling, Lilja Øvrelid, Elena Pascual,
Marco Passarotti, Cenel-Augusto Perez, Guy Per-
rier, Slav Petrov, Jussi Piitulainen, Emily Pitler,
Barbara Plank, Martin Popel, Lauma Pretkalnia,
Prokopis Prokopidis, Tiina Puolakainen, Sampo
Pyysalo, Alexandre Rademaker, Loganathan Ra-
masamy, Taraka Rama, Vinit Ravishankar, Livy
Real, Siva Reddy, Georg Rehm, Larissa Rinaldi,
Laura Rituma, Mykhailo Romanenko, Rudolf Rosa,
Davide Rovati, Benoı̂t Sagot, Shadi Saleh, Tanja
Samardžić, Manuela Sanguinetti, Baiba Saulīte, Se-
bastian Schuster, Djamé Seddah, Wolfgang Seeker,
Mojgan Seraji, Mo Shen, Atsuko Shimada, Dmitry
Sichinava, Natalia Silveira, Maria Simi, Radu
Simionescu, Katalin Simkó, Mária Šimková, Kiril
Simov, Aaron Smith, Antonio Stella, Milan Straka,
Jana Strnadová, Alane Suhr, Umut Sulubacak,
Zsolt Szántó, Dima Taji, Takaaki Tanaka, Trond
Trosterud, Anna Trukhina, Reut Tsarfaty, Francis
Tyers, Sumire Uematsu, Zdeňka Urešová, Larraitz
Uria, Hans Uszkoreit, Sowmya Vajjala, Daniel van
Niekerk, Gertjan van Noord, Viktor Varga, Eric
Villemonte de la Clergerie, Veronika Vincze, Lars
Wallin, Jonathan North Washington, Mats Wirén,
Tak-sum Wong, Zhuoran Yu, Zdeněk Žabokrtský,
Amir Zeldes, Daniel Zeman, and Hanzhi Zhu. 2017.
Universal dependencies 2.1. LINDAT/CLARIN
digital library at the Institute of Formal and Ap-
plied Linguistics (ÚFAL), Faculty of Mathematics
and Physics, Charles University.

Joakim Nivre, Marie-Catherine de Marneffe, Filip Gin-
ter, Yoav Goldberg, Jan Hajic, Christopher D. Man-
ning, Ryan McDonald, Slav Petrov, Sampo Pyysalo,
Natalia Silveira, Reut Tsarfaty, and Daniel Zeman.
2016. Universal dependencies v1: A multilingual
treebank collection. In Proc. of LREC.

Stephan Oepen, Marco Kuhlmann, Yusuke Miyao,
Daniel Zeman, Silvie Cinkova, Dan Flickinger,
Jan Hajic, Angelina Ivanova, and Zdenka Uresova.
2016. Towards comparability of linguistic graph
banks for semantic parsing. In Proc. of LREC.

Stephan Oepen, Marco Kuhlmann, Yusuke Miyao,
Daniel Zeman, Silvie Cinková, Dan Flickinger, Jan
Hajič, and Zdeňka Urešová. 2015. SemEval 2015
task 18: Broad-coverage semantic dependency pars-
ing. In Proc. of SemEval, pages 915–926.

Stephan Oepen, Marco Kuhlmann, Yusuke Miyao,
Daniel Zeman, Dan Flickinger, Jan Hajič, Angelina
Ivanova, and Yi Zhang. 2014. SemEval 2014 task
8: Broad-coverage semantic dependency parsing. In
Proc. of SemEval, pages 63–72.

Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The proposition bank: An annotated corpus
of semantic roles. Computational Linguistics, 31(1).

Hao Peng, Sam Thomson, and Noah A. Smith. 2017a.
Deep multitask learning for semantic dependency
parsing. In Proc. of ACL, pages 2037–2048.

https://arxiv.org/abs/1701.03980
https://arxiv.org/abs/1701.03980
http://aclweb.org/anthology/W06-2933
http://aclweb.org/anthology/W06-2933
http://hdl.handle.net/11234/1-2515
https://nlp.stanford.edu/pubs/nivre2016ud.pdf
https://nlp.stanford.edu/pubs/nivre2016ud.pdf
http://www.lrec-conf.org/proceedings/lrec2016/pdf/887_Paper.pdf
http://www.lrec-conf.org/proceedings/lrec2016/pdf/887_Paper.pdf
http://aclweb.org/anthology/S15-2153
http://aclweb.org/anthology/S15-2153
http://aclweb.org/anthology/S15-2153
http://aclweb.org/anthology/S14-2008
http://aclweb.org/anthology/S14-2008
http://www.aclweb.org/anthology/J05-1004
http://www.aclweb.org/anthology/J05-1004
https://doi.org/10.18653/v1/P17-1186
https://doi.org/10.18653/v1/P17-1186


385

Hao Peng, Sam Thomson, Swabha Swayamdipta, and
Noah A. Smith. 2018. Learning joint semantic
parsers from disjoint data. In Proc. of NAACL-HLT.

Xiaochang Peng, Chuan Wang, Daniel Gildea, and Ni-
anwen Xue. 2017b. Addressing the data sparsity is-
sue in neural AMR parsing. In Proc. of EACL, pages
366–375.

Barbara Plank. 2016. Keystroke dynamics as signal
for shallow syntactic parsing. In Proc. of COLING,
pages 609–619.

Barbara Plank and Gertjan van Noord. 2011. Effective
measures of domain similarity for parsing. In Proc.
of ACL-HLT, pages 1566–1576.

Carl Pollard and Ivan A Sag. 1994. Head-driven
phrase structure grammar. University of Chicago
Press.

Michael Pust, Ulf Hermjakob, Kevin Knight, Daniel
Marcu, and Jonathan May. 2015. Parsing English
into Abstract Meaning Representation using syntax-
based machine translation. In Proc. of EMNLP,
pages 1143–1154.

Kenji Sagae and Jun’ichi Tsujii. 2008. Shift-reduce de-
pendency DAG parsing. In Proc. of COLING, pages
753–760.

Sanjiv Kumar Sashank J. Reddi, Satyen Kale. 2018.
On the convergence of Adam and beyond. ICLR.

Sebastian Schuster and Christopher D. Manning. 2016.
Enhanced English Universal Dependencies: An im-
proved representation for natural language under-
standing tasks. In Proc. of LREC. ELRA.

Anders Søgaard and Yoav Goldberg. 2016. Deep
multi-task learning with low level tasks supervised
at lower layers. In Proc. of ACL, pages 231–235.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan Salakhutdinov. 2014.
Dropout: A simple way to prevent neural networks
from overfitting. Journal of Machine Learning Re-
search, 15:1929–1958.

Elior Sulem, Omri Abend, and Ari Rappoport. 2015.
Conceptual annotations preserve structure across
translations: A French-English case study. In Proc.
of S2MT, pages 11–22.

Mihai Surdeanu, Richard Johansson, Adam Meyers,
Lluı́s Màrquez, and Joakim Nivre. 2008. The
CoNLL 2008 shared task on joint parsing of syntac-
tic and semantic dependencies. In Proc. of CoNLL,
pages 159–177.

Swabha Swayamdipta, Miguel Ballesteros, Chris Dyer,
and Noah A. Smith. 2016. Greedy, joint syntactic-
semantic parsing with stack LSTMs. In Proc. of
CoNLL, pages 187–197.

Swabha Swayamdipta, Sam Thomson, Chris Dyer, and
Noah A. Smith. 2017. Frame-semantic parsing with
softmax-margin segmental rnns and a syntactic scaf-
fold. CoRR, abs/1706.09528.

Kristina Toutanova, Aria Haghighi, and Christopher
Manning. 2005. Joint learning improves semantic
role labeling. In Proc. of ACL, pages 589–596.

Chuan Wang, Sameer Pradhan, Xiaoman Pan, Heng Ji,
and Nianwen Xue. 2016. CAMR at SemEval-2016
task 8: An extended transition-based AMR parser.
In Proc. of SemEval, pages 1173–1178.

Chuan Wang, Nianwen Xue, and Sameer Pradhan.
2015a. Boosting transition-based AMR parsing
with refined actions and auxiliary analyzers. In
Proc. of ACL, pages 857–862.

Chuan Wang, Nianwen Xue, and Sameer Pradhan.
2015b. A transition-based algorithm for AMR pars-
ing. In Proc. of NAACL, pages 366–375.

Yuan Zhang and David Weiss. 2016. Stack-
propagation: Improved representation learning for
syntax. In Proc. of ACL, pages 1557–1566.

Yue Zhang and Stephen Clark. 2009. Transition-
based parsing of the Chinese treebank using a global
discriminative model. In Proc. of IWPT, pages
162–171.

Junsheng Zhou, Feiyu Xu, Hans Uszkoreit, Weiguang
Qu, Ran Li, and Yanhui Gu. 2016. AMR pars-
ing with an incremental joint model. In Proc. of
EMNLP, pages 680–689.

Yftah Ziser and Roi Reichart. 2017. Neural structural
correspondence learning for domain adaptation. In
Proc. of CoNLL, pages 400–410.

http://samthomson.com/papers/peng+etal.naacl2018.pdf
http://samthomson.com/papers/peng+etal.naacl2018.pdf
http://aclweb.org/anthology/E17-1035
http://aclweb.org/anthology/E17-1035
http://www.aclweb.org/anthology/C16-1059
http://www.aclweb.org/anthology/C16-1059
http://www.aclweb.org/anthology/P11-1157
http://www.aclweb.org/anthology/P11-1157
http://aclweb.org/anthology/D15-1136
http://aclweb.org/anthology/D15-1136
http://aclweb.org/anthology/D15-1136
http://aclweb.org/anthology/C08-1095
http://aclweb.org/anthology/C08-1095
https://openreview.net/forum?id=ryQu7f-RZ
https://nlp.stanford.edu/pubs/schuster2016enhanced.pdf
https://nlp.stanford.edu/pubs/schuster2016enhanced.pdf
https://nlp.stanford.edu/pubs/schuster2016enhanced.pdf
https://doi.org/10.18653/v1/P16-2038
https://doi.org/10.18653/v1/P16-2038
https://doi.org/10.18653/v1/P16-2038
http://jmlr.org/papers/v15/srivastava14a.html
http://jmlr.org/papers/v15/srivastava14a.html
http://aclweb.org/anthology/W15-3502
http://aclweb.org/anthology/W15-3502
http://www.aclweb.org/anthology/W08-2121
http://www.aclweb.org/anthology/W08-2121
http://www.aclweb.org/anthology/W08-2121
http://aclweb.org/anthology/K16-1019
http://aclweb.org/anthology/K16-1019
https://arxiv.org/abs/1706.09528
https://arxiv.org/abs/1706.09528
https://arxiv.org/abs/1706.09528
http://www.aclweb.org/anthology/P05-1073
http://www.aclweb.org/anthology/P05-1073
http://aclweb.org/anthology/S16-1181
http://aclweb.org/anthology/S16-1181
http://aclweb.org/anthology/P15-2141
http://aclweb.org/anthology/P15-2141
http://aclweb.org/anthology/N15-1040
http://aclweb.org/anthology/N15-1040
https://doi.org/10.18653/v1/P16-1147
https://doi.org/10.18653/v1/P16-1147
https://doi.org/10.18653/v1/P16-1147
http://aclweb.org/anthology/W09-3825
http://aclweb.org/anthology/W09-3825
http://aclweb.org/anthology/W09-3825
http://aclweb.org/anthology/D16-1065
http://aclweb.org/anthology/D16-1065
https://doi.org/10.18653/v1/K17-1040
https://doi.org/10.18653/v1/K17-1040

