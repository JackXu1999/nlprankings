



















































A Dictionary-Based Approach to Identifying Aspects Implied by Adjectives for Opinion Mining


Proceedings of COLING 2012: Posters, pages 309–318,
COLING 2012, Mumbai, December 2012.

A	Dictionary‐Based	Approach	to	Identifying	Aspects	Im‐
plied	by	Adjectives	for	Opinion	Mining		

Geli Fei 1  Bing Liu 1 Meichun Hsu 2 Malu Castellanos 2 Riddhiman Ghosh 2 
(1) Department of Computer Science, University of Illinois at Chicago, Chicago, USA 

(2) HP Labs, Palo Alto, California, USA 
gfei2@uic.edu, liub@cs.uic.edu 

{meichun.hsu, malu.castellanos, riddhiman.ghosh}@hp.com 

ABSTRACT One	of	the	central	problems	of	opinion	mining	is	to	extract	aspects	of	entities	or	topics	that	have	 been	 evaluated	 in	 an	 opinion	 sentence	 or	 document.	Much	 of	 the	 existing	 research	focused	 on	 extracting	 explicit	 aspects	which	 are	 nouns	 and	 nouns	 phrases	 that	 have	 ap‐peared	in	sentences,	e.g.,	price	in	 The	price	of	this	bike	is	very	high. 	(owever,	in	many	cas‐es,	people	do	not	explicitly	mention	an	aspect	in	a	sentence,	but	the	aspect	is	implied,	e.g.,	
This	bike	 is	expensive, 	 where	 expensive	 indicates	 the	 price	 aspect	 of	 the	 bike.	 Although	there	 are	 some	 existing	works	 dealing	with	 the	 problem,	 they	 all	 used	 the	 corpus‐based	approach,	which	 has	 several	 shortcomings.	 )n	 this	 paper,	we	 propose	 a	 dictionary‐based	approach	to	address	these	shortcomings.	We	formulate	the	problem	as	collective	classifica‐tion.	Experimental	results	show	that	the	proposed	approach	is	effective	and	produces	sig‐nificantly	better	results	than	strong	baselines	based	on	traditional	supervised	classification.	KEYWORDS:	)mplied	Aspects	or	Topics,	Opinion	Mining,	Sentiment	Analysis	

309



1 Introduction	)n	sentiment	analysis,	the	task	of	aspect	extraction	is	to	identify	aspects	of	entities	or	topics	on	which	opinions	have	been	expressed	 (u	and	Liu	 .	For	example,	 in	 the	sentence	
The	picture	quality	of	this	camera	 is	great, 	 picture	quality	 is	 an	 aspect	 of	 the	 camera.	 )n	most	 cases,	 aspects	 appear	 explicitly	 in	 sentences,	 e.g.,	 picture	quality.	 Such	 aspects	 are	
called	explicit	aspects	 (u	and	Liu	 .	(owever,	in	many	other	cases,	they	do	not	appear,	but	are	implied.	For	instance,	the	sentence	 This	is	an	expensive	bike 	gives	a	negative	opin‐ion	about	 the	price	 aspect.	(owever,	price	 is	not	 in	 the	sentence,	but	 it	 is	clearly	 implied.	
Price	is	called	an	implicit	aspect	 Liu,	 .	Price	is	also	called	an	attribute	of	expensive	in	lexical	semantics	 Almuhareb,	 .	)n	this	paper,	we	will	use	the	terms	aspect	and	attrib‐
ute	interchangeably	as	they	mean	the	same	thing	in	our	context.	Since	aspects	or	attributes	used	in	this	work	are	nouns,	we	also	call	them	aspects/attribute	nouns.	)mplicit	 aspects	 can	 be	 indicated	 by	many	 types	 of	 expressions,	 e.g.,	 adjectives,	 adverbs,	verbs	and	their	phrases.	This	paper	focuses	on	opinion	adjectives.	Although	there	are	gen‐eral	opinion	adjectives	which	can	describe	anything,	e.g.,	good	and	bad,	most	adjectives	de‐scribe	 some	 specific	 attributes	 of	 entities.	 The	 goal	 of	 this	 work	 is	 to	 identify	 attribute	nouns	of	each	adjective,	e.g.,	to	identify	price,	cost,	etc.,	for	adjective	expensive.		There	are	some	existing	works	that	tried	to	find	implicit	aspects	indicated	by	adjectives	 Su	et	al.,	 ;	(ai	et	al.,	 .	They	all	depend	on	co‐occurrences	of	adjectives	and	explicit	attribute	nouns	in	sentences	in	a	corpus.	There	are	also	some	relevant	works	in	lexical	se‐mantics,	 which	 also	 use	 corpus‐based	 techniques	 Almuhareb	 and	 Poesio	 ;	 (artung	and	Frank,	 ;	(artung	and	Frank,	 .	The	corpus‐based	approach	is	useful	for	find‐ing	 context	 specific	mappings	 of	 adjectives	 and	 attributes	 because	 an	 adjective	 can	 have	multiple	senses.	)n	a	specific	domain	or	context,	it	takes	only	a	specific	sense	 which	needs	to	be	discovered .	(owever,	the	corpus‐based	approach	alone	also	has	some	weaknesses:	. )t	is	hard	to	discover	attributes	that	do	not	co‐occur	with	their	adjectives.	For	example,	in	English,	people	don’t	say	 The	price	of	iPhone	is	expensive. 	)nstead,	they	say	 iPhone	

is	expensive.”	)t	is	thus	hard	for	a	corpus‐based	approach	to	find	price	for	expensive.		. Even	if	an	adjective	and	one	of	its	attribute	nouns	do	appear	in	a	corpus,	due	to	the	lim‐ited	corpus	size,	they	may	not	co‐occur	in	many	sentences	to	be	associated	reliably.		. )f	one	wants	to	find	all	attribute	nouns	for	each	adjective,	it	is	also	difficult	due	to	the	corpus	size	limit	because	not	all	adjectives	or	all	attributes	may	appear	in	a	corpus.		)n	 this	 work,	 we	 propose	 a	 dictionary‐based	 approach	 which	 complements	 the	 corpus‐based	 approach	 and	 can	 address	 these	 problems.	 The	 first	 and	 the	 second	 problems	 are	tackled	because	dictionaries	typically	define	adjectives	using	their	attributes.	For	example,	
expensive	is	defined	as	 Marked	by	high	prices 	in	thefreedictionary.com.	The	third	problem	is	 also	 addressed	 because	 dictionaries	 are	 not	 restricted	 by	 any	 specific	 corpus.	We	 can	work	on	every	adjective	 in	a	dictionary.	Since	not	all	attribute	nouns	of	an	adjective	may	appear	in	a	dictionary,	we	use	multiple	dictionaries	for	better	coverage.	To	our	knowledge,	this	is	the	first	dictionary‐based	approach.	)t	finds	all	attribute	nouns	for	an	adjective.		We	propose	to	solve	the	problem	using	a	relational	learning	method	called	collective	classi‐
fication	 Sen	et	 al.	 ,	which	 can	 take	advantage	of	 rich	 lexical	 relationships	of	words	e.g.,	 synonyms,	 antonyms,	 hyponym	 and	 hypernym 	 for	 classification.	 Our	 evaluation	shows	that	collective	classification	outperforms	traditional	classification	significantly.		

310



2 The	Proposed	Approach	Our	proposed	method	consists	of	three	steps:	. Given	a	set	of	adjectives	A	=	{A ,	A ,	…,	Ar},	crawl	the	online	dictionaries	for	their	glosses.	. For	 each	 adjective	Ai		A,	 perform	 POS	 tagging	 of	 its	 glosses	 and	 extract	 nouns	 from	them.	These	nouns	are	regarded	as	the	candidate	attribute	nouns	Ci	for	adjective	Ai.	. Classify	each	candidate	attribute	noun	cij		Ci	to	one	of	the	two	classes,	attribute	noun	or	
not	attribute	noun,	of	Ai.	This	step	uses	a	collective	classification	algorithm	to	exploit	the	lexical	relationships	of	words	in	dictionaries	to	build	more	accurate	classifiers.	Since	the	first	two	steps	are	straightforward,	the	rest	of	the	paper	focuses	on	step	 .		

2.1 Problem	Formulation	and	Solution	)n	traditional	supervised	learning,	each	instance	is	drawn	independently	of	others	 Mitch‐ell,	 .	 (owever,	 in	many	 real‐life	 data,	 instances	 are	 not	 independent	 of	 each	 other.	Such	data	is	often	represented	as	a	graph	where	nodes	are	instances	and	links	are	their	re‐lations.	The	classification	of	one	node	can	influence	its	neighboring	nodes.	This	type	of	clas‐sification	is	called	collective	classification	 Sen	et	al.,	 	as	opposed	to	the	instance‐based	classification.	We	formulate	the	proposed	problem	as	collective	classification.	Each	instance	in	our	data	denotes	a	pair	with	an	adjective	Ai	and	one	of	its	candidate	attrib‐ute	nouns	cij,	i.e.,	 Ai,	cij .	Due	to	the	relational	features	 which	will	be	detailed	later ,	we	use	a	graph	representation	of	instances,	with	a	set	of	nodes	 pairs ,	V	=	{ Ai,	cij 	|	cij		Ci,	Ai		A},	and	a	neighborhood	function	N,	where	Nij		V	–	{ Ai,	cij }.	Each	node	 a	pair	 Ai,	cij 	in	V	is	represented	with	a	vector	xij	of	features,	f ,	f ,	…,	fn,	and	is	associated	with	a	class	label	yij	in	the	domain	of	 {positive,	negative}.	The	positive	class	means	attribute	noun,	and	the	nega‐tive	class	means	not	attribute	noun.	V	 is	 further	divided	 into	 two	sets	of	nodes:	L,	 labeled	nodes,	and	U,	unlabeled	nodes.	Our	task	is	to	predict	the	label	for	each	node	uij		U.		A	collective	classification	algorithm	called	the	iterative	classification	algorithm	 )CA 	 Sen	et	al.	 	 is	 employed	 to	 solve	 this	problem.	 )CA	 is	given	 in	Figure	 .	 )ts	 training	process	not	in	Figure	 	trains	a	classifier	h	 just	like	traditional	supervised	learning,	using	the	la‐beled	set	L	with	all	features.	The	classification	 or	testing 	step	is	the	core	of	this	algorithm.		)n	testing,	the	learned	classifier	h	assigns	a	class	label	to	each	node	uij		U	in	the	test	data	lines	 ‐ .	 Line	 	 computes	 the	 feature	 vector	xij	for	uij.	 This	 and	 also	 line	 	 is	 an	 im‐portant	step	of	this	algorithm	which	makes	it	different	from	the	classic	supervised	learning.	)t	 computes	all	 the	relational	 features	 for	uij	using	 the	neighbors	of	uij.	(owever,	 line	 	 is	slightly	different	from	line	 	as	in	line	 	not	all	nodes	have	been	assigned	class	labels,	so	we	compute	xij	 based	on	 the	 intersection	of	 the	 labeled	nodes	 L 	 and	uij’s	 neighbors.	 Line	 	uses	h	to	assign	a	class	 yij 	to	node	uij.	Lines	 ‐ 	are	considered	as	the	initialization	step.	After	 initialization,	 the	 classifier	 is	 run	 iteratively	 lines	 ‐ 	 until	 the	 class	 labels	 of	 all	nodes	no	 longer	 change.	The	 iterations	are	needed	because	 some	 relational	 features	of	 a	node	depend	on	the	class	labels	of	its	neighbors.	Such	labels	are	assigned	in	each	iteration	and	may	change	from	one	iteration	to	the	next.		)n	each	iteration	 lines	 ‐ ,	the	algorithm	first	generates	an	ordering	of	nodes	to	be	classified.	We	order	them	randomly	in	order	to	reduce	bias	as	the	random	ordering	makes	the	process	stochastic.	Line	 	does	the	same	job	as	line	 .	Line	 	does	the	same	job	as	line	 .	Classifier	h	does	not	change	in	the	iterations.		
311



Figure	 	shows	a	simplified	example	of	a	graph	based	on	some	relationships	of	words.	)t	is	also	a	snapshot	of	an	iteration	of	)CA.	Each	oval	node	denotes	an	instance	 an	adjective	and	attribute	pair .	A	dashed	box	 encloses	 the	pairs	 that	belong	 to	 the	 same	adjective.	A	 link	between	two	oval	nodes	denotes	a	relationship	between	two	 candidate 	attribute	nouns,	and	a	link	between	two	dashed	boxes	denotes	a	relationship	between	two	adjectives.	Green	lines	denote	synonym	and	red	lines	denote	antonym.	The	green	shaded	nodes	denote	those	labeled	pairs,	the	grey	shaded	nodes	denote	those	candidate	attribute	nouns	whose	labels	have	been	predicted	 unlabeled	 at	 the	beginning ,	whereas	un‐shaded	oval	nodes	denote	those	candidate	attribute	nouns	whose	labels	are	yet	to	be	predicted	in	the	iteration.	)n	the	figure,	adjectives	Ak	and	Aj	are	synonyms,	attribute	noun	ck2	 labeled 	and	candidate	attrib‐ute	noun	cj1	are	synonyms,	and	candidate	attribute	nouns	cj1	and	cj2	are	antonyms.	 )n	 the	previous	iteration,	)CA	has	predicted/labeled	cj2	as	an	attribute	noun	of	Aj.	Since	cj2,	cj1	and	
ck2	are	related,	the	label	of	cj1	will	be	affected	by	the	labels	of	cj2	and	ck2	in	this	iteration.		
2.2 Useful	Relations	)n	this	work,	we	consider	two	kinds	of	relations	for	adjectives:	synonym	and	antonym,	and	four	kinds	of	relations	for	nouns:	synonym,	antonym,	hypernym	and	hyponym.	Using	them,	we	created	two	sets	of	relational	features,	static	 relational 	features	and	dynamic	 relation‐al 	features.	Static	features	are	not	affected	by	the	classification	process	in	testing.	Dynamic	features	 are	 affected	 by	 the	 classification	 process,	 i.e.,	 the	 values	 of	 these	 features	 can	change	during	the	testing	phase	because	they	depend	on	the	predicted	labels	of	its	neigh‐bours	 which	are	also	candidate	attribute	noun	and	adjective	pairs 	 see	Section	 . .	Final‐ly,	we	have	three	sets	of	features:	 	local	features	 these	are	the	traditional	features	about	each	instance	itself ,	 	static	relational	features,	and	 	dynamic	relational	features.	
2.3 Local	Features	The	local	features	 L ,	…,	L 	are	only	about	the	adjective‐noun	pair	 Ai,	cij 	itself:		L .	Word	n‐grams:	These	are	traditional	n‐grams	of	words	in	the	glosses	of	each	adjective	Ai.	L .	Part	of	speech	 POS 	n‐grams:	n‐grams	of	POS	tags.	These	are	also	traditional	features.	L .	Number	of	times	that	candidate	attribute	noun	cij	appears	in	the	glosses	for	adjective	Ai	in	all	dictionaries.	)ntuitively,	the	more	times	it	appears,	the	more	likely	it	is	a	true	attribute.	L .	Diversity	of	candidate	nouns	in	Ci	for	adjective	Ai:	The	idea	is	that	if	the	candidate	words	

 Figure	 .	An	example	of	a	graph of 
word relations and an ICA iteration 

Algorithm	)CA	‐	)terative	classification.				for	each	node	uij		U	 //	each	node	is	a	pair .	 				compute	xij	using	only	L		Nij	.								yij		h xij 	.				endfor	.				repeat	//	iterative	classification	.								generate	an	ordering	O	over	pairs	in	U	.								for	each	node	oij		O	do .												compute	xij	using	current	assignments	to	Nij	.												yij		h	 xij 	.			 endfor	.		until	all	class	labels	do	not	change		
 

312



are	too	numerous	and	all	different,	then	they	are	less	likely	to	be	true	attribute	nouns.	En‐tropy	is	one	of	the	methods	for	measuring	diversity.	Let	nij	be	the	frequency	that	the	candi‐date	attribute	noun	cij		Ci,	as	well	as	cij’s	synonyms	and	antonyms,	occur	in	the	glosses	of	Ai	in	all	dictionaries.	We	call	a	set	of	words	formed	by	cij	and	its	synonyms	and	antonyms	in	Ci	a	semantic	group	for	cij.	Let	m	be	the	number	of	semantic	groups	formed	by	the	words	in	Ci.	Let	Ti	be	the	occurrence	count	of	Ai’s	candidate	attribute	nouns	in	all	dictionaries.	Let	pij	 =	
nij	/Ti 	be	the	probability	of	occurrence	of	the	candidate	nouns	in	cij’s	semantic	group	in	the	dictionaries.	The	diversity	 entropy 	of	Ci	is	defined	as:		


 m

j
ijiji ppCdiversity

1

log)( 																																																	 	L .	Similarity	of	candidate	attribute	noun	cij	and	its	adjective	Ai.	This	is	the	number	of	same	letters	 mij 	in	their	prefixes	normalized	by	the	maximum	length	 len . 	of	the	two	words,	
))(),(max(

),(
iij

ij
iij Alenclen

m
Acsim  																																										 	We	use	this	feature	because	in	some	cases	a	noun	is	turned	into	an	adjective	with	ending	changes,	e.g.,	style	 cij 	and	stylistic	 Ai 	 their	similarity	is	 / .	L .	Frequent	POS	sequence	patterns	mined	from	the	POS	tags	of	q	 =	 	words	right	before	each	candidate	attribute	noun	cij	in	a	gloss,	using	a	sequence	pattern	mining	algorithm	 Sri‐kant	and	Agrawal,	 .	All	 the	discovered	patterns	are	used	as	 features.	Note	 that	POS	patterns	are	not	POS	n‐grams	because	a	pattern	can	skip	POS	tags	but	a	POS	n‐gram	 is	a	sequence	of	consecutive	POS	tags.	For	pattern	discovery,	every	gloss	sentence	containing	cij	generate	a	POS	 tag	sequence	 for	mining.	For	 testing,	when	multiple	glosses	containing	cij	we	use	multiple	dictionaries ,	as	long	as	the	POS	tags	of	the	q	word	before	one	occurrence	of	cij	satisfies	the	pattern,	the	feature	for	the	pattern	is	set	to	 ;	otherwise	 .	

2.4 Static	Relational	Features	To	define	relational	features,	we	first	need	to	define	some	relations.	Let	Rs	be	a	binary	syn‐onym	function	and	Ra	be	a	binary	antonym	function	on	the	set	of	all	adjectives	or	candidate	attribute	nouns.	For	wi,	wj		A	 all	adjectives 	or	wi,	wj		C	 all	candidate	attribute	nouns ,	if	
Rs wi,	wj 	=	 ,	wi	and	wj	are	synonyms.	)f	Rs wi,	wj 	=	 ,	wi	and	wj	are	not	synonyms.	)f	Ra wi,	
wj 	=	 ,	wi	and	wj	are	antonyms.	)f	Ra wi,	wj 	=	 ,	wi	and	wj	are	not	antonyms.	Similarly,	we	have	Rhyper	 hypernym 	and	Rhypo	 hyponym 	on	the	set	of	all	candidate	attribute	nouns	C.	We	also	assume	that	both	Rs	and	Ra	are	symmetric,	which	means	that	for	all	wi,	wj		A	or	wi,	
wj		C,	Rs wi,	wj 	implies	Rs wj,	wi ,	and	Ra wi,	wj 	implies	Ra wj,	wi .	We	now	present	the	static	relational	features.	Let	gid	be	the	glosses	in	the	d‐th	dictionary	for	adjective	Ai.	Let	E cij,	gid 	be	a	function	that	returns	the	number	of	times	that	cij	occurs	in	gid.	For	each	node	 or	pair 	 Ai,	cij ,	we	have	the	following	 	static	relational	features:	S ‐S .	These	four	features	represent	respectively	the	number	of	times	that	cij’s	synonyms,	antonyms,	hypernyms	and	hyponyms	appear	in	the	glosses	of	Ai	in	the	dictionaries,	

),(),(
||

1 1 id

S

k

H

d ikijik
gcEccR   																																												 	where	S	is	the	set	of	synonyms,	antonyms,	hypernyms	or	hyponyms	of	cij		Ci	and	H	is	the	number	of	dictionaries,	R		{Rs,	Ra,	Rhyper,	Rhypo}.	These	relationships	are	extracted	from	the	WordNet.	These	features	are	relational	because	they	are	related	to	other	nodes	in	the	graph	as	each	synonym,	antonym,	hypernym	or	hyponym	of	cij	in	S	that	appears	in	the	glosses	of	a	

313



dictionary	also	generates	an	instance	 or	a	node 	in	the	data.	And	the	reason	we	call	these	relational	features	static	is	because	they	don’t	change	during	the	testing	phase.	These	fea‐tures	are	used	because	the	more	times	that	cij’s	synonyms,	antonyms,	hypernyms	or	hypo‐nyms	appear	in	the	glosses	of	adjective	Ai,	the	more	likely	cij	is	a	true	attribute	noun	of	Ai.	S ‐S .	These	two	features	represent	respectively	the	total	number	of	times	that	cij	appears	in	the	glosses	of	Ai’s	synonyms	and	antonyms,	
),(),(

||

1 1 kd

S

k

H

d ijki
gcEAAR   																																											 	where	S	is	the	set	of	synonyms	or	antonyms	of	Ai	in	set	A,	and	R		{Rs,	Ra}.		S .	The	number	of	times	that	cij	appears	in	the	glosses	of	other	adjectives	which	are	neither	synonym	nor	antonym	of	Ai.	This	feature	can	be	calculated	as	follows,	

),()),(1))(,(1(
||

1 1 kd

S

k

H

d ijkiakis
gcEAARAAR    																																 	where	S	is	the	set	of	all	adjectives	in	the	data.	The	intuition	is	that	the	more	cij	appears,	the	less	likely	it	is	a	real	attribute	for	Ai.	

2.5 Dynamic	Relational	Features	Dynamic	relational	features	mean	that	their	values	can	change	during	the	testing	phase	be‐cause	they	are	calculated	based	on	the	classified	labels	of	neighboring	nodes.	That	is,	these	features	 let	 the	system	see	how	the	neighboring	nodes	of	 the	current	node	are	classified,	which	affects	the	classification	of	the	current	node.	For	each	cij		Ci	of	adjective	Ai,	Y cij,	Ai 	denotes	the	class	label	of	node	 Ai,	cij .	)f	the	node	is	classified	as	positive	 we	also	say	that	cij	 is	classified	as	an	attribute	noun	of	adjective	Ai ,	
Y cij,	Ai 	=	 ;	otherwise	Y cij,	Ai 	=	 .	We	have	the	following	 	dynamic	relational	features:	D ‐D .	 These	four	features	represent	respectively	the	number	of	times	that	cij’s	synonyms,	antonyms,	hypernyms	and	hyponyms	are	classified	as	attribute	nouns	for	Ai,	

),(),(
||

1 i

S

k ikijik
AcYccR  																																																										 	where	S	is	the	set	of	synonyms,	antonyms,	hypernyms	or	hyponyms	of	cij		Ci,	and	R		{Rs,	

Ra,	Rhyper,	Rhypo}.	We	use	these	features	because	if	a	synonym,	antonym,	hypernym	or	hypo‐nym	of	cij	is	an	attribute	noun	for	Ai	then	cij	is	also	likely	to	be	such	a	noun	for	Ai.	D ‐D .	 These	two	features	represent	respectively	the	number	of	times	that	cij	is	classified	as	attributes	for	Ai’s	synonyms	and	antonyms,	
 || 1 ),(),(Sk kijik AcYAAR                                                     				 	where	S	is	the	set	of	synonyms	or	antonyms	of	Ai		A	and	R		{Rs,	Ra}.	D ‐D .	 These	 eight	 features	 represent	 respectively	 the	 number	 of	 times	 that	 cij’s	 syno‐nyms,	antonyms,	hypernyms	and	hyponyms	are	classified	as	attribute	nouns	for	Ai’s	syno‐nyms	and	antonyms,	

),(),(),(
||

1

||

1 q

T

p

S

q ipiqAijipC
AcYAARccR   																																				 	where	S	is	the	set	of	synonyms	or	antonyms	of	Ai,	T	is	the	set	of	synonyms,	antonyms,	hy‐pernyms	or	hyponyms	of	cij		Ci,	and	RC		{Rs,	Ra,	Rhyper,	Rhypo},	RA		{Rs,	Ra}.	So	we	obtain	a	total	of	 	dynamic	features.	

314



3 Experimental Results	We	now	evaluate	the	proposed	technique.	First,	we	compare	the	results	of	different	feature	sets,	i.e.,	 local	features,	static	relational	features,	and	dynamic	relational	features,	and	also	two	 learning	 strategies.	 Note	 that	 using	 only	 local	 features	 is	 the	 traditional	 supervised	classification.	Second,	we	compare	our	results	with	WordNet	in	terms	of	attribute	coverage.		
3.1 Experiment	Settings	
Datasets:	Our	data	were	extracted	from	 	online	dictionaries:	Dictionary.com,	The	Free	Dic‐
tionary,	Longman	Dictionary	of	Contemporary	English,	Your	Dictionary,	 and	The	Free	Merri‐
am‐Webster	Dictionary.	For	opinion	adjectives,	we	used	a	subset	of	 	adjectives	from	the	opinion	 lexicon	of	(u	and	Liu	 .	 From	each	dictionary,	we	extracted	 the	glosses	of	these	adjectives.	The	Stanford	POS	Tagger 	 Toutanova	et	al.,	 	was	used	to	find	nouns.	The	nouns	from	each	adjective’s	gloss	were	considered	as	its	candidate	attribute	nouns.		Altogether	 	adjective‐noun	pairs	 from	 	adjectives	were	annotated	by	 two	human	labelers.	Kappa	 κ 	gave	κ	=	 . 	 substantial	agreement	 Landis	and	Koch,	 .	As	a	 ‐class	classification	problem,	we	treat	attribute	noun	as	the	positive	class,	and	not	attribute	
noun	as	the	negative	class.	The	distribution	of	the	positive	and	negative	classes	is	 %	and	%	respectively.	All	classification	results	were	obtained	through	 ‐fold	cross‐validations.	
3.2 Results	and	Discussions	We	first	assess	the	usefulness	of	different	local	features.	Traditional	classification	is	applied	to	 these	 features.	 Table	 	 gives	 the	 best	 local	 feature	 combination	 L ,	 L ,	 L ,	 and	 L .	Word	n‐grams	and	POS	n‐grams	were	found	not	so	useful.	POS	n‐grams	also	perform	worse	than	POS	patterns	 due	to	space	limitations,	we	cannot	show	the	detailed	results 	because	n‐grams	are	consecutive	POS	tags,	while	POS	patterns	do	not	have	to	be	consecutive.	This	makes	POS	patterns	better	able	to	capture	the	regularities	in	the	text.	Next	we	evaluate	the	collective	 classification	based	on	 the	best	 set	 of	 local	 features	 and	all	 static	 and	dynamic	features.	Two	classification	strategies	were	examined.	
                                                           	http://www.cs.uic.edu/~liub	/FBS/sentiment‐analysis.html		http://nlp.stanford.edu/software/tagger.shtml	

local	features	 Accuracy F‐score	Best	local	feature	combination	 L ,	L ,	L ,	L 	 . 	 . 	Table	 	–	Usefulness	of	different	local	features	
	

Feature	sets	
Logistic	Regression	 SVM	

Prec Rec F‐score Acc Prec Rec	 F‐score	 Acc	Strategy	 	Local	features	 traditional	learning . . . 	 . . . 	 . 	 . 	Local+static	features	 . . . 	 . . . 	 . 	 . 	Local+dynamic	features	 . 0.783 0.746	 . . . 	 . 	 . 	All	features	 0.747 . . 	 . . . 	 . 	 . 	Strategy	 	 )CA	 all	features 	 0.791 . . 	 . . . 	 . 	 . 	)CA	 local+dynamic	features 	 . 0.766 0.754	 0.742 . . 	 . 	 . 	Table	 	–	Average	Precision,	Recall,	F‐score	and	Accuracy	results	over	 ‐fold	cross‐validations	

315



Strategy	 	 two	stages :	The	 first	 stage	simply	builds	a	 local	classifier	using	 the	 local	 fea‐tures	or	a	combination	of	local	and	static	relational	features	to	classify	each	node.	The	re‐sults	serve	as	 the	 initialization	 for	stage	 two.	 )n	 the	second	stage,	dynamic	relational	 fea‐tures	are	added	to	run	the	)CA	algorithm	in	Figure	 	without	the	first	 	lines.		Strategy	 	 one	stage :	We	simply	train	with	both	local	and	relational	features.	The	trained	classifier	is	then	applied	to	classify	the	test	data	using	the	)CA	algorithm	in	Figure	 .		Table	 	shows	the	results	of	for	each	strategy	and	each	feature	set	for	Logistic	Regression	LR 	 and	 SVM.	 For	 LR,	 we	 used	 the	 Lingpipe	 system	 http://alias‐i.com/lingpipe/ .	 For	SVM,	we	used	SVMlight	 http://svmlight.	joachims.org/ .	From	the	table,	we	can	see	that	LR	performs	 better	 than	 SVM	 in	 general.	 Our	 discussions	 and	 comparisons	 below	 are	 thus	based	on	LR.	Table	 	also	allows	us	to	make	the	following	observations:	. Local 	 features	perform	 the	worst	 traditional	 classification .	With	 the	 addition	of	 ei‐ther	the	two	sets	of	relational	features,	the	results	improve.	The	dynamic	relational	fea‐tures	are	most	useful.	We	can	say	that	the	results	of	collective	classification	are	superior.	. For	strategy	 ,	we	see	that	 local+static 	outperforms	 local 	features.	Using	all	features	is	even	better.	 local+dynamic 	features	gives	us	the	best	F‐score.		. For	strategy	 ,	using	all	features	again	performs	better	than	only	 local 	features.	Using	local+dynamic 	gives	both	the	best	F‐score	and	accuracy	among	all	experiments.		
Compare	with	WordNet:	We	now	compare	our	method	with	WordNet,	which	can	retrieve	attributes	 given	 an	 adjective.	 Table	 	 shows	 the	 comparison	 results.	 Column	 	 gives	 the	average	number	of	correct	attributes	found	by	our	system	over	 ‐fold	cross	validation	and	by	WordNet	respectively.	Our	method	can	find	far	more	attribute	nouns	than	WordNet.	Alt‐hough	WordNet	 has	 %	 precision	 as	 it	was	manually	 compiled ,	 the	 recall	 is	 so	 low.	Many	adjectives	have	no	attribute	nouns	in	WordNet,	e.g.,	it	gives	no	attribute	for	expensive.	

5	 Conclusion	This	paper	studied	the	problem	of	mining	attribute	nouns	of	opinion	adjectives.	A	diction‐ary‐based	approach	was	proposed.	To	our	knowledge,	this	 is	the	first	work	using	such	an	approach.	Existing	works	are	all	based	on	corpuses.	To	solve	the	problem,	we	formulated	it	as	collective	classification	as	words	are	related	 through	many	 lexical	 relations.	Such	rela‐tions	can	be	exploited	to	produce	better	classifiers.	Our	evaluation	showed	that	collective	classification	using	dynamic	 relational	 features	 performed	 significantly	 better	 than	 tradi‐tional	 classification.	 )t	 also	 performs	 dramatically	 better	 than	WordNet.	 Finally,	 we	 note	that	there	are	two	related	approaches	used	in	finding	opinion	words:	the	corpus‐based	ap‐proach	 e.g.,	(azivassiloglou	and	McKeown,	 ;	Wilson	et	al.,	 ;	Kanayama	and	Nasu‐kawa,	 ;	Ding	et	al.,	 ;	Choi	and	Cardie,	 ;	Wu	and	Wen,	 	and	the	diction‐ary	based	approach	 e.g.,	(u	and	Liu	 ;	Kim	and	(ovy,	 ;	Kamps	et	al.,	 ;	Esuli	and	Sebastiani,	 ;	Andreevskaia	and	Bergler,	 ;	Blair‐Goldensohn	et	al.,	 ;	(as‐san	and	Radev,	 .	Although	the	two	approaches	are	analogous	to	the	two	correspond‐ing	approaches	for	the	attribute	discovery	of	adjectives,	the	two	tasks	are	entirely	different.	

	 No.	of	correct	attributes	found Prec. Rec. F‐score	
WordNet	 % . % . 	

Our	method	 	 . % . % . 	Table	 	–	Comparison	results	of	WordNet	and	our	method	 ‐fold	cross‐validation 	

316



References		Almuhareb,	 A.	 .	 Attributes	 in	Lexical	Acquisition.	 Ph.D.	 Dissertation,	 Department	 of	Computer	Science,	University	of	Essex.	Almuhareb,	A	and	M.	Poesio.	 .	Attribute‐Based	and	Value‐Based	Clustering:	An	Evalu‐ation.	Proceedings	of	the	Conference	on	Empirical	Methods	in	Natural	Language	Processing.	Andreevskaia,	A.	and	S.	Bergler.	 .	Mining	WordNet	for	fuzzy	sentiment:	Sentiment	tag	extraction	from	WordNet	glosses.	Proceedings	of	Conference	of	the	European	Chapter	of	the	
Association	for	Computational	Linguistics	 EACL‐ .	 .	Blair‐Goldensohn,	S.,	K.	(annan,	and	R.	McDonald,	Tyler	Neylon,	George	A.	Reis,	 and	 Jeff	Reynar.	 .	Building	a	sentiment	 summarizer	 for	 local	 service	 reviews.	Proceedings	of	
WWW‐2008	Workshop	on	NLP	in	the	Information	Explosion	Era.		Choi,	Y.	and	C.	Cardie.	Learning	with	compositional	semantics	as	structural	 inference	for	subsentential	sentiment	analysis.	Proceedings	of	Conference	on	Empirical	Methods	in	Natu‐
ral	Language	Processing	 EMNLP‐ .	 .	Ding,	X.,	B.	 Liu,	 and	P.	 S.	 Yu.	 .	A	holistic	 lexicon‐based	approach	 to	opinion	mining.	
Proceedings	of	the	Conference	on	Web	Search	and	Web	Data	Mining	 WSDM‐ .	Esuli,	 A.	 and	F.	 Sebastiani.	Determining	 the	 semantic	 orientation	of	 terms	 through	 gloss	classification.	Proceedings	of	ACM	International	Conference	on	Information	and	Knowledge	
Management	 C)KM‐ .	 .	(ai,	Z.,	K.	Chang,	and	J.	Kim.	 .	)mplicit	feature	identification	via	co‐occurrence	associa‐tion	 rule	mining.	Computational	Linguistics	and	Intelligent	Text	Processing,	 :	 p.	 ‐.	(artung,	M	 and	A.	 Frank,	 .	 	 A	 Structured	Vector	 Space	Model	 for	(idden	Attribute	Meaning	in	Adjective‐Noun	Phrases.	Coling	 .		(artung,	M	and	A.	Frank,	 .	Exploring	Supervised	LDA	Models	for	Assigning	Attributes	to	Adjective‐Noun	Phrases.	Proceedings	of	the	Conference	on	Empirical	Methods	in	Natural	
Language	Processing.		(assan,	A.	and	D.	Radev.	 .	)dentifying	text	polarity	using	random	walks.	Proceedings	
of	Annual	Meeting	of	the	Association	for	Computational	Linguistics	 ACL‐ .		(atzivassiloglou,	V.	and	K.	R.	McKeown.	 .	Predicting	the	semantic	orientation	of	ad‐jectives.	 Proceedings	 of	 Annual	Meeting	 of	 the	 Association	 for	 Computational	 Linguistics	ACL‐ .		(u,	 M.	 and	 Liu,	 B.	 .	 Mining	 and	 summarizing	 customer	 reviews.	 Proceedings	 of	
SIGKDD	International	Conference	and	Knowledge	Discovery	and	Data	Mining.			Kamps,	J.,	M.	Marx,	R.	J.	Mokken,	and	M.	De	Rijke.	 .	Using	WordNet	to	measure	seman‐tic	orientation	of	adjectives.	Proc.	of	LREC‐ .		Kanayama,	 (.	 and	 T.	 Nasukawa.	 .	 Fully	 automatic	 lexicon	 expansion	 for	 domain‐oriented	 sentiment	 analysis.	 Proceedings	of	Conference	on	Empirical	Methods	 in	Natural	
Language	Processing	 EMNLP‐ .		

317



Kim,	S‐M	and	E.	(ovy.	 .	Determining	the	sentiment	of	opinions.	Proceedings	of	Inter‐
national	Conference	on	Computational	Linguistics	 COL)NG‐ .		Landis,	J.	R.	and	G.	G.	Koch.	 .	The	measurement	of	observer	agreement	for	categorical	data.	Biometrics.	Liu,	B.	 .	Sentiment	analysis	and	subjectivity.	 	)n	(andbook	of	Natural	Language	Pro‐cessing,	edited	by	)ndurkhya,	N	and	Damerau,	F.	J.	Mitchell,	T.	 .	Machine	Learning,	McGraw	(ill.		Sen,	P.,	G.	Namata,	M.	Bilgic	and	L.	Getoor.	 .		Collective	Classification	in	Network	Data.	
Technical	Report	CS‐TR‐ 	and	UM)ACS‐TR‐ ‐ .	Srikant,	R	 and	R.	Agrawal.	 .	Mining	 sequential	 patterns:	Generalization	 and	perfor‐mance	improvements.	Advances	in	Database	Technology.		Su,	Q.,	X.	Xu,	(.	Guo,	Z.	Guo,	X.	Wu,	X.	Zhang,	B.	Swen,	and	Z.	Su.	 .	(idden	sentiment	as‐sociation	in	chinese	web	opinion	mining.	Proceedings	of	International	Conference	on	World	
Wide	Web.	Toutanova,	K.,	D.	Klein,	C.	Manning,	and	Y.	Singer.	 .	Feature‐Rich	Part‐of‐Speech	Tag‐ging	with	a	Cyclic	Dependency	Network.	Proceedings	of	HLT‐NAACL	 ,	pp.	 ‐ .	Wilson,	 T.,	 J.	Wiebe,	 and	 P.	 (offmann.	 .	 Recognizing	 contextual	 polarity	 in	 phrase‐level	 sentiment	 analysis.	Proceedings	of	the	Human	Language	Technology	Conference	and	
the	Conference	on	Empirical	Methods	in	Natural	Language	Processing	 (LT/EMNLP‐ .	Wu,	Y.	and	M.	Wen.	 .	Disambiguating	dynamic	sentiment	ambiguous	adjectives.	Pro‐
ceedings	of	the	23rd	International	Conference	on	Computational	Linguistics	 Coling	 .	

318


