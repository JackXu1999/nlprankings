



















































Improved Generalization of Arabic Text Classifiers


Proceedings of the Fourth Arabic Natural Language Processing Workshop, pages 167–174
Florence, Italy, August 1, 2019. c©2019 Association for Computational Linguistics

167

Improved Generalization of Arabic Text Classifiers

Alaa Khaddaj Hazem Hajj Wassim El-Hajj
American University of Beirut

Beirut, Lebanon
{awk11, hh63, we07}@aub.edu.lb

Abstract

While transfer learning for text has been very
active in the English language, progress in
Arabic has been slow, including the use of Do-
main Adaptation (DA). Domain Adaptation is
used to generalize the performance of any clas-
sifier by trying to balance the classifier’s ac-
curacy for a particular task among different
text domains. In this paper, we propose and
evaluate two variants of a domain adaptation
technique: the first is a base model called Do-
main Adversarial Neural Network (DANN),
while the second is a variation that incorpo-
rates representational learning. Similar to pre-
vious approaches, we propose the use of proxy
A-distance as a metric to assess the success
of generalization. We make use of ArSentD-
LEV, a multi-topic dataset collected from the
Levantine countries, to test the performance of
the models. We show the superiority of the
proposed method in accuracy and robustness
when dealing with the Arabic language.

1 Introduction

Natural Language Processing (NLP) for Arabic is
challenging due to the complexity of the language.
Additionally, resources in Arabic are scarce mak-
ing it difficult to achieve NLP progress at the pace
of other resource-rich languages such as English
(Badaro et al., 2019). As a result, there is a need
for transfer learning methods that can overcome
the resource limitations. In this paper, we pro-
pose the use of domain adaptation to address this
challenge while considering the task of sentiment
analysis (SA) also referred to as Opinion Mining
(OM).

When training over a dataset with multiple do-
mains, different domains have different data dis-
tributions. This has a negative impact when train-
ing on one domain and testing on another, since
the model would not be able to generalize well.

Although domains within the same dataset have
differences, they share some characteristics. For
example, consider reviews of Amazon products:
reviews of electronic products are different from
book reviews, but these two domains share the
general structure of reviews. We say there exists
a shift in the data’s distribution between the two
domains. To solve this problem, many approaches
were proposed within the field of Domain Adap-
tation (DA) (Ben-David et al., 2010). This field is
receiving a lot of attention in English, a lot more
than its Arabic counterpart.

Solving the data shift problem is of interest for
many reasons. First, it is harder for machine learn-
ing to learn good internal representations on the
Arabic text as opposed to English text. This is
due to the sparsity of the Arabic language, and its
morphological complexity compared to English.
Another reason is the limited amount of avail-
able data, especially for dialects, which causes
deep learning models to perform bad on any task.
Lastly, we are not aware of domain adaptation
techniques for the Arabic language, and thus much
work needs to be done in this area to catch up with
the research in English.

Traditionally, researchers focused their efforts
on extracting features shared between the source
and target domains (Blitzer et al., 2006, 2007;
Pan et al., 2010). After the advancement of
representational learning (Bengio et al., 2013),
several algorithms were introduced. The most
notable approaches are Stacked Denoising Au-
toencoder (SDA) (Vincent et al., 2010; Glorot
et al., 2011). Later, a modified version was in-
troduced by (Chen et al., 2012). This version,
called marginalized Stacked Denoising Autoen-
coder (mSDA), introduced a speedup compared to
the original SDA since the input/output relation
was provided in closed form. After Generative
Adversarial Nets (Goodfellow et al., 2014) were



168

introduced, the interest in adversarial training in-
creased. Researchers developed new approaches
that solve the DA problem through adversarial
training, with emphasis on applications in com-
puter vision and limited exploration for NLP. The
most notable approaches are Domain Adversarial
Neural Networks (DANN) (Ganin et al., 2016),
Domain Separation Network (DSN) (Bousmalis
et al., 2016), Adversarial Discriminative Domain
Adaptation (ADDA) (Tzeng et al., 2017) and Con-
ditional Adversarial Domain Adaptation (Long
et al., 2018). Although limited in Arabic, some
efforts have been spent to solve the domain shift
problem (Jeblee et al., 2014; Monroe et al., 2014).

In this paper, we propose and evaluate some ad-
versarial approaches for domain adaptation. The
first is a regular DANN model while the second
is a variant of DANN that incorporates represen-
tational learning. To assess the success of domain
adaptation, we use the proxy A-distance as a ma-
trix (Ben-David et al., 2007). The rest of the pa-
per is organized as follows. Section 2 presents
different approaches for DA. Section 3 introduces
the algorithms to be evaluated, and describes the
dataset. Section 4 presents the experiments and
the results. We finally summarize our work and
conclude the paper in Section 5.

2 Related Work

Domain Adaptation passed through several devel-
opment stages. The first stage was based on fea-
ture engineering methods, while in the later stages,
DA experienced a shift towards deep learning.

Initial approaches included finding words that
behaved similarly in both the source and target do-
mains. Blitzer et al. (2006) called such words
pivot features, and proposed different approaches
for extracting them. He first proposed using the
most frequent common words as pivot features
(Blitzer et al., 2006), and later on proposed us-
ing words with highest mutual information with
the source labels (Blitzer et al., 2007). The ex-
tracted pivot features are then used by the algo-
rithm to augment the initial dataset. This is done
by learning a mapping to a vector space with di-
mensionality smaller than the dimensionality of
the input data. Then, an optimization problem is
solved in the new space, with the objective func-
tion being a similarity measure. Using the re-
sults of the optimization problem, new features are
added to the original dataset. The resulting algo-

rithm is called Structural Correspondence Learn-
ing (SCL) (Blitzer et al., 2006, 2007). A similar
approach was introduced by Gong et al. (2013)
where they suggested finding words, which they
called landmarks, that have similar distributions
over the source and target domains. These land-
marks were used to increase the confusion be-
tween source and target domains, through optimiz-
ing a series of auxiliary tasks. Another point of
view was introduced by Pan et al. (2010) based
on the Spectral Graph Theory. Their approach,
called Spectral Feature Alignment (SFA), aligned
features from source and target domains using bi-
partite graphs. Although these approaches im-
proved accuracies in domain adaptation tasks, the
improvements remained limited.

The hype of deep learning motivated finding
deep learning algorithms that could solve this
problem. An interesting approach by Glorot et al.
(2011) was preparing the input of any classifier
by passing the input through Stacked Denoising
Autoencoders (SDA) (Vincent et al., 2010). The
use of SDAs helps find a new representation of the
data that is domain invariant. This is achieved by
reconstructing the input from stochastically dis-
rupted data (via noise injection). Once the data
is transformed, a linear SVM is trained on the new
representation. This approach was more accurate
than the previous approaches in predicting target
domain labels. However, training SDAs is very
time consuming. That is why Chen et al. (2012)
forced the reconstruction mapping to be linear.
This restriction yielded a closed form output solu-
tion. The new model, called marginalized Stacked
Denoising Autoencoder (mSDA), was able to per-
form as good as the original SDA, and took much
less time for training.

After the publication of GANs (Goodfellow
et al., 2014), many researchers took interest in ad-
versarial training. Ganin et al. (2016) proposed
an adversarial network for domain adaptation. By
introducing a Gradient Reversal Layer (GRL) that
inverts the gradient’s sign during backpropagation,
the Domain Adversarial Neural Network (DANN)
was forced to find a saddle point between 2 er-
rors: a label prediction error (that is to be min-
imized) and a domain classification error (to be
maximized). This approach led to the emergence
of domain invariant features. DANN achieved
state-of-the-art performance in domain adaptation
tasks for two specific applications, namely: senti-



169

Figure 1: Proposed Model Architecture

ment analysis and computer vision.
For the Arabic language, the domain adapta-

tion research area is still very limited. Joty et al.
investigated the problem of cross-language adap-
tation for question-question similarity, and pro-
posed a Cross-Language Adversarial Neural Net-
work (CLANN) (Joty et al., 2017). Monroe et
al. used feature space augmentation presented by
(Daume III, 2007) for word segmentation (Monroe
et al., 2014). Both approaches were successful.

3 Proposed Method

A Domain Adaptation task is, in general, a predic-
tion problem where given label data from a source
domain S, we are to predict the labels of a target
domain T with unlabeled data (Ben-David et al.,
2010). In this paper, we focus on domain adapta-
tion for sentiment analysis: Given data with senti-
ment labels from one domain, the model should be
able to predict the sentiment of data coming from
another domain.

Let (Xs, Ys) = {(xi, yi)}Nsi=1 represent the
source domain input data of Ns observations xi,
where xi could be any textual data (e.g. Bag-Of-
Words, Sequence, etc...), and yi the correspond-
ing label. The domain input data Xt = {xi}Nti=1
consists of Nt unlabeled observations. The source
and target observations are concatenated to form
the input data X of Ns + Nt observations to the
model. The architecture of DANN adopted is sim-
ilar to the one in (Ganin et al., 2016). The variant,
shown in Figure 1, is composed of 5 main parts:

• Feature Extractor

• Label Predictor
• Reconstruction Layer
• Domain Predictor
• Gradient Reversal Layer

The above model uses denoising reconstruction
(Vincent et al., 2010; Chen et al., 2012) and ad-
versarial training (Ganin et al., 2016), in order to
learn features that are discriminative towards the
tasks at hand, while at the same time being able to
generalize from one domain to another.

Three loss functions are associated with the net-
work: 1) a loss function related to the classifica-
tion task at hand, denoted as Ltask, 2) a loss func-
tion associated with the domain classifier, which
could be the binary cross-entropy function (or log
loss, etc...) and denoted as Ldomain, and 3) a loss
function associated with the reconstruction of the
input data, denoted as Lrecon, and could be the
mean-squared error (or hinge loss, etc...). The
model tries to minimize the sum of the 3 loss func-
tions, i.e. it wants to find the parameters θ∗ such
that:

θ∗ = argmin
θ
Ltask+λ·Ldomain+µ·Lrecon (1)

where λ and µ are real numbers in the range
[0, 1]. Since the reconstruction error tends to be
larger than the other 2 losses by orders of magni-
tude, its corresponding scalar µ tends to be small.

3.1 Label Predictor
Using the label predictor, the model predicts the
labels of the input data. During training, since
only the source domain data has labels, the input is
sliced in a way that theNs observations associated
with the source domain are passed into the label
predictor. The loss function Ltask depends on the
task at hand (Janocha and Czarnecki, 2017). For
example, one could use the mean squared error for
regression, or the binary cross entropy for classi-
fication. For our purpose, we use the binary cross
entropy.

3.2 Domain Classifier
The model above should be robust towards shift
in data distribution. Said differently, the model
should be able to predict accurately the label of
a given observation even when it comes from the
target domain instead of the source domain. Math-
ematically, this is equivalent to minimizing the



170

error on label prediction and maximizing the er-
ror on domain classification. Ganin et al. (2016)
showed that this can be done using a special layer
they called Gradient Reversal Layer (GRL). The
GRL does not affect the network during forward
propagation, but it flips the sign of the gradients
in backpropagation. The domain loss Ldomain
adopted by (Ganin et al., 2016) is the log-loss be-
tween the true domain and the predicted domain.
Other binary loss functions are possible (Janocha
and Czarnecki, 2017). In our approach, we use
the binary cross entropy. The error of the domain
classifier is scaled by λ.

3.3 Denoising Autoencoder
The noised version of X , denoted X̃ , is obtained
from X by using a masking noise, i.e. some ele-
ments of X are set to 0 with probability p (Glorot
et al., 2011). Then, X̃ is propagated through an
encoder network h(·) (Baldi, 2012) to get h(X̃).
The decoder network r(·) reconstructs the input
data X from the encoder’s output h(X̃). A possi-
ble loss function is the mean squared error

Lrecon = ‖r
(
h(X̃)

)
−X‖2 (2)

The error of the autoencoder is scaled by µ.

3.4 Proxy A-distance as a Generalization
Metric

Ben-David et al. (2007) developed a distance met-
ric called proxy A-distance. The lower the dis-
tance, the more similar the domains are. Intu-
itively, this would mean the source and target do-
mains share more common features. Hence, ma-
chine learning models won’t lose too much accu-
racy when trained over source domain and tested
over the target domain.

Let D and D′ be 2 probability distributions de-
fined over a domain χ, and a hypothesis class A.
The A-distance of D and D′ is defined as

dA(D′,D′) = 2 sup
A∈A
|Pr
D
[A]− Pr

D′
[A]| (3)

Intuitively, this is equivalent to finding the max-
imum L1 distance between the 2 probability dis-
tributions D and D′. Since computing this metric
is intractable, Ben-David et al. (2007) proposed a
way to approximate it from finite samples as fol-
lows: a linear SVM is trained to discriminate be-
tween the 2 domains, then the error �, called gen-
eralization error, is used to compute a proxy of the

A-distance d̂A = 2(1−2�). This proxy A-distance
(PAD) can then be used to represent the distance
between the 2 domains.

4 Experiments and Results

To test the effectiveness of the proposed approach,
we conduct a 5-point sentiment classification on
ArSentD-LEV1 (Baly et al., 2018), once using the
country of origin of the tweet as domain, and once
the category to which the tweet belongs. We then
show the effect of the data size on the performance
of the adaptation algorithms. We start by describ-
ing the available dataset, then we describe each ex-
periment alongside its results and we include some
insights.

Figure 2: Topic Distribution of Tweets in ArSentD-
LEV

4.1 Dataset Description and Experiment
Setup

ArSentD-LEV is a multi-domain dataset contain-
ing almost 4,000 tweets collected equally from the
4 Levantine countries: Jordan, Lebanon, Palestine
and Syria. For each tweet, the following labels
are available: the country of origin, the sentiment
conveyed by the tweet on 5-point scale (from very
negative to very positive), the way of expressing
the sentiment (explicit vs implicit) and the cat-
egory to which the tweet belongs. The tweets
were divided into 5 categories: politics, personal,
sports, religious and other. The distribution of the
tweets amongst these categories is shown in figure
2.

1The dataset is publicly available at http:
//oma-project.azurewebsites.net/ArSenL/
ArSenTD_Lev_Intro

http://oma-project.azurewebsites.net/ArSenL/ArSenTD_Lev_Intro
http://oma-project.azurewebsites.net/ArSenL/ArSenTD_Lev_Intro
http://oma-project.azurewebsites.net/ArSenL/ArSenTD_Lev_Intro


171

Following the approach used by (Chen et al.,
2012; Ganin et al., 2016), we extract from the
dataset the 5,000 most frequent unigrams and bi-
grams, as was adopted in (Ganin et al., 2016) for
English. We then form, using these unigrams and
bigrams, a bag-of-words matrix that will be used
as input data for the learned models. Although
many models represent text better (e.g. sequence
models, tree models, etc...) we limit ourselves to a
simpler model to show the improvement by the do-
main adaptation technique rather than by the text
model.

The different experiments evaluated the perfor-
mance of four models. A Linear SVM was used
as a baseline and representative of feature based
models. For the deep learning models, we con-
sider a fully-connected neural network (Rumelhart
et al., 1988) consisting of a hidden layer of 100
neurons and a label predictor of size 2. The setup
of DANN is similar to that in (Ganin et al., 2016).
The hidden layer is composed of 100 neurons, and
the label predictor is of size 2. The domain clas-
sifier of DANN (of size 2) is preceded by a GRL.
The proposed model is identical to the description
in section 3. All neural networks were trained us-
ing ADAM optimizer (Kingma and Ba, 2014) us-
ing a learning rate of 10−3.

Source Target SVM NN DANN Prop

Jordan
Lebanon 30 27.5 29 30
Palestine 33.5 33 34.5 35
Syria 30.5 31.5 32 33

Lebanon
Jordan 32 28 29 32
Palestine 35 25.5 31 35
Syria 30.5 33 37 37.5

Palestine
Jordan 29.5 31 32 32.5
Lebanon 32 29.5 31 31
Syria 37.5 21.5 28.5 27.5

Syria
Jordan 32.5 32 30.5 32
Lebanon 35 31.5 35 35.5
Palestine 37 28 31.5 37.5

Table 1: Accuracies of linear SVM, NN, DANN and
the proposed approach for Cross-Country adaptation
on ArSentD-LEV. We can see that the proposed vari-
ant outperforms other models in almost all DA tasks.

4.2 Evaluation for Cross Country Adaptation

For this experiment, we evaluate the adaptation
task between tweets from different countries. This
means the source domain will consist of tweets

from one of the 4 Levantine countries, and the
target domain will consist of tweets coming from
other countries. We thus have a total of 12 adap-
tation tasks. Baly et al. showed that Twitter is
used for different purposes in different countries
(Baly et al., 2017), which presents an additional
challenge.

The result of the domain adaptation tasks are
shown in Table 1. The proposed method outper-
formed all other models in most of the adapta-
tion tasks. Although many real-life applications
showed that traditional machine learning models
are usually better when the available data is lit-
tle (Cortes and Vapnik, 1995; Goodfellow et al.,
2016), the proposed model was able to outperform
the linear SVM in most of the tasks in our exper-
iment. This means it was able to extract useful
representation from the data. The model was also
able to outperform DANN, which shows that the
representational learning provides intrinsic repre-
sentation of the data.

4.3 Evaluation for Cross Topic Adaptation

In this second experiment, we consider the task of
adapting tweets from different topics. ArSentD-
LEV (Baly et al., 2018) contains 5 classes for
topic: politics, personal, religious, sports and
other. This means we have a total of 20 tasks.
The models evaluated are the linear SVM, DANN
and the proposed model. The models’ structure is
identical to the one defined in section 4.2.

The results of the experiment are shown in Table
2. The behavior of the algorithms is significantly
different in these categories. This is caused by the
unbalanced data distribution amongst the different
topics, as can be seen in Figure 2. We can see that
whenever the data is very limited, the linear SVM
outperforms the deep learning models. This is ex-
pected since neural networks cannot learn well the
underlying representation when the data is scarce.

Looking at the radar plot in Figure 3, we can
find the following interesting property. The higher
the PAD distance between the source and target
domains, the better the performance of the pro-
posed model. This can be related to the fact that
the proposed model tries to find a hidden represen-
tation that combines features from both source and
target domains, i.e. decrease the distance between
the 2 domains. Whenever the distance is low, the
proposed model can not thus decrease it much fur-
ther.



172

Source Target SVM DANN Prop

Politics

Personal 29.5 28.7 33.3
Religious 20.5 20.3 25.3
Sports 26.8 35.1 35.1
Other 16.1 22.5 24.2

Personal

Politics 37.5 41.7 36.8
Religious 19 22.8 23.4
Sports 34 26.8 25.8
Other 40.3 33.8 35.4

Religious

Politics 16.8 15.5 15.5
Personal 26.4 24.1 26.1
Sports 28.8 25.8 26.8
Other 48.4 30.6 27.4

Sports

Politics 41.4 36.4 30.7
Personal 28.4 25.3 24.5
Religious 16.5 20 19
Other 33.8 35.5 35.5

Other

Politics 20.5 23.2 23.2
Personal 28.4 30.3 24.9
Religious 53.2 41.8 43
Sports 26.8 23.7 27.8

Table 2: Accuracies of linear SVM, DANN and the
proposed approach for Cross-Topic on ArSentD-LEV.
We can see that the SVM and the proposed variant are
performing better than DANN, with SVM performing
better when available data is little.

Figure 3: Proxy A-distance Between Different Do-
mains. This radar plot shows the proxy A-distances
between the different domains. The closer the vertex of
a combination to the center, the closer the 2 domains.

4.4 Performance with Limited Data Size

To test the limitation of the proposed approach
with data size, we consider the task where the
source domain is ”Politics” and the target domain
is ”Personal”, since the available data is larger than
the data available for other tasks. We then start by
gradually increasing the size, and test the perfor-
mance of the model with each dataset size. Look-
ing at Figure 4, we can see that the performance of
the proposed method is better than that of DANN
at all sizes. This confirms our assumption that
DANN with SDA learns a better representation
through the incorporation of autoencoder. In con-
trast, DANN focuses on the discriminative task at
hand, and thus fails to generalize. We also have a
generally increasing trend which comes from the
fact that more data is available, hence the models
are able to learn better features.

Figure 4: DANN and Proposed Method Performance
vs Data size. We can see that the proposed variant out-
performs DANN at all data sizes, and learns more with
the increase in data size.

5 Conclusion

In this paper, we presented the first application of
domain adaptation to the Arabic language. Al-
though there exists work in English for domain
adaptation, no work exists for Arabic. We consid-
ered in this paper the Domain Adversarial Neural
Network (DANN) (Ganin et al., 2016) and pro-
posed a variant that incorporates into DANN a
stacked denoising autoencoder (SDA). The exper-
iments and results provided several insights. We
observed that integrating a reconstruction loss into
DANN helped the model learn a better latent rep-
resentation. This proved useful in all experiments,
especially when the available data is little. These



173

observations are consistent with what has been ob-
served in English. The success of domain adap-
tation suggests the possibility of usage of DA to
bridge the gap between different dialects of the
Arabic language. Future work includes testing DA
techniques to more Arabic dialects, trying other
domain adaptation algorithms in Arabic, develop-
ing new domain adaptation techniques, evaluating
the DA tasks using better text representation (e.g.
sequence models...) and integrating transfer learn-
ing techniques in the models (Ng et al., 2015).

References
Gilbert Badaro, Ramy Baly, Hazem Hajj, Wassim El-

Hajj, Khaled Shaban, Nizar Habash, Ahmad Sal-
lab, and Ali Hamdi. 2019. A survey of opinion
mining in arabic: A comprehensive system per-
spective covering challenges and advances in tools,
resources, models, applications and visualizations.
ACM Transactions on Asian Language Information
Processing, 18.

Pierre Baldi. 2012. Autoencoders, unsupervised learn-
ing, and deep architectures. In Proceedings of ICML
Workshop on Unsupervised and Transfer Learning,
volume 27 of Proceedings of Machine Learning Re-
search, pages 37–49, Bellevue, Washington, USA.
PMLR.

Ramy Baly, Gilbert Badaro, Georges El-Khoury,
Rawan Moukalled, Rita Aoun, Hazem Hajj, Wassim
El-Hajj, Nizar Habash, and Khaled Shaban. 2017.
A characterization study of Arabic twitter data with
a benchmarking for state-of-the-art opinion mining
models. In Proceedings of the Third Arabic Natu-
ral Language Processing Workshop, pages 110–118,
Valencia, Spain. Association for Computational Lin-
guistics.

Ramy Baly, Alaa Khaddaj, Hazem Hajj, Wassim El-
Hajj, and Khaled Shaban. 2018. Arsentd-lev: A
multi-topic corpus for target-based sentiment anal-
ysis in arabic levantine tweets. In Proceedings
of the Eleventh International Conference on Lan-
guage Resources and Evaluation (LREC 2018),
Paris, France. European Language Resources Asso-
ciation (ELRA).

Shai Ben-David, John Blitzer, Koby Crammer, Alex
Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. 2010. A theory of learning from different
domains. Machine Learning, 79(1):151–175.

Shai Ben-David, John Blitzer, Koby Crammer, and Fer-
nando Pereira. 2007. Analysis of representations for
domain adaptation. In B. Schölkopf, J. C. Platt, and
T. Hoffman, editors, Advances in Neural Informa-
tion Processing Systems 19, pages 137–144. MIT
Press.

Yoshua Bengio, Aaron Courville, and Pascal Vincent.
2013. Representation learning: A review and new
perspectives. IEEE Transactions on Pattern Analy-
sis and Machine Intelligence, 35(8):1798–1828.

John Blitzer, Mark Dredze, and Fernando Pereira.
2007. Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classi-
fication. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 440–447. Association for Computational Lin-
guistics.

John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In Proceedings of the 2006 Con-
ference on Empirical Methods in Natural Language
Processing, pages 120–128. Association for Com-
putational Linguistics.

Konstantinos Bousmalis, George Trigeorgis, Nathan
Silberman, Dilip Krishnan, and Dumitru Erhan.
2016. Domain separation networks. In D. D. Lee,
M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Gar-
nett, editors, Advances in Neural Information Pro-
cessing Systems 29, pages 343–351. Curran Asso-
ciates, Inc.

Minmin Chen, Zhixiang Xu, Kilian Q. Weinberger,
and Fei Sha. 2012. Marginalized denoising autoen-
coders for domain adaptation. In Proceedings of
the 29th International Coference on International
Conference on Machine Learning, ICML’12, pages
1627–1634, USA. Omnipress.

Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. In Machine Learning, pages 273–
297.

Hal Daume III. 2007. Frustratingly easy domain adap-
tation. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
256–263, Prague, Czech Republic. Association for
Computational Linguistics.

Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan,
Pascal Germain, Hugo Larochelle, François Lavio-
lette, Mario Marchand, and Victor Lempitsky. 2016.
Domain-adversarial training of neural networks. J.
Mach. Learn. Res., 17(1):2096–2030.

Xavier Glorot, Antoine Bordes, and Yoshua Bengio.
2011. Domain adaptation for large-scale senti-
ment classification: A deep learning approach. In
Proceedings of the 28th International Conference
on International Conference on Machine Learning,
ICML’11, pages 513–520, USA. Omnipress.

Boqing Gong, Kristen Grauman, and Fei Sha. 2013.
Connecting the dots with landmarks: Discrimina-
tively learning domain-invariant features for unsu-
pervised domain adaptation. In Proceedings of the
30th International Conference on Machine Learn-
ing, volume 28 of Proceedings of Machine Learning
Research, pages 222–230, Atlanta, Georgia, USA.
PMLR.

https://doi.org/10.1145/3295662
https://doi.org/10.1145/3295662
https://doi.org/10.1145/3295662
https://doi.org/10.1145/3295662
http://proceedings.mlr.press/v27/baldi12a.html
http://proceedings.mlr.press/v27/baldi12a.html
https://doi.org/10.18653/v1/W17-1314
https://doi.org/10.18653/v1/W17-1314
https://doi.org/10.18653/v1/W17-1314
https://doi.org/10.1007/s10994-009-5152-4
https://doi.org/10.1007/s10994-009-5152-4
http://papers.nips.cc/paper/2983-analysis-of-representations-for-domain-adaptation.pdf
http://papers.nips.cc/paper/2983-analysis-of-representations-for-domain-adaptation.pdf
https://doi.org/10.1109/TPAMI.2013.50
https://doi.org/10.1109/TPAMI.2013.50
http://aclweb.org/anthology/P07-1056
http://aclweb.org/anthology/P07-1056
http://aclweb.org/anthology/P07-1056
http://aclweb.org/anthology/W06-1615
http://aclweb.org/anthology/W06-1615
http://papers.nips.cc/paper/6254-domain-separation-networks.pdf
http://dl.acm.org/citation.cfm?id=3042573.3042781
http://dl.acm.org/citation.cfm?id=3042573.3042781
https://www.aclweb.org/anthology/P07-1033
https://www.aclweb.org/anthology/P07-1033
http://dl.acm.org/citation.cfm?id=2946645.2946704
http://dl.acm.org/citation.cfm?id=3104482.3104547
http://dl.acm.org/citation.cfm?id=3104482.3104547
http://proceedings.mlr.press/v28/gong13.html
http://proceedings.mlr.press/v28/gong13.html
http://proceedings.mlr.press/v28/gong13.html


174

Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
2016. Deep Learning. MIT Press. http://www.
deeplearningbook.org.

Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza,
Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron
Courville, and Yoshua Bengio. 2014. Generative ad-
versarial nets. In Proceedings of the 27th Interna-
tional Conference on Neural Information Process-
ing Systems - Volume 2, NIPS’14, pages 2672–2680,
Cambridge, MA, USA. MIT Press.

Katarzyna Janocha and Wojciech Czarnecki. 2017. On
loss functions for deep neural networks in classifica-
tion. 25.

Serena Jeblee, Weston Feely, Houda Bouamor, Alon
Lavie, Nizar Habash, and Kemal Oflazer. 2014. Do-
main and dialect adaptation for machine translation
into egyptian arabic. In ANLP@EMNLP.

Shafiq Joty, Preslav Nakov, Llus Mrquez, and Israa
Jaradat. 2017. Cross-language learning with adver-
sarial neural networks. pages 226–237.

Diederik Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization.

Mingsheng Long, Zhangjie Cao, Jianmin Wang, and
Michael I Jordan. 2018. Conditional adversarial
domain adaptation. In S. Bengio, H. Wallach,
H. Larochelle, K. Grauman, N. Cesa-Bianchi, and
R. Garnett, editors, Advances in Neural Information
Processing Systems 31, pages 1640–1650. Curran
Associates, Inc.

Will Monroe, Spence Green, and Christopher D. Man-
ning. 2014. Word segmentation of informal ara-
bic with domain adaptation. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 2: Short Papers), pages
206–211. Association for Computational Linguis-
tics.

Hong-Wei Ng, Viet Dung Nguyen, Vassilios Vonikakis,
and Stefan Winkler. 2015. Deep learning for emo-
tion recognition on small datasets using transfer
learning. In Proceedings of the 2015 ACM on In-
ternational Conference on Multimodal Interaction,
ICMI ’15, pages 443–449, New York, NY, USA.
ACM.

Sinno Jialin Pan, Xiaochuan Ni, Jian-Tao Sun, Qiang
Yang, and Zheng Chen. 2010. Cross-domain senti-
ment classification via spectral feature alignment. In
Proceedings of the 19th International Conference on
World Wide Web, WWW ’10, pages 751–760, New
York, NY, USA. ACM.

David E. Rumelhart, Geoffrey E. Hinton, and Ronald J.
Williams. 1988. Neurocomputing: Foundations
of research. chapter Learning Representations
by Back-propagating Errors, pages 696–699. MIT
Press, Cambridge, MA, USA.

Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor
Darrell. 2017. Adversarial discriminative domain
adaptation. In The IEEE Conference on Computer
Vision and Pattern Recognition (CVPR).

Pascal Vincent, Hugo Larochelle, Isabelle Lajoie,
Yoshua Bengio, and Pierre-Antoine Manzagol.
2010. Stacked denoising autoencoders: Learning
useful representations in a deep network with a local
denoising criterion. J. Mach. Learn. Res., 11:3371–
3408.

http://www.deeplearningbook.org
http://www.deeplearningbook.org
http://dl.acm.org/citation.cfm?id=2969033.2969125
http://dl.acm.org/citation.cfm?id=2969033.2969125
https://doi.org/10.18653/v1/K17-1024
https://doi.org/10.18653/v1/K17-1024
http://papers.nips.cc/paper/7436-conditional-adversarial-domain-adaptation.pdf
http://papers.nips.cc/paper/7436-conditional-adversarial-domain-adaptation.pdf
https://doi.org/10.3115/v1/P14-2034
https://doi.org/10.3115/v1/P14-2034
https://doi.org/10.1145/2818346.2830593
https://doi.org/10.1145/2818346.2830593
https://doi.org/10.1145/2818346.2830593
https://doi.org/10.1145/1772690.1772767
https://doi.org/10.1145/1772690.1772767
http://dl.acm.org/citation.cfm?id=65669.104451
http://dl.acm.org/citation.cfm?id=65669.104451
http://dl.acm.org/citation.cfm?id=1756006.1953039
http://dl.acm.org/citation.cfm?id=1756006.1953039
http://dl.acm.org/citation.cfm?id=1756006.1953039

