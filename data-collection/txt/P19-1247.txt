



















































Encoding Social Information with Graph Convolutional Networks forPolitical Perspective Detection in News Media


Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2594–2604
Florence, Italy, July 28 - August 2, 2019. c©2019 Association for Computational Linguistics

2594

Encoding Social Information with Graph Convolutional Networks for
Political Perspective Detection in News Media

Chang Li
Purdue University

li1873@purdue.edu

Dan Goldwasser
Purdue University

dgoldwas@purdue.edu

Abstract
Identifying the political perspective shaping
the way news events are discussed in the me-
dia is an important and challenging task. In
this paper, we highlight the importance of con-
textualizing social information, capturing how
this information is disseminated in social net-
works. We use Graph Convolutional Net-
works, a recently proposed neural architecture
for representing relational information, to cap-
ture the documents’ social context. We show
that social information can be used effectively
as a source of distant supervision, and when
direct supervision is available, even little so-
cial information can significantly improve per-
formance.

1 Introduction

Over the last decade we witness a dramatic change
in the way information is generated and dissem-
inated. Instead of a few dedicated sources that
employ reporters and fact checkers to ensure the
validity of the information they provide, social
platforms now provide the means for any user to
distribute their content, resulting in a sharp in-
crease in the number of information outlets and
articles covering news events. As a direct result
of this process, the information provided is often
shaped by their underlying perspectives, interests
and ideologies. For example, consider the follow-
ing two snippets discussing the comments made
by a Democratic Senator regarding the recent U.S.
government shutdown.

thehill.com (Center)

Sen. Mark Warner (D-Va.) on Sunday blasted Pres-
ident Trump for his “inept negotiation” to bring an
end to the ongoing partial government shutdown.
Warner, the ranking member of the Senate Intelli-
gence Committee, lamented the effect the shutdown
has had on hundreds of thousands of federal workers
who have been furloughed or forced to work without
pay.

infowars.com (Right)

Senator Mark Warner (D-Va.) is being called out on
social media for his statement on the partial govern-
ment shutdown. Warner blamed the “suffering” of
federal workers and contractors on President Trump
in a Sunday tweet framing Trump as an “inept ne-
gotiator”. Twitter users pointed out that Democrats
are attending a Puerto Rican retreat with over 100
lobbyists and corporate executives.

Despite the fact that both articles discuss the
same event, they take very different perspectives.
The first reporting directly about the comments
made, while the second one focuses on negative
reactions to these comments. Identifying the per-
spective difference and making it explicit can help
strengthen trust in the newly-formed information
landscape and ensure that all perspectives are rep-
resented. It can also help lay the foundation for
the automatic detection of false content and ru-
mors and help identify information echo-chambers
in which only a single perspective is highlighted.

Traditionally, identifying the author’s perspec-
tive is studied as a text-categorization prob-
lem (Greene and Resnik, 2009; Beigman Kle-
banov et al., 2010; Recasens et al., 2013; Iyyer
et al., 2014; Johnson and Goldwasser, 2016), fo-
cusing on linguistic indicators of bias or issue-
framing phrases indicating their authors’ bias.
These indicators can effectively capture bias in
ideologically-charged texts, such as policy docu-
ments or political debates, which do not try to hide
their political leaning and use a topic-focused vo-
cabulary. Identifying the authors’ bias in news nar-
ratives can be more challenging. News articles, by
their nature, cover a very large number of topics
resulting in a diverse and dynamic vocabulary that
is continuously updated as new events unfold. Fur-
thermore, unlike purely political texts, news narra-
tives attempt to maintain credibility and seem im-



2595

partial. As a result, bias is introduced in subtle
ways, usually by emphasizing different aspects of
the story.

Our main insight in this paper is that the social
context through which the information is propa-
gated can be leveraged to alleviate the problem, by
providing both a better representation for it, and
when direct supervision is not available, a distant-
supervision source based on information about
users who endorse the textual content and spread
it. Several recent works dealing with informa-
tion dissemination analysis on social networks, fo-
cused on analyzing the interactions between news
sources and users in social networks (Volkova
et al., 2017; Glenski et al., 2018; Ribeiro et al.,
2018). However, given the dynamic, and often
adversarial setting of this domain, the true source
of the news article might be hidden, unknown or
masked by taking a different identity. Instead of
analyzing the documents’ sources, our focus is to
use social information, capturing how information
is shared in the network, to help guide the text rep-
resentation and provide additional support when
making decisions over textual content.

We construct a socially-infused textual repre-
sentation, by embedding in a single space the news
articles and the social circles in which these ar-
ticles are shared so that the political biases asso-
ciated with them can be predicted. Figure 1 de-
scribes these settings. The graph connects article
nodes via activity-links to users nodes (share), and
these users in turn are connected via social-links
(follow) to politically affiliated users (e.g., the Re-
publican or Democratic parties twitter accounts).
We define an embedding objective capturing this
information, by aligning the documents represen-
tation, based on content, with the representation of
users who share these documents, based on their
social relations. We use a recently proposed graph
embedding framework, Graph Convolutional Net-
works (GCN) (Kipf and Welling, 2016, 2017) to
capture these relationships. GCNs are neural nets
operating on graphs, and similar to LSTMs on se-
quences, they create node embeddings based on
the graph neighborhood of a given node. In the
context of our problem, the embedding of a doc-
ument takes into account the textual content, but
also the social context of users who share it, and
their relationships with other users with known
political affiliations. We compare this powerful
approach with traditional graph embedding meth-

ods that only capture local relationships between
nodes.

Given the difficulty of providing direct super-
vision in this highly dynamic domain, we study
this problem both when direct supervision over the
documents is available, and when using distant-
supervision, in which the document level classifi-
cation depends on propagating political tendencies
through social network, which is often incomplete
and provides conflicting information.

To study these settings we focus on U.S. news
coverage. Our corpus consists of over 10k arti-
cles, covering more than 2k different news events,
about 94 different topics, taking place over a pe-
riod of 8 years. We remove any information about
the source of the article (both meta-data and in
the text) and rely only on the text and the reac-
tions to it on social media. To capture this in-
formation, we collected a set of 1.6k users who
share the news articles on Twitter and a handful
of politically-affiliated users followed by the shar-
ing users, which provide the distant supervision.
We cast the problem as a 3-class prediction prob-
lem, capturing left-leaning bias, right-leaning bias
or no bias (center).

Our experimental results demonstrate the
strength of our approach. We compare direct text
classification or node classification methods to our
embedding-based approach in both the fully super-
vised and distant supervised settings, showing the
importance of socially infused representations.

Social Link (follow)
Activity Link (share) Politically

-Affiliated  
Sharing 
User  

Figure 1: Information Flow Graph



2596

2 Related Work

The problem of perspective identification is typ-
ically studied as a supervised learning task (Lin
et al., 2006; Greene and Resnik, 2009), in which
a classifier is trained to differentiate between two
specific perspectives. For example, the bitter-
lemons dataset consisting of 594 documents de-
scribing the Israeli and Palestinian perspectives.
More recently, in SemEval-2019, a hyperpartisian
news article detection task was suggested1. The
current reported results on their dataset are com-
parable to ours, when using text information alone,
demonstrating that it is indeed a challenging task.
Other works use linguistic indicators of bias and
expressions of implicit sentiment (Greene and
Resnik, 2009; Recasens et al., 2013; Choi and
Wiebe, 2014; Elfardy et al., 2015). In recent years
several works looked at indications of framing bias
in news articles (Baumer et al., 2015; Budak et al.,
2016; Card et al., 2016; Field et al., 2018; Morstat-
ter et al., 2018). We build on these work to help
shape our text representation approach.

Recent works looked at false content identifica-
tion (Volkova et al., 2017; Patwari et al., 2017),
including a recent challenge2 identifying the rela-
tionship between an article’s title and its body. Un-
like these, we do not assume the content is false,
instead we ask if it reflects a different perspective.

Using social information when learning text
representations was studied in the context of graph
embedding (Pan et al., 2016), extending traditional
approaches that rely on graph relations alone (Per-
ozzi et al., 2014; Tang et al., 2015; Grover and
Leskovec, 2016) and information extraction and
sentiment tasks (Yang et al., 2016a; West et al.,
2014). In this work we focus on GCNs (Kipf
and Welling, 2017; Schlichtkrull et al., 2018), a
recent framework for representing relational data,
that adapts the idea of convolutional networks
to graphs. Distant supervision for NLP tasks
typically relies on using knowledge-bases (Mintz
et al., 2009), unlike our setting that uses social in-
formation. Using user activity and known user bi-
ases was explored in (Zhou et al., 2011), our set-
tings are far more challenging as we do not have
access to this information.

1https://webis.de/events/semeval-19/
2http://www.fakenewschallenge.org

Articles 10,385 Twitter Users 1,604
-Left 3,931 Pol. Users 135
-Right 2,290 Left Pol. Users 49
-Center 4,164 Right Pol. Users 51

Sources 86 Center Pol. Users 35
Types 94 Avg # shared per Article 23.29
Events 2,020 Avg # pol. users followed 20.36

Table 1: Dataset Statistics

3 Dataset Description

We collected 10,385 news articles from two news
aggregation websites3 on 2,020 different events
discussing 94 event types, such as elections, ter-
rorism, etc. The websites provide news cover-
age from multiple perspectives, indicating the bias
of each article using crowdsourced and editorial
reviewed approaches4. We preprocessed all the
documents to remove any information about the
source of the article.

We collected social information consisting of
Twitter users who share links to the collected ar-
ticles. We focused on Twitter users who follow
political users and share news articles frequently
(100 articles minimum). We found 1,604 such
Twitter users. The list of political users was cre-
ated by collecting information about active polit-
ically affiliated users. It consists of 135 Twitter
users who are mainly politicians, political journal-
ists and political organizations. The set of political
users and Twitter users are disjoint. The summary
of the dataset is shown in Table 1.

Data Folds We created several data splits to
evaluate our model in the supervised settings,
based on three criteria: randomly separated, event
separated and time separated splits. In the event-
separated case, we divide the news articles such
that all articles covering the same news event will
appear in a single fold. For the time-separated
case, we sort the publication dates (from oldest to
latest) and divide them in three folds. Each time
one fold is used as training data (33%) and the
other two combined as test data (66%). We use
the same folds throughout the experiment of su-
pervised classification for evaluation purpose.

Constructing the Social Information Graph
We represent the relevant relationships as an infor-
mation graph, similar to the one depicted in Fig-
ure 1. The social information graph G = {V,E},

3Memeorandum.com and Allsides.com
4https://www.allsides.com/media-bias/

media-bias-rating-methods

https://webis.de/events/semeval-19/
http://www.fakenewschallenge.org
Memeorandum.com
Allsides.com
https://www.allsides.com/media-bias/media-bias-rating-methods
https://www.allsides.com/media-bias/media-bias-rating-methods


2597

consisting of several different types of vertices and
edges, is defined as follows:

• Let P ⊂ V denote the set of the political
users. These are Twitter users with a clear, self-
reported, political bias. They may be the ac-
counts of politicians (e.g., Sarah Palin, Nancy
Pelosi), political writers in leading newspapers
(e.g., Anderson Cooper) or political organiza-
tions (e.g., GOP, House Democrats). Note that
even political users that share a general politi-
cal ideology can differ significantly in the type
of issues and agenda they would pursue, which
would be reflected in their followers.

• Let U ⊂ V denote the set of Twitter users that
actively spread content by sharing news articles.
The political bias of these users is not directly
known, only indicated indirectly through the po-
litical users they follow on Twitter.

• Let A ⊂ V denote the set of news articles
shared by the Twitter users (U ).

The graph vertices are connected via a set of
edges described hierarchically, as follows:

• EUP ⊂ E: All the Twitter users are connected
to the political users whom they follow. Note
that a Twitter user may be connected to many
different political users.

• EAU ⊂ E: All the articles are connected to the
Twitter users who share them. Note that an ar-
ticle may be shared by many different Twitter
users.

4 Text and Graph Model

Our goal is to classify news articles into 3-classes
corresponding to their bias. Since we have both
the textual and social information for the news ar-
ticles, we can obtain representations for them us-
ing either the text or graph models. In this section,
we briefly go through the text representation meth-
ods, and then move to describe the graph based
models we considered in this paper.

4.1 Text Representations and Linguistic Bias
Indicators

To predict the bias of the news articles, we can
consider it as a document classification task. We
use the textual content of a news article to generate
a feature representation. Deciding on the appro-
priate representation for this content is one of the

key design choices. Previous works either use tra-
ditional, manually engineered representations for
capturing bias (Recasens et al., 2013) or use la-
tent representations learned using deep learning
methods (Iyyer et al., 2014). We experimented
with several different choices of the two alterna-
tives, and compared them by training a classifier
for bias prediction over the document directly. The
results of these experiments are summarized in Ta-
ble 2. Due to space constraints, we provide a brief
overview of these alternatives, and point to the full
description in the relevant papers.

Linear BoW Unigram features were used. The
articles consist of 77,772 unique tokens. We used
TFIDF vectors as unigram features obtained by us-
ing scikit-learn (Pedregosa et al., 2011).

Bias Features These are content based features
drawn from a wide range of approaches described
in the literature on political bias, persuasion, and
misinformation, capturing structure, sentiment,
topic, complexity, bias and morality in the text.
We used the resources in (Horne et al., 2018b)
to generate 141 features based on the news article
text, which were shown to work well for the binary
hyper-partisan task (Horne et al., 2018a).

Averaged Word Embedding (WE) The sim-
plest approach for using pre-trained word embed-
dings. An averaged vector of all the document’s
words using the pre-trained GloVe word embed-
dings (Pennington et al., 2014) were used to rep-
resent the entire article.

Skip-Thought Embedding Unlike the Aver-
aged word vector that does not capture context, we
also used a sentence level encoder, Skip-Thought
(Kiros et al., 2015), to generate text representa-
tions. We regard each document as a long sentence
and map it directly to a 4800-dimension vector.

Hierarchical LSTM over tokens and sentences
We used a simplified version of the Hierarchical
LSTM model (Yang et al., 2016b). In this case
documents are first tokenized into sentences, then
each sentence was tokenized into words. We used
a word-level LSTM to construct a vector represen-
tation for each sentence, by taking the average of
all the hidden states. Then, we ran another single
layer unidirectional LSTM over the sentence rep-
resentations to get the document representation by
taking average of all the hidden states.



2598

4.2 Graph-Based Representations

In addition to the textual information, the news ar-
ticles are also part of the information network de-
fined in Section 3. Intuitively, news articles shared
by the same Twitter users are likely to have the
same bias, and users who share a lot of news in
common are close in their political preferences. A
similar intuition connects users who follow similar
politically affiliated users. Capturing this informa-
tion allows us to predict the bias of a news article,
given its social context. We design our embedding
function to map all graph nodes into a low dimen-
sional vector space, such that the graph relation-
ships are preserved in the embedding space. In the
shared embedding space, nodes that are connected
(or close) in the graph should have higher similar-
ity scores between their vector representations.

4.2.1 Directly Observed Relationships in
Graph (DOR)

Our first embedding approach aims to preserve the
local pairwise proximity between two vertices di-
rectly. This is similar to first-order graph embed-
ding methods (Tang et al., 2015). There are two
different relations observed in the graph: Twitter
user to political user (follow) and news article to
Twitter user (share). We construct our embedding
over multiple views of the data, each view w cor-
responds to a specific type of graph relation. We
can then define an loss function Lw for each view
w as follows:

• Twitter User to Political User (UP): This ob-
jective maximizes the similarity of a Twitter
user, u and all the political users in the set
Pu ⊂ P , where Pu is the set of political users
that u follows.

LUP = −
∑
u∈U

∑
p∈Pu

logP (p|u) (1)

• News Article to Twitter User (AU): This ob-
jective maximizes the similarity of a news ar-
ticles, a and all the Twitter users in the set
Ua ⊂ U , where Ua is the set of Twitter users
who shared news article a on Twitter.

LAU = −
∑
a∈A

∑
u∈Ua

logP (u|a) (2)

All the conditional probabilities can be com-
puted using a softmax function. Taking P (p|u)

as an example:

P (p|u) = exp(e
T
u ep)∑

q∈P exp(e
T
u eq)

(3)

where eu and ep are embeddings of twitter user
u and political user p respectively.

Computing Eq. 1 and Eq. 2 can be expensive
due to the size of the network. To address this
problem, we refer to the popular negative sam-
pling approach (Mikolov et al., 2013), which re-
duce the time complexity to be proportional to the
number of positive example pairs (i.e. number of
edges in our case).

The loss defined for the two views are summed
with the classification loss defined in Eq. 9 as the
final loss function to be optimized in DOR embed-
ding model.

LDOR = Lclf + LUP + LAU (4)

4.2.2 Graph Convolutional Networks (GCN)
Graph Convolutional Networks is an efficient vari-
ant of convolutional neural networks which oper-
ate directly on graphs. It can be regarded as special
cases of a simple differentiable message-passing
framework (Gilmer et al., 2017):

h
(l+1)
i = σ

( ∑
j∈N(i)

M (l)(h
(l)
i , h

(l)
j )

)
(5)

where h(l)i ∈ Rd
(l)

is the hidden state of node
vi in the l-th layer of the neural network, with
d(l) as the dimensionality of representation at layer
l. N(i) is the set of direct neighbors of node vi
(usually also include itself). Incoming messages
from the local neighborhood are aggregated to-
gether and passed through the activation function
σ(·), such as tanh(·). M (l) is typically chosen to
be a (layer-specific) neural network function. Kipf
and Welling (2017) used a simple linear transfor-
mation M (l)(hti, h

t
j) = W

(l)hj where W (l) is a
layer-specific weight matrix.

This linear transformation has been shown to
propagate information effectively on graphs. It
leads to significant improvements in node classi-
fication (Kipf and Welling, 2017), link predic-
tion (Kipf and Welling, 2016), and graph classi-
fication (Duvenaud et al., 2015).

One GCN layer can be expressed as follows:

H(l+1) = σ(ÂH(l)W (l)) (6)



2599

where Â is the normalized adjacency matrix,
andW (l) is the layer-specific trainable weight ma-
trix. H(l) ∈ RN×D(l) is the matrix of hidden states
in the l-th layer. H(0) = X is the input vectors. It
can either be one-hot representations of nodes or
features of the nodes if available. σ(·) is the acti-
vation function.

Multiple GCN layers can be stacked in order
to capture high-order relations in the graph. We
consider a two-layer GCN in this paper for semi-
supervised node classification. Our forward model
takes the form:

V = tanh
(
Â tanh

(
ÂXW (0)

)
W (1)

)
(7)

where X is the input matrix with one-hot rep-
resentations and V is the representation matrix for
all nodes in the graph.

Figure 2 shows an example of how our GCN
model aggregates information from a node’s local
neighborhood. The orange document is the node
of interest. Blue edges link to first order neighbors
and green edges link to second order neighbors.

Figure 2: Example of Unfolding of GCN Computa-
tional Graph

4.3 Document Classification
The representation v of a news article (obtained
with text models or graph models) captures the
high level information of the document. It can be
used as features for predicting the bias label with
a feed-forward network.

p = softmax(Wcv + bc) (8)

We use the negative log likelihood of the correct
labels as classification training loss:

Lclf = −
∑
a

log paj (9)

where j is the bias label of news article a.

5 Joint Model

Given that we have two representations available
for news articles, namely the textual one and social
one, it is natural to make the prediction combining
both of them. We propose to align the represen-
tations of the same document from graph and text
models in a joint training fashion as shown in Fig-
ure 3. The objective function for the alignment is:

Lalign = −
∑
a∈A

logP (eGa |eTa ) (10)

where eTa is the embedding for document a
based on its content, and eGa is the embedding for
document a based on graph structures. P (eGa |eTa )
is defined the same way as in Eq. 3. Negative sam-
pling is again utilized to reduce time complexity.

Connecting the text and graph embedding of the
same news articles, allows the bias signal to flow
between the two sides. Therefore the text model
may learn from the social signal and the graph
model may use textual content to adjust its repre-
sentation as well. We describe the loss function for
the joint model in two settings - full supervision
(i.e., labels associated with documents directly)
and distant supervision, when bias information is
only provided for a handful of users, which do not
actively share documents.

Full Supervision In the full supervision case,
the loss consists of three parts, namely the clas-
sification loss of text model (LTclf ), the classifica-
tion loss of graph model (LGclf ), and the loss for
aligning the embeddings of the text and the graph
models (Lalign).

Ljoint = αL
T
clf + βL

G
clf + γLalign (11)

Here α, β and γ are hyper-parameters to adjust the
contribution of the three parts. We set all of them
to default value 1 in experiments in this paper.

Distant Supervision Unlike the full supervision
case where we have training labels for documents,
we only have access to the labels of political users.
However, since the text and social representation
use the same space, user bias information can be
propagated to the document representation, acting
as a distant supervision source.

Inference Given the graph representation, deci-
sions can be made in multiple ways. Each docu-
ment has a dual representation, as a text node and
a social node. Also, given the social context of a



2600

Text
Representations

𝑎

Graph-Based
Representations

𝑎

𝑎

𝑎

𝑎

𝑎

𝑢

𝑢

𝑢

𝑢

𝑝

𝑝

𝑝

𝑎

𝑎

𝑎

𝑎

𝑎

𝑎

Classification
Module

Alignment

Figure 3: Overall Architecture: Representations are learned for news articles based on textual information and
graph structure; these two representations are aligned in our joint model; only labels of political users are available
during training in distant supervision case

document, decision can be defined over the users
that share it (assuming that users tend to share in-
formation which agrees with their biases). To take
advantage of that fact, we define a simplified infer-
ence process. At test time, we can predict the bias
of a news article with the embeddings from text
model (Text), the embeddings from graph model
(Graph), and the embeddings of sharing users who
shared this article (User). The last method (User)
works by averaging bias prediction scores sbu for
all Twitter users that shared an article a. The bias
prediction score is computed in Eq. 8 before the
softmax(·) applied.

argmax
b

∑
u∈Ua s

b
u

|Ua|
(12)

Finally, two or three of the scores listed above
can be combined to make the decision.

6 Experiments

We designed our experiments to evaluate the con-
tribution of social information in both the fully su-
pervised setting, and when only distant supervi-
sion is available through the social graph. We be-
gin by evaluating several text classification mod-
els that help contextualize the social information.
Finally, we evaluate our model’s ability to make
predictions when very little social information is
available at test time.

6.1 Implementation Details

We used the spaCy toolkit for preprocessing the
documents. All models are implemented with Py-
Torch (Paszke et al., 2017). Hyperbolic tangent
(tanh) is used as non-linear activation function.
We use feed-forward neural network with one hid-
den layer for the bias prediction task given textual
or social representation. The sizes of LSTM hid-
den states for both word level and sentence level
are 64. The sizes of hidden states for both GCN
layers are 16. For the training of the neural net-
work, we used the Adam optimizer (Kingma and
Ba, 2014) to update the parameters. We use 5% of
the training data as the validation set. We run the
training for 200 epochs (50 epochs for HLSTM
models), and select the best model based on per-
formance on validation set. Other parameters
in our model includes negative sample size k=5,
mini-batch size b=30 (mini-batch update only used
for HLSTM models). The learning rate is 0.001
for HLSTM models and 0.01 otherwise.

6.2 Experimental Results

Text Classification Results The result of super-
vised text classification is summarized in Table 2.
We report the accuracy of bias prediction. Re-
sults clearly show that HLSTM outperforms the
other methods in supervised text classification set-
ting. Also, adding the hand engineered bias fea-
tures with HLSTM representation does not help to



2601

improve performance.

Model Split Text

Majority
Rand 40.10
Event 40.10
Time 40.50

Linear BoW
Rand 58.47
Event 59.88
Time 55.41

Bias Feat.
Rand 54.06
Event 53.51
Time 52.96

Avg WE
Rand 59.37
Event 59.37
Time 53.46

SkipThought
Rand 68.67
Event 66.35
Time 60.89

HLSTM
Rand 74.59
Event 73.55
Time 66.98

HLSTM + Bias Feat.
Rand 69.32
Event 69.87
Time 66.79

Table 2: Supervised Classification Using Textual Fea-
tures

Network Classification Results We show the
results of predicting bias using graph information
alone, without text, in Table 3. The GCN model
outperforms DOR significantly in each of the four
settings. Similar to the text classification results,
performance on random and event splits are com-
parable. However, there is a sharp drop in per-
formance for time split. This can be explained by
the fact that temporally separated news events will
discuss different entities and world events and as a
result will have very different word distributions.
Event-separated splits are less susceptible to this
problem, as similar figures and topics are likely to
be discussed in different events.

Model Split Graph User G+U

DOR

Rand 74.74 72.02 74.57
Event 74.87 72.74 75.18
Time 65.65 65.07 65.36
Dist 56.45 56.95 56.54

GCN

Rand 88.65 78.83 88.89
Event 88.78 76.11 88.70
Time 81.14 71.31 82.00
Dist 63.72 40.08 67.03

Table 3: Classification Results Using Social Relations
in Full Supervised and Distant Supervised Setting

Joint Model Results Table 4 shows the results
of our joint model. When aligning the text and
graph embeddings using joint training, both show
improvement, and prediction with text or graph

representations alone is better than those listed in
Table 2 and 3, especially for text. Note that the in-
crease in accuracy is much greater for the more ex-
pressive HLSTM model. Making prediction with
the aggregation of multiple scores usually leads to
better accuracy.

Interestingly, the model’s distant supervision
performance is almost comparable with fully su-
pervised text classification results. This demon-
strates the strength of our joint model, and its abil-
ity to effectively propagate label information from
users down to documents.

We also evaluated our model when smaller
amounts of social information was available at test
time. We tested our joint model with only 50%
and 10% of the links for test articles kept. The re-
sults are summarized in Table 5. Clearly the per-
formance improves as more social links are avail-
able. However, even with little social links pro-
vided in the latter case, our joint model propagates
information effectively and results in an increase
in performance compared to text classification.

Qualitative Analysis In Table 6, we compared
the bias prediction by our text and joint model on
several news articles (only titles shown in the ta-
ble). These examples demonstrate the subtlety of
bias expression in text, which helps motivate so-
cial representations to support the decision.

7 Conclusion

In this paper we follow the intuition that the po-
litical perspectives expressed in news articles will
also be reflected in the way the documents spread
and the identity of the users who endorse them.
We suggest a GCN-based model capturing this so-
cial information, and show that it provides a dis-
tant supervision signal, resulting in a model per-
forming comparably to supervised text classifica-
tion models. We also study this approach in the su-
pervised setting and show that it can significantly
enhance a text-only classification model.

Modeling the broader context in which text is
consumed is a vital step towards getting a bet-
ter understanding of its perspective. We intend to
study fine-grained political perspectives, capturing
how different events are framed.

Acknowledgements

We thank the reviewers for their insightful com-
ments. This work was partially supported by a
Google Gift.



2602

Model Split Graph User G+U Text G+T G+U+T

GCN + SkipThought

Rand 89.95 81.49 89.75 70.61 90.34 91.02
Event 89.40 79.06 89.64 69.16 90.15 90.78
Time 84.95 76.59 85.30 64.12 84.09 86.25
Dist 67.78 45.30 70.03 58.68 69.82 70.66

GCN + HLSTM

Rand 89.03 83.66 88.57 86.84 91.48 91.74
Event 89.34 80.22 88.62 88.39 91.69 91.72
Time 84.83 74.50 85.09 81.36 85.57 86.21
Dist 71.74 69.39 71.16 61.13 72.16 71.85

Table 4: Results of Joint Model Combining Text and Graph Relations

Model Split Graph User G+U Text G+T G+U+T

GCN + HLSTM (50%)

Rand 86.73 78.62 86.24 85.62 89.31 89.35
Event 86.55 78.34 85.89 84.52 89.21 89.51
Time 82.25 70.93 81.45 80.05 85.57 85.48

GCN + HLSTM (10%)

Rand 76.13 57.76 75.55 78.61 81.35 81.49
Event 76.58 57.10 75.75 77.60 80.55 80.93
Time 73.24 54.09 72.48 72.92 76.52 76.75

Table 5: Results of Joint Model with Reduced Links for Test Documents

Text Joint Gold Title
Right Right Right Hacked Powell email reveals Hillary hates Obama for 2008
Right Right Right Donald Trump will let James Comey testify
Center Center Center Clinton: I am done with being a candidate
Center Center Center Senate confirms Sessions as attorney general

Left Left Left Clinton: Trump Doesn’t See President Obama as an American Video
Left Left Left Trump uses Twitter to promote leaked intelligence on North Korea

Center Left Left Hillary Clinton’s Campaign Says It Will Participate In Wisconsin Recount
Left Center Center Supreme Court justices hint at striking Voting Rights Act provision
Left Center Right Boston Marathon bombs: how investigators use technology to identify suspects

Right Right Left Israel risks becoming apartheid state if peace talks fail, says John Kerry

Table 6: Examples of Bias Prediction by Text and Joint Model

References
Eric Baumer, Elisha Elovic, Ying Qin, Francesca Pol-

letta, and Geri Gay. 2015. Testing and compar-
ing computational approaches for identifying the
language of framing in political news. In Pro-
ceedings of the 2015 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 1472–1482, Denver, Colorado. Association
for Computational Linguistics.

Beata Beigman Klebanov, Eyal Beigman, and Daniel
Diermeier. 2010. Vocabulary choice as an indica-
tor of perspective. In Proceedings of the ACL 2010
Conference Short Papers, pages 253–257, Uppsala,
Sweden. Association for Computational Linguistics.

Ceren Budak, Sharad Goel, and Justin M Rao. 2016.
Fair and balanced? quantifying media bias through
crowdsourced content analysis. Public Opinion
Quarterly, 80(S1):250–271.

Dallas Card, Justin Gross, Amber Boydstun, and
Noah A. Smith. 2016. Analyzing framing through
the casts of characters in the news. In Proceedings of
the 2016 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1410–1420, Austin,
Texas. Association for Computational Linguistics.

Yoonjung Choi and Janyce Wiebe. 2014. +/-
EffectWordNet: Sense-level lexicon acquisition for
opinion inference. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1181–1191, Doha,
Qatar. Association for Computational Linguistics.

David Duvenaud, Dougal Maclaurin, Jorge Aguilera-
Iparraguirre, Rafael Gómez-Bombarelli, Timothy
Hirzel, Alán Aspuru-Guzik, and Ryan P. Adams.
2015. Convolutional networks on graphs for learn-
ing molecular fingerprints. In Proceedings of the
28th International Conference on Neural Informa-
tion Processing Systems - Volume 2, NIPS’15, pages
2224–2232, Cambridge, MA, USA. MIT Press.

Heba Elfardy, Mona Diab, and Chris Callison-Burch.
2015. Ideological perspective detection using se-
mantic features. In Proceedings of the Fourth Joint
Conference on Lexical and Computational Seman-
tics, pages 137–146, Denver, Colorado. Association
for Computational Linguistics.

Anjalie Field, Doron Kliger, Shuly Wintner, Jennifer
Pan, Dan Jurafsky, and Yulia Tsvetkov. 2018. Fram-
ing and agenda-setting in Russian news: a com-
putational analysis of intricate political strategies.
In Proceedings of the 2018 Conference on Em-
pirical Methods in Natural Language Processing,

https://doi.org/10.3115/v1/N15-1171
https://doi.org/10.3115/v1/N15-1171
https://doi.org/10.3115/v1/N15-1171
https://www.aclweb.org/anthology/P10-2047
https://www.aclweb.org/anthology/P10-2047
https://doi.org/10.1093/poq/nfw007
https://doi.org/10.1093/poq/nfw007
https://doi.org/10.18653/v1/D16-1148
https://doi.org/10.18653/v1/D16-1148
https://doi.org/10.3115/v1/D14-1125
https://doi.org/10.3115/v1/D14-1125
https://doi.org/10.3115/v1/D14-1125
http://dl.acm.org/citation.cfm?id=2969442.2969488
http://dl.acm.org/citation.cfm?id=2969442.2969488
https://doi.org/10.18653/v1/S15-1015
https://doi.org/10.18653/v1/S15-1015
https://www.aclweb.org/anthology/D18-1393
https://www.aclweb.org/anthology/D18-1393
https://www.aclweb.org/anthology/D18-1393


2603

pages 3570–3580, Brussels, Belgium. Association
for Computational Linguistics.

Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley,
Oriol Vinyals, and George E. Dahl. 2017. Neural
message passing for quantum chemistry. In Pro-
ceedings of the 34th International Conference on
Machine Learning, volume 70 of Proceedings of
Machine Learning Research, pages 1263–1272, In-
ternational Convention Centre, Sydney, Australia.
PMLR.

Maria Glenski, Tim Weninger, and Svitlana Volkova.
2018. Identifying and understanding user reactions
to deceptive and trusted social news sources. In Pro-
ceedings of the 56th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 2: Short
Papers), pages 176–181, Melbourne, Australia. As-
sociation for Computational Linguistics.

Stephan Greene and Philip Resnik. 2009. More than
words: Syntactic packaging and implicit sentiment.
In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 503–511, Boulder, Colorado. Asso-
ciation for Computational Linguistics.

Aditya Grover and Jure Leskovec. 2016. Node2vec:
Scalable feature learning for networks. In Proceed-
ings of the 22Nd ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining,
KDD ’16, pages 855–864, New York, NY, USA.
ACM.

Benjamin D. Horne, William Dron, Sara Khedr, and
Sibel Adali. 2018a. Assessing the news landscape:
A multi-module toolkit for evaluating the credibility
of news. In Companion Proceedings of the The Web
Conference 2018, WWW ’18, pages 235–238, Re-
public and Canton of Geneva, Switzerland. Interna-
tional World Wide Web Conferences Steering Com-
mittee.

Benjamin D. Horne, Sara Khedr, and Sibel Adali.
2018b. Sampling the news producers: A large news
and feature data set for the study of the complex
media landscape. In Proceedings of the Twelfth In-
ternational Conference on Web and Social Media,
ICWSM 2018, Stanford, California, USA, June 25-
28, 2018., pages 518–527.

Mohit Iyyer, Peter Enns, Jordan Boyd-Graber, and
Philip Resnik. 2014. Political ideology detection us-
ing recursive neural networks. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
1113–1122, Baltimore, Maryland. Association for
Computational Linguistics.

Kristen Johnson and Dan Goldwasser. 2016. “all
I know about politics is what I read in twitter”:
Weakly supervised models for extracting politicians’
stances from twitter. In Proceedings of COLING

2016, the 26th International Conference on Compu-
tational Linguistics: Technical Papers, pages 2966–
2977, Osaka, Japan. The COLING 2016 Organizing
Committee.

Diederik P. Kingma and Jimmy Ba. 2014. Adam:
A method for stochastic optimization. CoRR,
abs/1412.6980.

Thomas N. Kipf and Max Welling. 2016. Variational
graph auto-encoders. CoRR, abs/1611.07308.

Thomas N. Kipf and Max Welling. 2017. Semi-
supervised classification with graph convolutional
networks. In 5th International Conference on
Learning Representations, ICLR 2017, Toulon,
France, April 24-26, 2017, Conference Track Pro-
ceedings.

Ryan Kiros, Yukun Zhu, Ruslan Salakhutdinov,
Richard S. Zemel, Raquel Urtasun, Antonio Tor-
ralba, and Sanja Fidler. 2015. Skip-thought vec-
tors. In Advances in Neural Information Process-
ing Systems 28: Annual Conference on Neural In-
formation Processing Systems 2015, December 7-
12, 2015, Montreal, Quebec, Canada, pages 3294–
3302.

Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and
Alexander Hauptmann. 2006. Which side are you
on?: Identifying perspectives at the document and
sentence levels. In Proceedings of the Tenth Con-
ference on Computational Natural Language Learn-
ing, CoNLL-X ’06, pages 109–116, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor-
rado, and Jeffrey Dean. 2013. Distributed represen-
tations of words and phrases and their composition-
ality. In Proceedings of the 26th International Con-
ference on Neural Information Processing Systems -
Volume 2, NIPS’13, pages 3111–3119, USA. Curran
Associates Inc.

Mike Mintz, Steven Bills, Rion Snow, and Daniel Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of
the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP,
pages 1003–1011, Suntec, Singapore. Association
for Computational Linguistics.

Fred Morstatter, Liang Wu, Uraz Yavanoglu,
Stephen R. Corman, and Huan Liu. 2018. Iden-
tifying framing bias in online news. Trans. Soc.
Comput., 1(2):5:1–5:18.

Shirui Pan, Jia Wu, Xingquan Zhu, Chengqi Zhang,
and Yang Wang. 2016. Tri-party deep network
representation. In Proceedings of the Twenty-Fifth
International Joint Conference on Artificial Intelli-
gence, IJCAI’16, pages 1895–1901. AAAI Press.

http://proceedings.mlr.press/v70/gilmer17a.html
http://proceedings.mlr.press/v70/gilmer17a.html
https://www.aclweb.org/anthology/P18-2029
https://www.aclweb.org/anthology/P18-2029
https://www.aclweb.org/anthology/N09-1057
https://www.aclweb.org/anthology/N09-1057
https://doi.org/10.1145/2939672.2939754
https://doi.org/10.1145/2939672.2939754
https://doi.org/10.1145/3184558.3186987
https://doi.org/10.1145/3184558.3186987
https://doi.org/10.1145/3184558.3186987
https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17796
https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17796
https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17796
https://doi.org/10.3115/v1/P14-1105
https://doi.org/10.3115/v1/P14-1105
https://www.aclweb.org/anthology/C16-1279
https://www.aclweb.org/anthology/C16-1279
https://www.aclweb.org/anthology/C16-1279
https://www.aclweb.org/anthology/C16-1279
http://arxiv.org/abs/1611.07308
http://arxiv.org/abs/1611.07308
https://openreview.net/forum?id=SJU4ayYgl
https://openreview.net/forum?id=SJU4ayYgl
https://openreview.net/forum?id=SJU4ayYgl
http://papers.nips.cc/paper/5950-skip-thought-vectors
http://papers.nips.cc/paper/5950-skip-thought-vectors
http://dl.acm.org/citation.cfm?id=1596276.1596297
http://dl.acm.org/citation.cfm?id=1596276.1596297
http://dl.acm.org/citation.cfm?id=1596276.1596297
http://dl.acm.org/citation.cfm?id=2999792.2999959
http://dl.acm.org/citation.cfm?id=2999792.2999959
http://dl.acm.org/citation.cfm?id=2999792.2999959
https://www.aclweb.org/anthology/P09-1113
https://www.aclweb.org/anthology/P09-1113
https://doi.org/10.1145/3204948
https://doi.org/10.1145/3204948
http://dl.acm.org/citation.cfm?id=3060832.3060886
http://dl.acm.org/citation.cfm?id=3060832.3060886


2604

Adam Paszke, Sam Gross, Soumith Chintala, Gre-
gory Chanan, Edward Yang, Zachary DeVito, Zem-
ing Lin, Alban Desmaison, Luca Antiga, and Adam
Lerer. 2017. Automatic differentiation in pytorch.

Ayush Patwari, Dan Goldwasser, and Saurabh Bagchi.
2017. TATHYA: A multi-classifier system for de-
tecting check-worthy statements in political debates.
In Proceedings of the 2017 ACM on Conference
on Information and Knowledge Management, CIKM
2017, Singapore, November 06 - 10, 2017, pages
2259–2262.

F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-
sos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. 2011. Scikit-learn: Machine learning
in Python. Journal of Machine Learning Research,
12:2825–2830.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1532–1543, Doha,
Qatar. Association for Computational Linguistics.

Bryan Perozzi, Rami Al-Rfou, and Steven Skiena.
2014. Deepwalk: Online learning of social rep-
resentations. In Proceedings of the 20th ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD ’14, pages 701–
710, New York, NY, USA. ACM.

Marta Recasens, Cristian Danescu-Niculescu-Mizil,
and Dan Jurafsky. 2013. Linguistic models for an-
alyzing and detecting biased language. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 1650–1659, Sofia, Bulgaria. Associa-
tion for Computational Linguistics.

Filipe Nunes Ribeiro, Lucas Henrique, Fabrı́cio Ben-
evenuto, Abhijnan Chakraborty, Juhi Kulshrestha,
Mahmoudreza Babaei, and Krishna P. Gummadi.
2018. Media bias monitor: Quantifying biases of
social media news outlets at large-scale. In Proceed-
ings of the Twelfth International Conference on Web
and Social Media, ICWSM 2018, Stanford, Califor-
nia, USA, June 25-28, 2018., pages 290–299.

Michael Sejr Schlichtkrull, Thomas N. Kipf, Peter
Bloem, Rianne van den Berg, Ivan Titov, and Max
Welling. 2018. Modeling relational data with graph
convolutional networks. In The Semantic Web - 15th
International Conference, ESWC 2018, Heraklion,
Crete, Greece, June 3-7, 2018, Proceedings, pages
593–607.

Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun
Yan, and Qiaozhu Mei. 2015. Line: Large-scale in-
formation network embedding. In Proceedings of
the 24th International Conference on World Wide
Web, WWW ’15, pages 1067–1077, Republic and

Canton of Geneva, Switzerland. International World
Wide Web Conferences Steering Committee.

Svitlana Volkova, Kyle Shaffer, Jin Yea Jang, and
Nathan Hodas. 2017. Separating facts from fiction:
Linguistic models to classify suspicious and trusted
news posts on twitter. In Proceedings of the 55th
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 2: Short Papers), pages
647–653, Vancouver, Canada. Association for Com-
putational Linguistics.

Robert West, Hristo S. Paskov, Jure Leskovec, and
Christopher Potts. 2014. Exploiting social network
structure for person-to-person sentiment analysis.
Transactions of the Association for Computational
Linguistics, 2.

Yi Yang, Ming-Wei Chang, and Jacob Eisenstein.
2016a. Toward socially-infused information extrac-
tion: Embedding authors, mentions, and entities.
In Proceedings of the 2016 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1452–1461, Austin, Texas. Association for Compu-
tational Linguistics.

Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He,
Alex Smola, and Eduard Hovy. 2016b. Hierarchi-
cal attention networks for document classification.
In Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 1480–1489, San Diego, California. Associa-
tion for Computational Linguistics.

Daniel Xiaodan Zhou, Paul Resnick, and Qiaozhu Mei.
2011. Classifying the political leaning of news ar-
ticles and users from user votes. In Proceedings of
the Fifth International Conference on Weblogs and
Social Media, Barcelona, Catalonia, Spain, July 17-
21, 2011.

https://doi.org/10.1145/3132847.3133150
https://doi.org/10.1145/3132847.3133150
https://doi.org/10.3115/v1/D14-1162
https://doi.org/10.3115/v1/D14-1162
https://doi.org/10.1145/2623330.2623732
https://doi.org/10.1145/2623330.2623732
https://www.aclweb.org/anthology/P13-1162
https://www.aclweb.org/anthology/P13-1162
https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17878
https://aaai.org/ocs/index.php/ICWSM/ICWSM18/paper/view/17878
https://doi.org/10.1007/978-3-319-93417-4_38
https://doi.org/10.1007/978-3-319-93417-4_38
https://doi.org/10.1145/2736277.2741093
https://doi.org/10.1145/2736277.2741093
https://doi.org/10.18653/v1/P17-2102
https://doi.org/10.18653/v1/P17-2102
https://doi.org/10.18653/v1/P17-2102
https://doi.org/10.1162/tacl_a_00184
https://doi.org/10.1162/tacl_a_00184
https://doi.org/10.18653/v1/D16-1152
https://doi.org/10.18653/v1/D16-1152
https://doi.org/10.18653/v1/N16-1174
https://doi.org/10.18653/v1/N16-1174
http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/view/2782
http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/view/2782

