



















































Dialog Generation Using Multi-Turn Reasoning Neural Networks


Proceedings of NAACL-HLT 2018, pages 2049–2059
New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics

Dialog Generation Using Multi-turn Reasoning Neural Networks

Xianchao Wu1, Ander Martı́nez2∗, Momo Klyen1

1A.I.&Research, Microsoft Development Co., Ltd.
2 Graduate School of Information Science, Nara Institute of Science and Technology
{xiancwu, momokl}@microsoft.com, ander.martinez.zy4@is.naist.jp

Abstract

In this paper, we propose a generalizable di-
alog generation approach that adapts multi-
turn reasoning, one recent advancement in the
field of document comprehension, to gener-
ate responses (“answers”) by taking current
conversation session context as a “document”
and current query as a “question”. The major
idea is to represent a conversation session into
memories upon which attention-based mem-
ory reading mechanism can be performed mul-
tiple times, so that (1) user’s query is properly
extended by contextual clues and (2) optimal
responses are step-by-step generated. Consid-
ering that the speakers of one conversation are
not limited to be one, we separate the single
memory used for document comprehension
into different groups for speaker-specific topic
and opinion embedding. Namely, we utilize
the queries’ memory, the responses’ memory,
and their unified memory, following the time
sequence of the conversation session. Experi-
ments on Japanese 10-sentence (5-round) con-
versation modeling show impressive results on
how multi-turn reasoning can produce more
diverse and acceptable responses than state-
of-the-art single-turn and non-reasoning base-
lines.

1 Introduction

Dialogue systems such as chatbots are a thriving
topic that is attracting increasing attentions from
researchers (Sordoni et al., 2015; Serban et al.,
2016; Li et al., 2015; Wen et al., 2016). Recent
achievements, such as deep neural networks for
text generating, user profiling (Li et al., 2014), and
natural language understanding, have accelerated
the progresses of this field, which was historically
approached by conventional rule-based and/or sta-
tistical response ranking strategies.

∗Work done when Ander was an intern in Microsoft. Wu
and Ander contributed equally to this paper.

Response ranking models retrieve the most suit-
able response(s) from a fixed set of (question,
answer) pairs given a dialogue context and cur-
rent query from a user (Banchs and Li, 2012;
Lowe et al., 2015). Learning-to-rank approaches
were applied to compute the similarity scores of
between (query, context) and indexed candidate
(question, answer) pairs to return the optimal “an-
swer” to the user. These ranking-based retrieval
strategies have been well-applied as an impor-
tant approach to dialogue systems, yet the set of
scripted responses are limited and are short at gen-
eralization. On the other hand, statistical machine
translation (SMT) systems have been applied to
dialogue systems (Ritter et al., 2011), taking user’s
query as a source language sentence and the chat-
bot’s response as a target language sentence. La-
beled data for learning-to-ranking training will not
be necessary anymore and all we need is the large-
scale (question, answer) pairs.

The sequence-to-sequence model proposed in
(Sutskever et al., 2014) applied end-to-end train-
ing of neural networks to text generation. This
model, further enhanced by an attention mecha-
nism (Bahdanau et al., 2014), was generic and
allowed its application to numerous sequence-
to-sequence learning tasks such as neural ma-
chine translation (NMT) (Cho et al., 2014; Bah-
danau et al., 2014), image captioning (Donahue
et al., 2015; Mao et al., 2015), speech recogni-
tion (Chan et al., 2015) and constituency parsing
(Vinyals et al., 2015). The simplicity of these
models makes them attractive, since “translation”
and “alignment” are learned jointly on the fly.

Specially, Vinyals and Le (2015) applied the
sequence-to-sequence model to conversational
modeling and achieved impressive results on var-
ious datasets. Their model was trained to predict
a response given the previous sentence (s). Shang
et al. (2015) combined local and global attentions

2049



and reported better results than retrieval based sys-
tems. Sordoni et al. (2015) explored three differ-
ent end-to-end approaches for the problem of pre-
dicting the response given a query attached with a
single message context.

Multi-turn conversation modeling is considered
to be more difficult than machine translation, since
there are many more acceptable responses for a
given (context, query) input and these often rely
on external knowledge and/or contextual reason-
ing. Dialogue systems trained with a maximum
likelihood estimation (MLE) objective function, as
most SMT utilizes, often learn to reply generic
sentences as “I don’t know” or “sounds good”,
which have a high incidence in the “answer” part
of (question, answer) style training datasets. There
have been various attempts at diversifying the re-
sponses (Li et al., 2016a; Yu et al., 2016; Li et al.,
2017) but the lack of variations in the responses
remains as an essential challenge. We wonder that
if this stress can be relieved by modeling the prior
context in a rather fine-grained way.

In document comprehension fields, multi-turn
reasoning (also called multi-hop reasoning) has
delivered impressive results by assimilating vari-
ous pieces of information to produce an unified
answer (Hill et al., 2015; Dhingra et al., 2016).
Through multi-turn reading the document’s mem-
ory using attention models, current question can
be extended with much richer knowledge. This
makes it easier to figure out the correct answer
from that document. Different documents need to
be read different times to yield out the correct an-
swer for the input question. Specially, Shen et al.
(2016) use a dynamic number of turns by intro-
ducing a termination gate to control the number of
iterations of reading and reasoning.

Motivated by the reasoning network for docu-
ment comprehension (Shen et al., 2016), we pro-
pose multi-turn reasoning neural networks that
generate the proper response (or, “answer”) by
attention-based reasoning from current conver-
sation session (“document”) and current query
(identical to “question” in document comprehen-
sion) from the user. In particular, our networks
utilize conversation context and explicitly sep-
arate speakers’ interventions into sentence-level
and conversation-level memories. Our first model
uses plain single-turn attention to integrate all
the memories, and the second approach integrates
multi-turn reasoning. The formulation of our pro-

posed approach is designed in a generalized way,
allowing for inclusion of additional information
such as external knowledge bases (Yih and Ma,
2016; Ghazvininejad et al., 2017; Han et al., 2015)
or emotional memories (Zhou et al., 2017). More-
over, our approach for two-speaker scenario can
be easily extended to group chatting by a further
speaker-specific memory splitting.

We evaluate the performances of our meth-
ods by comparing three configurations trained on
a Japanese twitter conversation session dataset.
Each conversation session contains 10 sentences
which are 5-round between two real-world speak-
ers. The results provide evidences that multi-turn
reasoning neural networks can help improving the
consistency and diversity of multi-turn conversa-
tion modeling.

This paper is structured as follows: Section 2
gives a general description of multi-turn conver-
sation modeling; Section 3 describes background
neural language modeling, text generation, and at-
tention mechanisms; Section 4.1 first introduces a
model with multiple attention modules and then
explains how the multi-turn reasoning mechanism
can be further integrated into the previous mod-
els; Sections 5, 6 and 7 describe the experimen-
tal settings and results using automatic evaluation
metrics, detailed human-evaluation based analy-
sis, and conclusions, respectively.

2 Multi-turn Conversation Modeling

Consider a dataset D consisting of a list of con-
versations between two speakers. Each conversa-
tion d ∈ D is an ordered sequence of sentences
si, where i ∈ [1, Td] and Td is the number of sen-
tences in d, produced by two speakers alternately.
In this way, for si, sj ∈ d, both sentences are from
the same speaker if and only if i ≡ j (mod 2).
Note that, our definition includes the case that one
speaker continuously expresses his/her message
through several sentences. We simply concatenate
these sentences into one to ensure that the conver-
sation is modeled with alternate speakers.

A multi-turn conversation model is trained to
search parameters that maximize the likelihood of
every sentence si ∈ d where i ≥ 2, supposing
that the beginning sentence s1 is always given as a
precondition:

θM = argmax
θ
{L(θ,D)}, (1)

2050



where

L(θ,D) =
∑

d∈D

Td∏

i=2

p(si|s<i). (2)

Here, s<i are sentences sj ∈ d and j < i.
The probability of each sentence, p(si|s<i), is

frequently estimated by a conditional language
model. Note that, traditional single-turn conver-
sation models or NMT models are a special case
of this model by simply setting Td to be 2. That
is, the generation of the next sentence is session-
insensitive and is only determined by the former
single sentence. Another aspect of understand-
ing this contextual conversation model is that, the
number of reference contextual sentences s<i is
not limited to be one. Suppose there are already 9
sentences known in one conversation session and
we want to generate the 10-th sentence, then from
p(s1) to p(s9) are all preconditions and we will
only need to focus on estimating p(s10|s<10).

We adapt sequence-to-sequence neural models
(Sutskever et al., 2014) for multi-turn conversa-
tion modeling. They are separated into an encoder
part and a decoder part. The encoder part applies
a RNN on the input sequence(s) s<i to yield prior
information. The decoder part estimates the prob-
ability of the generated output sequence si by em-
ploying the last hidden state of the encoder as the
initial hidden state of the decoder. Sutskever et al.
(2014) applied this technique to NMT and impres-
sive experimental results were reported thereafter.

Using Equation 2, we are modeling two chat-
bots talking with each other, since all the s2,...,Td
are modeled step-by-step on the fly. However, we
can add constraints to determine whose responses
to be generated, either one speaker or both of
them. That is, when i takes odd integers of 1, 3, 5
and so on, we are modeling the first speaker. Even
integers of i indicates a generation of responses for
the second speaker.

3 Language Modeling and Text
Generation

Language models (LM) are trained to compute the
probability of a sequence of tokens (words or char-
acters or other linguistic units) being a linguistical
sentence. Frequently, the probability of a sentence
s with Ts tokens is computed by the production
of the probabilities of each token yj ∈ s given its

contexts y<j and y>j :

p(s) =

Ts∏

j=1

p(yj |y<j , y>j). (3)

When generating a sequence based on a LM,
we can generate one word at a time based on the
previously predicted words. In this situation, only
the previously predicted words are known and the
probability of current sequence is approximated
by dropping the posterior context. That is,

p(yj |y<j , y>j) ≈ p(yj |y<j). (4)

We construct a sequence generation LM using
sequence-to-sequence neural network f . The neu-
ral network intercalates linear combinations and
non-linear activate functions to estimate the prob-
ability of mass function. Then, in the encoder part
of f , the contextual information is represented by
a fixed-size hidden vector hj :

p(yj |y<j , y>j) ≈ f(yj−1, hj , θf ), (5)

where θf represents f ’s trainable parameters.
To embed the previous word sequence into

a fixed-size vector, recurrent neural networks
(RNN) such as long short term memory (LSTM)
networks (Hochreiter and Schmidhuber, 1997) or
gated recurrent units (GRU) (Cho et al., 2014) are
widely used. These networks repeat a recurrent
operation on each input word:

hj = g(hj−1, yj−1, θg), (6)

where θg represents the trainable parameters of a
RNN function g, and hj is the hidden state of the
RNN at time j.

3.1 Conditional Language Modeling
The hidden state h of a RNN can accumulate infor-
mation from previous words (yj ∈ s and j < Ts)
or previous sentences (si ∈ d and i < Td) which
ensures the encoding and decoding processes in
sequence-to-sequence models. Since the contex-
tual sentences are known already, the encoder can
represent them in both forward (~hj) and back-
ward ( ~hj) directions. The results from both re-
cursions can be combined by a concatenated op-
eration. This is referred to as bidirectional RNN
shorted as BiRNN (Schuster and Paliwal, 1997).

hj = [~h
>
j ;

~h
>
j ]
>. (7)

2051



For each sentence si ∈ d (i < Td), we
annotate the combination of the final states of
each RNN direction as a memory vector mi =

[(~h
(i)
Tsi

)T; ( ~h
(i)

1 )
T]T. A projection of annotationmi

can be used as the decoder’s initial state t0 such as
t0 = tanh(WsmTd′ ) and Td′ < Td. Ws here is
a weight matrix that projects mTd′ into a vector
that shares a same dimension with t0. In (Bah-
danau et al., 2014) for NMT, ~h1, backward encod-
ing of a single source sentence, was used to initial-
ize t0 = tanh(Ws ~h1).

3.2 Attention Mechanism

Summarizing all contextual information into one
single fixed-length vector becomes weaker to
guide the generation of the target sentence as the
contextual information grows longer. To tackle
this problem, an attention mechanism (Bahdanau
et al., 2014) was applied to NMT for learning to
align and translate jointly. In this attention-based
model, the conditional probability in Equation 4 is
defined as:

p(yj |y<j) = f(yj−1, tj , cj , θf ), (8)

where

tj = g(tj−1, yj−1, cj , θg) (9)

is a RNN hidden state in the decoder part for time
j and cj =

∑Ts
i=1 α

(j)
i hi is a context vector, a

weighted combination of the annotation set mem-
ory (h1, ..., hTs) produced by encoding a source
sentence swith length Ts. The weight α

(j)
i of each

(source) annotation hi is computed by

α
(j)
i =

exp(e
(j)
i )∑Ts

l=1 exp(e
(j)
l )

. (10)

where e(j)i is an alignment model and is imple-
mented by a feed-forward network a:

e
(j)
i = a(hi, tj−1). (11)

This method was applied to single-turn conver-
sation modeling (Vinyals and Le, 2015). We use
this model, with attention over each immediately
previous sentence si−1 ∈ d for generating si, as
a baseline for our experiments. We annotate this
model as SIMPLE subsequently in this paper.

4 Multi-turn Reasoning Network with
Multiple Type Memories

The attention mechanism described in Equations
8 and 9 is performed in a single-turn feed-forward
fashion. However, for complex context and com-
plex queries, human readers often revisit the given
context in order to perform deeper inference af-
ter one turn reading. This real-world reading phe-
nomenon motivated the multi-turn reasoning net-
works for document comprehension (Shen et al.,
2016). Considering dialog generation scenario
with given rich context, we intuitively think if the
attentions can be performed multi-turns so that the
conversation session is better understood and the
simple query, which frequently omits unknown
number of context-sensitive words, can be ex-
tended for a better generation of the response. The
domain adaptation from document comprehension
to dialog generation is feasible by taking the rich
context of the speakers as a “document”, current
user’s query as a “question” and the chatbot’s re-
sponse as an “answer”.

However, there are still several major chal-
lenges for this domain adaptation. First, a docu-
ment is frequently written by a single author with
one (hidden) personality, one writing style, and
one distribution of the engagement rates of the top-
ics appearing in that document. These are not the
case for conversation scenario in which at least
two speakers are involved with different (hidden)
personalities, personalized speaking styles, and di-
verse engagement rate distributions of the topics in
that conversation session. Second, for document
comprehension, the output is frequently a single
named entity (Shen et al., 2016) and thus a single
softmax function can satisfy this one-shot rank-
ing problem. However, we will need a RNN de-
coder utilizing context vectors for generating the
target response sentence being a sequence of to-
kens (words or characters) instead of one single
named entity.

We tackle the first challenge by separating the
context into multiple type memories upon which
attention models are performed. For the second
difference, we replace the simple softmax output
layer by a GRU decoder employing reasoning-
attention context vectors.

4.1 Separation of contextual information

The SIMPLEmodel can use multiple turns of con-
text to infer the response by concatenating them

2052



during decoding, using a separator symbol such
as EOS for end-of-sentence. Sordoni et al. (2015)
separated the query message and the previous two
context messages when conditioning the response.
The previous context messages were concatenated
and treated as a single message.

In our proposed models, we use more than three
turns for the context. We separate the last mes-
sage (the query) from the previous turns to pro-
duce a set of annotations h, one per character1 in
the sentence. While encoding the contextual in-
formation, we separate the mi from each speaker
into two sets. The motivation is to capture indi-
vidual characteristics such as personalized topical
information and speaking style (Li et al., 2016b).
We refer to the set of annotations from the same
speaker as one memory. That is, the sentences for
which the probabilities are being predicted as Mr
(response memory, specially corresponds to the
chatbot’s side) and the question set as Mq (query
memory, specially corresponds to the user’s side).
We further apply a RNN on top of mi to produce
one more set of vectors Mc (context memory):

Mc =

Tc⋃

i=0

{m(c)i }, (12)

in which,

m
(c)
i = RNN(mi,m

(c)
i−1), (13)

where Tc is the number of turns (sentences) in the
conversation. The initial state m(c)0 is a trainable
parameter.

We apply an attention mechanism on each of the
memories Mq, Mr, Mc and Mh (of current query)
separately. Refer to Figure 1 for an intuitive illus-
tration of these memories. Following (Shen et al.,
2016), we choose projected cosine similarity func-
tion as the attention module. The attention score
aqj,i on memory m

q
i ∈ Mq for a RNN hidden state

tj in the decoder part is computed as follows:

aqj,i = softmaxi=1,...,|Mq |cos(W
q
1m

q
i ,W

q
2 tj),

(14)
where W q1 and W

q
2 are weight vectors associated

with mqi and tj , respectively. Consequently, the
attention vector on the query sequences is given
by:

cqj =

|Mq |∑

i=1

aqj,im
q
i . (15)

1Most Japanese characters, such as Kanji, have indepen-
dent semantic meanings other than English letters

Figure 1: Illustration of the architecture of our
REASON model. In the example conversation session,
six context sentences are encoded independently by
a biRNN. The character-specific annotations from the
sixth sentence (i.e., current query) compose the only
sentence-level Mh memory. Mr,q,c are conversation-
level memories. The last mi from each sentence are
distributed alternately in Mq and Mr memories. Also,
m1,...,6 are iterated sequentially by a single-direction
RNN to produce six context annotations in Mc using
Equation 13. In the bottom of the diagram, a reasoning
module (Figure 2) is used instead of the plain attention
used in MULTI.

Similarly, the attention scores and attention vec-
tors on the other three memories can be derived by
replacing q with r, c, and h in Equations 14, 15.

We then concatenate these resulting attention
vectors into a final context vector cMj , which is
consequently applied to Equations 8 and 9. Since
the dimension of the updated context vector cMj is
four times larger, its weight matrix C will need
to be enlarged with a same column dimension
with the dimension of cMj so that Cc

M
j still aligns

with the dimension of the hidden layer vector tj .
More details of the GRU function style definition
of tj using cj can be found in (Bahdanau et al.,
2015). We refer to this model that integrates multi-
ple types of memories through separated attention
mechanisms as MULTI.

Note that, by separately embedding conversa-
tion context into multiple type memories follow-
ing the number of speakers, we can easily extend
this two speaker scenario into group chatting in
which tens or hundreds of speakers can be engaged
in. The only extension is to further separateMq by
speakers. Consequently, the context vector can be
concatenated using the attention vectors by read-

2053



�✁✂✄

☎✆�✁✂✄

✝✞✟

✠✁

✡✄
☛

✡☞
☛ ✡✌

☛

✍
✄ ✍☞ ✍✌

✎✏✑✒✓ ✎✏✑✒✓

✔✕✖✗✘✕✖✙ ✔✕✖✗✘✕✖✙
✚✛✜✓

✢✍✔✣✤✥✦

✔
✧✕✕
✗✘
✧✕✕
✙ ★✁✩

☛
✄

✪✓✫✬✛✭✓✒✮ ✯✰✩✱✩✲✩✳

✏✴✴✓✵✴✭✬✵

✔
✧✕✕
✗✘
✧✕✕
✙ ★✁✩

☛
☞

✔✕✖✗✘✕✖✙

✴✓✛✫✭✵✏✴✭✬✵

�
✁

☎
✆�✁

✝✞✟

✪✓✫✬✛✭✓✒✮ ✯✰✩✱✩✲✩✳

✞✓✏✒✬✵✭✵✶ ✷✬✸

✞✓✏✒✬✵✭✵✶ ✷✬✸

✹✺✻

✹✏✴✓✻

✼

✠✁✂✄

★✽
✁✩

☛

✾✿☞

✼

✢✍✔✣✤✥✦

★✽
✁❀✄❁

☛

✾

★✽✁✩

☛

✾✿☞

Figure 2: Illustration of the reason part of the REASON
model. This figure is drawn by partially referring Fig-
ure 1 in (Shen et al., 2016).

ing all the memories. The theoretical benefit is
that the chatbot can softly keep track of each indi-
vidual speaker’s topics and then make a decision
of how to response to that speaker. Another exten-
sion will be using a reinforcement learning policy
to determine when to let the chatbot to give a re-
sponse to which speaker in current group chatting.

Generally, the number and type of memories
can be enlarged in a reasonable way, such as by in-
troducing external knowledge (Yih and Ma, 2016;
Ghazvininejad et al., 2017; Han et al., 2015) or
performing sentiment analysis to the “fact mem-
ories” to yield emotional memories (Zhou et al.,
2017). A detailed description and experimental
testifying is out of the scope of this paper.

4.2 Reasoning Neural Dialogue System

As illustrated in Figure 2, we apply a multi-
turn reasoning mechanism, following Shen et al.
(2016), to the multiple-type annotation memories.
This reasoning mechanism replaces the single-turn
attention mechanism. We adapt the idea of us-
ing a termination state during the inference to dy-
namically determine how many turns to reason.
The termination module can decide whether to
continue to infer the next turn (of re-reading the
four types of memories) after digesting interme-
diate topical and speaker-specific information, or
to terminate the whole inference process when it

concludes that existing information is sufficient to
generate the next word in a response. Generally,
the idea is to construct a reasoning attention vector
that works as a context vector during generating
the next word. This idea is included in the “Rea-
soning box” in Figure 2. Specially, yj−1 stands for
a former word generated by the hidden state ŝj−1
in the GRU decoder. Ey is the embedding matrix.
We use a full-connection layer to map from ŝj−1
to the initial reasoning hidden state hR1 , since h

R
m

should be with the same length alike each memory
vector in Mq,r,c,h and ŝj−1’s dimension is smaller
than that. Thus, (1) outside the “reasoning box”,
we use a GRU decoder to yield ŝj so that a next
word yj can be generated, and (2) inside the “rea-
soning box”, we read the memories to yield the
“optimal” contextual vector. The “reasoning box”
takes the memoriesMq,r,c,h and ŝj−1 as inputs and
finally outputs cRj,m.

The number of reasoning turns for yielding the
“reasoning attention vectors” (cRj which is further
indexed by reasoning steps of 1, 2 in Figure 2)
during the decoding inference is dynamically pa-
rameterized by both the contextual memories and
current query, and is generally related to the com-
plexities of the conversation context and current
query.

The training steps are performed as per the gen-
eral framework as described in Equations 8 and 9.
For each reasoning hidden state hRm, the termina-
tion probability om is estimated by ftg(hRm; θtg),
which is

om = (1− om−1) ∗ σ(w>t hRm + bt), (16)
where θtg = {wt, bt}, wt is a weight vector, bt
is a bias, and σ is the sigmoid logistic function.
Then, different hidden states hRm are first weighted
by their termination probabilities om and then
summed to produce a reasoning-attention context
vector cRj (using the equations as described pre-
viously in Section 3.2), which is consequently
used to construct the next reasoning step’s hR2 =
RNN(hR1 , c

R
j,1). The final c

R
j,m (m ≥1 is the final

reasoning step) will be used in Equations 8 and 9
in a way alike former attention vectors. During
our experiments, we instead used a sum of from
o2 × cRj,1 to om+1 × cRj,m as the final c′Rj,m for next
word generation.

During generating each word in the response,
our network performs a response action rm at
the m-th step, which implies that the termina-
tion gate variables o1:m = (o1 = 0, o2 =

2054



A: i’m bored
B: boooring
A: isn’t it? (ˆ_ˆ)
B: everybody is asleep
A: really?

(ˆ_ˆ) my friends are still awake! :P
B: lucky!

xD feels lonely with everyone asleep
A: almost everyone is awake (ˆvˆ)
B: whyyy?!

my friends go early to bed.
Or is it me that’s late? xD

A: it’s us who are late! xD
B: true, very true xD

Figure 3: A 5-round conversation of speakers A and B.

0, ..., om−1 = 0, om = 1). A stochastic pol-
icy π((om, rm)|hRm, tj ; θ) with parameters θ to get
a distribution of termination actions, to continue
reading the conversation context (i.e., Mq,r,c,h) or
to stop, and of response actions rm for predict-
ing the next word if the model decides to stop at
current step. In our experiments, we set a max-
imum step parameter Tmax to be 5 for heuristi-
cally avoiding too many reasoning times. We fol-
low (Shen et al., 2016) to compute the expected
reward and its gradient for one instance. We refer
to this model with multi-turn reasoning attentions
as REASON.

5 Experiments

In our experiments, we used a dataset consisting of
Japanese twitter conversations. Each conversation
contains 10 sentences from two real-world alter-
nating speakers. Given the origin of the dataset, it
is quite noisy, containing misspelled words, slang
and kaomoji (multi-character sequences of facial
emoticons) among meaningful words and charac-
ters. Preliminary experiments by using a word-
based approach resulted in the vocabulary size be-
ing too big and with too many word breaking er-
rors, we instead used a character-based approach.
Figure 3 shows a sample 10-sentence conversa-
tion in which original Japanese sentences were
translated into English and similar spelling pat-
terns were kept in a sense (such as boooring for
boring and whyyy for why).

We kept the conversations in which all sen-
tences were no more than 20 characters. This fil-
tering strategy resulted in a dataset of 254K con-
versations from which 100 (1K sentences) where
taken out for testing and another 100 for validat-

Conversation Characters
sessions Sentences (Unique)

Train 253K 2.5M 24M (6,214)
Validation 100 1K 10K (836)
Test 100 1K 9.3K (780)

Table 1: Statistics of the filtered datasets.

Figure 4: Cost curves of NLL during training.

ing and hyper-parameter tuning. The training set
contains 6,214 unique characters, which are used
as our vocabulary with the addition of two spe-
cial symbols, an UNK (out-of-vocabulary unknown
word) and an EOS (end-of-sentence). Table 1
shows major statistics of the dataset.

The training minimizes negative log-likelihood
(NLL) per character on the nine sentences s2,...,10
of each conversation. One configuration in MULTI
and REASON is that, we respectively use the
reference contexts (instead of former automati-
cally generated sentences) to generate current sen-
tence. That is, when generating si, we use the
golden contextual sentences of from s1 to si−1.
These three systems were respectively trained 3
epochs (10,000 iterations) on an AdaDelta (Zeiler,
2012) optimizer. Character embedding matrix was
shared by both the encoder and the decoder parts.
All the hidden layers, in the encoding/decoding
parts and the attention models, were of size 200
and the character embeddings were of size 100.
The recurrent units that we used were GRU. The
gradients were clipped at the maximum gradient
norm of 1. The reasoning module’s maximum
steps Tmax was set to be 5. The data was iterated
on mini-batches of less than 1,500 symbols each.

We initialized the recurrent weight matrices in
GRUs as random orthogonal matrices. Unless spe-
cially mentioned, all the elements of the 0-indexed
vectors and all bias vectors were initialized to
be zero. Any other weight matrices were initial-
ized by sampling from the Gaussian distribution
of mean 0 and variance 0.01.

Figure 4 shows the progression of the NLLs per

2055



SIMPLE MULTI REASON

B
L

E
U

-4 Train 1.98 1.97 2.30
Validation 1.80 2.12 2.62
Test 2.20 2.13 2.89

B
L

E
U

-2 Train 6.77 6.78 7.03
Validation 6.67 6.89 8.14
Test 7.19 7.24 7.97

Table 2: Character-level BLEU-2/4 (%) scores.

character during training. The validation costs be-
gun converging in the third epoch for the three
models. The plot roughly shows lower cost for
more complex models.

Galley et al. (2015) obtained better correla-
tion with human evaluation when using BLEU-2
rather than BLEU-4. We thus report both of these
scores for automatic evaluation and comparison.
The character-level BLEU-4 and BLEU-2 scores
for the trained models are reported in Table 2.
The REASON model achieved consistently better
BLEU-2 and BLEU-4 scores in the three datasets.
MULTI performed slightly better than SIMPLE on
the validation set yet that performance is less sta-
ble than REASON.

Figure 4 also reflects that, (1) the final train-
ing costs of SIMPLE and MULTI are quite close
with each other at iteration 10,000; (2) there is a
big margin of between the final training cost of
REASON and that of SIMPLE or MULTI; and (3)
the validation costs exactly follows an order of
SIMPLE > MULTI > REASON.

6 Analysis

Figure 5 illustrates an English translation of a con-
versation and the responses suggested by each of
the described models. This conversation is ex-
tracted from the test set. The three responses are
different from the reference response, but the one
from REASON looks the most consistent with the
given context. The response from MULTI is con-
tradicting the context of speaker B as he/she said
Not at all in a former sentence.

As it has been shown in (Liu et al., 2016) that
BLEU doesn’t correlate well with human judg-
ments, we asked three human evaluators to re-
spectively examine 900 responses from each of the
models given their reference contexts. The evalua-
tors were asked to judge (1) whether one response
is acceptable and (2) whether one response is bet-
ter than the other two responses. A summary of
this evaluation is displayed in Table 3. The accept-
able column refers to the percentage of responses

A: I feel nostalgic. This was so cute.
B: It’s gross. What’s that picture?
A: It’s cute! It used to be on TV.
B: Isn’t that from a children’s show?
A: Yes
B: I know that one!!
A: Isn’t it cute?
B: Not at all
A: Uh! I can’t believe it...
SIMPLE (B:) MULTI (B:) REASON (B:)
Uh! it isn’t. It’s cute! Do you think it’s cute?
Reference
B: Are you asking me whether the picture is cute?

Figure 5: Sample responses generated by the three
models and the recorded reference response, translated
to English. Both MULTI and REASON include cute, yet
MULTI contradicts a previous response Not at all.

accept- best-of- > >
able three † SIMPLE‡ MULTI‡

SIMPLE 42% 25% - 45%
MULTI 52% 29% 55% -
REASON 65% 46% 59% 58%

Table 3: Human evaluation of the responses generated
by the three models. † Percentage over the conversa-
tions that had at least one response accepted. ‡ From
the cases where any of both compared models was ac-
ceptable. > = “better than”.

that were considered acceptable by at least two
of the human evaluators while the best-of-three
columns refers to the percentage of times that each
model’s response was considered by at least two
evaluators to be better than the other two’s, from
the contexts that had at least one acceptable re-
sponse. The last two columns make one-to-one
comparisons. In 18% of the contexts, none of the
models produced an acceptable response.

This human evaluation shows that complexer
models are more likely to produce acceptable re-
sponses. The MULTI and REASON models are
only different in the attention mechanism of multi-
turn reasoning. The reasoning module performed
better than single-turn attention 58% of the times.

Table 4 contains the character-level distinct-n
(Li et al., 2016a) metrics for n-grams where 1 ≤
n ≤ 5. This metric measures the number of dis-
tinct n-grams divided by the total number of n-
grams in the generated responses. The displayed
results are computed on the concatenation of all
the responses to the test-set contexts. The Refer-
ence column was computed on the reference re-
sponses and represents the optimal human-like ra-
tio.
SIMPLE performed the best at uni-gram diver-

2056



SIMPLE MULTI REASON Reference
distinct-1 .039 .028 .032 .088
distinct-2 .112 .095 .121 .407
distinct-3 .199 .180 .238 .588
distinct-4 .248 .241 .310 .587
distinct-5 .255 .265 .328 .530

Table 4: N-gram diversity metrics of between (1) the
responses generated to the test set and (2) their refer-
ence responses.

sity. For n-grams n ≥ 2, REASON produced
the most diverse outputs. While the results for
REASON were consistently better than the other
two models, the results for MULTI were not al-
ways better than SIMPLE. This indicates MULTI
does not always benefit from the augmented con-
text without the multi-turn reasoning attentions.

7 Conclusions

We have presented a novel approach to multi-turn
conversation modeling. Our approach uses multi-
ple explicitly separated memories to represent rich
conversational contexts. We also presented multi-
turn reasoning attentions to integrate various an-
notation memories. We run experiments on three
different models with and without the introduced
approaches and measured their performances us-
ing automatic metrics and human evaluation.

Experimental results verified that the increased
contexts are able to help producing more accept-
able and diverse responses. Driven by the depth
of the reasoning attention, the diversities of the
responses are significantly improved. We argue
that the reasoning attention mechanism helps in-
tegrating the multiple pieces of information as it
can combine them in a more complex way than a
simple weighted sum. We further observed that as
the accuracy of the conversation model improves,
the diversity of the generated responses increases.

The proposed approach of multi-turn reason-
ing over multiple memory attention networks is
presented in a general framework that allows the
inclusion of memories of multiple resources and
types. Applying to group chatting with more than
two speakers and reasoning over emotion embed-
dings or knowledge vectors included from an ex-
ternal knowledge base/graph are taken as our fu-
ture directions.

Acknowledgments

The authors thank the anonymous reviewers for
their impressive comments and suggestions for

improving the earlier version.

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2014. Neural Machine Translation by Jointly
Learning to Align and Translate. arXiv:1409.0473
[cs, stat] ArXiv: 1409.0473. http://arxiv.
org/abs/1409.0473.

Dzmitry Bahdanau, Jan Chorowski, Dmitriy
Serdyuk, Philemon Brakel, and Yoshua Ben-
gio. 2015. End-to-End Attention-based
Large Vocabulary Speech Recognition.
arXiv:1508.04395 [cs] ArXiv: 1508.04395.
http://arxiv.org/abs/1508.04395.

Rafael E. Banchs and Haizhou Li. 2012. IRIS: a
Chat-oriented Dialogue System based on the Vec-
tor Space Model. In Proceedings of the ACL 2012
System Demonstrations. Association for Computa-
tional Linguistics, Jeju Island, Korea, pages 37–
42. http://www.aclweb.org/anthology/
P12-3007.

William Chan, Navdeep Jaitly, Quoc V. Le, and
Oriol Vinyals. 2015. Listen, Attend and Spell.
arXiv:1508.01211 [cs, stat] ArXiv: 1508.01211.
http://arxiv.org/abs/1508.01211.

Kyunghyun Cho, Bart van Merrienboer, Caglar
Gulcehre, Dzmitry Bahdanau, Fethi Bougares,
Holger Schwenk, and Yoshua Bengio. 2014.
Learning Phrase Representations using RNN
Encoder-Decoder for Statistical Machine Transla-
tion. arXiv:1406.1078 [cs, stat] ArXiv: 1406.1078.
http://arxiv.org/abs/1406.1078.

Bhuwan Dhingra, Hanxiao Liu, Zhilin Yang,
William W. Cohen, and Ruslan Salakhutdinov. 2016.
Gated-Attention Readers for Text Comprehension.
arXiv:1606.01549 [cs] ArXiv: 1606.01549.
http://arxiv.org/abs/1606.01549.

Jeff Donahue, Lisa Anne Hendricks, Sergio Guadar-
rama, Marcus Rohrbach, Subhashini Venugopalan,
Kate Saenko, and Trevor Darrell. 2015. Long-
term Recurrent Convolutional Networks for Visual
Recognition and Description. In CVPR.

Michel Galley, Chris Brockett, Alessandro Sordoni,
Yangfeng Ji, Michael Auli, Chris Quirk, Mar-
garet Mitchell, Jianfeng Gao, and Bill Dolan. 2015.
deltaBLEU: A Discriminative Metric for Genera-
tion Tasks with Intrinsically Diverse Targets. In
Proceedings of the 53rd Annual Meeting of the
Association for Computational Linguistics and the
7th International Joint Conference on Natural Lan-
guage Processing (Volume 2: Short Papers). Associ-
ation for Computational Linguistics, Beijing, China,
pages 445–450. http://www.aclweb.org/
anthology/P15-2073.

2057



Marjan Ghazvininejad, Chris Brockett, Ming-Wei
Chang, Bill Dolan, Jianfeng Gao, Wen-tau Yih,
and Michel Galley. 2017. A knowledge-grounded
neural conversation model. CoRR abs/1702.01932.
http://arxiv.org/abs/1702.01932.

Sangdo Han, Jeesoo Bang, Seonghan Ryu, and
Gary Geunbae Lee. 2015. Exploiting knowl-
edge base to generate responses for natural lan-
guage dialog listening agents. In Proceedings
of the 16th Annual Meeting of the Special Inter-
est Group on Discourse and Dialogue. Association
for Computational Linguistics, Prague, Czech Re-
public, pages 129–133. http://aclweb.org/
anthology/W15-4616.

Felix Hill, Antoine Bordes, Sumit Chopra, and Jason
Weston. 2015. The Goldilocks Principle: Reading
Children’s Books with Explicit Memory Represen-
tations. arXiv:1511.02301 [cs] ArXiv: 1511.02301.
http://arxiv.org/abs/1511.02301.

Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long
short-term memory. Neural Comput. 9(8):1735–
1780. https://doi.org/10.1162/neco.
1997.9.8.1735.

Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2015. A Diversity-Promoting Ob-
jective Function for Neural Conversation Models.
arXiv:1510.03055 [cs] ArXiv: 1510.03055. http:
//arxiv.org/abs/1510.03055.

Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,
and Bill Dolan. 2016a. A Diversity-Promoting Ob-
jective Function for Neural Conversation Models. In
Proceedings of the 2016 Conference of the North
American Chapter of the Association for Compu-
tational Linguistics: Human Language Technolo-
gies. Association for Computational Linguistics,
San Diego, California, pages 110–119. http://
www.aclweb.org/anthology/N16-1014.

Jiwei Li, Michel Galley, Chris Brockett, Georgios Sp-
ithourakis, Jianfeng Gao, and Bill Dolan. 2016b. A
Persona-Based Neural Conversation Model. In Pro-
ceedings of the 54th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers). Association for Computational Linguistics,
Berlin, Germany, pages 994–1003. http://www.
aclweb.org/anthology/P16-1094.

Jiwei Li, Will Monroe, Tianlin Shi, Sbastien Jean,
Alan Ritter, and Dan Jurafsky. 2017. Adver-
sarial Learning for Neural Dialogue Generation.
arXiv:1701.06547 [cs] ArXiv: 1701.06547. http:
//arxiv.org/abs/1701.06547.

Jiwei Li, Alan Ritter, and Eduard Hovy. 2014.
Weakly supervised user profile extraction from twit-
ter. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 1: Long Papers). Association for
Computational Linguistics, Baltimore, Maryland,
pages 165–174. http://www.aclweb.org/
anthology/P14-1016.

Chia-Wei Liu, Ryan Lowe, Iulian Serban, Mike Nose-
worthy, Laurent Charlin, and Joelle Pineau. 2016.
How NOT To Evaluate Your Dialogue System:
An Empirical Study of Unsupervised Evaluation
Metrics for Dialogue Response Generation. In
Proceedings of the 2016 Conference on Empiri-
cal Methods in Natural Language Processing. As-
sociation for Computational Linguistics, Austin,
Texas, pages 2122–2132. https://aclweb.
org/anthology/D16-1230.

Ryan Lowe, Nissan Pow, Iulian Serban, and Joelle
Pineau. 2015. The Ubuntu Dialogue Corpus: A
Large Dataset for Research in Unstructured Multi-
Turn Dialogue Systems. arXiv:1506.08909 [cs]
ArXiv: 1506.08909. http://arxiv.org/
abs/1506.08909.

Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng
Huang, and Alan Yuille. 2015. Deep Captioning
with Multimodal Recurrent Neural Networks (m-
RNN). ICLR .

Alan Ritter, Colin Cherry, and William B. Dolan. 2011.
Data-Driven Response Generation in Social Media.
In Proceedings of the 2011 Conference on Empiri-
cal Methods in Natural Language Processing. As-
sociation for Computational Linguistics, Edinburgh,
Scotland, UK., pages 583–593. http://www.
aclweb.org/anthology/D11-1054.

M. Schuster and K.K. Paliwal. 1997. Bidirectional
Recurrent Neural Networks. Trans. Sig. Proc.
45(11):2673–2681. https://doi.org/10.
1109/78.650093.

Iulian V. Serban, Alessandro Sordoni, Yoshua Bengio,
Aaron Courville, and Joelle Pineau. 2016. Building
End-to-end Dialogue Systems Using Generative Hi-
erarchical Neural Network Models. In Proceedings
of the Thirtieth AAAI Conference on Artificial Intel-
ligence. AAAI Press, Phoenix, Arizona, AAAI’16,
pages 3776–3783. http://dl.acm.org/
citation.cfm?id=3016387.3016435.

Lifeng Shang, Zhengdong Lu, and Hang Li. 2015.
Neural Responding Machine for Short-Text Conver-
sation. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguis-
tics and the 7th International Joint Conference on
Natural Language Processing (Volume 1: Long Pa-
pers). Association for Computational Linguistics,
Beijing, China, pages 1577–1586. http://www.
aclweb.org/anthology/P15-1152.

Yelong Shen, Po-Sen Huang, Jianfeng Gao, and
Weizhu Chen. 2016. ReasoNet: Learning
to Stop Reading in Machine Comprehension.
arXiv:1609.05284 [cs] ArXiv: 1609.05284.
https://doi.org/10.1145/3097983.
3098177.

Alessandro Sordoni, Michel Galley, Michael Auli,
Chris Brockett, Yangfeng Ji, Margaret Mitchell,
Jian-Yun Nie, Jianfeng Gao, and Bill Dolan. 2015.

2058



A Neural Network Approach to Context-Sensitive
Generation of Conversational Responses. In Pro-
ceedings of the 2015 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies. Asso-
ciation for Computational Linguistics, Denver, Col-
orado, pages 196–205. http://www.aclweb.
org/anthology/N15-1020.

Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.
Sequence to Sequence Learning with Neural Net-
works. In Z. Ghahramani, M. Welling, C. Cortes,
N. D. Lawrence, and K. Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
27, Curran Associates, Inc., pages 3104–3112.

Oriol Vinyals, ukasz Kaiser, Terry Koo, Slav Petrov,
Ilya Sutskever, and Geoffrey Hinton. 2015. Gram-
mar as a Foreign Language. In C. Cortes, N. D.
Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett,
editors, Advances in Neural Information Processing
Systems 28, Curran Associates, Inc., pages 2773–
2781. http://papers.nips.cc/paper/
5635-grammar-as-a-foreign-language.
pdf.

Oriol Vinyals and Quoc Le. 2015. A Neural
Conversational Model. arXiv:1506.05869 [cs]
ArXiv: 1506.05869. http://arxiv.org/
abs/1506.05869.

Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic,
Lina M. Rojas-Barahona, Pei-Hao Su, David
Vandyke, and Steve Young. 2016. Multi-domain
Neural Network Language Generation for Spo-
ken Dialogue Systems. In Proceedings of the
2016 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies. Association
for Computational Linguistics, San Diego, Cali-
fornia, pages 120–129. http://www.aclweb.
org/anthology/N16-1015.

Wen-tau Yih and Hao Ma. 2016. Question Answer-
ing with Knowledge Base, Web and Beyond. In
Proceedings of the 2016 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Tutorial Abstracts. Association
for Computational Linguistics, San Diego, Califor-
nia, pages 8–10. http://www.aclweb.org/
anthology/N16-4003.

Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu.
2016. SeqGAN: Sequence Generative Adversar-
ial Nets with Policy Gradient. arXiv:1609.05473
[cs] ArXiv: 1609.05473. http://arxiv.org/
abs/1609.05473.

Matthew D. Zeiler. 2012. ADADELTA: An Adap-
tive Learning Rate Method. arXiv:1212.5701 [cs]
ArXiv: 1212.5701. http://arxiv.org/abs/
1212.5701.

Hao Zhou, Minlie Huang, Tianyang Zhang, Xiaoyan
Zhu, and Bing Liu. 2017. Emotional chatting ma-

chine: Emotional conversation generation with in-
ternal and external memory. CoRR abs/1704.01074.
http://arxiv.org/abs/1704.01074.

2059


