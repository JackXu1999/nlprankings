99

Coling 2010: Poster Volume, pages 99–107,

Beijing, August 2010

Toward Qualitative Evaluation of Textual Entailment Systems

Elena Cabrio

FBK-Irst, University of Trento

cabrio@fbk.eu

Bernardo Magnini

FBK-Irst

magnini@fbk.eu

Abstract

This paper presents a methodology for a
quantitative and qualitative evaluation of
Textual Entailment systems. We take ad-
vantage of the decomposition of Text Hy-
pothesis pairs into monothematic pairs,
i.e. pairs where only one linguistic phe-
nomenon at a time is responsible for en-
tailment judgment, and propose to run TE
systems over such datasets. We show
that several behaviours of a system can
be explained in terms of the correlation
between the accuracy on monothematic
pairs and the accuracy on the correspond-
ing original pairs.

Introduction

1
Since 2005, Recognizing Textual Entailment
(RTE) has been proposed as a task whose aim is
to capture major semantic inference needs across
applications in Computational Linguistics (Dagan
et al., 2009). Systems are asked to automatically
judge whether the meaning of a portion of text, re-
ferred as Text (T), entails the meaning of another
text, referred as Hypothesis (H). This evaluation
provides useful cues for researchers and develop-
ers aiming at the integration of TE components in
larger applications (see, for instance, the use of a
TE engine in the QALL-ME project system1, the
use in relation extraction (Romano et al., 2006),
and in reading comprehension systems (Nielsen
et al., 2009)).

Although the RTE evaluations showed pro-
gresses in TE technologies, we think that there is

1http://qallme.fbk.eu/

still large room for improving qualitative analysis
of both the RTE datasets and the system results.
In particular, we intend to focus this paper on the
following aspects:

1. There is relatively poor analysis of the lin-
guistic phenomena that are relevant for the
RTE datasets, and very little is known about
the distribution of such phenomena, and
about the ability of participating systems to
correctly detect and judge them in T,H pairs.
Experiments like the ablation tests attempted
in the last RTE-5 campaign on lexical and
lexical-syntactic resources go in this direc-
tion, although the degree of comprehension
is still far from being optimal.

2. We are interested in the correlations among
the capability of a system to address single
linguistic phenomena in a pair and the ability
to correctly judge the pair itself. Despite the
strong intuition about such correlation (i.e.
the more the phenomena for which a system
is trained, the better the ﬁnal judgment), no
empirical evidences support it.

3. Although the ability to detect and manage
single phenomena seems to be a crucial fea-
ture of high performing systems, very little is
known about how systems manage to com-
bine such results in a global score for a pair.
The mechanism underlying such composi-
tion may shed light on meaning composition
related to TE tasks.

4. Finally, we are interested in the relation be-
tween the above mentioned items over the
different kinds of pairs represented in RTE

100

datasets, speciﬁcally entailment, contradic-
tion and unknown pairs. In this case the in-
tuition is that some phenomena are more rel-
evant for a certain judgment rather than for
another.

To address the issues above, we propose an
evaluation methodology aiming at providing a
number of quantitative and qualitative indicators
about a TE system. The method is based on
the decomposition of T,H pairs into monothematic
pairs, each representing one single linguistic phe-
nomenon relevant for entailment judgment. Eval-
uation is carried out both on the original T,H pair
and on the monothematic pairs originated from it.
We deﬁne a correlation index between the accu-
racy of the system on the original T,H pairs and
the accuracy on the corresponding monothematic
pairs. We investigate the use of such correlations
on different subsets of the evaluation dataset (i.e.
positive vs negative pairs) and we try to induce
regular patterns of evaluation.

The method we propose has been tested on a
sample of 60 pairs, each decomposed in the corre-
sponding monothematic pairs, and using two sys-
tems that obtained similar performances in RTE-
5. We show that the main features and differences
of these systems come to light when evaluated us-
ing qualitative criteria. Futhermore, we compare
such systems with two different baseline systems,
the ﬁrst one performing Word Overlap, while the
second one is an ideal system that knows a priori
the probability of a linguistic phenomenon to be
associated with a certain entailment judgement.

The paper is structured as follows.

Sec-
tion 2 explains the procedure for the creation of
monothematic pairs starting from RTE pairs. Sec-
tion 3 presents the evaluation methodology we
propose, while Section 4 describes our pilot study.
Section 5 concludes the paper and proposes future
developments.

2 Decomposing RTE pairs
Our proposal on qualitative evaluation takes ad-
vantage of previous work on specialized entail-
ment engines and monothematic datasets. A
monothematic pair is deﬁned (Magnini and
Cabrio, 2009) as a T,H pair in which a certain

phenomenon relevant to the entailment relation is
highlighted and isolated. The main idea is to cre-
ate the monothematic pairs basing on the phenom-
ena that are actually present in the original RTE
pairs, so that the actual distribution of the linguis-
tic phenomena involved in the entailment relation
emerges.

For the decomposition procedure, we refer to
the methodology described in (Bentivogli et al.,
2010), consisting of a number of steps carried out
manually. The starting point is a [T,H] pair taken
from one of the RTE data sets, that should be
decomposed in a number of monothematic pairs
[T, Hi], where T is the original Text and Hi are
the Hypotheses created for each linguistic phe-
nomenon relevant for judging the entailment re-
lation in [T,H]. In details, the procedure for the
creation of monothematic pairs is composed of the
following steps:

1. Individuate the phenomena contributing to

the entailment decision in [T,H].

2. For each linguistic phenomenon i:

(a) Detect a general entailment rule ri for
i, and instantiate it using the part of T
expressing i as the left hand side (LHS)
of the rule, and information from H on i
as the right side (RHS).

(b) substitute the portion of T that matches

the LHS of ri with the RHS of ri.

(c) consider the result of the previous step
as Hi, and compose the monothematic
pair [T, Hi]. Mark the pair with phe-
nomenon i.

3. Assign an entailment

judgment

to each

monothematic pair.

Relevant linguistic phenomena are grouped us-
ing both ﬁne-grained categories and broader cate-
gories, deﬁned referring to widely accepted clas-
siﬁcations in the literature (e.g. (Garouﬁ, 2007))
and to the inference types typically addressed in
RTE systems: lexical, syntactic, lexical-syntactic,
discourse and reasoning. Each macro category in-
cludes ﬁne-grained phenomena (Table 2 lists the
phenomena detected in RTE-5 datasets).

101

Text snippet (pair 125)

T Mexico’s new president, Felipe Calderon, seems to be doing

all the right things in cracking down on Mexico’s drug trafﬁckers. [...]
Felipe Calderon is the outgoing President of Mexico.

H

H2

H1 Mexico’s outgoing president, Felipe Calderon, seems to be doing all
all the right things in cracking down on Mexico’s drug trafﬁckers. [...]
The new president of Mexico, Felipe Calderon, seems to be doing
all the right things in cracking down on Mexico’s drug trafﬁckers. . [...]
Felipe Calderon is Mexico’s new president.

H3

Phenomena

lexical:semantic-opposition
syntactic:argument-realization, syntactic:apposition
lexical:semantic-opposition

syntactic:argument-realization

syntactic:apposition

Judg.

C

C

E

E

Table 1: Application of the decomposition methodology to an original RTE pair

i.e.

Table 1 shows an example of the decompo-
sition of a RTE pair (marked as contradiction)
into monothematic pairs.
At step 1 of the
methodology both the phenomena that preserve
the entailment and those that break the entailment
rules causing a contradiction in the pair are
detected,
argument realization, apposition
and semantic opposition (column phenomena in
the table). While the monothematic pairs created
basing on the ﬁrst two phenomena preserve the
entailment, the semantic opposition generates a
contradiction (column judgment). As an example,
let’s apply step by step the procedure to the
phenomenon of semantic opposition. At step 2a
of the methodology the general rule:

Pattern: x ⇐ / ⇒ y
Constraint: semantic opposition(y,x)

is instantiated (new⇐ / ⇒outgoing), and at step
2b the substitution in T is carried out (Mexico’s
outgoing president, Felipe Calderon [...]). At
step 2c a negative monothematic pair T, H1 is
composed (column text snippet in the table) and
marked as semantic opposition (macro-category
lexical), and the pair is judged as contradiction.

3 Evaluation methodology

Aim of the evaluation methodology we propose is
to provide quantitative and qualitative indicators
about the behaviours of actual TE systems.

3.1 General Method
The basic assumption of the evaluation methodol-
ogy is that the more a system is able to correctly
solve the linguistic phenomena underlying the en-
tailment relation separately, the more the system
should be able to correctly judge more complex

pairs, in which different phenomena are present
and interact in a complex way. Such assumption is
motivated by the notion of meaning composition-
ality, according to which the meaning of a com-
plex expression e in a language L is determined
by the structure of e in L and the meaning of the
constituents of e in L (Frege, 1892). In a parallel
way, we assume that it is possible to understand
the entailment relation of a T,H pair (i.e. to cor-
rectly judge the entailment/contradiction relation)
only if all the phenomena contributing to such re-
lation are solved.

According to such assumption, we expect that
the higher the accuracy of a system on the
monothematic pairs and the compositional strat-
egy, the better its performances on the original
RTE pairs. Furthermore, the precision a system
gains on single phenomena should be maintained
over the general dataset, thanks to suitable mech-
anisms of meaning combination.

Given a dataset composed of original RTE pairs
[T, H], a dataset composed of all the monothe-
matic pairs derived from it [T, H]mono, and a TE
system S, the evaluation methodology we propose
consists of the following steps:

1. Run S both on [T, H] and on [T, H]mono, to
obtain the accuracies of S both on the RTE
original and on monothematic pairs;

2. Extract data concerning the behaviour of S on
each phenomenon or on categories of phe-
nomena, and calculate separate accuracies.
This way it is possible to evaluate how much
a system is able to correctly deal with single
or with categories of phenomena;

3. Calculate the correlation between the ability
of the system to correctly judge the monothe-
matic pairs of [T, H]mono with respect to the

102

ability to correctly judge the original ones
in [T, H].
Such correlation is expressed
through a Correlation Index (CI), as deﬁned
in Section 3.2;

4. In order to check if the same CI is main-
tained over both entailment and contradiction
pairs (i.e. to verify if the system has peculiar
strategies to correctly assign both judgments,
and if the high similarity of monothematic
pairs does not bias its behaviour), we calcu-
late a Deviation Index (DI) as the difference
between the CIs on entailment and on con-
tradiction pairs, as explained in more details
in Section 3.3.

3.2 Correlation Index (CI)
As introduced before, we assume that the ac-
curacy obtained on [T, H]mono should positively
correlate with the accuracy obtained on [T, H].
We deﬁne a Correlation Index as the ratio between
the accuracy of the system on the original RTE
dataset and the accuracy obtained on the monothe-
matic dataset, as follows:

CI =

acc[T, H]

acc[T, H]mono

(1)

We expect the correlation index of an optimal
ideal system (or the human goldstandard) to be
equal to 1, i.e. 100% accuracy on the monothe-
matic dataset should correspond to 100% accu-
racy on the original RTE dataset. For this reason,
we consider CI = 1 as the ideal correlation, and
we calculate the difference between such ideal CI
and the correlation obtained for a system S.

Given such expectations, CIS can assume three
different conﬁgurations with respect to the upper-
bound (i.e. the ideal correlation):

• CIS ∼= 1 (ideal correlation): When CIS ap-
proaches to 1, the system shows high corre-
lation with the ideal behaviour assumed by
the compositionality principle. As a conse-
quence, we can predict that improving sin-
gle modules will correspondingly affect the
global performance.

• CIS < 1 (missing correlation): The system
is not able to exploit the ability in solving sin-

gle phenomena to correctly judge the origi-
nal RTE pairs. This may be due to the fact
that the system does not adopt suitable com-
bination mechanisms and loses the potential-
ity shown by its performances on monothe-
matic pairs.

• CIS > 1 (over correlation): The system does
not exploit the ability to solve single linguis-
tic components to solve the whole pairs, and
has different mechanisms to evaluate the en-
tailment. Probably, such a system is not in-
tended to be modularized.

Beside this “global” correlation index calcu-
lated on the complete RTE data and on all the
monothematic pairs created from it, the CI can
also be calculated i) on categories of phenomena,
to verify which phenomena a system is more able
to solve both when isolated and when interacting
with other phenomena, e.g. :

CIlex =

acc[T, H]lex

acc[T, H]mono−lex

(2)

including in [T, H]lex all the pairs in which at
least one lexical phenomenon is present and con-
tribute to the entailment/contradiction judgments,
and in [T, H]mono−lex all the monothematic pairs
in which a lexical phenomenon is isolated; or ii)
on kind of judgment (entailment, contradiction,
unknown), allowing deeper qualitative analysis of
the performances of a system.

3.3 Deviation Index (DI)
We explained that a low CI (i.e. < 1) of a system
reﬂects the inability to correctly exploit the poten-
tially promising results obtained on monothematic
pairs to correctly judge RTE pairs. Actually, it
could also be the case that the system does not
perform a correct combination because even the
results got on the monothematic pairs were due to
chance (e.g. a word overlap system performs well
on monothematic pairs because of the high sim-
ilarity between T and H, and not because it has
linguistic strategies).

We detect such cases by decomposing the eval-
uation datasets, separating positive (i.e. entail-
ment) from negative (i.e. contradiction, unknown)
examples both in [T, H] and in [T, H]mono, and

103

independently run S on the new datasets. Then,
we have more ﬁne grained evaluation patterns
through which we can analyze the system be-
haviour.

In the ideal case, we expect to have good cor-
relation between the accuracy obtained on the
monothematic pairs and the accuracy obtained on
the original ones (0 < CIpos ≤ 1 and 0 <
CIneg ≤ 1). On the contrary, we expect that sys-
tems either without a clear composition strategy or
without strong components on speciﬁc linguistic
phenomena (e.g. a word overlap system), would
show a signiﬁcant difference of correlation on the
different datasets. More speciﬁcally, situations of
inverse correlation on the entailment and contra-
diction pairs (e.g. over correlation on contradic-
tion pairs and missing correlation on entailment
pairs) may reveal that the system itself is affected
by the nature of the dataset (i.e.
its behaviour
is biased by the high similarity of [T, H]mono),
and weaknesses in the ability of solving phenom-
ena that more frequently contribute to the assign-
ment of a contradiction (or an entailment) judg-
ment come to light.

We formalize such intuition deﬁning a Devia-
tion Index (DI) as the difference between the cor-
relation indexes, respectively, on entailment and
contradiction/unknown pairs, as follows:

|DI| = CIpos − CIneg

(3)

For instance, an high Deviation Index due to
a missing correlation on positive entailment pairs
and an over correlation for negative pairs, is in-
terpreted as an evidence that the system has low
accuracy on [T, H]mono - T and H are very sim-
ilar and the system has no strategies to under-
stand that the phenomenon that is present has to
be judged as contradictory -, and a higher accu-
racy on [T, H], probably due to chance.
In the
ideal case DIS ∼= 0, since we assumed the ideal
CIs on both positive and negative examples to be
as close as possible to 1 (see Section 3.2).

4 Experiments and discussion

This Section describes the experimental setup of
our pilot study, carried out using two systems that
took part in RTE-5 i.e EDITS and VENSES. We

show the results obtained and the qualitative anal-
ysis performed basing on the proposed evaluation
methodology. Their respective CIs and DIs are
compared with two baselines: a word overlap sys-
tem, and a system biased by the knowledge of
the probability that a linguistic phenomenon con-
tributes to the assignment of a certain entailment
judgment.

4.1 Dataset
The evaluation method has been tested on a
dataset composed of 60 pairs from RTE-5 test set
([T, H]RT E5−sample, composed of 30 entailment,
and 30 contradiction randomly extracted exam-
ples), and a dataset composed of all the monothe-
matic pairs derived by the ﬁrst one following
the procedure described in Section 2. The sec-
ond dataset [T, H]RT E5−mono is composed of 167
pairs (135 entailment, 32 contradiction examples,
considering 35 different linguistic phenomena)2.
On average, 2.78 monothematic pairs have been
created from the original pairs. In this pilot study
we decided to limit our analysis to entailment and
contradiction pairs since, as observed in (Ben-
tivogli et al., 2010), in most of the unknown pairs
no linguistic phenomena relating T to H could be
detected.

4.2 TE systems
EDITS The EDITS system (Edit Distance Tex-
tual Entailment Suite)3 (Negri et al., 2009) as-
sumes that the distance between T and H is a
characteristic that separates the positive pairs, for
which entailment holds, from the negative pairs,
for which entailment does not hold (two way
task). It is based on edit distance algorithms, and
computes the [T,H] distance as the overall cost of
the edit operations (i.e.
insertion, deletion and
substitution) required to transform T into H. For
our experiments we applied the model that pro-
duced EDITS best run at RTE-5 (acc. on test set:
60.2%). The main features are: Tree Edit Dis-
tance algorithm on the parsed trees of T and H,
Wikipedia lexical entailment rules, and PSO opti-
mized operation costs (Mehdad et al., 2009).

2http://hlt.fbk.eu/en/Technology/TE- Specialized Data
3Available as open source at http://edits.fbk.eu/

104

VENSES The other system used in our ex-
periments is VENSES4 (Delmonte et al., 2009),
that obtained performances similar to EDITS at
RTE-5 (acc. on test set: 61.5%).
It applies a
linguistically-based approach for semantic infer-
ence, and is composed of two main components:
i) a grammatically-driven subsystem validates the
well-formedness of the predicate-argument struc-
ture and works on the output of a deep parser pro-
ducing augmented head-dependency structures;
and ii) a subsystem detects allowed logical and
lexical
inferences basing on different kind of
structural transformations intended to produce a
semantically valid meaning correspondence. Also
in this case, we applied the best conﬁguration of
the system used in RTE-5.

Baseline system 1: Word Overlap algorithm
The ﬁrst baseline applies a Word Overlap (WO)
algorithm on tokenized text. The threshold to sep-
arate positive from negative pairs has been learnt
on the whole RTE-5 training dataset.

Baseline system 2: Linguistic biased system
The second baseline is produced by a more so-
phisticated but biased system.
It exploits the
probability of linguistic phenomena to contribute
more to the assignment of a certain judgment than
to another. Such probabilities are learnt on the
[T, H]RT E5−mono goldstandard: given the list of
the phenomena with their frequency in monothe-
matic positive and negative pairs (columns 1,2,3
of Table 2), we calculate the probability P of phe-
nomenon i to appear in a positive (or in a negative)
pair as follows:

P (i|[T, H]positive) =

#(i|[T, H]RT E5−mono)

#(i|[T, H]RT E5−positive−mono)
(4)
For instance, if the phenomenon apposition ap-
pears in 11 monothematic positive pairs and in 6
negative pairs, it has a probability of 64.7% to ap-
pear in positive examples and 35.3% to appear in
negative ones. Such knowledge is then stored in
the system, and is used in the classiﬁcation phase,
assigning the most probable judgment associated
to a certain phenomenon.

4http://project.cgm.unive.it/venses en.html

When applied to [T, H]RT E5−sample, this sys-
tem uses a simple combination strategy: if phe-
nomena associated with different judgments are
present in a pair, and one phenomenon is associ-
ated with a contradiction judgment with a proba-
bility > 50%, the pair is marked as contradiction,
otherwise it is marked as entailment.

4.3 Results
Following the methodology described in Sec-
tion 3, at step 1 we run EDITS and VENSES
on [T, H]RT E5−sample, and on [T, H]RT E5−mono
(Table 3 reports the accuracies obtained).
At step 2, we calculate the accuracy of ED-
ITS and VENSES on each single linguistic phe-
nomenon, and on categories of phenomena. Ta-
ble 2 shows the distribution of the phenomena on
the dataset, reﬂected in the number of positive and
negative monothematic pairs created for each phe-
nomenon. As can be seen, some phenomena ap-
pear more frequently than others (e.g. corefer-
ence, general inference). Furthermore, some lin-
guistic phenomena allow only the creation of pos-
itive or negative examples, while others can con-
tribute to the assignment of both judgments. Due
to the small datasets we used, some phenomena
appear rarely; the accuracy on them cannot be
considered completely reliable.

Nevertheless, from these data the main features
of the systems can be identiﬁed. For instance,
EDITS obtains the highest accuracy on positive
monothematic pairs, while it seems it has no pe-
culiar strategies to deal with phenomena caus-
ing contradiction (e.g. semantic opposition, and
quantity mismatching). On the contrary, VENSES
shows an opposite behaviour, obtaining the best
results on the negative cases.

At step 3 of the proposed evaluation methodol-
ogy, we calculate the correlation index between
the ability of the system to correctly judge the
monothematic pairs of [T, H]RT E5−mono with re-
spect to the ability to correctly judge the original
ones in [T, H]RT E5−sample.
Table 3 compares EDITS and VENSES CI with
the two baseline systems described before. As can
be noticed, even if EDITS CI outperforms the WO
system, they show a similar behaviour (high ac-
curacy on monothematic pairs, and much lower

105

phenomena

lex:identity
lex:format
lex:acronymy
lex:demonymy
lex:synonymy
lex:semantic-opp.
lex:hypernymy
lex:geo-knowledge
TOT lexical
lexsynt:transp-head
lexsynt:verb-nom.
lexsynt:causative
lexsynt:paraphrase
TOT lex-syntactic
synt:negation
synt:modiﬁer
synt:arg-realization
synt:apposition
synt:list
synt:coordination
synt:actpass-altern.
TOT syntactic
disc:coreference
disc:apposition
disc:anaphora-zero
disc:ellipsis
disc:statements
TOT discourse
reas:apposition
reas:modiﬁer
reas:genitive
reas:relative-clause
reas:elliptic-expr.
reas:meronymy
reas:metonymy
reas:representat.
reas:quantity
reas:spatial
reas:gen-inference
TOT reasoning
TOT (all phenom)

# [T, H]

RT E5−mono
pos.
neg.
3
1
-
2
-
3
-
1
11
-
3
-
-
3
-
1
6
22
-
2
8
-
-
1
-
3
-
14
1
-
1
3
5
-
6
11
-
1
-
3
2
4
9
28
20
-
-
3
-
5
-
4
-
1
-
33
2
1
-
3
-
1
-
1
-
1
1
1
3
-
-
1
5
-
-
1
10
24
17
38
135
32

EDITS
% acc.

VENSES
% acc.

pos.
100
100
100
100
90.9

-
100
100
95.4
100
87.5
100
100
92.8

-
100
100
100
100
100
100
96.4
95
100
80
100
100
93.9
100
66.6
100
100
100
100
100
100
-
100
87.5
89.4
93.3

neg.
0
-
-
-
-
0
-
-
0
-
-
-
-
-
0
0
-

33.3

-
-
0

22.2

-
-
-
-
-
-
0
-
-
-
-
0
-
-
0
-
50
35.2
25

pos.
100
100
33.3
100
90.9

-

66.6
100
77.2
50
25
100
66.6
42.8

-

33.3
40
54.5
100
33.3
25
42.8
50
0
20
25
0

36.3
50
100
100
0
0
100
33.3

0
-
0

37.5
42.1
45.9

neg.
33.3

-
-
-
-
100
-
-

66.6

-
-
-
-
-
0
100
-

83.3

-
-
50
77.7

-
-
-
-
-
-
100
-
-
-
-
0
-
-
80
-
90
82.3
81.2

Table 2: Systems’ accuracy on phenomena

on the RTE sample). According to our deﬁni-
tion, their CIs (0 < CI < 1) show a good ability
of the systems to deal with linguistic phenomena
when isolated, but a scarce ability in combining
them to assign the ﬁnal judgment. EDITS CI is
not far from the CI of the linguistic biased base-
line system, even if we were expecting a higher
CI for the latter system. The reason is that beside
the linguistic phenomena that allow only the cre-
ation of negative monothematic pairs, all the phe-
nomena that allow both judgments have a higher
probability to contribute to the creation of positive
monothematic pairs.

Comparing the CI of the four analyzed systems
with the ideal correlation (CIS ∼= 1, see Section
3.2), VENSES is the closest one (∆ = 0.15), even
if it shows a light over correlation (probably due
to the nature of the dataset). The second closest

EDITS
VENSES
Word Overlap
ling baseline

acc. %

acc. %

RT E5−sample

58.3
60
38.3
68.3

RT E5−mono

80.8
52.6
77.24
86.8

CI

0.72
1.15
0.49
0.79

Table 3: Evaluation on RTE pairs and on
monothematic pairs

EDITS

RTE5 data
sample

mono
CI

sample

mono
CI

sample

mono
CI

sample

mono
CI

VENSES

WO
baseline

ling-
biased
baseline

lex.
47.8
75
0.63
47.2
75
0.62
36.3
78.5
0.46
82.6
96.4
0.85

categories of linguistic phenomena

lex-synt.

64.3
92.8
0.69
42.8
42.8
1
57.1
71.4
0.79
92.8
100
0.92

synt.
51.7
78.3
0.66
62
51.3
1.2
34.4
72.9
0.47
58.6
75.6
0.77

disc.
75
93.9
0.79
46.4
33
1.4
50
96.9
0.51
82.1
96.9
0.84

reas.
62.5
72.7
0. 85
67.5
54.5
1.23
35
69
0.5
70
80
0.87

Table 4: Evaluation on categories of phenomena

one is the linguistic biased system (∆ = 0.21),
showing that the knowledge of the most probable
judgment assigned to a certain phenomenon can
be a useful information.

Table 4 reports an evaluation of the four sys-

tems on categories of linguistic phenomena.

To check if the same CI is maintained over
both entailment and contradiction pairs, we cal-
culate a Deviation Index as the difference be-
tween the CIs on entailment and on contradiction
pairs (step 4 of our methodology). As described
in Section 3, we created four datasets dividing
both [T, H]RT E5−sample and [T, H]RT E5−mono
into positive (i.e. entailment) and negative (i.e.
contradiction) examples. We run EDITS and
VENSES on the datasets and we calculate the
CI on positive and on negative examples sepa-
rately.
If we obtained missing correlation be-
tween the accuracy on the monothematic pairs
and the accuracy on RTE original ones, it would
mean that the potentiality that the systems show
on monothematic pairs is not exploited to cor-
rectly judge more complex pairs, therefore com-
positional mechanisms should be improved.

Table 5 shows that the DIs of the linguistic bi-
ased system and of VENSES are close to the ideal
case (DIS ∼= 0), indicating a good capacity to
correctly differentiate entailment from contradic-
tion cases. EDITS results demonstrate that the

106

Figure 1: Correlation Index on entailment and contradiction pairs for EDITS and VENSES

% acc. RT E5

% acc. RT E5

CI

EDITS

VENSES

WO
baseline
ling-biased
baseline

E
C
E
C
E
C
E
C

sample

83.3
33.3
50
70
50
26.6
96.6
40

mono
94.7
24

47.01
75.7
88
33
98.5
39.4

0.88
1.38
1.08
0.92
0.56
0.80
0.98
1.01

DI

0.5

0.16

0.24

0.03

Table 5: Evaluation on entail. and contr. pairs

shallow approach implemented by the system has
no strategies to correctly judge negative examples
(similarly to the WO system), therefore should be
mainly improved with this respect.

We also calculated the CI for every pair of the
dataset, putting into relation each original pair
with all the monothematic pairs derived from it.
Figure 1 shows EDITS and VENSES’s CI on each
pair of our sample.5 Even if the systems obtained
similar performances in the challenge, the second
system seems to behave in an opposite way with
respect to EDITS, showing higher CI for negative
cases than for the positive ones.

5The ideal case CI=1 corresponds to 0 on the logarithmic

scale.

5 Conclusion and Future work
We have proposed a methodology for the evalu-
ation of TE systems based on the analysis of the
system behaviour on monothematic pairs with re-
spect to the behaviour on corresponding original
pairs. Through the deﬁnition of two indicators,
a Correlation Index and a Deviation Index, we
infer evaluation patterns which indicate strength
and weaknesses of the system. As a pilot study,
we have compared two systems that took part in
RTE-5. We discovered that, although the two sys-
tems have similar accuracy on RTE-5 datasets,
they show signiﬁcant differences in their respec-
tive abilities to manage different linguistic phe-
nomena and to properly combine them. We hope
that the analysis provided by our methodology
may bring interesting elements both to TE system
developers and for deep discussion on the nature
of TE itself.

As future work, we plan to reﬁne the evaluation
methodology introducing the possibility to assign
different relevance to the phenomena.

6 Acknowledgements
Thanks to Professor Rodolfo Delmonte and to
Sara Tonelli for running the VENSES system on
our data sets.

107

Nielsen, Rodney D., Wayne Ward, and James H. Mar-
tin. 2009. Recognizing entailment in intelligent tu-
toring systems. In Ido Dagan, Bill Dolan, Bernardo
Magnini and Dan Roth (Eds.) The Journal of Nat-
ural Language Engineering, (JNLE).
, 15, pp 479-
501. Copyright Cambridge University Press, Cam-
bridge, United Kingdom.

Ido Kalman Dagan,
2006.

Romano, Lorenza, Milen Ognianov Kouylekov,
and Al-
Idan Szpektor,
berto Lavelli,
Investigating a Generic
Paraphrase-Based Approach for Relation Extrac-
tion. Proceedings of the 11th Conference of the
European Chapter of the Association for Computa-
tional Linguistics (EACL 2006). Trento, Italy. 3-7
April.

References
Bentivogli, Luisa, Bernardo Magnini,

Ido Dagan,
Hoa Trang Dang, and Danilo Giampiccolo. 2009.
The Fifth PASCAL Recognizing Textual Entailment
Challenge. Proceedings of the TAC 2009 Workshop
on Textual Entailment. Gaithersburg, Maryland. 17
November.

Bentivogli, Luisa, Elena Cabrio,

Ido Dagan,
Danilo Giampiccolo, Medea Lo Leggio,
and
Bernardo Magnini. 2010. Building Textual En-
a Methodology
tailment Specialized Data Sets:
for Isolating Linguistic Phenomena Relevant
to
Inference. Proceedings of the 7th International
Conference on Language Resources and Evaluation
(LREC) . Valletta, Malta. 19-21 May.

Dagan,

Ido, Bill Dolan, Bernardo Magnini, and
Dan Roth. 2009. Recognizing textual entailment:
Rational, evaluation and approaches. Natural Lan-
guage Engineering (JNLE), Volume 15, Special Is-
sue 04, October 2009, pp i-xvii. Cambridge Univer-
sity Press.

Delmonte, Rodolfo, Sara Tonelli, Rocco Tripodi.
2009.
Semantic Processing for Text Entailment
with VENSES. Proceedings of the TAC 2009 Work-
shop on Textual Entailment. To appear. Gaithers-
burg, Maryland. 17 November.

Garouﬁ, Konstantina. 2007. Towards a Better Un-
derstanding of Applied Textual Entailment. Mas-
ter Thesis. Saarland University. Saarbr¨ucken, Ger-
many.

Gottlob, Frege. 1892.

¨Uber Sinn und Bedeutung.
Zeitschrift f¨ur Philosophie und philosophische Kri-
tik. 100.25-50.

Magnini, Bernardo, and Elena Cabrio. 2009. Combin-
ing Specialized Entailment Engines. Proceedings of
the 4th Language & Technology Conference (LTC
’09). Poznan, Poland. 6-8 November.

Mehdad, Yashar, Matteo Negri, Elena Cabrio,
Milen Kouylekov, and Bernardo Magnini. 2009.
Using Lexical Resources in a Distance-Based Ap-
proach to RTE. Proceedings of the TAC 2009 Work-
shop on Textual Entailment. Gaithersburg, Mary-
land. 17 November.

Negri, Matteo, Milen Kouylekov, Bernardo Magnini,
Yashar Mehdad, and Elena Cabrio. 2009. Towards
Extensible Textual Entailment Engines: The EDITS
Package. AI*IA 2009: Emergent Perspectives in
Artiﬁcial Intelligence, Lecture Notes in Computer
Science. Volume 5883. ISBN 978-3-642-10290-5.
Springer-Verlag Berlin Heidelberg, p. 314.

