



















































A Dual-Attention Hierarchical Recurrent Neural Network for Dialogue Act Classification


Proceedings of the 23rd Conference on Computational Natural Language Learning, pages 383–392
Hong Kong, China, November 3-4, 2019. c©2019 Association for Computational Linguistics

383

A Dual-Attention Hierarchical Recurrent Neural Network
for Dialogue Act Classification

Ruizhe Li♠, Chenghua Lin♥, Matthew Collinson♠, Xiao Li♠ and Guanyi Chen♣
♠Department of Computing Science, University of Aberdeen, UK
{r02rl17, matthew.collinson, x.li}@abdn.ac.uk
♥Department of Computer Science, University of Sheffield, UK

c.lin@sheffield.ac.uk
♣Department of Information and Computing Sciences, Utrecht University, The Netherlands

g.chen@uu.nl

Abstract

Recognising dialogue acts (DA) is important
for many natural language processing tasks
such as dialogue generation and intention
recognition. In this paper, we propose a dual-
attention hierarchical recurrent neural network
for DA classification. Our model is partially
inspired by the observation that conversational
utterances are normally associated with both
a DA and a topic, where the former captures
the social act and the latter describes the sub-
ject matter. However, such a dependency be-
tween DAs and topics has not been utilised
by most existing systems for DA classifica-
tion. With a novel dual task-specific atten-
tion mechanism, our model is able, for utter-
ances, to capture information about both DAs
and topics, as well as information about the
interactions between them. Experimental re-
sults show that by modelling topic as an auxil-
iary task, our model can significantly improve
DA classification, yielding better or compara-
ble performance to the state-of-the-art method
on three public datasets.

1 Introduction

Dialogue Acts (DA) are semantic labels of utter-
ances, which are crucial to understanding com-
munication: much of a speaker’s intent is ex-
pressed, explicitly or implicitly, via social actions
(e.g., questions or requests) associated with utter-
ances (Searle, 1969). Recognising DA labels is
important for many natural language processing
tasks. For instance, in dialogue systems, know-
ing the DA label of an utterance supports its in-
terpretation as well as the generation of an appro-
priate response (Searle, 1969; Chen et al., 2018).
In the security domain, being able to detect inten-
tion in conversational texts can effectively support
the recognition of sensitive information exchanged
in emails or other communication channels, which

is critical to timely security intervention (Verma
et al., 2012).

A wide range of techniques have been inves-
tigated for DA classification. Early works on
DA classification are mostly based on general
machine learning techniques, framing the prob-
lem either as multi-class classification (e.g., us-
ing SVMs (Liu, 2006) and dynamic Bayesian net-
works (Dielmann and Renals, 2008)) or a struc-
tured prediction task (e.g., using Conditional Ran-
dom Fields (Kim et al., 2010; Chen et al., 2018;
Raheja and Tetreault, 2019, CRF)). Recent stud-
ies to the problem of DA classification have seen
an increasing uptake of deep learning techniques,
where promising results have been obtained. Deep
learning approaches typically model the depen-
dency between adjacent utterances (Ji et al., 2016;
Lee and Dernoncourt, 2016). Some researchers
further account for dependencies among both con-
secutive utterances and consecutive DAs, i.e.,
both are considered factors that influence natu-
ral dialogue (Kumar et al., 2018; Chen et al.,
2018). There is also work exploring different deep
learning architectures (e.g., hierarchical CNN or
RNN/LSTM) for incorporating context informa-
tion for DA classification (Liu et al., 2017).

It has been observed that conversational utter-
ances are normally associated with both a DA
and a topic, where the former captures the so-
cial act (e.g., promising) and the latter describes
the subject matter (Wallace et al., 2013). It is
also recognised that the types of DA associated
with a conversation are likely to be influenced by
the topic of the conversation (Searle, 1969; Wal-
lace et al., 2013). For instance, conversations
relating to topics about customer service might
be more frequently associated with DAs of type
Wh-question (e.g., Why my mobile is not work-
ing?) and a complaining statement (Bhuiyan et al.,
2018); whereas meetings covering administrative



384

topics about resource allocation are likely to ex-
hibit significantly more defending statements and
floor grabbers (e.g., Well I mean - is the handheld
really any better?) (Wrede and Shriberg, 2003).
However, such a reasonable source of informa-
tion, surprisingly, has not been explored in the
deep learning literature for DA classification. We
assume that modelling the topics of utterances as
additional contextual information may effectively
support DA classification.

In this paper, we propose a dual-attention hi-
erarchical recurrent neural network with a CRF
(DAH-CRF) for DA classification. Our model is
able to account for rich context information with
the developed dual-attention mechanism, which,
in addition to accounting for the dependencies be-
tween utterances, can further capture, for utter-
ances, information about both topics and DAs.
Topic is a useful source of context information
which has not previously been explored in existing
deep learning models for DA classification. Sec-
ond, compared to the flat structure employed by
existing models (Khanpour et al., 2016; Ji et al.,
2016), our hierarchical recurrent neural network
can represent the input at the character, word, ut-
terance, and conversation levels, preserving the
natural hierarchical structure of a conversation. To
capture the topic information of conversations, we
propose a simple automatic utterance-level topic
labelling mechanism based on LDA (Blei et al.,
2003), which avoids expensive human annotation
and improves the generalisability of our model.

We evaluate our model against several strong
baselines (Wallace et al., 2013; Ji et al., 2016;
Kumar et al., 2018; Chen et al., 2018; Raheja
and Tetreault, 2019) on the task of DA classifica-
tion. Extensive experiments conducted on three
public datasets (i.e., Switchboard Dialog Act Cor-
pus (SWDA), DailyDialog (DyDA), and the Meet-
ing Recorder Dialogue Act corpus (MRDA)) show
that by modelling the topic information of utter-
ances as an auxiliary task, our model can signif-
icantly improve DA classification for all datasets
compared to a base model without modelling topic
information. Our model also yields better or com-
parable performance to state-of-the-art deep learn-
ing method (Raheja and Tetreault, 2019) in classi-
fication accuracy.

To summarise, the contributions of our paper
are three-fold: (1) we propose to leverage topic
information of utterances, a useful source of con-

textual information which has not previously been
explored in existing deep learning models for DA
classification; (2) we propose a dual-attention hi-
erarchical recurrent neural network with a CRF
which respects the natural hierarchical structure
of a conversation, and is able to incorporate rich
context information for DA classification, achiev-
ing better or comparable performance to the state-
of-the-art; (3) we develop a simple topic labelling
mechanism, showing that using the automatically
acquired topic information for utterances can ef-
fectively improve DA classification.

2 Related Work

Broadly speaking, methods for DA classifica-
tion can be divided into two categories: multi-
class classification (e.g., SVMs (Liu, 2006) and
dynamic Bayesian networks (Dielmann and Re-
nals, 2008)) and structured prediction tasks includ-
ing HMM (Stolcke et al., 2000) and CRF (Kim
et al., 2010). Recently, deep learning has been
widely applied in many NLP tasks, including
DA classification. Kalchbrenner and Blunsom
(2013) proposed to model a DA sequence with a
RNN where sentence representations were con-
structed by means of a convolutional neural net-
work (CNN). Lee and Dernoncourt (2016) tackled
DA classification with a model built upon RNNs
and CNNs. Specifically, their model can leverage
the information of preceding texts, which can ef-
fectively help improve the DA classification accu-
racy. A latent variable recurrent neural network
was developed for jointly modelling sequences of
words and discourse relations between adjacent
sentences (Ji et al., 2016). In their work, the shal-
low discourse structure is represented as a latent
variable and the contextual information from pre-
ceding utterances are modelled with a RNN.

Kumar et al. (2018) proposed a hierarchical Bi-
LSTM model with a CRF for DA classification,
where the inter-utterance and intra-utterance in-
formation are encoded by a hierarchical Bi-LSTM
and the dependency between DA labels is cap-
tured by a CRF. Chen et al. (2018) developed
a CRF-Attentive Structured Network (CRF-ASN)
for DA classification. They applied structured at-
tention network to the CRF layer in order to model
contextual utterances and corresponding DAs to-
gether. Raheja and Tetreault (2019) achieved the
state-of-the-art performance on the SWDA dataset
by employing a self-attention mechanism, a CRF



385

layer and character-level embeddings.
In addition to modelling dependency between

utterances, various contexts have also been ex-
plored for improving DA classification or joint
modelling DA under multi-task learning. For in-
stance, Wallace et al. (2013) proposed a generative
joint sequential model to classify both DA and top-
ics of patient-doctor conversations. Their model
is similar to the factorial LDA model (Paul and
Dredze, 2012), which generalises LDA to assign
each token a K-dimensional vector of latent vari-
ables. We would like to emphasise that the model
of Wallace et al. (2013), only assumed that each
utterance is generated conditioned on the previous
and current topic/DA pairs. In contrast, our model
is able to model the dependencies of all preceding
utterances of a conversation, and hence can better
capture the effect between DAs and topics.

3 Methodology

Given a training corpus D = 〈(Cn, Yn, Zn)〉Nn=1,
where Cn = 〈unt 〉Tt=1 is a conversation contain-
ing a sequence of T utterances, Yn = 〈ynt 〉Tt=1 and
Zn = 〈znt 〉Tt=1 are the corresponding labels of DA
and topics for Cn, respectively. Each utterance
ut = 〈wit〉Ki=1 of Cn is a sequence of K words.
Our goal is to learn a model from D, such that,
given an unseen conversation Cu, the model can
predict the DA labels of the utterances of Cu.

Figure 1 gives an overview of the proposed
Dual-Attention Hierarchical recurrent neural net-
work with a CRF (DAH-CRF). A shared utterance
encoder encodes each word wit of an utterance ut
into a vector hit. The DA attention and topic at-
tention mechanisms capture DA and topic infor-
mation as well as the interactions between them.
The outputs of the dual-attention are then encoded
in the conversation-level sequence taggers (i.e., gt
and st), based on the corresponding utterance rep-
resentations (i.e., lt and vt). Finally, the target la-
bels (i.e., yt and zt) are predicted in the CRF layer.

3.1 Shared Utterance Encoder

In our model, we adopt a shared utterance encoder
to encode the input utterances. Such a design
is based on the rationale that the shared encoder
can transfer parameters between two tasks and re-
duce the risk of overfitting (Ruder, 2017). Specifi-
cally, the shared utterance encoder is implemented
using the bidirectional gated recurrent unit (Cho
et al., 2014, BiGRU), which encodes each utter-

ance ut = 〈wit〉Ki=1 of a conversation Cn as a se-
ries of hidden states 〈hit〉Ki=1. Here, i indicates the
timestamp of a sequence, and we define hit as fol-
lows

hit =
−→
h it ⊕

←−
h it (1)

where ⊕ is an operation for concatenating two
vectors, and

−→
h it and

←−
h it are the i-th hidden state

of the forward gated recurrent unit (Cho et al.,
2014, GRU) and backward GRU for wit, respec-
tively. Formally, the forward GRU

−→
h it is com-

puted as follows

−→
h it = GRU(

−→
h i−1t , e

i
t) (2)

where eit is the concatenation of the word embed-
ding and the character embedding of word wit. Fi-
nally, the backward GRU encodes ut from the re-
verse direction (i.e. wKt → w1t ) and generates
〈
←−
hit〉Ki=1 following the same formulation as the for-

ward GRU.

3.2 Task-specific Attention
Recall that one of the key challenges of our model
is to capture for each utterance, information about
both DAs and topics, as well as information about
the interactions between them. We address this
challenge by incorporating into our model a novel
task-specific dual-attention mechanism, which ac-
counts for both DA and topic information ex-
tracted from utterances. In addition, DAs and top-
ics are semantically relevant to different words in
an utterance. With the proposed attention mecha-
nism, our model can also assign different weights
to the words of an utterance by learning the degree
of importance of the words to the DA or topic la-
belling task, i.e., promoting the words which are
important to the task and reducing the noise intro-
duced by less important words.

For each utterance ut, the DA attention calcu-
lates a weight vector 〈αit〉Ki=1 for 〈hit〉Ki=1, the hid-
den states of ut. ut can then be represented as an
attention vector lt computed as follows

lt =

K∑
i=1

αith
i
t (3)

In contrast to the traditional attention mech-
anism (Bahdanau et al., 2015), which only de-
pends on one set of hidden vectors from the
Seq2Seq decoder, the DA attention of our model
relies on two sets of hidden vectors, i.e., gt−1 of



386

Figure 1: Overview of the dual-attention hierarchical recurrent neural network with a CRF.

the conversation-level DA tagger and st−1 of the
conversation-level topic tagger, where dual atten-
tion mechanism can capture, for utterances, in-
formation about both DAs and topics as well as
the interaction between them. Specifically, the
weights 〈αit〉Ki=1 for the DA attention are calcu-
lated as follows:

αit = softmax(o
i
t) (4)

oit = w
>
a tanh

(
W(act)(st−1 ⊕ gt−1 ⊕ hit) + b(act)

)
(5)

The topic attention layer has a similar architec-
ture to the DA attention layer, which takes as in-
put both st−1 and gt−1. The weight vector 〈βit〉Ki=1
for the topic attention output vt can be calculated
similar to Eq. 3 and Eq. 4. Note that wa, W(act),
and b(act) are vectors of parameters that need to
be learned during training.

3.3 Conversational Sequence Tagger
CRF sequence tagger for DA. The conversa-
tional CRF sequence tagger for DA predicts the
next DA yt conditioned on the conversational hid-
den state gt and adjacent DAs (c.f. Figure 1). For-
mally, this conditional probability of the whole
conversation can be formulated as

p (y1:T |C; θ) =
∏T

t=1 Ψ (yt−1, yt,gt; θ)∑
Y

∏T
t=1 Ψ (yt−1, yt,gt; θ)

(6)

Ψ (yt−1, yt,gt; θ) = Ψemi (yt,gt) Ψtran (yt−1, yt)

= gt [yt]Pyt,yt−1
(7)

Here the feature function Ψ(·) includes two score
potentials: emission and transition. The emission
potential Ψemi regards utterance representation gt
as the unary feature. The transition potential Ψtran
is a pairwise feature constructed from a T×T state
transition matrix P, where T is the number of DA
classes, and Pyt,yt−1 is the probability of transiting
from state yt−1 to yt. C = 〈ut〉Tt=1 is the sequence
of all utterances seen so far, θ is the parameters of
the CRF layer. gt is calculated in a BiGRU similar
to Eq. 1 and Eq. 2:

gt =
−→g t ⊕←−g t (8)

−→g t = GRU(−→g t−1, lt) (9)

CRF sequence tagger for topic. The conversa-
tional CRF sequence tagger for topic is designed
to predict topic zt conditioned on vt and adjacent
topics, which can be calculated similar to the for-
mulation of the CRF tagger for DA.
Training the model. Let Θ be all the model
parameters that need to be estimated for DAH-
CRF. Θ then is estimated based on D =
〈(Cn, Yn, Zn)〉Nn=1 (i.e., a corpus with N conver-
sations) by maximising the following objective
function

L =
N∑

n=1

[log (p (yn1:T |Cn; Θ))

+α log (p (zn1:T |Cn; Θ))] (10)

The hyper-parameter α controls the contribution
of the conversational topic tagger towards the ob-
jective function. In our experiments, α = 0.5 is
determined using the validation datasets. During



387

Figure 2: Coherence score of LDA on three datasets.

the test, the optimal DA or topic sequence is calcu-
lated using the Viterbi algorithm (Viterbi, 1967).

Y ′ = arg max
y1:T∈Y

p(y1:T |C,Θ) (11)

3.4 Automatically Acquiring Topic Labels
To avoid expensive human annotation and to im-
prove the generalisability of our model, we pro-
pose to label the topic of each utterance of the
datasets using LDA (Blei et al., 2003). While per-
plexity has been widely used for model selection
for LDA (Lin, 2011; He et al., 2012), we employ
a topic coherence measure proposed by (Röder
et al., 2015) to determine the optimal topic number
for each dataset, which combines the indirect co-
sine measure with the normalised pointwise mu-
tual information (Bouma, 2009, NPMI) and the
Boolean sliding window. Empirically, we found
the latter yields much better topic clusters than
perplexity for supporting DA classification.

We treat each conversation as a document and
train topic models using Gensim with topic num-
ber settings ranging from 10 to 100 (using an in-
crement step of 10). Gibbs sampling is used to es-
timate the model posterior and for each model we
run 1,000 iterations. For each trained model, we
calculate the averaged coherence score of the ex-
tracted topics using Gensim1, an implementation
following (Röder et al., 2015). Figure 2 shows
the topic coherence score for each topic number
setting for all datasets, from which we determine
that the optimal topic number setting for SWDA,
DyDA, and MRDA are 60, 30, and 30, respec-
tively.

Based on the optimal models (i.e., a trained
LDA model using the optimal topic number set-
ting), we assign topic labels to the datasets with
two different strategies, i.e., conversation-level la-
belling (conv) and utterance-level labelling (utt).

1https://radimrehurek.com/gensim/models/
coherencemodel.html

Dataset |C| |T | |V | Training Validation Testing
SWDA 42 66 20K 1003/193K 112/23K 19/5K
DyDA 4 10 22K 11K/92.7K 1K/8.5K 1K/8.2K
MRDA 5 - 15K 51/77.9K 11/15.8K 11/15.5K

Table 1: |C| is the number of DA classes, |T | is the
number of manually labelled conversation-level topic
classes, |V | is the vocabulary size. Training, Vali-
dation and Testing indicate the number of conversa-
tions/utterances in the respective splits.

For conversation-level labelling, we assign the
topic label with the highest marginal probabil-
ity to the conversation based on the correspond-
ing per-document topic proportion estimated by
LDA. Every utterance of the conversation then
shares the same topic label of the conversation.
For utterance-level labelling, there is an additional
step to perform inference on every utterance based
on corresponding optimal model (e.g., for every
utterance of SWDA, we do inference using the
LDA trained on SWDA with 60 topics), and assign
the topic label with the highest marginal probabil-
ity to the utterance. Therefore, the topic labels of
the utterances of the same conversation could be
different for utterance-level labelling.

4 Experimental Settings

4.1 Datasets
We evaluate the performance of our model on
three public DA datasets with different charac-
teristics, namely, Switchboard Dialog Act Cor-
pus (Jurafsky, 1997, SWDA), Dailydialog (Li
et al., 2017, DyDA), and the Meeting Recorder Di-
alogue Act corpus (Shriberg et al., 2004, MRDA).
SWDA2 consists of 1,155 two-sided tele-
phone conversations manually labelled with 66
conversation-level topics (e.g., taxes, music, etc.)
and 42 utterance-level DAs (e.g., statement-
opinion, statement-non-opinion, wh-question).
DyDA3 contains 13,118 human-written daily
conversations, manually labelled with 10
conversation-level topics (e.g., tourism, poli-
tics, finance) as well as four utterance-level DA
classes, i.e., inform, question, directive and com-
missive. The former two classes are information
transfer acts, while the latter two are action
discussion acts.
MRDA4 contains 75 meeting conversations anno-

2https://web.stanford.edu/∼jurafsky/ws97/manual.
august1.html

3http://yanran.li/dailydialog
4http://www1.icsi.berkeley.edu/∼ees/dadb/

https://radimrehurek.com/gensim/models/coherencemodel.html
https://radimrehurek.com/gensim/models/coherencemodel.html
https://web.stanford.edu/~jurafsky/ws97/manual.august1.html
https://web.stanford.edu/~jurafsky/ws97/manual.august1.html
http://yanran.li/dailydialog
http://www1.icsi.berkeley.edu/~ees/dadb/


388

tated with 5 DAs, i.e., Statement (S), Question
(Q), Floorgrabber (F), Backchannel (B), and Dis-
ruption (D). The average number of utterances per
conversation is 1,496. There are no manually an-
notated topic labels available for this dataset.

4.2 Implementation Details
For all experimental datasets, the top 85% high-
est frequency words were indexed. For SWDA
and MRDA, we split training/validation/testing
datasets following (Stolcke et al., 2000; Lee
and Dernoncourt, 2016). For DyDA, we used
the standard split from the original dataset (Li
et al., 2017). The statistics of the experimen-
tal datasets are summarised in Table 1. We rep-
resented input data with 300-dimensional Glove
word embeddings (Pennington et al., 2014) and
50-dimensional character embeddings (Ma and
Hovy, 2016). We set the dimension of the hid-
den layers (i.e., hit, gt and st) to 256 and applied
a dropout layer to both the shared encoder and the
sequence tagger at a rate of 0.2. The Adam opti-
miser (Kingma and Ba, 2015) was used for train-
ing with an initial learning rate of 0.001 and a
weight decay of 0.0001. Each utterance in a mini-
batch was padded to the maximum length for that
batch, and the maximum batch-size allowed was
50.

4.3 Baselines
We compare the proposed DAH-CRF model in-
corporating utterance-level topic labels extracted
by LDA (denoted as DAH-CRF+LDAutt) against
five strong baselines and two variants of our own
models:
JAS5: A generative joint, additive, sequential
model of topics and speech acts in patient-doctor
communication (Wallace et al., 2013);
DRLM-Cond6: A latent variable recurrent neural
network for DA classification (Ji et al., 2016);
Bi-LSTM-CRF7: A hierarchical Bi-LSTM with a
CRF to classify DAs (Kumar et al., 2018);
CRF-ASN: An attentive structured network with
a CRF for DA classification (Chen et al., 2018);
SelfAtt-CRF: A hierarchical Bi-GRU with self-
attention and CRF (Raheja and Tetreault, 2019);
DAH-CRF+MANUALconv: Use the manually
annotated conversation-level topic labels (i.e.,
each utterance of the conversation shares the same

5https://github.com/bwallace/JAS
6https://github.com/jiyfeng/drlm
7https://github.com/YanWenqiang/HBLSTM-CRF

Model SWDA MRDA DyDA

B
as

el
in

es JAS 71.2 81.3 75.9
DRLM-Cond 77.0† 88.4 81.1
Bi-LSTM-CRF 79.2† 90.9† 83.6
CRF-ASN 80.8† 91.4† -
SelfAtt-CRF 82.9† 91.1† -

O
ur

s

DAH-CRF + MANUALconv 80.9 - 86.5
DAH-CRF + LDAconv 80.7 91.2 86.4
DAH-CRF + LDAutt 82.3 92.2 88.1
Human Agreement 84.0 - -

Table 2: DA classification accuracy. † indicates the re-
sults which are reported from the prior publications.

topic) for DAH-CRF model training rather than
the topic labels automatically acquired from LDA;
DAH-CRF+LDAconv: Use conversation-level
topic labels automatically acquired from LDA for
DAH-CRF model training.

Note that only JAS (a non-deep-learning model)
has attempted to model both DAs and topics,
whereas all the deep learning baselines do not
model topic information as a source of context
for DA classification. All the baselines mentioned
above use the same test dataset as our models for
all experimental datasets.

5 Experimental Results

5.1 Dialogue Acts Classification

Table 2 shows the DA classification accuracy of
our models and the baselines on three experi-
mental datasets. We fine-tuned the model pa-
rameters for JAS, DRLM-Cond and Bi-LSTM-
CRF in order to make the comparison as fair as
possible. The implementation of CRF-ASN and
SelfAtt-CRF are not available so we can only re-
port their results for SWDA and MRDA based on
the original papers (Chen et al., 2018; Raheja and
Tetreault, 2019).

It can be observed that by jointly modelling
DA and topics, DAH-CRF+LDAutt outperforms
the two best baseline models SelfAtt-CRF and
CRF-ASN around 1% on the MRDA dataset. Our
model also gives similar performance to SelfAtt-
CRF, the baseline which achieved the state-of-
the-art performance on the SWDA dataset (i.e.,
82.3% vs. 82.9%). While both manually an-
notated and automatically acquired topic labels
are effective, we see that DAH-CRF+LDAutt
outperforms both DAH-CRF+MANUALconv and
DAH-CRF+LDAconv, i.e., with over 1.6% gain
on DyDA and over 1.4% on SWDA (signifi-
cant; paired t-test p < .01). It is also ob-

https://github.com/bwallace/JAS
https://github.com/jiyfeng/drlm
https://github.com/YanWenqiang/HBLSTM-CRF


389

Model SWDA MRDA DyDA
SAH 76.2 88.5 82.5
SAH-CRF 78.4 89.6 84.1
DAH + LDAutt 79.5 91.1 86.0
DAH-CRF + LDAutt
(without Dual-Att)

81.0 91.3 86.3

DAH-CRF + LDAutt 82.3 92.2 88.1

Table 3: Ablation studies of DA classification.

served that DAH-CRF+MANUALconv and DAH-
CRF+LDAconv perform very similar to each other.

5.2 Ablation Study Results

We conducted ablation studies (see Table 3) in or-
der to evaluate the contribution of the components
of our DAH-CRF+LDAutt model, and more im-
portantly, the effectiveness of leveraging topic in-
formation for supporting DA classification.

DAH-CRF+LDAutt (without Dual-Att) re-
moves the dual-attention component from DAH-
CRF+LDAutt, and DAH+LDAutt removes the
CRF from DAH-CRF+LDAutt but retaining the
dual-attention component. SAH is a Single-
Attention Hierarchical RNN model without a
CRF, i.e., a simplified version of DAH+LDAutt
that only models DAs with topical information
omitted. As can be seen in Table 3, DAH+LDAutt
achieves over 3% averaged gain on all datasets
when compared to SAH, which clearly shows that
leveraging topic information can effectively sup-
port DA classification. It is also observed that both
the dual-attention mechanism and the CRF com-
ponent are beneficial, but are more effective on the
SWDA and DyDA datasets than MRDA.

In summary, while all the analysed model com-
ponents are beneficial, the biggest gain is obtained
by jointly modelling DAs and topics.

5.3 Analysing the Effectiveness of Joint
Modelling Dialogue Act and Topic

In this section, we provide detailed analysis on
why DAH-CRF+LDAutt can yield better perfor-
mance than SAH-CRF by jointly modelling DAs
and topics. Due to the page limit, our discussion
focuses on SWDA and DyDA datasets.

Figure 4 shows the normalized confusion ma-
trix derived from 10 DA classes of SWDA for
both SAH-CRF and DAH-CRF+LDAutt models.
It can be observed that DAH-CRF+LDAutt yields
improvement on recall for many DA classes com-
pared to SAH-CRF, e.g., 23.8% improvement

Figure 3: We highlight the prominent topics for some
example DAs. The topic distribution of a topic k under
a DA label d is calculated by averaging the marginal
probability of topic k for all utterances with the DA
label d.

on bk and 11.7% on sv. For bk (Response
Acknowledge) which has the highest improve-
ment level, we see that the improvement largely
comes from the reduction of misclassifing bk to
b (Acknowledge Backchannel). The key
difference between bk and b is that an utter-
ance labelled with bk has to be produced within
a question-answer context, whereas b is a “con-
tinuer” simply representing a response to the
speaker (Jurafsky, 1997). It is not surprising that
SAH-CRF makes poor prediction on the utter-
ances of these two DAs: they share many syntac-
tic cues, e.g., indicator words such ‘okay’, ‘oh’,
and ‘uh-huh’, which can easily confuse the model.
When comparing the topic distribution of the ut-
terances under the bk and b categories (cf. Fig-
ure 3), we found topics relating to personal leisure
(e.g., buying cars, music, and exercise) are much
more prominent in bk than b. By leveraging the
topic information, DAH-CRF+LDAutt can better
handle the confusion cases and hence improve the
prediction for bk significantly.

There are also cases where DAH-CRF+LDAutt
performs worse than SAH-CRF. Take the
DA pair of qo (Open Question) and qw
(wh-questions) as an example. qo refers
to questions like ‘How about you?’ and its
variations (e.g., ‘What do you think?’), whereas
qw represents wh-questions which are much



390

Figure 4: The normalized confusion matrix of DAs using SAH-CRF (left) and DAH-CRF+LDAutt (right) on
SWDA (a) and DyDA (b).

Figure 5: DA Attention visualisation using SAH-CRF and DAH-CRF+LDAutt on (a) SWDA and (b) DyDA
datasets. The true labels of the utterances above are sd (statement-non-opinion) and Directive, respectively. SAH-
CRF misclassified the DA as sv (statement-opinion) and Inform whereas DAH-CRF+LDAutt gives correct predic-
tion for both cases.

more specific in general (e.g. ‘What other long
range goals do you have?’). SAH-CRF gives
quite decent performance in distinguishing qw
and qo classes. This is somewhat reasonable, as
linguistically the utterances of these two classes
are quite different, i.e., the qw utterance expresses
very specific question and is relatively lengthy,
whereas qo utterances tends to be very brief. We
see that DAH-CRF+LDAutt performs worse than
SAH-CRF: a greater number of qw utterances
are misclassified by DAH-CRF+LDAutt as qo.
This might be attributed to the fact that topic
distributions of qw and qo are similar to each
other (see Figure 3), i.e., incorporating the topic
information into DAH-CRF may cause these two
DAs to be less distinguishable for the model.

We also conducted a similar analysis on the
DyDA dataset. As can be seen from the
confusion matrices shown in Figure 4, DAH-
CRF+LDAutt gives improvement over SAH-CRF
for all the four DA classes of DyDA. In partic-
ular, Directives and Commissive achieve
higher improvement margin compared to the other
two classes, where the improvement are largely

attributed to less number of instances of the
Directives and Commissive classes being
mis-classified into Inform and Questions.
Examining the topic distributions in Figure 3
reveals that Directives and Commissive
classes are more relevant to the topics such as
food, shopping, and credit card. In contrast, the
topics of Inform and Questions classes are
more about business, and weather.

Finally, Figure 5 shows the DA attention vi-
sualisation examples of SAH-CRF and DAH-
CRF+LDAutt for an utterance from SWDA and
DyDA. For SWDA, it can be seen that SAH-
CRF gives very high weight to the word “be-
cause” and de-emphasizes other words. However,
DAH-CRF+LDAutt can capture more important
words (e.g., “if”, “reasonable”, etc.) and cor-
rectly predicts the DA label as sd. For DyDA,
SAH-CRF only focuses on “me” and “your”, but
DAH-CRF+LDAutt captures more words relevant
to Directive, such as “please”, “tell”, etc. To
summarise, DAH-CRF+LDAutt can capture more
significant words related to the corresponding DA,
by modelling both DAs and topic information with



391

the dual-attention mechanism.

6 Conclusion

In this paper, we developed a dual-attention hi-
erarchical recurrent neural network with a CRF
for DA classification. With the proposed task-
specific dual-attention mechanism, our model is
able to capture information about both DAs and
topics, as well as information about the interac-
tions between them. Moreover, our model is gen-
eralised by leveraging an unsupervised model to
automatically acquire topic labels. Experimental
results based on three public datasets show that
modelling utterance-level topic information as an
auxiliary task can effectively improve DA classifi-
cation, and that our model is able to achieve better
or comparable performance to the state-of-the-art
deep learning methods for DA classification.

We envisage that our idea of modelling topic
information for improving DA classification can
be adapted to other DNN models, e.g., to encode
topic labels into word embeddings and then con-
catenate with the utterance-level or conversation-
level hidden vectors of our baselines, e.g. SelfAtt-
CRF. It will also be interesting to explicitly take
into account speaker’s role in the future.

Acknowledgment

This work is supported by the award made by the
UK Engineering and Physical Sciences Research
Council (Grant number: EP/P011829/1).

References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben-

gio. 2015. Neural machine translation by jointly
learning to align and translate. In 3rd Inter-
national Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
Conference Track Proceedings.

Mansurul Bhuiyan, Amita Misra, Saurabh Tripathy,
Jalal Mahmud, and Rama Akkiraju. 2018. Don’t
get Lost in Negation: An Effective Negation Han-
dled Dialogue Acts Prediction Algorithm for Twit-
ter Customer Service Conversations. In Proc. of
ICWSM workshop on Chatbots.

David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent Dirichlet Allocation. Journal of ma-
chine Learning research, 3(Jan):993–1022.

Gerlof Bouma. 2009. Normalized (pointwise) mutual
information in collocation extraction. Proceedings
of GSCL, pages 31–40.

Zheqian Chen, Rongqin Yang, Zhou Zhao, Deng Cai,
and Xiaofei He. 2018. Dialogue act recognition via
crf-attentive structured network. In The 41st Inter-
national ACM SIGIR Conference on Research & De-
velopment in Information Retrieval, pages 225–234.
ACM.

Kyunghyun Cho, Bart van Merriënboer, Dzmitry Bah-
danau, and Yoshua Bengio. 2014. On the Properties
of Neural Machine Translation: Encoder–Decoder
Approaches. Syntax, Semantics and Structure in
Statistical Translation, page 103.

Alfred Dielmann and Steve Renals. 2008. Recogni-
tion of dialogue acts in multiparty meetings using
a switching DBN. IEEE transactions on audio,
speech, and language processing, 16(7):1303–1314.

Yulan He, Chenghua Lin, and Amparo Elizabeth Cano.
2012. Online sentiment and topic dynamics track-
ing over the streaming data. In International Con-
fernece on Social Computing, pages 258–266.

Yangfeng Ji, Gholamreza Haffari, and Jacob Eisen-
stein. 2016. A latent variable recurrent neural net-
work for discourse-driven language models. In Pro-
ceedings of the 2016 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
332–342.

Dan Jurafsky. 1997. Switchboard swbd-damsl
shallow-discourse-function annotation coders man-
ual. Institute of Cognitive Science Technical Report.

Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent
convolutional neural networks for discourse compo-
sitionality. In Proceedings of the Workshop on Con-
tinuous Vector Space Models and their Composition-
ality, pages 119–126.

Hamed Khanpour, Nishitha Guntakandla, and Rod-
ney Nielsen. 2016. Dialogue act classification in
domain-independent conversations using a deep re-
current neural network. In Proceedings of COLING
2016, the 26th International Conference on Compu-
tational Linguistics: Technical Papers, pages 2012–
2021.

Su Nam Kim, Lawrence Cavedon, and Timothy Bald-
win. 2010. Classifying dialogue acts in one-on-one
live chats. In Proceedings of the 2010 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 862–871. Association for Computa-
tional Linguistics.

Diederik P Kingma and Jimmy Ba. 2015. Adam: A
method for stochastic optimization. In Proceed-
ings of the 3rd International Conference on Learn-
ing Representations (ICLR).

Harshit Kumar, Arvind Agarwal, Riddhiman Dasgupta,
and Sachindra Joshi. 2018. Dialogue Act Sequence
Labeling Using Hierarchical Encoder With CRF. In
Thirty-Second AAAI Conference on Artificial Intelli-
gence.



392

Ji Young Lee and Franck Dernoncourt. 2016. Sequen-
tial Short-Text Classification with Recurrent and
Convolutional Neural Networks. In Proceedings of
the 2016 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 515–520.

Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang
Cao, and Shuzi Niu. 2017. DailyDialog: A Manu-
ally Labelled Multi-turn Dialogue Dataset. In Pro-
ceedings of the Eighth International Joint Confer-
ence on Natural Language Processing (Volume 1:
Long Papers), pages 986–995.

Chenghua Lin. 2011. Probabilistic topic models for
sentiment analysis on the Web. Ph.D. thesis, Uni-
versity of Exeter.

Yang Liu. 2006. Using SVM and error-correcting
codes for multiclass dialog act classification in meet-
ing corpus. In Ninth International Conference on
Spoken Language Processing.

Yang Liu, Kun Han, Zhao Tan, and Yun Lei. 2017.
Using Context Information for Dialog Act Classi-
fication in DNN Framework. In Proceedings of the
2017 Conference on Empirical Methods in Natural
Language Processing, pages 2170–2178.

Xuezhe Ma and Eduard Hovy. 2016. End-to-end se-
quence labeling via bi-directional lstm-cnns-crf. In
Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 1064–1074.

Michael Paul and Mark Dredze. 2012. Factorial LDA:
Sparse multi-dimensional text models. In Advances
in Neural Information Processing Systems, pages
2582–2590.

Jeffrey Pennington, Richard Socher, and Christopher
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of the 2014 confer-
ence on empirical methods in natural language pro-
cessing (EMNLP), pages 1532–1543.

Vipul Raheja and Joel Tetreault. 2019. Dialogue act
classification with context-aware self-attention. In
Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
Volume 1 (Long and Short Papers), pages 3727–
3733.

Michael Röder, Andreas Both, and Alexander Hinneb-
urg. 2015. Exploring the space of topic coherence
measures. In Proceedings of the eighth ACM inter-
national conference on Web search and data mining,
pages 399–408. ACM.

Sebastian Ruder. 2017. An overview of multi-task
learning in deep neural networks. arXiv preprint
arXiv:1706.05098.

John R Searle. 1969. Speech acts: An essay in the phi-
losophy of language, volume 626. Cambridge uni-
versity press.

Elizabeth Shriberg, Raj Dhillon, Sonali Bhagat, Jeremy
Ang, and Hannah Carvey. 2004. The icsi meeting
recorder dialog act (mrda) corpus. In Proceedings
of the 5th SIGdial Workshop on Discourse and Dia-
logue at HLT-NAACL 2004, pages 97–100.

Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-
beth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul
Taylor, Rachel Martin, Carol Van Ess-Dykema, and
Marie Meteer. 2000. Dialogue act modeling for au-
tomatic tagging and recognition of conversational
speech. Computational Linguistics, 26(3):339–373.

Rakesh Verma, Narasimha Shashidhar, and Nabil Hos-
sain. 2012. Detecting phishing emails the natural
language way. In European Symposium on Research
in Computer Security, pages 824–841. Springer.

Andrew Viterbi. 1967. Error bounds for convolutional
codes and an asymptotically optimum decoding al-
gorithm. IEEE transactions on Information Theory,
13(2):260–269.

Byron C Wallace, Thomas A Trikalinos, M Barton
Laws, Ira B Wilson, and Eugene Charniak. 2013. A
generative joint, additive, sequential model of topics
and speech acts in patient-doctor communication.
In Proceedings of the 2013 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1765–1775.

Britta Wrede and Elizabeth Shriberg. 2003. Rela-
tionship between dialogue acts and hot spots in
meetings. In 2003 IEEE Workshop on Automatic
Speech Recognition and Understanding (IEEE Cat.
No. 03EX721), pages 180–185. IEEE.


