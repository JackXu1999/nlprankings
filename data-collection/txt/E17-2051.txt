



















































Don't Stop Me Now! Using Global Dynamic Oracles to Correct Training Biases of Transition-Based Dependency Parsers


Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 318–323,
Valencia, Spain, April 3-7, 2017. c©2017 Association for Computational Linguistics

Don’t Stop Me Now!
Using Global Dynamic Oracles to Correct Training Biases of

Transition-Based Dependency Parsers

Lauriane Aufrant1,2, Guillaume Wisniewski1 and François Yvon1

1LIMSI, CNRS, Univ. Paris-Sud, Université Paris-Saclay, 91 405 Orsay, France
2DGA, 60 boulevard du Général Martial Valin, 75 509 Paris, France

{lauriane.aufrant,guillaume.wisniewski,francois.yvon}@limsi.fr

Abstract

This paper formalizes a sound extension
of dynamic oracles to global training, in
the frame of transition-based dependency
parsers. By dispensing with the pre-
computation of references, this extension
widens the training strategies that can be
entertained for such parsers; we show this
by revisiting two standard training pro-
cedures, early-update and max-violation,
to correct some of their search space
sampling biases. Experimentally, on the
SPMRL treebanks, this improvement in-
creases the similarity between the train
and test distributions and yields perfor-
mance improvements up to 0.7 UAS, with-
out any computation overhead.

1 Introduction

Transition-based parsers with beam search are
among the most widely used models for depen-
dency parsing: they achieve state-of-the-art per-
formance while their training and inference, which
rely on approximate search, are very efficient.
Training a beam parser faces two difficulties: error
propagation and search errors (Huang et al., 2012).
Specific learning methods, early-update and max-
violation (presented in §2), have been designed to
address them. But they require to update the pa-
rameters on partial derivations only, which intro-
duces a discrepancy between the feature distribu-
tions seen during training and testing. Notably,
derivation endings are under-represented during
training, which hurts parsing performance.

In this work, we propose an improved train-
ing strategy that corrects such sampling biases for
beam parsers (§3). Experiments with the SPMRL
treebanks (Seddah et al., 2013), reported in §4,
show that the training configurations sampled by

this new strategy are closer to the parser configu-
rations seen at test time and result in increases up
to 0.7 UAS, with no computation time overhead.
These improvements rely on a sound extension of
dynamic oracles for global training, the lack of
which has repeatedly been pointed out (Goldberg
and Nivre, 2012; Sartorio, 2015). These global dy-
namic oracles have more general benefits than the
training strategy proposed here; for instance, they
allow to train beam parsers on partially annotated
data in a context of active learning or multilingual
transfer (Lacroix et al., 2016).

2 Training a Dependency Parser

In a transition-based parser (Nivre, 2008), a parse
is computed by performing a sequence of tran-
sitions building the parse tree in an incremen-
tal fashion. In the following, c denotes a parser
configuration representing a partially built depen-
dency tree. Applying transition t to configuration
c results in the parser moving to a successor of c,
denoted c ◦ t.

At each step of the parsing process, every pos-
sible transition is scored by a classifier, given a
feature representation of c and model parameters
θ; the score of a derivation (a sequence of transi-
tions) generating a given parse tree is the sum of
its transition scores. Parsing thus amounts to find-
ing the derivation having the highest score, usually
through greedy or beam search.

Parsers using beam search are typically trained
with a global criterion, that updates the parameters
once for each training sentence. Algorithm 1 sum-
marizes the training for each sentence x (with gold
parse y): INITIAL(x) denotes the initial configu-
ration for x and the procedure ORACLE performs
decoding to find configurations that play the role
of the ‘positive’ and ‘negative’ examples (resp. c+

and c−) required by the UPDATE operation (typi-

318



Algorithm 1: Global training on one sen-
tence.
θ: model parameters, initialized to θ0 before
training
Function DPTRAINING(x,y)

c← INITIAL(x)
c+, c− ← ORACLE(c, y, θ)
θ ← UPDATE(θ, c+, c−)

cally a perceptron update rule (Collins and Roark,
2004) or a gradient computation with the globally
normalized loss of Andor et al. (2016)). Several
strategies, corresponding to various implementa-
tions of the ORACLE function, have been used to
find these examples.

In the early-update strategy (Collins and Roark,
2004; Zhang and Clark, 2008), a reference deriva-
tion is first computed, generally using hand-
crafted heuristics. The sentence is then parsed
using conventional beam decoding and an update
happens as soon as this pre-computed gold deriva-
tion falls off the beam, while the rest of the se-
quence is ignored. The top scoring configura-
tion at this step is penalized and the reference that
has just fallen off the beam is reinforced. An-
other strategy, max-violation (Huang et al., 2012),
is to continue decoding even though the refer-
ence has fallen off the beam, in order to find the
configuration having the largest gap between the
scores of the (partial) hypothesis and the (par-
tial) gold derivation. Compared to early-update,
max-violation speeds up convergence by covering
longer transition sequences and can yield slightly
better parsers.

3 Correction of Training Biases

Both standard learning strategies suffer from bi-
ases that introduce a discrepancy between the fea-
ture distributions seen during training and testing.

First, parameters updates reinforce only gold
derivations; at test time, the model might find
itself, after an error, in a part of the search
space where it was not trained to take good de-
cisions, thus propagating errors (Goldberg and
Nivre, 2012).1

Second, they both use a static oracle that relies
on the deterministic pre-computation of a canon-

1While beam search already addresses error propagation
issues that are due to inexact search, it does not handle this
kind of error propagation, which results from training issues.

ical reference. An update occurs as soon as the
parser strays from this particular gold derivation,
even when the reference tree could still be ob-
tained using an alternative derivation. Updating
in such cases raises the risk of lowering parser
performance. Indeed, we measured that a beam
parser trained with early-update and a static or-
acle counter-intuitively predicts correctly fewer
heads of the current sentence just after an update
than just before, for 15% of the updates (French
SPMRL, during 10th epoch).

Third, both the early-update and the max-
violation strategies consider only partial deriva-
tions when updating the model parameters. For in-
stance on the French SPMRL, when training with
an early-update strategy, the end of the derivation
is reached for only 41% of the examples at the 10th
epoch2 and, on average, only 57% of a derivation
is considered; the max-violation strategy, which
computes longer partial derivations, partly allevi-
ates this effect: these proportions raise, respec-
tively, to 53% and 81%. While the choice of
partial updates has been experimentally proved
(Huang et al., 2012) to be critical in achiev-
ing good performance, it prevents parsers from
visiting configurations corresponding to deriva-
tion endings. This explains why configurations
and transitions involving final punctuation marks,
verbs in SOV languages like Japanese or German
subordinate clauses, the ROOT token when placed
at the end (Ballesteros and Nivre, 2013), but also
stack features involving long distance siblings, are
too rarely seen in training, thereby hurting predic-
tions in such configurations.

In the following, we describe improvements ad-
dressing those issues.

Dynamic oracles The limits of static oracles
have already been highlighted for ARCEAGER
greedy parsers: Goldberg and Nivre (2012) show
how parsing performance can be significantly im-
proved with a dynamic oracle that computes a ref-
erence tailored to the current parser state. Dy-
namic oracles are at the heart of most state-of-
the-art parsers (Ballesteros et al., 2016; Coavoux
and Crabbé, 2016; Cross and Huang, 2016; Kiper-
wasser and Goldberg, 2016). But, to the best of
our knowledge, dynamic oracles have only been
partially generalized to beam parsers: Björkelund
and Nivre (2015)’s oracles address the second but

2On the French SPMRL treebank, at the 10th epoch, the
parser is close to convergence (see §4).

319



not the first issue, while the dynamic oracle of the
YaraParser (Rasooli and Tetreault, 2015) arbitrar-
ily rules out some configurations that can generate
the reference tree.

Algorithm 2 shows how a dynamic oracle can
be integrated within the early-update learning
strategy; this extension can be done in the same
way for the max-violation strategy but is not de-
tailed here, for space reasons. The specificity of
that formalism is to consider that an error occurs
only when none of the configurations in the beam
can result in the dependency tree that was initially
the best reachable one, i.e. when all hypotheses in-
sert new erroneous dependencies.3

The Boolean function that tests this condition,
denoted CORRECTy(c′|c), can be efficiently com-
puted using the COSTy(t) function, formally de-
fined in Goldberg and Nivre (2013) as the num-
ber of dependencies of a gold parse tree y that
can no longer be predicted when transition t is
applied: a configuration c′ is considered as COR-
RECT in the context of a configuration c, if there
exists a sequence of transitions t1, . . . , tn such that
c′ = c ◦ t1 ◦ . . . ◦ tn and COSTy(t1) = · · · =
COSTy(tn) = 0.

Once an error is detected, the negative exam-
ple c− is chosen, as in the ‘standard’ early-update
strategy, as the top scoring configuration in the
beam. The positive example c+ is computed in
constant time, by choosing the top scoring config-
uration in the beam (just before k-best truncation)
for which CORRECT is true.

Restart Strategy To avoid over-representing the
beginning of derivations during training, we pro-
pose a new learning strategy: contrary to the base-
line training method (Algorithm 1) in which pars-
ing stops as soon as an error is detected and the
parameters updated, in our strategy (Algorithm 3)
decoding is restarted with a beam containing only
the positive configuration c+ and parsing contin-
ues until a new error is detected, triggering new
updates. The ORACLE function is then called from
several successive configurations, as many times
as needed to completely parse the sentence.

This training method ensures that configura-
tions that are close to derivations endings will be
seen more often during training.4

3While fairly simple, this formalism is a major change
from the traditional paradigm where references are explicitly
computed for each action.

4Standard training with full update also ensures this, but

Algorithm 2: Dynamic oracle for the early-
update strategy.

c0: configuration to start decoding from
topθ(·): best scoring element according to θ
NEXT(c): the set of all successors of c
Function EARLYUPDATEORACLE(c0, y, θ)

Beam← {c0}
while ∃c ∈ Beam,¬FINAL(c) do

S ← ∪c∈BeamNEXT(c)
Beam← k-best(S, θ)
if ∀c ∈ Beam,¬CORRECTy(c|c0)
then

gold←
{c ∈ S|CORRECTy(c|c0)}

return topθ(gold), topθ(Beam)

gold← {c ∈ Beam|CORRECTy(c|c0)}
return topθ(gold), topθ(Beam)

Algorithm 3: Global training with restart.
FINAL(·): true iff the whole sentence is
parsed
Function DPTRAININGRESTART(x,y)

c← INITIAL(x)
while ¬FINAL(c) do

c+, c− ← ORACLE(c, y, θ)
θ ← UPDATE(θ, c+, c−)
c← c+

Restarting with an oracle tailored to the restart
configuration is made possible by our global dy-
namic oracle. In this frame, the strategy can even
be further improved: similarly to their greedy
counterpart, global dynamic oracles enable to aug-
ment training with an error exploration component
by restarting from c− instead of c+ after an error,
thus addressing the first issue mentioned.

4 Experiments

Experimental Setup The validity of our ap-
proach is evaluated on the SPMRL treebank (Sed-
dah et al., 2013). We consider, as baselines,
a greedy parser trained with a dynamic oracle
(GREEDY DYN) and beam parsers trained with the
early-update and max-violation strategies and a
static oracle (resp. EARLY and MAXV). The im-

with the risk of divergence (Huang et al., 2012). Restarting
in c+ with a new beam has the same convergence guarantee
as standard early-update and max-violation.

320



ar de eu fr he hu ko pl sv average

GREEDY DYN 83.98 90.73 84.00 84.23 83.78 84.33 82.79 87.66 86.35 85.32

EARLY 85.03 92.74 84.42 86.02 85.39 85.63 82.73 89.60 87.00 86.51
IMP-EARLY 85.27 92.89 84.59 86.26 85.84 85.74 82.98 89.55 87.37 86.72

MAXV 85.06 92.77 84.59 86.10 85.53 85.57 82.68 89.42 87.16 86.54
IMP-MAXV 85.04 92.90 84.68 86.26 85.83 85.55 82.94 90.12 87.31 86.74

Table 1: Performance (UAS) of the various training strategies on the SPMRL datasets.

provements of §3 are applied to these two strate-
gies (resp. IMP-EARLY and IMP-MAXV).

In all our experiments, we use our in-house,
open source implementation of a beam ARCEA-
GER parser in the PanParser framework (Aufrant
and Wisniewski, 2016),5 with the averaged struc-
tured perceptron (Collins, 2002), a beam size
of 8 and the ROOT placed at the end. We use
coarse gold PoS tags and the extended features
set of Zhang and Nivre (2011), without label in-
formation. These features, designed for English,
have not been adapted to the specificities of the
languages. All models are trained up to conver-
gence on a validation set. As a point of compar-
ison, on average over the treebank, our GREEDY
DYN baseline is 2.7 UAS higher than a MaltParser
trained with ARCEAGER and the same kind of in-
formation (coarse tags, no label).

Results Table 1 reports the performance of all
training strategies evaluated by the traditional
UAS on the projective test sets, ignoring punctua-
tion tokens. All reported scores are averaged over
5 runs. Results show that our learning strategy
consistently outperforms the corresponding base-
line, with average increases of 0.2 UAS, up to
0.7 UAS.

Discussion Table 2 shows the performance im-
balance between various positions in the sentence
and confirms that our improvements partly allevi-
ate this phenomenon: the scores on the first half
of the sentence are mostly unchanged, while large
gains are reported on the second half.

To assess that these UAS gains result from a bet-
ter matching of training and test configurations,
we compute the Kullback-Leibler divergence be-

5The oracle for beam parsers described in this work can
be used with any scoring function and learning method, such
as Andor et al. (2016). But its implementation may require to
change the whole code architecture as reference derivations
must be computed on the fly.

Quarter 1st 2nd 3rd 4th

EARLY 90.0 85.4 83.1 84.7
IMP-EARLY 90.0 85.3 84.2 85.1

Table 2: Performance (UAS) of the standard
and improved early-update strategies, depending
on the position in the sentence (French SPMRL
dataset, with similar results in other languages).
The first quarter corresponds to the attachment of
tokens in the first 25% of the sentence length.

Baseline Improved

EARLY 0.350 0.280
MAXV 0.357 0.277

Table 3: Effect of our improvements on the
Kullback-Leibler divergence between the train and
test feature distributions (French SPMRL dataset,
with similar results in other languages).

tween the probability distribution (estimated with
frequency counts and 0.1 Laplace smoothing) of
the features of all configurations in beam scored
during the 10th training epoch and the feature dis-
tribution seen at test time.

Table 3 reports the Kullback-Leibler diver-
gences induced by our refinements with respect to
the corresponding baselines. It clearly shows that
our ‘improved’ learning strategy considers train-
ing examples that are closer to test configurations.
Similar experiments on greedy parsers show that
their train-test divergence is reduced from 0.320
to 0.219 by the dynamic oracle and exploration
strategy of Goldberg and Nivre (2012). In these
two experiments, feature similarity correlates with
UAS improvements and can therefore provide a
new way to interpret oracle influence.

Finally, regarding efficiency, we observe (Fig-
ure 1) that IMP-EARLY converges in a number

321



20 40
84

85

86

87

Epochs

UAS

0.2 0.4 0.6 0.8 1
·106

84

85

86

87

Updates

UAS

10 20 30
84

85

86

87

CPU time

UAS

EARLY
IMP-EARLY

MAXV

Figure 1: Learning curves on the validation set (SPMRL, fr). IMP-EARLY has the same update efficiency
as EARLY, but with the epoch and computation time convergence of MAXV.

of epochs similar to that of standard MAXV. De-
spite an increased number of updates, it is however
slightly faster (in CPU time) because it avoids the
extra reference pre-computation.

5 Conclusion

In this paper, we have extended the dynamic oracle
framework to global training, for transition-based
dependency parsers. This innovation lets us pro-
pose an alternative training strategy, that reduces
the discrepancy between the feature distributions
seen at train and test time that exists in state-of-
the-art methods. Experiments on the 9 SPMRL
treebanks show that our restart strategy improves
both parsing accuracy and model convergence. We
intend for future work to investigate other ways
to reduce the train-test distribution discrepancy in
structured prediction, using the new possibilities
offered by this extended framework.

Acknowledgments

This work has been partly funded by the French
Direction générale de l’armement.

References

Daniel Andor, Chris Alberti, David Weiss, Aliaksei
Severyn, Alessandro Presta, Kuzman Ganchev, Slav
Petrov, and Michael Collins. 2016. Globally nor-
malized transition-based neural networks. In Pro-
ceedings of the 54th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 2442–2452, Berlin, Germany, Au-
gust. Association for Computational Linguistics.

Lauriane Aufrant and Guillaume Wisniewski. 2016.
PanParser: a Modular Implementation for Efficient
Transition-Based Dependency Parsing. Technical
report, LIMSI-CNRS, March.

Miguel Ballesteros and Joakim Nivre. 2013. Going
to the roots of dependency parsing. Computational
Linguistics, 39(1):5–13.

Miguel Ballesteros, Yoav Goldberg, Chris Dyer, and
Noah A. Smith. 2016. Training with exploration
improves a greedy stack lstm parser. In Proceed-
ings of the 2016 Conference on Empirical Methods
in Natural Language Processing, pages 2005–2010,
Austin, Texas, November. Association for Computa-
tional Linguistics.

Anders Björkelund and Joakim Nivre. 2015.
Non-Deterministic Oracles for Unrestricted Non-
Projective Transition-Based Dependency Parsing.
In Proceedings of the 14th International Conference
on Parsing Technologies, pages 76–86.

Maximin Coavoux and Benoit Crabbé. 2016. Neu-
ral greedy constituent parsing with dynamic oracles.
In Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 172–182, Berlin, Germany,
August. Association for Computational Linguistics.

Michael Collins and Brian Roark. 2004. Incremen-
tal parsing with the perceptron algorithm. In Pro-
ceedings of the 42nd Meeting of the Association for
Computational Linguistics (ACL’04), Main Volume,
pages 111–118, Barcelona, Spain, July.

Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings
of the 2002 Conference on Empirical Methods in
Natural Language Processing, pages 1–8. Associ-
ation for Computational Linguistics, July.

James Cross and Liang Huang. 2016. Span-based
constituency parsing with a structure-label system
and provably optimal dynamic oracles. In Proceed-
ings of the 2016 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1–11,
Austin, Texas, November. Association for Compu-
tational Linguistics.

Yoav Goldberg and Joakim Nivre. 2012. A dynamic
oracle for arc-eager dependency parsing. In Pro-
ceedings of COLING 2012, pages 959–976, Mum-

322



bai, India, December. The COLING 2012 Organiz-
ing Committee.

Yoav Goldberg and Joakim Nivre. 2013. Training
deterministic parsers with non-deterministic oracles.
Transactions of the Association for Computational
Linguistics, 1:403–414.

Liang Huang, Suphan Fayong, and Yang Guo. 2012.
Structured perceptron with inexact search. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
142–151, Montréal, Canada, June. Association for
Computational Linguistics.

Eliyahu Kiperwasser and Yoav Goldberg. 2016. Sim-
ple and accurate dependency parsing using bidirec-
tional lstm feature representations. Transactions
of the Association for Computational Linguistics,
4:313–327.

Ophélie Lacroix, Lauriane Aufrant, Guillaume Wis-
niewski, and François Yvon. 2016. Frustratingly
easy cross-lingual transfer for transition-based de-
pendency parsing. In Proceedings of the 2016
Conference of the North American Chapter of the
Association for Computational Linguistics: Hu-
man Language Technologies, pages 1058–1063, San
Diego, California, June. Association for Computa-
tional Linguistics.

Joakim Nivre. 2008. Algorithms for deterministic in-
cremental dependency parsing. Comput. Linguist.,
34(4):513–553.

Mohammad Sadegh Rasooli and Joel Tetreault. 2015.
Yara parser: A fast and accurate dependency parser.
arXiv preprint arXiv:1503.06733.

Francesco Sartorio. 2015. Improvements in Transition
Based Systems for Dependency Parsing. Ph.D. the-
sis, Universit degli studi di Padova.

Djamé Seddah, Reut Tsarfaty, Sandra Kübler, Marie
Candito, Jinho D. Choi, Richárd Farkas, Jen-
nifer Foster, Iakes Goenaga, Koldo Gojenola Gal-
letebeitia, Yoav Goldberg, Spence Green, Nizar
Habash, Marco Kuhlmann, Wolfgang Maier, Joakim
Nivre, Adam Przepiórkowski, Ryan Roth, Wolfgang
Seeker, Yannick Versley, Veronika Vincze, Marcin
Woliński, Alina Wróblewska, and Eric Villemonte
de la Clergerie. 2013. Overview of the SPMRL
2013 shared task: A cross-framework evaluation of
parsing morphologically rich languages. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically-Rich Languages, pages 146–
182, Seattle, Washington, USA, October. Associa-
tion for Computational Linguistics.

Yue Zhang and Stephen Clark. 2008. A tale of two
parsers: Investigating and combining graph-based
and transition-based dependency parsing. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing, pages 562–
571, Honolulu, Hawaii, October. Association for
Computational Linguistics.

Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 188–193, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.

323


