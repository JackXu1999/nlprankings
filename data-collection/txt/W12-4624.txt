



















































On the Form-Meaning Relations Definable by CoTAGs


Proceedings of the 11th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+11), pages 207–213,
Paris, September 2012.

On the Form-Meaning Relations Definable by CoTAGs

Gregory M. Kobele
University of Chicago

Chicago, Illinois
USA

Jens Michaelis
Bielefeld University

Bielefeld
Germany

Abstract

Adding cosubstitution to the classical TAG
operations of substitution and adjunction,
coTAGs have been proposed as an “alterna-
tive conceptualization” to resolve the ten-
sion between the TAG mantra of locality
of syntactic dependencies and the seeming
non-locality of quantifier scope. CoTAGs
follow the tradition of synchronous TAGs
(STAGs) in that they derive syntactic and
semantic representations simultaneously as
pairs. We demonstrate that the mappings
definable by coTAGs go beyond those of
“simple” STAGs. While with regard to the
first component, coTAGs are weakly and
strongly equivalent to classical TAGs, the
second projection of the synchronously de-
rived representations, can in particular be—
up to a homomorphism—the non-tree ad-
joining language MIX(k), for any k ≥ 3.

1 Introduction

Given a classical TAG as, e.g., defined in the
handbook article by Joshi and Schabes (1997), the
set of derivation trees constitutes a regular set of
unordered labeled trees with an additional label-
ing of the tree edges. The nodes of a derivation
tree are labeled with elementary trees, and each
edge is labeled with a Gorn address. Such an
address indicates the node of the elementary tree
(labeling the outgoing node of the corresponding
edge in the derivation tree) at which another el-
ementary tree (labeling the incoming node of the
corresponding edge in the derivation tree) was ad-
joined or substituted during the derivation repre-
sented by the derivation tree. The representation
of a TAG derivation in this way is independent of
the derivational order. This is the reason why the
set of derivation trees of a classical TAG consti-
tutes a regular tree set.

Work on semantics in the TAG framework of-
ten considers the derivation tree as a compact, or-
der independent representation of all derivations
yielding the same syntactic tree, but at the same
time as a compact representation of different se-
mantics associated with the same syntactic repre-
sentation. Work in this line, in particular includes
the extensive work of Kallmeyer and colleagues
as well as Nesson and Shieber.1

Suggesting an “alternative conceptualization”
to resolve the tension between the TAG mantra
of locality of syntactic dependencies and the
seeming non-locality of quantifier scope, Barker
(2010) proposes to add to the classical TAG op-
erations of substitution and adjunction as a third
operation a modified version of substitution. He
calls the resulting operation cosubstitution and the
version of TAGs incorporating this operation co-
TAGs.

CoTAGs are defined in the spirit of syn-
chronous TAGs (STAGs) as introduced by Shieber
and Schabes (1990), deriving syntactic and se-
mantic representations simultaneously as pairs.
Syntactically, cosubstitution can essentially be
understood as substitution, but with reversed roles
of functor and argument. Barker notes that for
this reason, from a purely syntactic perspective,
in the context of simple (i.e. not multicomponent)
TAGs, adding cosubstitution affects neither weak
nor strong generative capacity (in the sense of de-
rived string and tree languages).

Clearly, however, something is different: af-
ter adding the operation of cosubstitution, deriva-
tional order matters in the sense that one derived
syntactic representation can potentially be associ-
ated with more than one simultaneously derived
semantic representation. As Barker points out,

1See, e.g., Kallmeyer and Romero (2004) and Nesson
and Shieber (2007), and references cited therein.

207



the introduction of the cosubstitution operator al-
lows for a straightforward adaption of the notion
of derivation tree such that two derivation trees
can be different depending on when a cosubstitu-
tion step takes place.

We demonstrate that the form-meaning map-
pings definable by coTAGs go beyond those of
“simple” STAGs (Shieber, 1994; Shieber, 2006).2

In particular, the set of meanings, the second pro-
jection of the synchronously derived syntactic and
semantic representations, can be—up to a homo-
morphism abstracting away from instances of λ
and variables—the non-tree adjoining language
MIX(k), for any k ≥ 3. The complexity of the
corresponding set of meanings is a reflex of the
complexity of the connected derivation tree set,
whose path language—up to a homomorphism—
also provides the non-tree adjoining language
MIX(k). The result can already be established
when restricting the attention to coTSGs, under-
stood as coTAGs without classical adjunction.
From this perspective it could be argued that the
additional expressive power is really due to the
cosubstitution operation alone.

2 CoTAGs

From the perspective of lexical entries, each
coTAG consists of a finite set of pairs of la-
beled trees. The first component of such a pair
〈αsyn, αsem〉 provides a syntactic representation,
the second component a semantic representation
of the corresponding lexical entry. Nodes in αsyn
are uniquely linked to nodes in αsem. The label of
a node νsem from αsem linked to a node νsyn from
αsyn displays the semantic type of the correspond-
ing syntactic subconstituent dominated by νsyn.
An operation applying to νsyn must be accompa-
nied by a parallel operation applying to νsem.

Regarding the syntactic component of the
coTAG-relation, coTAGs are identical to classi-
cal TAGs except for the following difference:
whereas the roots of TAG-initial trees and sub-
stitution nodes of arbitrary TAG-elementary trees
are labeled with elements from Cat and Cat↓,
respectively,3 the roots of syntactic coTAG-initial

2While we focus here on coTAGs, the results herein
straightforwardly apply as well to limited delay vector TAGs
(LDV-TAGs) (Nesson, 2009) which would allow for a differ-
ent implementation of essentially the same mechanism.

3Cat denotes the set of categories, i.e. the nonterminals,
of the grammar.

〈
i ↓δ↓ i

,
i δ i

〉 function
+

〈
j δ j

B

,
j δ j

Z
〉 argument

〈 i δ i
B

, i δ i

B

〉

 

Figure 1: Substitution schematically. Syntactically,
tree with root-label δ is substituted at leaf labeled δ↓;
while semantically, the corresponding tree with root-
label δ is substituted at the linked node labeled δ.

trees and substitution nodes of arbitrary syn-
tactic coTAG-elementary trees have labels from
the sets Cat(↑Cat)∗ and Cat(↑Cat)∗↓, respec-
tively. Expressions of the syntactic component
are constructed in very much the same manner as
in TAGs, with one important addition: a derived
structure βsyn with syntactic root-label δ↑B for
some B ∈ Cat and δ ∈ Cat(↑Cat)∗ can be co-
substituted into a derived syntactic structure αsyn
with syntactic root-label B and a leaf labeled δ↓
derived structure. The result of applying cosubsti-
tution in this situation is the same as substituting
β′syn into αsyn at the corresponding leaf labeled δ↓,
where β′syn results from βsyn by replacing the root-
label δ↑B of βsyn with δ. From this perspective,
cosubstitution can be understood as substitution
reversing the roles of argument and functor, i.e.,
αsyn is rather cosubstituted onto the root of βsyn.
As will become immediately clear, the “reversed
perspective” of argument and functor chimes in
with the operational semantic counterpart of ap-
plying cosubstitution.

Regarding the semantic component of the
coTAG-relation, the trees derived represent well-
typed lambda terms, which can be read off from
the yield.4 The matching semantic operation to
applying substitution and adjunction syntactically
is also substitution and adjunction, providing us
with “functional application” in terms of lambda
calculus, cf. Figure 1 for the case of substitution.5

4Arriving at a concrete lambda term is achieved by re-
placing each leaf-label which is a semantic type by a vari-
able of corresponding type, when reading off the leaf-labels
“from left to right.”

5For δ ∈ Cat(↑Cat)∗ and B ∈ Cat, the boldface ver-
sions δ and δ↑B denote the corresponding semantic types of

208



〈
B

i ↓δ ↓ i
,

B

i δ i
〉 argument

+

〈
δ ↑B

B

,
δ ↑B

Z
〉 function

〈
B

i δ i

B

,

B

( δ B )

B

δ

x

δ

x

λ

i δ ↑B i

B 〉

 

Figure 2: Cosubstitution schematically. Syntactically,
tree with root-label with root-label δ↑B is cosubsti-
tuted into tree with root-label B at leaf labeled δ↓;
while semantically, the corresponding tree with root-
label δ ↑B is “quantified in” at the root of the corre-
sponding tree with root-label B.

The matching semantic operation to applying
cosubstitution syntactically consists of a “quanti-
fying in” step as outlined in Figure 2. Note that
within the resulting semantic representation, new
terminal leaves are introduced labeled by λ and a
variable x. The operation is set up such that x is
chosen to be “fresh.”

As a concrete example, consider the grammar
Gscope presented in Figure 3.6 One can start de-
riving the sentence “every boy loves some girl”
either by substituting boy into every, and then co-
substituting every boy into the subject position of
loves as shown in Figure 4, or by substituting girl
into some, and then cosubstituting some girl into
the object position of loves as shown in Figure
5. Both complete derivations of the sentence are
given in Figure 6. The derived syntactic trees are
identical, while the semantic trees are different,
because of the different order of the derivation
steps. Accordingly, we require a novel notion of
derivation to represent this “timing” information,
which we leave at an intuitive level in this paper

δ↓? and δ↑B, respectively. δ↑B is the lifted type (( δ B)B ).
6Links will usually be marked with diacritics of the form

n for some n ≥ 1. We may occasionally avoid explicitly
mentioning the links between nodes of the syntactic and the
semantic representation, when we think the canonical linking
is obvious.

(αevery ) , (αsome )

〈
1 DP↑S 1

3 ↓NP↓ 32 D 2

every | some

,

1 ((e t) t) 1

3 (e t) 32 ((e t)((e t) t)) 2

every | some

〉

(αboy ) , (αgirl )

〈
1 NP 1

boy | girl

,
1 (e t) 1

boy | girl
〉

(αloves )

〈

1 S 1

3 VP 3

5 ↓DP↓ 54 V 4

lovesy

2 ↓DP↓ 2
,

1 t 1

2(e 23 (e t) 3

5(e 54 (e (e t)) 4

lovesy

〉

Figure 3: The example coTAG Gscope

for reasons of space.
Displaying a derivation tree, we use a solid line

for drawing an edge in order to indicate an in-
stance of substitution, and the edge label marks
the address of the substitution site of the elemen-
tary tree into which substitution takes place. We
use a dashed line in order to indicate an instance
of cosubstitution, and the edge label marks the ad-
dress of the substitution site of the elementary tree
into which cosubstitution takes place. But in con-
trast to the case of substitution, this elementary
tree labels the incoming node of the edge.

3 Expressivity

For k ≥ 1, we now provide a coTAG Gk gener-
ating as its string language the regular language
{(a1 · · · ak)m : m ≥ 1}, while the path language
of the set of derivation trees and the set of mean-
ings, up to a homomorphism, provide the lan-
guage MIX(k), i.e. the set {w ∈ {a1, . . . , ak}∗ :
|w|ai = |w|aj , 1 ≤ i, j ≤ k}.
Gk consists of k+4 lexical entries, namely, the

entries α1, . . . , αk, βk, γk, τk and σk, and for each
entry, we use the (additional) subscripts syn and

sem in order to refer to the entry’s syntactic and
semantic component, respectively, cf. Figure 7. S

209



αevery , syn

αboy , syn
2

αloves , syn
1

〈

1 S 1

3 VP 3

5 ↓DP↓ 54 V 4

loves

2 DP 2

7 NP 7

boy

6 D 6

every

,

1 S 1

(DP S)

S

()DP

x

3 VP 3

5()DP 54 V 4

lovesy

DP

x

λ

2 DP↑S 2

7 NP 7

boy

6 D 6

every
〉

Figure 4: Cosubstituting every boy into the subject position before filling the object position of loves, derived
syntactic tree and semantic tree, and derivation tree.

αsome , syn

αgirl , syn
2

αloves , syn
22

〈

1 S 1

3 VP 3

5 DP 5

7 NP 7

girl

6 D 6

some

4 V 4

loves

2 ↓DP↓ 2

,

1 S 1

(DP S)

S

2()DP 23 VP 3

3()DP 3

y

4 V 4

lovesy

DP

y

λ

5 DP↑S 5

7 NP 7

girl

6 D 6

some
〉

Figure 5: Cosubstituting some girl into the object position before filling the subject position of loves, derived
syntactic and semantic tree, and derivation tree.

αsome , syn

αgirl , syn
2

αevery , syn

αboy , syn
2

αloves , syn
1

22

〈

1 S 1

3 VP 3

5 DP 5

9 NP 9

girl

8 D 8

some

4 V 4

loves

2 DP 2

7 NP 7

boy

6 D 6

every

,

1 S 1

(DP S)

S

(DP S)

S

()DP

x

3 VP 3

3()DP 3

y

4 V 4

lovesy

DP

x

λ

2 DP↑S 2

7 NP 7

boy

6 D 6

every

DP

y

λ

5 DP↑S 5

9 NP 9

girl

8 D 8

some 〉

αevery , syn

αboy , syn
2

αsome , syn

αgirl , syn
2

αloves , syn
22

1

〈

1 S 1

3 VP 3

5 DP 5

7 NP 7

girl

6 D 6

some

4 V 4

loves

2 DP 2

9 NP 9

boy

8 D 8

every

,

1 S 1

(DP S)

S

(DP S)

S

()DP

x

3 VP 3

3()DP 3

y

4 V 4

lovesy

DP

y

λ

5 DP↑S 5

7 NP 7

girl

6 D 6

some

DP

x

λ

2 DP↑S 2

9 NP 9

boy

8 D 8

every 〉

Figure 6: The two complete derived pairs of structures of every boy loves some girl, and derivation trees.

210



T1

A1↓ 1 T2

A2↓ 2 Tk

Ak↓ k Uk↓ k+1

βk, syn:

S

A1↓ 1 T2

A2↓ 2 Tk

Ak↓ k Uk↓ k+1

σk, syn:

Uk

V k

�

T 1↓

γk, syn:

Uk

�

τk, syn:

Ai↑S

ai

αi, syn:

t

e 1 ( e t )

e 2 ( ek−1 t )

e k ( ek t ) k+1

βk, sem:

t

e 1 ( e t )

e 2 ( ek−1 t )

e k ( ek t ) k+1

σk, sem:

( ek t )

( t ( ek t ))

�

t

γk, sem:

( ek t )

�

τk, sem:

(( e t ) t )

ai

αi, sem:

Figure 7: The syntactic and the semantic components of Gk.

is the start symbol of Gk.
For m ≥ 1, consider wk,m = (a1 . . . ak)m.

Each derivation tree for wk,m is a single path. All
derivation trees for wk,m share a unique subtree,
cf. Figure 8. From a bottom-up perspective, the
derivation starts by substituting τk directly into σk
in case m = 1, or into βk otherwise. If m > 1,
the resulting tree is substituted into γk, and the re-
sult in its turn is substituted into βk again. This
procedure is repeated m− 1 times, before the re-

σk, syn

γk, syn

βk, syn

γk, syn

βk, syn

τk, syn

2k

2

2k

2

2k

Dk, sub:

σk, syn ( γk, syn (βk, syn (. . . ( γk, syn (βk, syn︸ ︷︷ ︸
m− 1 times

( τk, syn ))) . . . )))

Figure 8: The unique subtree Dk, sub of any derivation
tree for wk,m = am1 . . . a

m
k .

sulting tree is substituted into σk. Note that the
substitution site in each of these derivation steps
is uniquely determined. Note also that we can-
not cosubstitute any instance of αi before we have
substituted into σk, because cosubstitution of an
αi demands the presence of a root labeled S.

The derived tree described by the derivation
tree Dk, sub contains exactly m substitution sites
for every Ai. We can now cosubstitute into any
of these sites in any order. Thus, for each per-
mutation of (a1 . . . ak)m there is a derivation of
(a1 . . . ak)

m such that the permutation is reflected
in the corresponding derivation tree in terms of the
node labels αi,syn. More precisely, starting at the
root following down the unique path, the node la-
bels provide a permutation of (α1,syn . . . αk,syn)m

before we hit the node label σk,syn.

4 Remarks on ACGs

The formalism of an abstract categorial gram-
mar (ACG) (de Groote, 2001) has been intro-
duced with the idea to provide a general frame-
work in terms of linear logic allowing the encod-
ing of existing grammatical models. An ACG dis-
tinguishes between an abstract language and an
object language each of which is a set of linear
lambda terms over some signature. Following the
presentation by, e.g., Pogodalla (2004b), an ACG
G defines 1) two sets of typed linear lambda terms,
namely, a set Λ1 based on the typed constant set
C1, and a set Λ2 based on the typed constant set
C2; 2) a morphismL : Λ1 → Λ2; and 3) and a dis-

211



tinguished type S. The abstract and the object lan-
guage of G are defined asA(G) = {t ∈ Λ1 | t : S}
and O(G) = {L(t) ∈ Λ2 | t ∈ A(G)}, respec-
tively.

In this way the ACG-framework, in particular,
provides a logical setting in which an abstract lan-
guage can be used as a specification of the deriva-
tion set of a grammar instantiation of some gram-
mar formalism, and by applying two different
morphisms to the abstract language, we can “si-
multaneously” obtain a syntactic object language
and a semantic object language.

The order of an ACG is the maximal order of
the types assigned to the abstract constants from
C1.7 As demonstrated by de Groote (2002), each
classical TAG can be encoded as second-order
ACGs realizing the object language as the set of
derived trees, and the set of derived strings can be
extracted from that object language by compos-
ing the first second-order ACG with a second one.
Salvati (2007) has shown more generally, that
second-order ACGs, where the object language
is realized over a string signature, derive exactly
the string languages generated by, e.g., set-local
multicomponent TAGs. Kanazawa (2010) has
shown, that second-order ACGs, where the ob-
ject language is realized over a tree signature,
derive exactly the string languages generated by,
e.g., context-free graph grammars (Bauderon and
Courcelle, 1987).

Of course, the notion of derivation (trees) and
derived trees we have informally presented in the
previous sections is essentially one making use of
binding and abstraction. Recasting the above no-
tation into the ACG-framework provides one way
of analyzing the properties of coTAGs, in partic-
ular, from the perspective of an comparison to
other formalisms and approaches which fit into
the ACG-shape.

Closer inspection reveals Barker’s accompany-
ing notion of derivation tree to be in line with the
abstract language of the TAG-guided, ACG-based
semantic analysis of Pogodalla (2004a; 2007),
where the abstract language is a set of lambda
terms containing third-order constants.

It is easy to see that, although as far as the
syntactic component is concerned, coTAGs are
strongly equivalent to TAGs, this is only be-

7The order an atomic type is 1. For two types ζ and η,
the order of (ζη) is defined as the maximum of the order of
ζ increased by 1 and the order of η.

cause the syntactic interpretation of the higher-
order derivations “goes through” the second-order
derivation trees of TAGs. Once we turn to the do-
main of meanings, where the higher-order deriva-
tion terms are used essentially, we obtain a greater
generative capacity. We have exemplified this
above with regard to the language MIX(k), for
k ≥ 3. Note that MIX(3) is not a tree adjoining
language (Kanazawa and Salvati, 2012), and that
for k ≥ 4, MIX(k) is conjectured to be beyond
the scope of set-local multicomponent TAGs.

5 Conclusion

As already mentioned in the introduction, Barker
intends to provide an “alternative conceptualiza-
tion” of TAG semantic computation. An ear-
lier approach to TAG semantics in explicit terms
of STAGs has been worked out by Nesson and
Shieber (2007, and follow-up work). But in con-
trast to Barker’s presentation, their initial version
does not exceed the expressivity of simple STAGs
(Shieber, 1994; Shieber, 2006), where also the
second component does not exceed the (weak)
generative capacity of TAGs.

The difference from coTAGs results from the
fact that the semantic component may constitute
a tree-local multicomponent TAG, which allows
Nesson and Shieber to lexically represent, e.g., a
scope-taking quantifier as a pair of an elementary
auxiliary tree and an elementary substitution tree.
Sticking to the realm of simple STAGs implies
that in the context of nested quantifiers and in-
verse linking, when there are more than two quan-
tifiers involved, not all logically possible readings
are derivable. Nesson and Shieber discuss this
point in the context of the example two politi-
cians spy on someone from every city. Their ap-
proach delivers four possible readings. A particu-
lar fifth reading, namely, the case of scope order-
ing every > two > some is not available, which
some authors, among them Barker, think is a pos-
sible reading, albeit hard to process.

Introducing limited delay vector TAGs (LDV-
TAGs), Nesson (2009) suggests a modification of
the earlier STAG approach which also allows the
derivation of the “fifth reading.” If for any given
LDV-TAG there is no hard upper bound on the
degree of delay and on the number of multiple ad-
junctions that can take place at a single node, our
argument for coTAG expressivity can be straight-
forwardly adapted to LDV-TAGs. That is to say,

212



we can write an LDV-TAG whose set of deriva-
tion trees and set of derived meanings is, up to a
homomorphism, MIX(k) for arbitrary, but fixed
k ≥ 1.

Arbitrary delay allows for a qualitative in-
crease in the relation-generating power of syn-
chronous TAGs, demonstrated above in terms of
coTAGs and the operation of cosubstitution. Re-
casting this in terms of ACGs allows for a fur-
ther characterization, which makes clear the in-
crease in derivational generative capacity by mov-
ing from second-order abstract constants to third-
order ones.

References
Chris Barker. 2010. Cosubstitution, derivational lo-

cality, and quantifier scope. In Proceedings of
the Tenth International Workshop on Tree Adjoin-
ing Grammars and Related Formalisms (TAG+10),
New Haven, CT, pages 135–142.

Michel Bauderon and Bruno Courcelle. 1987. Graph
expressions and graph rewriting. Mathematical
Systems Theory, 20:83–127.

Philippe de Groote. 2001. Towards abstract catego-
rial grammars. In 39th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL 2001),
Toulouse, pages 252–259. ACL.

Philippe de Groote. 2002. Tree-adjoining grammars
as abstract categorial grammars. In Proceedings of
the Sixth International Workshop on Tree Adjoin-
ing Grammars and Related Formalisms (TAG+6),
Venezia, pages 145–150.

Aravind K. Joshi and Yves Schabes. 1997. Tree ad-
joining grammars. In G. Rozenberg and A. Salo-
maa, editors, Handbook of Formal Languages, vol-
ume 3, pages 69–124. Springer, Berlin, Heidelberg.

Laura Kallmeyer and Maribel Romero. 2004. Ltag
semantics with semantic unification. In Proceed-
ings of the Seventh International Workshop on
Tree Adjoining Grammars and Related Formalisms
(TAG+7), Vancouver, BC, pages 155–162.

Makoto Kanazawa and Sylvain Salvati. 2012. MIX
is not a tree-adjoining language. In 50th Annual
Meeting of the Association for Computational Lin-
guistics (ACL 2012), Jeju Island. ACL.

Makoto Kanazawa. 2010. Second-order abstract cat-
egorial grammars as hyperedge replacement gram-
mars. Journal of Logic, Language and Information,
19:137–161.

Rebecca Nesson and Stuart M. Shieber. 2007. Simpler
TAG semantics through synchronization. In Wint-
ner (2007), pages 129–142.

Rebecca Nesson. 2009. Synchronous and Multicom-
ponent Tree-Adjoining Grammars. Complexity, Al-

gorithms and Linguistic Applications. Ph.D. thesis,
Havard University, Cambridge, MA.

Sylvain Pogodalla. 2004a. Computing semantic rep-
resentation. Towards ACG abstract terms as deriva-
tion trees. In Proceedings of the Seventh Inter-
national Workshop on Tree Adjoining Grammars
and Related Formalisms (TAG+7), Vancouver, BC,
pages 64–71.

Sylvain Pogodalla. 2004b. Using and extending ACG
technology. Endowing categorial grammars with an
underspecified semantic representation. In Pro-
ceedings of Categorial Grammars 2004, Montpel-
lier, pages 197–209.

Sylvain Pogodalla. 2007. Ambiguı̈té de portée et ap-
proche fonctionnelle des grammaires d’arbres ad-
joints. In Traitement Automatique des Langues Na-
turelles (TALN 2007), Toulouse. 10 pages.

Sylvain Salvati. 2007. Encoding second order string
ACG with deterministic tree walking transducers.
In Wintner (2007), pages 143–156.

Stuart M. Shieber and Yves Schabes. 1990. Syn-
chronous tree-adjoining grammars. In Proceedings
of the 13th International Conference on Compu-
tational Linguistics (COLING ’90), Helsinki, vol-
ume 3, pages 253–258.

Stuart M. Shieber. 1994. Restricting the weak-
generative capacity of synchronous tree-adjoining
grammars. Computational Intelligence, 10:371–
385.

Stuart M. Shieber. 2006. Unifying synchronous tree
adjoining grammars and tree transducers via bimor-
phisms. In 11th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL 2006), Trento, pages 377–384. ACL.

Shuly Wintner, editor. 2007. Proceedings of FG 2006:
The 11th Conference on Formal Grammar. CSLI
Publications, Stanford, CA.

213


