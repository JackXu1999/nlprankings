



















































Dynamic encoding of structural uncertainty in gradient symbols


Proceedings of the 8th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2018), pages 19–28,
Salt Lake City, Utah, USA, January 7, 2018. c©2018 Association for Computational Linguistics

Dynamic encoding of structural uncertainty in gradient symbols
Pyeong Whan Cho

Department of Cognitive Science
Johns Hopkins University

pcho4@jhu.edu

Matthew Goldrick
Department of Linguistics
Northwestern University

matt-goldrick@northwestern.edu

Richard L. Lewis
Department of Psychology

University of Michigan
rickl@umich.edu

Paul Smolensky
Department of Cognitive Science

Johns Hopkins University
smolensky@jhu.edu

Abstract

An important achievement in modeling
online language comprehension is the dis-
covery of the relationship between pro-
cessing difficulty and surprisal (Hale,
2001; Levy, 2008). However, it is not
clear how structural uncertainty can be
represented and updated in a continuous-
time continuous-state dynamical system
model, a reasonable abstraction of neural
computation. In this study, we investi-
gate the Gradient Symbolic Computation
(GSC) model (Smolensky et al., 2014) and
show how it can dynamically encode and
update structural uncertainty via the gra-
dient activation of symbolic constituents.
We claim that surprisal is closely related
to the amount of change in the optimal ac-
tivation state driven by a new word input.
In a simulation study, we demonstrate that
the GSC model implementing a simple
probabilistic symbolic grammar can sim-
ulate the effect of surprisal on processing
time. Our model provides a mechanistic
account of the effect of surprisal, bridg-
ing between probabilistic symbolic mod-
els and subsymbolic connectionist models.

1 Introduction

A core computational problem in online language
comprehension is to deal with local ambiguity,
the one-to-many mapping from a unit symbol wk
(e.g., word) to symbol strings containing w at the
k-th position W ∗k = · · ·wk · · · and their interpre-
tations S (e.g., sentences and their parses). Ratio-
nal models of sentence comprehension solve this
problem by computing P (S|Wk), a conditional
probability of interpretations given a partial string
of symbols (henceforth, prefix) Wk = w1 · · ·wk,

and updating it discretely for every new symbol in-
put (Jurafsky, 1996; Hale, 2001; Levy, 2008). We
will refer to this class of incremental processing
models simply as (structural) probabilistic models.

The probabilistic model has drawn a lot of
attention because it predicts processing diffi-
culty in different regions of a sentence based on
information-theoretic complexity metrics. The
surprisal hypothesis (e.g., Hale, 2001; Levy, 2008)
claims that reading time of wk (as a measure of
processing difficulty) is proportional to its sur-
prisal, − logP (wk|Wk−1), or equivalently, the
Kullback-Leibler (KL) divergence of P (S|Wk)
from P (S|Wk−1) (Levy, 2008). This hypothesis
has been supported in many psycholinguistic ex-
periments (e.g., Boston et al., 2008; Demberg and
Keller, 2008; Smith and Levy, 2013).

In this study, our goal is to provide a neurally-
plausible, mechanistic account of the relationship
between surprisal and processing time. For our
purpose, we need a model from which both kinds
of information, P (S|Wk) and processing times of
wk, can be collected directly without relying on
stipulated linking hypotheses. Since the model is
a dynamical system, processing time is directly
modeled. To model the probability P (S|Wk) rel-
evant for rational analysis, we treat the model, pri-
marily developed to study interpretation, as a gen-
erator: it is run to equilibrium with no input, pro-
ducing a sentence parse as output. This is done
repeatedly as the dynamical system is stochastic;
this gives a probability distribution over gener-
ated parses we call ∗P (S) : this we take to be the
knowledge of sentence probabilities that is embod-
ied in the model’s dynamics. Then for anyWk, for
rational analysis we compute ∗P (S|Wk) by condi-
tioning ∗P (S) on Wk, i.e., ∗P (S|Wk) is the pro-
portion of all generated parses that have prefix
equal to Wk. We can then examine the extent to
which the model, when serving as an incremental

19



parser, behaves in accord with rational inference
given its knowledge.

The Gradient Symbolic Computation (GSC)
framework (Smolensky et al., 2014) serves
our goal. The GSC model is a continuous-
time, continuous-state stochastic dynamical sys-
tem model that computes the representation of
a discrete structure gradually. This framework
grew out of the Integrated Connectionist/Symbolic
cognitive architecture (Smolensky and Legendre,
2006). GSC aims to provide an integrated account
of the contribution of the continuous dynamics of
cognitive processing and the discrete competence
that characterizes our knowledge of language.

Cho et al. (2017) applied the framework to in-
cremental processing problems focusing on tran-
sient dynamics during incremental processing and
argued that the model can achieve two core com-
putational goals in incremental processing: main-
taining multiple context-appropriate and globally-
coherent interpretations while rejecting interpre-
tations that are context-inappropriate. The GSC
parser meets these challenges by moving, dur-
ing the processing of a word, to an intermedi-
ate activation state (a blend state) in which multi-
ple symbolic constituents are simultaneously acti-
vated to varying partial degrees. From this state,
the parser can reach all activation states repre-
senting context-appropriate and globally-coherent
structures but does not move to activation states
representing context-inappropriate structures (ei-
ther grammatical or ungrammatical). The relation
between intermediate activation states and proba-
bility distributions over discrete parses was briefly
discussed but was not investigated systematically.

In this study, we propose a version of the GSC
parser and show how it can be related to other
probabilistic sentence-processing models. We ar-
gue that the parser’s internal state – the activation
values of multiple symbolic constituents along
with control parameters of the parser – encodes a
probability distribution over complete parses (Sec-
tion 3). After encountering new input, the parser
incrementally changes its internal state to encode a
new probability distribution. The work the parser
needs to do to shift this internal state is closely re-
lated to the KL divergence between the probabil-
ity distributions, providing a link between process-
ing time and surprisal (Section 4). In a simulation
study (Section 5), we demonstrate that the GSC
parser can approximate rational inference and re-

port the correlation between processing time and
surprisal in our model. In Section 6, we summa-
rize our results and discuss some implications of
our work.

2 Gradient Symbolic Computation

2.1 Representation

Consider a tree structure S[1](A,B).1 Let us
assign a unique label for every position (called
role) in the tree structure. For example, we as-
sign labels r, 0, 1 to the mother (root) and the left
and right daughter nodes, respectively. Then, we
can describe the tree as an unordered set of sym-
bol/position (or filler/role) bindings: S[1](A,B)
≡ {B/1,S[1]/r,A/0}.

Let f and r be subsymbolic vector encodings
of filler f and role r. The encoding of binding
f/r is defined as the tensor product of the two
vectors: f/r ≡ f ⊗ r whose (i,j)-th component
is the product of the i-th component of f and the
j-th component of r. The encoding of a set of
filler/role bindings is defined as the superposition
(vector sum) of the encodings of component bind-
ings: {f1/r1, · · · , fk/rk} ≡

∑
k fk ⊗ rk. For

example, S[1](A,B)≡ S[1]⊗r+A⊗0+B⊗1.
In this study, we used local representation (or

one-hot encodings) of fillers and roles for facilitat-
ing computation. However, many equivalent mod-
els with distributed representations can be eas-
ily constructed by change of basis (Smolensky,
1986). The result will not change if the distributed
representations of bindings remain orthonormal
(Smolensky, 1990).

2.2 Constraints

The GSC model uses Harmonic Grammar (HG)
(Hale and Smolensky, 2006) to specify grammars
via soft constraints each of which imposes a re-
ward (a ‘positive constraint’) or a penalty (a ‘neg-
ative constraint’) on the wellformedness or Gram-
matical Harmony of a gradient symbolic structure.
The grammatical structures are those with maxi-
mal grammatical Harmony: these structures best
satisfy the constraints of the grammar.

As an example, consider a rewrite rule: S[1]
→ A B. This rule defines a treelet S[1](A,B) as

1The motivation of using bracketed symbols (e.g., S[1])
is presented in Hale and Smolensky (2006). For our purpose,
it suffices to say that a bracketed symbol can be considered
as a different instance of the same class which has a unique
pair of children.

20



grammatical. HG assigns a positive Harmony re-
ward to any structure for every grammatical pair of
bindings — e.g., (S[1]/r,A/0) — it contains.
In a network implementation of this HG, these
binary rules are implemented as positive weights
on between-binding connections, so that whenever
one binding is active, it sends positive activation to
its grammatical parent and child binding(s).

In addition to these positive contributions from
grammatical mother/daughter pairs, the Harmonic
Grammar assigns a negative penalty −b to every
filler, where b is the number of edges that the filler
must have in a grammatical structure. If all those
edges are grammatically legal, they will produce
positive binary rewards which by design exactly
cancel the unary penalties, so that an illformed tree
has negative Harmony but a wellformed tree has
zero Harmony — the maximum value. The unary
HG rules are implemented as negative weights on
self-connections of binding units.

The Grammatical Harmony of a set of active
filler/role bindings is simply the sum of the Har-
mony values assigned by all binary and unary HG
rules. In the GSC implementation, Grammatical
Harmony is defined as in Eq. 1.

HG(a;W, ex) =
1

2
a>Wa + ex>a (1)

where a is an activation state vector, W is a weight
matrix implementing the grammatical constraints,
and ex is an external input vector, stimulating
the target terminal binding corresponding to the
present input word. For example, suppose the
model is given a second word ‘B’. Because it is
the second word of a sentence, it must occupy the
second terminal role (in our case, 1).2 Thus, the
component of ex corresponding to binding B/1
has a positive value (a model parameter) and all
the other components have a value of 0.

The goal of the GSC parser is to produce an out-
put that represents a discrete tree (at least to a good
approximation). This turns out to require further
constraints which penalize representations that are
not approximately discrete. The Harmony term in
Eq. 2, in which f and r are filler and role indices,
penalizes representations with multiple symbols
filling the same role: it introduces competition
among bindings in each role. It is called the Com-
petition Constraint. The Harmony term in Eq. 3

2In this study, we consider minimal tree structures so the
three role labels r,0,1 will be enough. To deal with deep
structures, a more elaborated role labeling system is required.

penalizes every binding whose activation value is
not close to either 0 or 1 — this is the crucial Dis-
creteness Constraint, andHQ is Discreteness Har-
mony. Note that the Competition and Discrete-
ness Constraints in collaboration force the model
to choose one filler, with activation 1, in each role.
The representations of discrete trees satisfy both
these constraints3 and fall on what we call the grid
of states: in these states, for each role, the bind-
ings of that role to all symbols all have activa-
tion 0 except one, which has activation 1. The
representation of the tree S[1] [A B] is on the grid,
while an example non-grid state is the one encod-
ing 0.3 S[1] [(0.2 A + 0.5 C) (0.4 B− 0.1 D)]

Finally, to ensure the network state does not
blow up, we also impose the Baseline Constraint
(Eq. 4), which penalizes activation state distant
from a baseline activation state z.

HC(a) = −
∑

r

(1−
∑

f

a2f,r)
2 (2)

HQ(a) = −
∑

r

∑

f

(af,r)
2(1− af,r)2 (3)

HB(a; z) = −
1

2
‖a− z‖2 (4)

The Total Harmony H is the weighted sum of the
four Harmony values in Equations 1 – 4:

H(a) = HG(a) + βHB(a) + cHC(a) + qHQ(a)

where β, c, and q are the coefficients of non-
grammatical constraints. While β and c are fixed,
q changes in time, controlled by an external mech-
anism we do not model here.

The coefficient q governs the strength of the
constraint to have discrete activation values (0 or
1) — that is, the strength of the requirement that
the model commit to symbols being predicted to
be present or absent. The Competition Constraint
prohibits more than one symbol having activation
1 in any given role, so large q values force the
model to choose among competitors. Hence we
refer to q as the commitment level.

2.3 Processing dynamics
The model updates its activation state a as follows:

da = ∇aH(a; q(t))dt+
√

2TdW (5)

whereW is the standard multidimensional Wiener
process and T is the level of noise. ∇aH(a) is the

3There is a special Null Symbol “@” which is bound to
every role that would otherwise be empty.

21



gradient of the total harmony evaluated at a. The
model optimizes the constraints by stochastically
following the gradient, a Brownian motion with
drift given by the gradient of Harmony hence, on
average, increasing Harmony over time.
q(t) is the commitment level at time t. For con-

venience, we assume that q(0) = 0 and q increases
in time because the goal of computation (either in
production or in comprehension) is to build a dis-
crete symbolic structure. We will refer to how q
changes in time as the commitment policy and dis-
cuss it in more detail in Section 3.

3 GSC parser as a probabilistic model

3.1 GSC parser
The GSC parser is an application of the GSC
framework to incremental parsing. It processes a
sentence word-by-word incrementally and passes
through intermediate activation states (or blend
states) to reach a grid point, the encoding of the
parse of the sentence.

Let exk, qk, and ak be the external input vector
corresponding to wk, the commitment level and
the activation state vector after processing the k-th
word. ak is a local optimum if T = 0. For T > 0,
we take ak to be an approximation of the local op-
timum. Let ex0(= 0), q0(= 0), and a0 be the ini-
tial values of the variables before processing the
first word of a sentence. As the parser processes
a length-N sentence, its activation state changes
from a0 through ak to aN . Taking qN to be large,
aN is close to a grid point and is classified into
the nearby grid point by choosing the filler most
strongly activated in each role (the snap-to-the-
grid method). Word processing time for wk is the
time the parser takes to move from ak−1 to ak.

More specifically, the parser processes each
word wk in three phases. Let a

j
k be the activation

state after phase j given word wk; ak = a3k.
• Phase 1a: Update ex from exk−1 to exk.
• Phase 1b: Update a from ak−1(= a3k−1) to
a1k, using H(a, qk−1), allowing settling to
convergence.

• Phase 2: Update a from a1k to a2k by us-
ing H(a, qk−1) → H(a, qk), i.e., increasing
from qk−1 to qk at a constant rate dq/dt = 1.

• Phase 3: Update a from a2k to a3k(= ak),
using H(a, qk), allowing settling to conver-
gence.4

4During phase 1 and phase 3, the model monitors conver-

The processing time of wk is defined as the sum of
the settling times in phase 1 and 3 and the duration
of phase 2.

The parser, in phase 1, integrates a new word
input with its internal language model (or struc-
tural prediction) and, in phase 2, updates the in-
ternal language model via the control of commit-
ment level to make a new structural prediction. In
the proposed model, the effect of instantaneous
surprisal of wk (phase 1) is conceptually distin-
guished from the effect of model update (phase 2)
(c.f., O’Reilly et al., 2013).5

The role of phase 2 is to reduce the number of
grid points reachable from the present activation
state.6 As q increases, the system passes through
a series of bifurcations, the qualitative changes
in the organization of the representation space.
When q passes some critical values qc, more lo-
cal optima emerge. Each local optimum forms
a local hump (basin of attraction) on the Har-
mony surface. Those local optima are separated
by Harmony valleys that block transitions from
one hump to another: the state seeks higher Har-
mony. Metaphorically, the paths to some futures
(corresponding to different parses) are separated
from the present state by these valleys. That is,
some structural hypotheses are rejected (Cho and
Smolensky, 2016).

Given a length-N sentence, we define a com-
mitment policy πN as a sequence of q values
(q0, · · · , qk, · · · , qN ) where qk is the commitment
level after processing the k-th word in a sentence.

gence as follows. Let Hmax(t) be the maximum total har-
mony in a phase up through time t. If Hmax has not been
updated for a certain amount of time (= 0.5 in our simulation
study; Section 5), the phase ends and the following phase be-
gins. During phase 2, q increases at a constant rate dq/dt = 1
so the duration of phase 2 is simply qk − qk−1.

5Alternatively, we can consider a GSC parser with a dis-
crete commitment policy. Given a new word input wk,
the model updates both q and ex discretely from qk−1 and
exk−1 to qk and exk. Note that the surprisal of wk is com-
puted given the updated internal model in this alternative
model. Although this alternative parsed every sentence of a
minimal grammar G (see Section 5) equally well, we prefer
the proposed model to the alternative for the following rea-
son. While exk is given from the environment, an optimal
value of qk given exk must be computed by the parser and
the computation must take time.

6In terms of the number of reachable grid points, entropy
is reduced during phase 2. Because the phase-2 duration
is a monotonically increasing function of the amount of in-
crease in q and q is associated with entropy (roughly speak-
ing, the higher q, the smaller entropy), it is likely that a longer
phase-2 duration is associated with a larger entropy reduc-
tion, which is consistent with the entropy reduction hypoth-
esis (Hale, 2006), although the exact relation between q and
entropy needs further investigation.

22



q0 = 0 and qN is set to qmax; in this setting, the
model is guaranteed to reach a grid point after pro-
cessing the whole sentence (to a close approxima-
tion; the higher qmax, the better the approxima-
tion).

3.2 GSC parser as a probabilistic model
The GSC parser can be related to a structural prob-
abilistic model in the following way. Consider
a prefix Wk = w1 · · ·wk where wk is not the
final word of a sentence. The GSC parser pro-
cesses the prefix under a policy πk = (q0, · · · , qk).
During processingwk, the activation state changes
from ak−1 to ak. If we set qk to qmax, the parser
will be forced to choose a grid point. If T > 0
and the same process is run multiple times, the
parser will choose different grid points (encodings
of S) in different frequencies. In this way, we can
estimate a conditional probability that the parser
reaches S if it starts from a tuple (ak−1, qk−1)
under exk. Because ak−1 is reachable after the
parser has processed Wk−1 under the policy πk,
P (S|ak−1, qk−1, exk) = P (S|Wk, πk). In this
way, we can map a tuple of the activation state and
the control state (a, q) to a probability distribution
over S under the constraint ex. An important spe-
cial case of this, with k = 0, allows us to estimate
the unconditional distribution P (S) by increasing
q from 0 to qmax with ex0 = 0: this amounts
to using the model as a generator as previewed in
Section 1. This estimated distribution is ∗P (S).

3.3 Rational inference
Rational inference with wk is defined as the up-
date from ∗P (S|Wk−1) to ∗P (S|Wk) given ∗P (S)
where ∗ indicates conditional probabilities com-
puted by marginalizing ∗P (S) over cases where
Wk were generated for the first k terminal roles.

The surprisal of wk, − lnP (wk|Wk−1), equals
the KL divergence between ∗P (S|Wk−1) (=
Pk−1) and ∗P (S|Wk) (= Pk) (Levy, 2008), which
is the expected value of (lnPk − lnPk−1).

3.4 Optimal commitment policy
We define a commitment policy π to be optimal
if, for every Wk, it minimizes the KL divergence
Dk = D(

∗P (S|Wk)‖P (S|Wk, πk)). If the Dk are
small, the parser approximates rational inference.

4 Surprisal as Harmony difference

The GSC parser processes a sentence word-by-
word and processes every word in three phases. In

this section, we argue that surprisal can be com-
puted from the intermediate activation states di-
rectly and the value will be approximately propor-
tional to the settling time in phase 1.

As the parser processes the k-th word in phase
1, the activation state changes from a3k−1 to a

1
k

under the influence of exk. During this phase, q
is fixed at qk−1. When q and ex are fixed (all
the other parameters are constant), the equilibrium
probability density follows the Boltzmann distri-
bution (Eq. 6) and the logarithm of the probability
ratio of P (a1k) to P (a

3
k−1) can be computed as in

Eq. 7.

P (a) =
eH(a)/T∫
eH(a′)/Tda′

(6)

lnP (a1k)− lnP (a3k−1) =
1

T
(H(a1k)−H(a3k−1))

(7)
where H is parameterized such that q = qk−1 and
ex = exk. Note that the LHS term of Eq. 7 cor-
responds to the KL divergence D(Pk‖Pk−1) =
E(lnPk − lnPk−1) where E(·) is the expected
value. Thus the surprisal atwk isE(∆H)/T , with
∆H being the Harmony difference between the lo-
cal optima before and after the input update.7

We can estimate the expected settling time tc
from the old to the new optimum by recalling that,
on average, da/dt = ∇aH , so:

∆H =

∫ tc
0

dH(a)

dt
dt =

∫ tc
0
∇aH(a)>

da

dt
dt

≈
∫ tc
0
‖∇aH(a)‖2dt = tc · E(‖∇aH(a)‖2)

where the approximation symbol indicates we ig-
nore the stochastic term in Eq. 5. We approximate
the average gradient with the average of the gra-
dients at the initial and the final activation states
a3k−1 and a

1
k. The gradient at a

1
k is 0 because a

1
k

is the new optimum. The gradient at a3k−1 can be
calculated as follows: ∇aH(a3k−1; qk−1, exk) =
(exk−exk−1) +∇aH(a3k−1; qk−1, exk−1). Note
that the last term is 0 because it was the opti-
mum under exk−1 (i.e., before the input word was
updated) so the initial gradient is simply (exk −
exk−1). It follows that the magnitude of the av-
erage of the initial and final harmony gradients in

7As the parser processes wk, its state changes from
(a3k−1, qk−1) through (a

1
k, qk−1) to (a

3
k, qk), all of which

have the same future under the influence of exk. Thus, under
an optimal commitment policy, Pk = ∗P (S|Wk) ≈
P (S|a3k−1, qk−1, exk) = P (S|a1k, qk−1, exk).
Pk−1 =

∗P (S|Wk−1) ≈ P (S|a3k−2, qk−2, exk−1)
= P (S|a3k−1, qk−1, exk−1).

23



phase 1 is constant for every wk.8 Thus, ∆H is
approximately proportional to the settling time tc.

In sum, surprisal of wk, under an opti-
mal commitment policy, is related to ∆Hk =
H(a1k; qk−1, exk)−H(a3k−1; qk−1, exk) which in
turn is proportional to settling time. In our model,
surprisal has a geometrical meaning: it is the
amount of hill climbing required to reach a new
optimum due to the update of the word input.

5 Case study

We investigated a GSC model implementing a
minimal probabilistic context-free grammar G =
{p1 S[1] → A B, p2 S[2] → A C, p3 S[3] →
D B, p4 S[4] → D C} where pk is the probabil-
ity for the k-th sentence and

∑
k pk = 1. Cho

et al. (2017) used this minimal grammar (with
p1=p2=p3=p4=0.25) to investigate whether and
how the GSC model can deal with computa-
tional challenges arising from local ambiguity.
They argued that this language creates the core
computational problems of incremental process-
ing in the purest form. For example, after pro-
cessing ‘A’ as a first word, an ideal incremen-
tal processing system must reject S[3](D,B)
and S[4](D,C). At the same time, it must
consider both S[1](A,B) and S[2](A,C) as
candidate interpretations without choosing one
over the other too early. They showed that the
GSC model can achieve both computational goals
by regulating commitment level q appropriately.
When q increased too quickly or too slowly,
the model respectively made “garden-path” errors
(e.g., S[2](A,C) for an input sentence ‘AB’;
Bever, 1970; Frazier, 1987) or “local-coherence”
errors (e.g., S[3](D,B) for an input sentence
‘AB’; Tabor et al., 2004; Konieczny, 2005).

We investigated the same grammar G but we
considered the cases where p1 ≥ p2 because
our interest is in the relationship between sur-
prisal and processing times. To introduce a struc-
tural preference for S[1]/(A,B), a small value
∆h ∈ {0, 0.1, 0.2, 0.3} was added to the Gram-
mar Harmony of S[1]-bindings (see Table 1 in
Supplementary Material). (The model parame-
ter ∆h must be distinguished from ∆H discussed
above). pk was empirically estimated by running

8Because wk−1 and wk are presented at two different po-
sitions in a sentence, exk−1 6=exk. In every exk (for k > 0),
only one component has a non-zero value (+2 in the present
study) and all the other components have a value of 0. Thus,
‖exk − exk−1‖ is 2

√
2 for every k > 1; it is 2 for k = 1.

the model as a generator (i.e., with no external in-
put) 800 times.

5.1 Model

Figure 1 presents the GSC model implementing
the grammar. Note that for a different choice of
∆h, the parser implements a different PCFG. In
addition to ∆h, we manipulated T (see Eq. 5) in
two levels (0.01 or 0.1) to see how the effect of
∆h depends on T .

S[1] S[2]

S[4]

S[3]

A

B

C
D

@

A

B

C

D

S[1] S[1]

S[2]

S[2] D

S[3]

S[3]

S[4]

S[4] A
B

C

@

@

-2

-2

-2

-2

-4 + 2∆h

-4
-4

-4 0.1

0

1

r

+2

-0.5

+2

Figure 1: GSC implementation of grammar G via
harmonic grammar rules. Only the implementa-
tion of grammatical constraints (W and ex) are
presented. The thick gray arcs show the grouping
of bindings into different roles. Pairwise connec-
tions are bidirectional and implement binary HG
rules. Every binding unit has a self-connection
(implementing unary HG rules) and their values
are presented near the binding units in role 0. The
same fillers in other roles have the same negative
self-connections as the filler in role 0. The arrow
connecting to the binding A/0 indicates external
input modeling the word input A as a first word.
The colors of the binding units represent partial
activation values (white=0, dark=1).

The GSC parser needs a commitment pol-
icy. Because every sentence of G is two words
long, we considered a commitment policy π =
(q0, q1, q2) where q0 = 0, q2 = qmax = 15, and q1
was a free parameter.

5.2 Investigation of commitment policy

First, we investigated whether the GSC parser can
approximate rational inference as introduced in
Section 3. We considered 6 policies in which q1
was set to one of the values (1, 3, 5, 7, 9, 11).

24



1 3 5 7 9 11
0

0.5

1

1.5

0.01

h
0.0
0.1
0.2
0.3

1 3 5 7 9 11

0.1

Figure 2: Plot of KL divergence of ∗P (S|W2)
from P (S|W2, π2) against q1 in π2 = (0, q1, 15).
Columns correspond to different T conditions.

Every model with a unique combination of
∆h, T , and q1 processed each of four sentences
(S1=AB, S2=AC, S3=DB, S4=DC) word-by-word
200 times. By applying the algorithm introduced
in Section 3, we estimated P (S), P (S|W1, π1),
and P (S|W2, π2). Because processing time was
not of interest here, we excluded phase 1 and phase
3 as the parser processes each word. If dq/dt
in phase 2 is small (dq/dt = 1 in the simula-
tion), the omission of phase 1 and 3 does not
change the result much. An optimal policy was de-
fined as (0, q1, 15) that minimizes the divergence
D(∗P (S|Wk)‖P (S|Wk, πk)) averaged over Wk.

Because π1 was fixed to (q0, q1) = (0, 15),
commitment policy does not play any role for the
estimation of P (S|W1). The mean KL divergence
from P (S|W1) to ∗P (S|W1) across different first
words were small (range=[0.001, 0.021] when
T = 0.01 and [0.001, 0.020] when T = 0.1), sug-
gesting the GSC parser approximates ∗P (S|W1).

For w2, we estimated P (S|W2, π2) under each
of the 6 policies. Figure 2 presents the average
KL divergences of ∗P (S|W2) from P (S|W2, π2)
as a function of ∆h and T . When T = 0.01, the
divergence was 0 when q1 is either 5 or 7 in every
∆h condition, suggesting the model parsed each
of the four sentences accurately. When T = 0.1,
the divergence was minimal (< 0.017) when q1 =
7 for every ∆h condition.9

5.3 Investigation of processing times

To investigate the relationship among harmony
difference, surprisal (assuming rational inference),
and word processing time, we chose the best of the
commitment policies π = (0, 5, 15) for the condi-
tion T = 0.01. Each of four GSC parsers, im-
plementing different PCFGs (due to the different
∆h values), processed each of four sentences 200
times under the best policy. Because the goal now

9See Figures 1 and 2 in Supplementary Material for esti-
mated probability distributions.

0 0.5 1 1.5

1

2

3

4

5
0.0

S1=AB
S2=AC
S3=DB
S4=DC

0 0.5 1 1.5

0.1

0 0.5 1 1.5

0.2

0 0.5 1 1.5

0.3

Figure 3: Scatterplot of w2 processing time
(phase-1 duration) against ∆H . Different panels
correspond to different ∆h conditions. A linear fit
line is overlaid in each panel.

was to measure word processing time, all three
phases were included in this simulation.

In Section 4, we argued that word process-
ing time, more specifically, phase-1 settling time,
must be must be proportional to HarmonyDif-
ference ∆Hk = H(a1k) − H(a3k−1). Figure 3
presents w2 phase-1 duration against ∆H2, sug-
gesting a linear trend.10 In a regression analy-
sis (Model 1A), we modeled w2 phase-1 dura-
tion as a function of SentType (S1=AB, S2=AC,
S3=DB, S4=DC to model processing ofw2 in con-
text of w1), NetID (a unique ID for each GSC
parser with a unique ∆h value), and HarmonyD-
ifference. SentType and NetID were included to
factor out manipulation-irrelevant variance so we
do not report the estimates of their coefficients.11

The coefficient of HarmonyDifference was signif-
icant: b = 1.529, SE = 0.024, t = 64.919,
p < .001, supporting our claim. The adjusted
R2 statistic was 0.787 and AIC = 3037. We
also tested whether ln(∆H) explains the phase-
1 settling time well (Model 1B). The coefficient
of log harmony difference was significant as well:
b = 0.445, SE = 0.008, t = 57.014, p < .001.
The adjusted R2 stastistic was .755 and AIC was
3458, suggesting Model 1A explains processing
time data slightly better.

In Section 3, we presented a method to derive a
probability distribution over parses S from a tuple
of an activation state and a control state q under
ex and a commitment policy π. Based on this, we

10The result was the same when total word processing time
was used instead of phase-1 duration. This is because phase 2
has the same length for every sentence under the same policy
and phase 3 settling time was not systematic in the current T
setting. We present phase-1 duration data because it is theo-
retically related to harmony difference (Section 4).

11We did not include the interaction term between Sent-
Type and NetID because it covaried with harmony difference
and surprisal. Recall that different levels of NetID are asso-
ciated with different ∆h values which in turn were used to
create different surprisal values for different sentence types.

25



0 2 4 6
0

0.5

1

1.5

0.0

S1=AB
S2=AC
S3=DB
S4=DC

0 2 4 6

0.1

0 2 4 6

0.2

0 2 4 6

0.3

Figure 4: Scatterplot of ∆H2 against surprisal of
w2 under rational inference. Different panels cor-
respond to different ∆h conditions.

argued that the harmony difference (scaled by T ),
can be interpreted as the parser-specific surprisal
D(P (S|Wk, πk)‖P (S|Wk−1, πk−1)), which will
be similar to surprisal under rational inference,
D(∗P (S|Wk)‖∗P (S|Wk−1)), under an optimal
commitment policy. Thus, we predict harmony
difference is a function of surprisal under rational
inference under an optimal commitment policy.

Figure 4 presents harmony difference when the
input word was updated fromw1 tow2 against sur-
prisal of w2 under rational inference, suggesting
a non-linear relationship between harmony differ-
ence and surprisal. In a regression analysis (Model
2A), we modeled harmony difference as a lin-
ear function of surprisal, controlling the effects of
SentType and NetID. The coefficient of surprisal
was significant: b = 0.342, SE = 0.006, t =
53.933, p < .001. The adjusted R2 statistic was
0.786 and AIC = −860.4. In another regression
analysis (Model 2B), we modeled harmony differ-
ence as a linear function of ln(surprisal). The coef-
ficient of ln(surprisal) was significant: b = 0.286,
SE = 0.005, t = 60.984, p < .001. The R2

statistic was 0.811 and AIC = −1259, suggest-
ing Model 2B better explains variance in ∆H .

We summarize the result in the following con-
ceptual model: surprisal under rational inference
→ harmony difference (under an optimal commit-
ment policy) → word processing time. In other
words, harmony difference is the parser’s actual
surprisal under a commitment policy. The loga-
rithm trend observed between surprisal and har-
mony difference needs further investigation but we
consider two possibilities. First, the average mag-
nitude of the actual gradient is systematically dif-
ferent depending on surprisal so our approxima-
tion introduces a bias. Second, although we chose
the best commitment policy of 6 candidates, the
chosen policy may not be optimal. Note that we
used the same commitment policy for all four sen-
tences. However, an optimal q1 value may differ

for the first word A and the first word D.

6 General Discussion

An important research question concerning online
sentence processing is to understand the source
of processing difficulty. The surprisal hypothesis
(Hale, 2001; Levy, 2008) provides a simple, intu-
itive, and general explanation at a computational
level: processing difficulty is proportional to sur-
prisal. The underlying mechanism is still beyond
our understanding but researchers have started de-
veloping mechanistic accounts of surprisal (e.g.,
Rasmussen and Schuler, 2017). In this study,
we tried to contribute to this line of research by
providing a mechanism that relates surprisal to
processing time via a stochastic, wellformedness-
optimizing mechanism.

Our effort can be summarized as follows. First,
the GSC model encodes structural uncertainty in
the gradient activation of constituent symbols. An
activation state at a given commitment level is
analogous to the state of a symbolic parser but
contains uncertainty information. It corresponds
to a probability distribution over parses in the fol-
lowing sense: if the system starts from the given
activation state and the given commitment level
and is forced to choose a parse, it will choose dif-
ferent parses (grid points) with different frequen-
cies (see Section 3).

Second, the model updates uncertainty in two
ways: in response to the update of external infor-
mation and via the control of commitment level.
On the one hand, external input update makes the
previously optimal activation state suboptimal so
drives the system to a new optimum. In Section 4,
we claimed that the amount of change required to
travel from the old to the new optimum, harmony
difference, can be interpreted as surprisal. There
we showed why the settling time is proportional
to the harmony difference. On the other hand, the
internal control of commitment level is critical in
holding the amount of structural ambiguity at an
optimal level; this is implied in Figure 2 in Sup-
plementary Material but was not the focus of this
study. See Cho and Smolensky (2016) for the role
of commitment policy.

Third, as we demonstrated in a simulation study
(Section 5), the model can approximate rational
inference under a good commitment policy and
simulate the correlation between surprisal and pro-
cessing time via harmony difference that is the

26



parser’s surprisal under the policy. There we re-
ported the result that surprisal under rational in-
ference explains variance in harmony difference,
which in turn explains variance in processing time.
In other words, surprisal under rational inference
→ harmony difference (the parser’s surprisal) un-
der a commitment policy→ processing time.

An implication of our work is that surprisal
is not a function of linguistic environment only,
which we assume the parser learned well. From
the GSC point of view, both the linguistic envi-
ronment and the parser’s commitment policy de-
termine surprisal of each word input. For optimal
sentence processing, the model needs both types
of knowledge.

A limitation of our work is the simplicity of the
grammar we investigated. We are actively inves-
tigating (with promising preliminary results) the
model’s ability to process more complex cases.
But we point out that finding a good parameter set-
ting and a good commitment policy, which can be
challenging, is a separate issue from understand-
ing the relation between surprisal and processing
time. The present study focuses on the latter and
the claim we made is generalizable.

Probabilistic models (e.g., Hale, 2001; Levy,
2008) provide a computational account of why and
what problems must be solved in online language
comprehension. Dynamical connectionist models
(e.g., Tabor and Hutchins, 2004; Vosse and Kem-
pen, 2009) provide a mechanistic account of why
some sentences (e.g., garden-path sentences) take
longer to process than others. By proposing how
structural uncertainty can be encoded and updated
in a symbolically-interpretable dynamical system
model, our work bridges between these two gen-
eral approaches to modeling human sentence pro-
cessing.

Supplementary Material

Supplementary information is available at
https://goo.gl/uUudqx.

Acknowledgments

We thank Geraldine Legendre, Akira Omaki, Kyle
Rawlins, Ben Van Durme, and Colin Wilson for
their contributions to this work, and gratefully ac-
knowledge the support of NSF INSPIRE grant
BCS-1344269. We thank Paul Tupper for suggest-
ing the form of the HC and HQ functions used in
this work.

References
Thomas G. Bever. 1970. The cognitive basis for lin-

guistic structures. In John R. Hayes, editor, Cogni-
tion and the Development of Language, John Wiley,
New York, pages 279–362.

Marisa Ferrara Boston, John Hale, Reinhold Kliegl,
Umesh Patil, and Shravan Vasishth. 2008. Parsing
costs as predictors of reading difficulty: An evalua-
tion using the Potsdam Sentence Corpus. Journal of
Eye Movement Research 2(1):1–12.

Pyeong Whan Cho, Matthew Goldrick, and Paul
Smolensky. 2017. Incremental parsing in a continu-
ous dynamical system: Sentence processing in Gra-
dient Symbolic Computation. Linguistics Vanguard
3(1). https://doi.org/10.1515/lingvan-2016-0105.

Pyeong Whan Cho and Paul Smolensky. 2016. Bifur-
cation analysis of a Gradient Symbolic Computation
model of incremental processing. In A. Papafragou,
D. Grodner, D. Mirman, and J. C. Trueswell, editors,
Proceedings of the 38th Annual Conference of the
Cognitive Science Society. Cognitive Science Soci-
ety, Austin, TX.

Vera Demberg and Frank Keller. 2008. Data from eye-
tracking corpora as evidence for theories of syntactic
processing complexity. Cognition 109(2):193–210.
https://doi.org/10.1016/j.cognition.2008.07.008.

Lyn Frazier. 1987. Sentence processing: A tutorial re-
view. In M. Coltheart, editor, Attention and Perfor-
mance XII: The Psychology of Reading, Lawrence
Erlbaum Associates, pages 559–586.

John Hale. 2001. A probabilistic Earley parser
as a psycholinguistic model. In Proceedings
of the Second Meeting of the North Ameri-
can Chapter of the Association for Computa-
tional Linguistics on Language Technologies.
Association for Computational Linguistics,
Stroudsburg, PA, USA, NAACL ’01, pages
1–8. https://doi.org/10.3115/1073336.1073357.

John Hale. 2006. Uncertainty about the rest of the sen-
tence. Cognitive Science 30(4):643–672.

John Hale and Paul Smolensky. 2006. Harmonic
Grammars and harmonic parsers for formal lan-
guages. In Paul Smolensky and Géraldine Legendre,
editors, The Harmonic Mind: From Neural Compu-
tation to Optimality-Theoretic Grammar. Volume I:
Cognitive Architecture, The MIT Press, pages 393–
416.

Daniel Jurafsky. 1996. A probabilistic model
of lexical and syntactic access and disam-
biguation. Cognitive Science 20(2):137–194.
https://doi.org/10.1016/S0364-0213(99)80005-6.

Lars Konieczny. 2005. The psychological reality of lo-
cal coherences in sentence processing. In Proceed-
ings of the 27th Annual Conference of the Cognitive
Science Society. pages 1178–1183.

27



Roger Levy. 2008. Expectation-based syntactic
comprehension. Cognition 106(3):1126–1177.
https://doi.org/10.1016/j.cognition.2007.05.006.

Jill X. O’Reilly, Urs Schüffelgen, Steven F. Cuell, Tim-
othy E. J. Behrens, Rogier B. Mars, and Matthew
F. S. Rushworth. 2013. Dissociable effects of
surprise and model update in parietal and ante-
rior cingulate cortex. Proceedings of the Na-
tional Academy of Sciences 110(38):E3660–E3669.
https://doi.org/10.1073/pnas.1305373110.

Nathan E. Rasmussen and William Schuler. 2017.
Left-Corner Parsing With Distributed Associa-
tive Memory Produces Surprisal and Local-
ity Effects. Cognitive Science pages n/a–n/a.
https://doi.org/10.1111/cogs.12511.

Nathaniel J. Smith and Roger Levy. 2013. The
effect of word predictability on reading time
is logarithmic. Cognition 128(3):302–319.
https://doi.org/10.1016/j.cognition.2013.02.013.

Paul Smolensky. 1986. Neural and conceptual interpre-
tation of PDP models. In Parallel Distributed Pro-
cessing: Explorations in the Microstructure of Cog-
nition, Vol. 2: Psychological and Biological Models,
MIT Press, Cambridge, MA, pages 390–431.

Paul Smolensky. 1990. Tensor product variable bind-
ing and the representation of symbolic structures
in connectionist systems. Artificial Intelligence
46(1):159–216. https://doi.org/10.1016/0004-
3702(90)90007-M.

Paul Smolensky, Matthew Goldrick, and Donald
Mathis. 2014. Optimization and quantization in gra-
dient symbol systems: A framework for integrating
the continuous and the discrete in cognition. Cogni-
tive Science 38(6):1102–1138.

Paul Smolensky and Géraldine Legendre, editors.
2006. The Harmonic Mind: From Neural Compu-
tation to Optimality-Theoretic Grammar. Volume 1:
Cognitive Architecture. The MIT Press, Cambridge,
MA.

Whitney Tabor, Bruno Galantucci, and Daniel Richard-
son. 2004. Effects of merely local syntac-
tic coherence on sentence processing. Jour-
nal of Memory and Language 50(4):355–370.
https://doi.org/10.1016/j.jml.2004.01.001.

Whitney Tabor and Sean Hutchins. 2004. Evidence
for self-organized sentence processing: Digging-
in effects. Journal of Experimental Psychology:
Learning, Memory, and Cognition 30(2):431–450.
https://doi.org/10.1037/0278-7393.30.2.431.

Theo Vosse and Gerard Kempen. 2009. The Unifi-
cation Space implemented as a localist neural net:
Predictions and error-tolerance in a constraint-based
parser. Cognitive Neurodynamics 3(4):331–346.
https://doi.org/10.1007/s11571-009-9094-0.

28


