Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 152–160,

Beijing, August 2010

152

Exploiting Background Knowledge for Relation Extraction

Yee Seng Chan and Dan Roth

University of Illinois at Urbana-Champaign

{chanys,danr}@illinois.edu

Abstract

Relation extraction is the task of recog-
nizing semantic relations among entities.
Given a particular sentence supervised ap-
proaches to Relation Extraction employed
feature or kernel functions which usu-
ally have a single sentence in their scope.
The overall aim of this paper is to pro-
pose methods for using knowledge and re-
sources that are external to the target sen-
tence, as a way to improve relation ex-
traction. We demonstrate this by exploit-
ing background knowledge such as rela-
tionships among the target relations, as
well as by considering how target rela-
tions relate to some existing knowledge
resources. Our methods are general and
we suggest that some of them could be ap-
plied to other NLP tasks.

1 Introduction
Relation extraction (RE) is the task of detecting
and characterizing semantic relations expressed
between entities in text. For instance, given the
sentence “Cone, a Kansas City native, was origi-
nally signed by the Royals and broke into the ma-
jors with the team.”, one of the relations we might
want to extract is the employment relation between
the pair of entity mentions “Cone” and “Royals”.
RE is important for many NLP applications such
as building an ontology of entities, biomedical in-
formation extraction, and question answering.

Prior work have employed diverse approaches
towards resolving the task. One approach is to
build supervised RE systems using sentences an-
notated with entity mentions and predeﬁned target

relations. When given a new sentence, the RE sys-
tem has to detect and disambiguate the presence of
any predeﬁned relations that might exist between
each of the mention pairs in the sentence. In build-
ing these systems, researchers used a wide variety
of features (Kambhatla, 2004; Zhou et al., 2005;
Jiang and Zhai, 2007). Some of the common fea-
tures used to analyze the target sentence include
the words appearing in the sentence, their part-of-
speech (POS) tags, the syntactic parse of the sen-
tence, and the dependency path between the pair
of mentions. In a related line of work, researchers
have also proposed various kernel functions based
on different structured representations (e.g. de-
pendency or syntactic tree parses) of the target
sentences (Bunescu and Mooney, 2005; Zhou et
al., 2007; Zelenko et al., 2003; Zhang et al.,
2006). Additionally, researchers have tried to au-
tomatically extract examples for supervised learn-
ing from resources such as Wikipedia (Weld et al.,
2008) and databases (Mintz et al., 2009), or at-
tempted open information extraction (IE) (Banko
et al., 2007) to extract all possible relations.

In this work, we focus on supervised RE. In
prior work, the feature and kernel functions em-
ployed are usually restricted to being deﬁned on
the various representations (e.g. lexical or struc-
tural) of the target sentences. However, in recog-
nizing relations, humans are not thus constrained
and rely on an abundance of implicit world knowl-
edge or background information. What quantiﬁes
as world or background knowledge is rarely ex-
plored in the RE literature and we do not attempt
to provide complete nor precise deﬁnitions in this
paper. However, we show that by considering the
relationship between our relations of interest, as

153

well as how they relate to some existing knowl-
edge resources, we improve the performance of
RE. Speciﬁcally, the contributions of this paper
are the following:

• When our relations of interest are clustered
or organized in a hierarchical ontology, we
show how to use this information to improve
performance. By deﬁning appropriate con-
straints between the predictions of relations
at different levels of the hierarchy, we obtain
globally coherent predictions as well as im-
proved performance.

• Coreference is a generic relationship that
might exists among entity mentions and we
show how to exploit this information by as-
suming that co-referring mentions have no
other interesting relations. We capture this
intuition by using coreference information to
constraint the predictions of a RE system.

• When characterizing the relationship be-
tween a pair of mentions, one can use a
large encyclopedia such as Wikipedia to in-
fer more knowledge about the two mentions.
In this work, after probabilistically map-
ping mentions to their respective Wikipedia
pages, we check whether the mentions are
related. Another generic relationship that
might exists between a pair of mentions is
whether they have a parent-child relation and
we use this as additional information.

• The sparsity of features (especially lexical
features) is a common problem for super-
vised systems.
In this work, we show that
one can make fruitful use of unlabeled data,
by using word clusters automatically gath-
ered from unlabeled texts as a way of gen-
eralizing the lexical features.

• We combine the various relational predic-
tions and background knowledge through a
global inference procedure, which we for-
malize via an Integer Linear Programming
(ILP) framework as a constraint optimization
problem (Roth and Yih, 2007). This allows
us to easily incorporate various constraints
that encode the background knowledge.

Roth and Yih (2004) develop a relation extrac-
tion approach that exploits constraints among en-
tity types and the relations allowed among them.
We extend this view signiﬁcantly, within a simi-
lar computational framework, to exploit relations
among target relations, background information
and world knowledge, as a way to improve rela-
tion extraction and make globally coherent predic-
tions.

In the rest of this paper, we ﬁrst describe the
features used in our basic RE system in Section 2.
We then describe how we make use of background
knowledge in Section 3. In Section 4, we show
our experimental results and perform analysis in
Section 5. In Section 6, we discuss related work,
before concluding in Section 7.

2 Relation Extraction System
In this section, we describe the features used in
our basic relation extraction (RE) system. Given
a pair of mentions m1 and m2 occurring within
the same sentence, the system predicts whether
any of the predeﬁned relation holds between the
two mentions. Since relations are usually asym-
metric in nature, hence in all of our experi-
ments, unless otherwise stated, we distinguish be-
tween the argument ordering of the two mentions.
For instance, we consider m1:emp-org:m2 and
m2:emp-org:m1 to be distinct relation types.

Most of the features used in our system are
based on the work in (Zhou et al., 2005). In this
paper, we propose some new collocation features
inspired by word sense disambiguation (WSD).
We give an overview of the features in Table 1.
Due to space limitations, we only describe the col-
location features and refer the reader to (Zhou et
al., 2005) for the rest of the features.

2.1 Collocation Features
Following (Zhou et al., 2005), we use a single
word to represent the head word of a mention.
Since single words might be ambiguous or poly-
semous, we incorporate local collocation features
which were found to be very useful for WSD.
Given the head word hwm of a mention m, the
collocation feature Ci,j refers to the sequence of
tokens in the immediate context of hwm. The off-
sets i and j denote the position (relative to hwm)

154

Collocations C−1,−1, C+1,+1
Structural

Category
Lexical

M-lvl
and
E-type

Dependency

Feature
hw of m1
hw of m2
hw of m1, m2
BOW in m1
BOW in m2
single word between m1, m2
BOW in between m1, m2
bigrams in between m1, m2
ﬁrst word in between m1, m2
last word in between m1, m2

C−2,−1, C−1,+1, C+1,+2
m1-in-m2
m2-in-m1
#mentions between m1, m2
any word between m1, m2
M-lvl of m1, m2
m1, m2 E-maintype
m1, m2 E-subtype
m1, m2 M-lvl and E-maintype
m1, m2 M-lvl and E-subtype
m1, m2 E-subtype and m1-in-m2
m1, m2 E-subtype and m2-in-m1
path between m1, m2
bag-of dep labels between m1, m2
hw of m1 and dep-parent
hw of m2 and dep-parent

Table 1: Features in the basic RE system. The
abbreviations are as follows. hw: head word, M-
lvl: mention level, E-type: entity type, dep-parent:
the word’s parent in the dependency tree.

of the ﬁrst and last token of the sequence respec-
tively. For instance, C−1,+1 denotes a sequence of
three tokens, consisting of the single token on the
immediate left of hwm, the token hwm itself, and
the single token on the immediate right of hwm.
For each mention, we extract 5 features: C−1,−1,
C+1,+1, C−2,−1, C−1,+1, and C+1,+2.
3 Using Background Knowledge

Now we describe how we inject additional knowl-
edge into our relation extraction system.

3.1 Hierarchy of Relations
When our relations of interest are arranged in a
hierarchical structure, one should leverage this in-
formation to learn more accurate relation predic-
tors. For instance, assume that our relations are
arranged in a two-level hierarchy and we learn
two classiﬁers, one for disambiguating between
the ﬁrst level coarse-grained relations, and an-
other for disambiguating between the second level

ﬁne-grained relations.

Since there are a lot more ﬁne-grained relation
types than coarse-grained relation types, we pro-
pose using the coarse-grained predictions which
should intuitively be more reliable, to improve the
ﬁne-grained predictions. We show how to achieve
this through deﬁning appropriate constraints be-
tween the coarse-grained and ﬁne-grained rela-
tions, which can be enforced through the Con-
strained Conditional Models framework (aka ILP)
(Roth and Yih, 2007; Chang et al., 2008). Due
to space limitations, we refer interested readers
to the papers for more information on the CCM
framework.

By doing this, not only are the predictions of
both classiﬁers coherent with each other (thus ob-
taining better predictions from both classiﬁers),
but more importantly, we are effectively using the
(more reliable) predictions of the coarse-grained
classiﬁer to constrain the predictions of the ﬁne-
grained classiﬁer. To the best of our knowledge,
this approach for RE is novel.

In this paper, we work on the NIST Automatic
Content Extraction (ACE) 2004 corpus. ACE de-
ﬁnes several coarse-grained relations such as em-
ployment/membership, geo-political entity (GPE)
afﬁliation, etc. Each coarse-grained relation is
further reﬁned into several ﬁne-grained relations1
and each ﬁne-grained relation has a unique par-
ent coarse-grained relation. For instance, the ﬁne-
grained relations employed as ordinary staff, em-
ployed as an executive, etc. are children relations
of employment/membership.

Let mi and mj denote a pair of mentions i and
j drawn from a document containing N mentions.
Let Ri,j denote a relation between mi and mj, and
let R = {Ri,j}, where 1≤i, j≤N ; i6=j denote the
set of relations in the document. Also, we denote
the set of predeﬁned coarse-grained relation types
and ﬁne-grained relation types as LRc and LRf
respectively. Since there could possibly be no re-
lation between a mention pair, we add the null la-
bel to LRc and LRf , allowing our classiﬁers to
predict null for Ri,j. Finally, for a ﬁne-grained re-
lation type rf, let V(rf ) denote its parent coarse-
grained relation type.

1With the exception of the Discourse coarse-grained re-

lation.

155

We learn two classiﬁers, one for disambiguat-
ing between the coarse-grained relations and one
for disambiguating between the ﬁne-grained rela-
tions. Let θc and θf denote the feature weights
learned for predicting coarse-grained and ﬁne-
grained relations respectively. Let pR(rc) =
logPc(rc|mi, mj; θc) be the log probability that
relation R is predicted to be of coarse-grained
relation type rc.
let pR(rf ) =
logPf (rf|mi, mj; θf ) be the log probability that
relation R is predicted to be of ﬁne-grained re-
lation type rf. Let xhR,rci be a binary variable
which takes on the value of 1 if relation R is la-
beled with the coarse-grained label rc. Similarly,
let yhR,rfi be a binary variable which takes on the
value of 1 if relation R is labeled with the ﬁne-
grained label rf. Our objective function is then:

Similarly,

maxXR∈R Xrc∈LRc
+XR∈R Xrf∈LRf

pR(rc) · xhR,rci

pR(rf ) · yhR,rfi

subject to the following constraints:

Xrc∈LRc
Xrf∈LRf

xhR,rci = 1 ∀R ∈ R

yhR,rfi = 1 ∀R ∈ R

xhR,rci ∈ {0, 1} ∀R ∈ R, rc ∈ LRc
yhR,rfi ∈ {0, 1} ∀R ∈ R, rf ∈ LRf

(1)

(2)

(3)

(4)
(5)

Equations (2) and (3) require that each relation
can only be assigned one coarse-grained label and
one ﬁne-grained label. Equations (4) and (5) indi-
cate that xhR,rci and yhR,rfi are binary variables.
Two more constraints follow:

xhR,rci ≤

X{rf∈LRf|V(rf )=rc}

yhR,rfi

∀R ∈ R , rc ∈ LRc

(6)
yhR,rfi ≤ xhR,V(rf )i ∀R ∈ R, rf ∈ LRf (7)
The logical form of Equation (6) can be written
as: xhR,rci ⇒ yhR,rf1i ∨ yhR,rf2i . . . ∨ yhR,rfni,
where rf1, rf2, . . . , rfn are (child) ﬁne-grained
relations of the coarse-grained relation rc. This
states that if we assign rc to relation R, then we
must also assign to R a ﬁne-grained relation rf

art:

Ei ∈{gpe, org, per},
Ej ∈{fac, gpe, veh, wea}
emp-org: Ei ∈{gpe, org, per},
Ej ∈{gpe, org, per}
gpe-aff:
Ei ∈{gpe, org, per},
Ej ∈{gpe, loc}
other-aff: Ei ∈{gpe, org, per},
Ej ∈{gpe, loc}
per-soc:
Ei ∈{per}, Ej ∈{per}

Table 2: Entity type constraints.

which is a child of rc. The logical form of Equa-
tion (7) can be written as: yhR,rfi ⇒ xhR,V(rf )i.
This captures the inverse relation and states that
if we assign rf to R, then we must also assign to
R the relation type V(rf ), which is the parent of
rf. Together, Equations (6) and (7) constrain the
predictions of the coarse-grained and ﬁne-grained
classiﬁers to be coherent with each other. Finally,
we note that one could automatically translate log-
ical constraints into linear inequalities (Chang et
al., 2008).

This method is general and is applicable to
other NLP tasks where a hierarchy exists, such
as WSD and question answering. For instance,
in WSD, one can predict coarse-grained and ﬁne-
grained senses using suitably deﬁned sense inven-
tories and then perform inference via ILP to obtain
coherent predictions.

3.2 Entity Type Constraints

Each mention in ACE-2004 is annotated with one
of seven coarse-grained entity types: person (per),
organization (org), location (loc), geo-political en-
tity (gpe), facility (fac), vehicle (veh), and weapon
(wea).

Roth and Yih (2007) had shown that entity type
information is useful for constraining the possible
labels that a relation R can assume. For instance,
both mentions involved in a personal/social re-
lation must be of entity type per.
In this work,
we gather such information from the ACE-2004
documentation and inject it as constraints (on the
coarse-grained relations) into our system. Due
to space limitations, we do not state the con-
straint equations or objective function here, but
we list the entity type constraints we imposed for
each coarse-grained relation mi-R-mj in Table

156

22, where Ei (Ej) denotes the allowed set of en-
tity types for mention mi (mj). Applying the en-
tity type information improves the predictions of
the coarse-grained classiﬁer and this in turn could
improve the predictions of the ﬁne-grained classi-
ﬁer.

3.3 Using Coreference Information
We can also utilize the coreference relations
among entity mentions. Assuming that we know
mentions mi and mj are coreferent with each
other, then there should be no relation between
them3. Let zhi,ji be a binary variable which takes
on the value of 1 if mentions mi and mj are coref-
erent, and 0 if they are not. When zhi,ji=1, we cap-
ture the above intuition with the following con-
straints:

zhi,ji ≤ xhRi,j ,nulli
zhi,ji ≤ yhRi,j ,nulli

(8)
(9)

which can be written in logical form as: zhi,ji ⇒
xhRi,j ,nulli, and zhi,ji ⇒ yhRi,j ,nulli. We add the
following to our objective function in Equation
(1):

Xmi,mj∈m2

cohi,ji · zhi,ji + ¯cohi,ji · (1− zhi,ji) (10)

where m is the set of mentions in a document,
cohi,ji and ¯cohi,ji are the log probabilities of pre-
dicting that mi and mj are coreferent and not
coreferent respectively. In this work, we assume
we are given coreference information, which is
available from the ACE annotation.

3.4 Using Knowledge from Wikipedia
We propose two ways of using Wikipedia to
gather features for relation extraction. Wikipedia
is a huge online encyclopedia and mainly contains
articles describing entities or concepts.

The ﬁrst intuition is that if we are able to cor-
rectly map a pair of mentions mi and mj to their
corresponding Wikipedia article (assuming they

2We do not impose entity type constraints on the coarse-

grained relations disc and phys.

3In this work, we assume that no relations are reﬂexive.
After the experiments in this paper are performed, we ver-
iﬁed that in the ACE corpus we used, less than 1% of the
relations are reﬂexive.

are represented in Wikipedia), we could use the
content on their Wikipedia pages to check whether
they are related.

In this work, we use a Wiki system (Rati-
nov et al., 2010) which performs context-sensitive
mapping of mentions to Wikipedia pages.
In
their work, the authors ﬁrst identify phrases or
mentions that could be mapped. The correct
Wikipedia article for each mention is then prob-
abilistically predicted using a combination of fea-
tures based on Wikipedia hyperlink structure, se-
mantic coherence, etc. The authors’ own evalua-
tion results indicate that the performance of their
system ranges from 70–80%. When given a pair
of mentions and the system returns the Wikipedia
page for either one of the mentions, we introduce
a feature:

w1(mi, mj) =

1,

if Ami(mj)
or Amj (mi)

0, otherwise

where Ami(mj) returns true if the head extent
of mj is found (via simple string matching) in
the predicted Wikipedia article of mi. The in-
terpretation of Amj (mi) is similar. We introduce
a new feature into the RE system by combining
w1(mi, mj) with mi, mj E-maintype (deﬁned as
in Table 1).

The second feature based on Wikipedia is as
follows. It will be useful to check whether there
is any parent-child relationship between two men-
tions. Intuitively, this will be useful for recogniz-
ing several relations such as physical part-whole
(e.g. a city is part of a state), subsidiary (a com-
pany is a child-company of another), citizenship
(a person is a citizen of a country), etc.

Given a pair of mentions mi and mj, we use a
Parent-Child system (Do and Roth, 2010) to pre-
dict whether they have a parent-child relation. To
achieve this, the system ﬁrst gathers all Wikipedia
articles that are related to mi and mj. It then uses
the words in these pages and the category ontol-
ogy of Wikipedia to make its parent-child predic-
tions, while respecting certain deﬁned constraints.
In this work, we use its prediction as follows:

w2(mi, mj) =‰ 1,

if parent-child(mi, mj)

0, otherwise

157

Figure 1: An example of Brown word cluster hi-
erarchy from (Koo et al., 2008).

where we combine w2(mi, mj) with mi, mj E-
maintype, introducing this as a new feature into
our RE system.

3.5 Using Word Clusters
An inherent problem faced by supervised systems
is that of data sparseness. To mitigate such is-
sues in the lexical features, we use word clusters
which are automatically generated from unlabeled
texts. In this work, we use the Brown clustering
algorithm (Brown et al., 1992), which has been
shown to improve performance in various NLP
applications such as dependency parsing (Koo et
al., 2008), named entity recognition (Ratinov and
Roth, 2009), and relation extraction (Boschee et
al., 2005). The algorithm performs a hierarchical
clustering of the words and represents them as a
binary tree.

Each word is uniquely identiﬁed by its path
from the root and every path is represented with
a bit string. Figure 1 shows an example clustering
where the maximum path length is 3. By using
path preﬁxes of different lengths, one can obtain
clusterings at different granularity. For instance,
using preﬁxes of length 2 will put apple and pear
into the same cluster, Apple and IBM into the same
cluster, etc. In our work, we use clusters gener-
ated from New York Times text and simply use a
path preﬁx of length 10. When Brown clusters are
used in our system, all lexical features consisting
of single words will be duplicated. For instance,
for the feature hw of m1, one new feature which is
the length-10 bit string path representing the orig-
inal lexical head word of m1, will be introduced
and presented to the classiﬁer as a string feature.

4 Experiments

used

the ACE-2004

We
(catalog
LDC2005T09 from the Linguistic Data Con-
sortium) to conduct our experiments. ACE-2004

dataset

deﬁnes 7 coarse-grained relations and 23 ﬁne-
grained relations.
In all of our experiments,
unless otherwise stated, we explicitly model the
argument order (of the mentions) when asked
to disambiguate the relation between a pair of
mentions. Hence, we built our coarse-grained
classiﬁer with 15 relation labels to disambiguate
between (two for each coarse-grained relation
type and a null label when the two mentions are
not related). Likewise, our ﬁne-grained classiﬁer
has to disambiguate between 47 relation labels.
In the dataset, relations do not cross sentence
boundaries.

For our experiments, we trained regularized av-
eraged perceptrons (Freund and Schapire, 1999),
implemented within the Sparse Network of Win-
now framework (Carlson et al., 1999), one for pre-
dicting the coarse-grained relations and another
for predicting the ﬁne-grained relations. Since the
dataset has no split of training, development, and
test sets, we followed prior work (Jiang and Zhai,
2007) and performed 5-fold cross validation to ob-
tain our performance results. For simplicity, we
used 5 rounds of training and a regularization pa-
rameter of 1.5 for the perceptrons in all our exper-
iments. Finally, we concentrate on the evaluation
of ﬁne-grained relations.

4.1 Performance of the Basic RE system

As a gauge on the performance of our basic rela-
tion extraction system BasicRE using only the fea-
tures described in Section 2, we compare against
the state-of-the-art feature-based RE system of
Jiang and Zhai (2007). However, we note that in
that work, the authors performed their evaluation
using undirected coarse-grained relations. That is,
they do not distinguish on argument order of men-
tions and the classiﬁer has to decide among 8 re-
lation labels (7 coarse-grained relation types and a
null label). Performing 5-fold cross validation on
the news wire (nwire) and broadcast news (bnews)
corpora in the ACE-2004 dataset, they reported a
F-measure of 71.5 using a maximum entropy clas-
siﬁer4. Evaluating BasicRE on the same setting,

4After they heuristically performed feature selection and
applied the heuristics giving the best evaluation performance,
they obtained a result of 72.9.

158

All nwire

10% of nwire

50.5

51.0

Rec% Pre% F1% Rec% Pre% F1%
Features
29.0
49.9
31.0
33.2
BasicRE
+1.2 +1.1
+Hier
+1.3 +1.3 +1.3 +1.1
+3.5 +3.4
+Hier+relEntC +1.5 +2.0 +1.8 +3.3
+1.0 +0.5
+Coref
+1.4 +0.7 −0.1
∼
+0.2 +1.9 +1.0 +1.5
+Wiki
+2.5 +2.0
+Cluster
+3.9 +1.7
−0.2 +3.2 +1.4 −0.7
+1.5 +6.7 +3.9 +4.7 +10.2 +7.6
+ALL

Table 3: BasicRE gives the performance of our basic RE system on predicting ﬁne-grained relations,
obtained by performing 5-fold cross validation on only the news wire corpus of ACE-2004. Each sub-
sequent row +Hier, +Hier+relEntC, +Coref, +Wiki, and +Cluster gives the individual contribution
from using each knowledge. The bottom row +ALL gives the performance improvements from adding
+Hier+relEntC+Coref+Wiki+Cluster. ∼ indicates no change in score.

we obtained a competitive F-measure of 71.25.

4.2 Experimental Settings for Evaluating

Fine-grained Relations

Two of our knowledge sources, the Wiki system
described in Section 3.4 and the word clusters de-
scribed in Section 3.5, assume inputs of mixed-
cased text. We note that the bnews corpus of
ACE-2004 is entirely in lower-cased text. Hence,
we use only the nwire corpus for our experiments
here, from which we gathered 28,943 relation in-
stances and 2,226 of those have a valid (non-null)
relation6.

We also propose the following experimental
setting. First, since we made use of coreference
information, we made sure that while performing
our experiments, all instances from the same doc-
ument are either all used as training data or all
used as test data. Prior work in RE had not en-
sured this, but we argue that this provides a more
realistic setting. Our own experiments indicate
that this results in a 1-2% lower performance on
ﬁne-grained relations.

Secondly, prior work calculate their perfor-
mance on relation extraction at the level of men-
tions. That is, each mention pair extracted is
scored individually. An issue with this way of
scoring on the ACE corpus is that ACE annota-

5Using 10 rounds of training and a regularization param-
eter of 2.5 improves the result to 72.2. In general, we found
that more rounds of training and a higher regularization value
beneﬁts coarse-grained relation classiﬁcation, but not ﬁne-
grained relation classiﬁcation.

6The number of relation instances in the nwire and bnews

corpora are about the same.

tors rarely duplicate a relation link for coreferent
mentions. For instance, assume that mentions mi,
mj, and mk exist in a given sentence, mentions
mi and mj are coreferent, and the annotator es-
tablishes a particular relation type r between mj
and mk. The annotator will not usually duplicate
the same relation r between mi and mk and thus
the label between these two mentions is then null.
We are not suggesting that this is an incorrect ap-
proach, but clearly there is an issue since an im-
portant goal of performing RE is to populate or
build an ontology of entities and establish the re-
lations existing among the entities. Thus, we eval-
uate our performance at the entity-level.7 That is,
given a pair of entities, we establish the set of re-
lation types existing between them, based on their
mention annotations. Then we calculate recall
and precision based on these established relations.
Of course, performing such an evaluation requires
knowledge about the coreference relations and in
this work, we assume we are given this informa-
tion.

4.3 Knowledge-Enriched System
Evaluating our system BasicRE (trained only on
the features described in Section 2) on the nwire
corpus, we obtained a F1 score of 50.5, as shown
in Table 3. Next, we exploited the relation hier-
archy as in Section 3.1 and obtained an improve-
ment of 1.3, as shown in the row +Hier. Next,
we added the entity type constraints of Section

7Our experiments indicate that performing the usual eval-
uation on mentions gives similar performance ﬁgures and the
trend in Table 3 stays the same.

159

3.2. Remember that these constraints are imposed
on the coarse-grained relations. Thus, they would
only affect the ﬁne-grained relation predictions if
we also exploit the relation hierarchy. In the ta-
ble, we show that all the background knowledge
helped to improve performance, providing a to-
tal improvement of 3.9 to our basic RE system.
Though the focus of this work is on ﬁne-grained
relations, our approach also improves the perfor-
mance of coarse-grained relation predictions. Ba-
sicRE obtains a F1 score of 65.3 on coarse-grained
relations and exploiting background knowledge
gives a total improvement of 2.9.

5 Analysis

We explore the situation where we have very little
training data. We assume during each cross val-
idation fold, we are given only 10% of the train-
ing data we originally had. Previously, when per-
forming 5-fold cross validation on 2,226 valid re-
lation instances, we had about 1780 as training
instances in each fold. Now, we assume we are
only given about 178 training instances in each
fold. Under this condition, BasicRE gives a F1
score of 31.0 on ﬁne-grained relations. Adding all
the background knowledge gives an improvement
of 7.6 and this represents an error reduction of
39% when measured against the performance dif-
ference of 50.5 (31.0) when we have 1780 train-
ing instances vs.
178 training instances. On
the coarse-grained relations, BasicRE gives a F1
score of 51.1 and exploiting background knowl-
edge gives a total improvement of 5.0.

We also tabulated the list of ﬁne-grained re-
lations that improved by more than 1 F1 score
when we incorporated +Wiki, on the experiment
using all of nwire data: phys:near (physically
near), other-aff:ideology (ideology afﬁliation),
art:user-or-owner (user or owner of artifact), per-
soc:business (business relationship), phys:part-
whole (physical part-whole), emp-org:subsidiary
(organization subsidiary), and gpe-aff:citizen-or-
resident (citizen or resident). Most of these intu-
itively seemed to be information one would ﬁnd
being mentioned in an encyclopedia.

6 Related Work

Few prior work has explored using background
knowledge to improve relation extraction perfor-
mance. Zhou et al.
(2008) took advantage of
the hierarchical ontology of relations by propos-
ing methods customized for the perceptron learn-
ing algorithm and support vector machines.
In
contrast, we propose a generic way of using the
relation hierarchy which at the same time, gives
globally coherent predictions and allows for easy
injection of knowledge as constraints. Recently,
Jiang (2009) proposed using features which are
common across all relations. Her method is com-
plementary to our approach, as she does not con-
sider information such as the relatedness between
different relations. On using semantic resources,
Zhou et al.
(2005) gathered two gazettes, one
containing country names and another containing
words indicating personal relationships. In relat-
ing the tasks of RE and coreference resolution, Ji
et al. (2005) used the output of a RE system to
rescore coreference hypotheses. In our work, we
reverse the setting and explore using coreference
to improve RE.

7 Conclusion

In this paper, we proposed a broad range of meth-
ods to inject background knowledge into a rela-
tion extraction system. Some of these methods,
such as exploiting the relation hierarchy, are gen-
eral in nature and could be easily applied to other
NLP tasks. To combine the various relation pre-
dictions and knowledge, we perform global infer-
ence within an ILP framework. Besides allowing
for easy injection of knowledge as constraints, this
ensures globally coherent models and predictions.

Acknowledgements This research was partly
sponsored by Air Force Research Laboratory
(AFRL) under prime contract no. FA8750-09-
C-0181. We thank Ming-Wei Chang and James
Clarke for discussions on this research.

References
Banko, Michele, Michael J. Cafarella, Stephen Soder-
land, Matthew Broadhead, and Oren Etzioni. 2007.

160

Open information extraction from the web. In Pro-
ceedings of IJCAI-07, pages 2670–2676.

Boschee, Elizabeth, Ralph Weischedel, and Alex Za-
manian. 2005. Automatic information extraction.
In Proceedings of the International Conference on
Intelligence Analysis.

Brown, Peter F., Vincent J. Della Pietra, Peter V. deS-
ouza, Jenifer C. Lai, and Robert L. Mercer. 1992.
Class-based n-gram models of natural language.
Computational Linguistics, 18(4):467–479.

Bunescu, Razvan C. and Raymond J. Mooney. 2005.
A shortest path dependency kernel for relation ex-
traction. In Proceedings of HLT/EMNLP-05, pages
724–731.

Carlson, Andrew J., Chad M. Cumby, Jeff L. Rosen,
and Dan Roth. 1999. The SNoW learning archi-
tecture. Technical Report UIUCDCS-R-99-2101,
UIUC Computer Science Department, May.

Chang, Ming-Wei, Lev Ratinov, Nicholas Rizzolo, and
Dan Roth. 2008. Learning and inference with con-
straints.
In Proceedings of AAAI-08, pages 1513–
1518.

2010.

Do, Quang and Dan Roth.

On-the-
ﬂy constraint-based taxonomic relation identiﬁca-
tion.
Technical report, University of Illinois.
http://L2R.cs.uiuc.edu/∼danr/Papers/DoRo10.pdf.
Freund, Yoav and Robert E. Schapire. 1999. Large
margin classiﬁcation using the perceptron algo-
rithm. Machine Learning, 37(3):277–296.

Ji, Heng, David Westbrook, and Ralph Grishman.
2005. Using semantic relations to reﬁne corefer-
ence decisions. In Proceedings of HLT/EMNLP-05,
pages 17–24.

Jiang, Jing and ChengXiang Zhai. 2007. A system-
atic exploration of the feature space for relation ex-
traction. In Proceedings of HLT-NAACL-07, pages
113–120.

Jiang, Jing. 2009. Multi-task transfer learning for
weakly-supervised relation extraction. In Proceed-
ings of ACL-IJCNLP-09, pages 1012–1020.

Kambhatla, Nanda. 2004. Combining lexical, syntac-
tic, and semantic features with maximum entropy
models for information extraction. In Proceedings
of ACL-04, pages 178–181.

Koo, Terry, Xavier Carreras, and Michael Collins.
2008. Simple semi-supervised dependency parsing.
In Proceedings of ACL-08:HLT, pages 595–603.

Mintz, Mike, Steven Bills, Rion Snow, and Daniel Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data.
In Proceedings of
ACL-IJCNLP-09, pages 1003–1011.

Ratinov, Lev and Dan Roth. 2009. Design challenges
and misconceptions in named entity recognition. In
Proceedings of CoNLL-09, pages 147–155.

Lev,

2010.

Doug Downey,

Ratinov,
Roth.
tion
sity
danr/Papers/RatinovDoRo10.pdf.

and Dan
informa-
report, Univer-
http://L2R.cs.uiuc.edu/∼

Wikiﬁcation for
Technical

retrieval.
of

Illinois.

Roth, Dan and Wen Tau Yih. 2004. A linear program-
ming formulation for global inference in natural lan-
guage tasks.
In Proceedings of CoNLL-04, pages
1–8.

Roth, Dan and Wen Tau Yih. 2007. Global infer-
ence for entity and relation identiﬁcation via a lin-
ear programming formulation. In Getoor, Lise and
Ben Taskar, editors, Introduction to Statistical Rela-
tional Learning. MIT Press.

Weld, Daniel S., Raphael Hoffman, and Fei Wu. 2008.
Using wikipedia to bootstrap open information ex-
traction. ACM SIGMOD Special Issue on Managing
Information Extraction, 37(4):62–68.

Zelenko, Dmitry, Chinatsu Aone,

and Anthony
Richardella. 2003. Kernel methods for relation ex-
traction. Journal of Machine Learning Research,
3:1083–1106.

Zhang, Min, Jie Zhang, Jian Su, and GuoDong Zhou.
2006. A composite kernel to extract relations be-
tween entities with both ﬂat and structured features.
In Proceedings of COLING-ACL-06, pages 825–
832.

Zhou, Guodong, Jian Su, Jie Zhang, and Min Zhang.
2005. Exploring various knowledge in relation ex-
traction. In Proceedings of ACL-05.

Zhou, GuoDong, Min Zhang, DongHong Ji, and
Tree kernel-based re-
QiaoMing Zhu.
lation extraction with context-sensitive structured
parse tree information. In Proceedings of EMNLP-
CoNLL-07, pages 728–736.

2007.

Zhou, Guodong, Min Zhang, Dong-Hong Ji, and
Qiaoming Zhu. 2008. Hierarchical learning strat-
egy in semantic relation extraction.
Information
Processing & Management, 44(3):1008–1021.

