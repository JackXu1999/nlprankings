@proceedings{ws-2019-linguistic,
    title = "Proceedings of the 13th Linguistic Annotation Workshop",
    author = "Friedrich, Annemarie  and
      Zeyrek, Deniz  and
      Hoek, Jet",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4000",
}
@inproceedings{ulinski-hirschberg-2019-crowdsourced,
    title = "Crowdsourced Hedge Term Disambiguation",
    author = "Ulinski, Morgan  and
      Hirschberg, Julia",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4001",
    doi = "10.18653/v1/W19-4001",
    pages = "1--5",
    abstract = "We address the issue of acquiring quality annotations of hedging words and phrases, linguistic phenomenona in which words, sounds, or other constructions are used to express ambiguity or uncertainty. Due to the limited availability of existing corpora annotated for hedging, linguists and other language scientists have been constrained as to the extent they can study this phenomenon. In this paper, we introduce a new method of acquiring hedging annotations via crowdsourcing, based on reformulating the task of labeling hedges as a simple word sense disambiguation task. We also introduce a new hedging corpus we have constructed by applying this method, a collection of forum posts annotated using Amazon Mechanical Turk. We found that the crowdsourced judgments we obtained had an inter-annotator agreement of 92.89{\%} (Fleiss{'} Kappa=0.751) and, when comparing a subset of these annotations to an expert-annotated gold standard, an accuracy of 96.65{\%}.",
}
@inproceedings{lechelle-etal-2019-wire57,
    title = "{W}i{R}e57 : A Fine-Grained Benchmark for Open Information Extraction",
    author = "Lechelle, William  and
      Gotti, Fabrizio  and
      Langlais, Phillippe",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4002",
    doi = "10.18653/v1/W19-4002",
    pages = "6--15",
    abstract = "We build a reference for the task of Open Information Extraction, on five documents. We tentatively resolve a number of issues that arise, including coreference and granularity, and we take steps toward addressing inference, a significant problem. We seek to better pinpoint the requirements for the task. We produce our annotation guidelines specifying what is correct to extract and what is not. In turn, we use this reference to score existing Open IE systems. We address the non-trivial problem of evaluating the extractions produced by systems against the reference tuples, and share our evaluation script. Among seven compared extractors, we find the MinIE system to perform best.",
}
@inproceedings{yung-etal-2019-crowdsourcing,
    title = "Crowdsourcing Discourse Relation Annotations by a Two-Step Connective Insertion Task",
    author = "Yung, Frances  and
      Demberg, Vera  and
      Scholman, Merel",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4003",
    doi = "10.18653/v1/W19-4003",
    pages = "16--25",
    abstract = "The perspective of being able to crowd-source coherence relations bears the promise of acquiring annotations for new texts quickly, which could then increase the size and variety of discourse-annotated corpora. It would also open the avenue to answering new research questions: Collecting annotations from a larger number of individuals per instance would allow to investigate the distribution of inferred relations, and to study individual differences in coherence relation interpretation. However, annotating coherence relations with untrained workers is not trivial. We here propose a novel two-step annotation procedure, which extends an earlier method by Scholman and Demberg (2017a). In our approach, coherence relation labels are inferred from connectives that workers insert into the text. We show that the proposed method leads to replicable coherence annotations, and analyse the agreement between the obtained relation labels and annotations from PDTB and RSTDT on the same texts.",
}
@inproceedings{gold-etal-2019-annotating,
    title = "Annotating and analyzing the interactions between meaning relations",
    author = "Gold, Darina  and
      Kovatchev, Venelin  and
      Zesch, Torsten",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4004",
    doi = "10.18653/v1/W19-4004",
    pages = "26--36",
    abstract = "Pairs of sentences, phrases, or other text pieces can hold semantic relations such as paraphrasing, textual entailment, contradiction, specificity, and semantic similarity. These relations are usually studied in isolation and no dataset exists where they can be compared empirically. Here we present a corpus annotated with these relations and the analysis of these results. The corpus contains 520 sentence pairs, annotated with these relations. We measure the annotation reliability of each individual relation and we examine their interactions and correlations. Among the unexpected results revealed by our analysis is that the traditionally considered direct relationship between paraphrasing and bi-directional entailment does not hold in our data.",
}
@inproceedings{evang-etal-2019-ccgweb,
    title = "{CCG}web: a New Annotation Tool and a First Quadrilingual {CCG} Treebank",
    author = "Evang, Kilian  and
      Abzianidze, Lasha  and
      Bos, Johan",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4005",
    doi = "10.18653/v1/W19-4005",
    pages = "37--42",
    abstract = "We present the first open-source graphical annotation tool for combinatory categorial grammar (CCG), and the first set of detailed guidelines for syntactic annotation with CCG, for four languages: English, German, Italian, and Dutch. We also release a parallel pilot CCG treebank based on these guidelines, with 4x100 adjudicated sentences, 10K single-annotator fully corrected sentences, and 82K single-annotator partially corrected sentences.",
}
@inproceedings{laarmann-quante-etal-2019-making,
    title = "The making of the Litkey Corpus, a richly annotated longitudinal corpus of {G}erman texts written by primary school children",
    author = "Laarmann-Quante, Ronja  and
      Dipper, Stefanie  and
      Belke, Eva",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4006",
    doi = "10.18653/v1/W19-4006",
    pages = "43--55",
    abstract = "To date, corpus and computational linguistic work on written language acquisition has mostly dealt with second language learners who have usually already mastered orthography acquisition in their first language. In this paper, we present the Litkey Corpus, a richly-annotated longitudinal corpus of written texts produced by primary school children in Germany from grades 2 to 4. The paper focuses on the (semi-)automatic annotation procedure at various linguistic levels, which include POS tags, features of the word-internal structure (phonemes, syllables, morphemes) and key orthographic features of the target words as well as a categorization of spelling errors. Comprehensive evaluations show that high accuracy was achieved on all levels, making the Litkey Corpus a useful resource for corpus-based research on literacy acquisition of German primary school children and for developing NLP tools for educational purposes. The corpus is freely available under https://www.linguistics.rub.de/litkeycorpus/.",
}
@inproceedings{mysore-etal-2019-materials,
    title = "The Materials Science Procedural Text Corpus: Annotating Materials Synthesis Procedures with Shallow Semantic Structures",
    author = "Mysore, Sheshera  and
      Jensen, Zachary  and
      Kim, Edward  and
      Huang, Kevin  and
      Chang, Haw-Shiuan  and
      Strubell, Emma  and
      Flanigan, Jeffrey  and
      McCallum, Andrew  and
      Olivetti, Elsa",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4007",
    doi = "10.18653/v1/W19-4007",
    pages = "56--64",
    abstract = "Materials science literature contains millions of materials synthesis procedures described in unstructured natural language text. Large-scale analysis of these synthesis procedures would facilitate deeper scientific understanding of materials synthesis and enable automated synthesis planning. Such analysis requires extracting structured representations of synthesis procedures from the raw text as a first step. To facilitate the training and evaluation of synthesis extraction models, we introduce a dataset of 230 synthesis procedures annotated by domain experts with labeled graphs that express the semantics of the synthesis sentences. The nodes in this graph are synthesis operations and their typed arguments, and labeled edges specify relations between the nodes. We describe this new resource in detail and highlight some specific challenges to annotating scientific text with shallow semantic structure. We make the corpus available to the community to promote further research and development of scientific information extraction systems.",
}
@inproceedings{tjuka-etal-2019-tagging,
    title = "Tagging modality in Oceanic languages of Melanesia",
    author = "Tjuka, Annika  and
      Wei{\ss}mann, Lena  and
      von Prince, Kilu",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4008",
    doi = "10.18653/v1/W19-4008",
    pages = "65--70",
    abstract = "Primary data from small, low-resource languages of Oceania have only recently become available through language documentation. In our study, we explore corpus data of five Oceanic languages of Melanesia which are known to be mood-prominent (in the sense of Bhat, 1999). In order to find out more about tense, aspect, modality, and polarity, we tagged these categories in a subset of our corpora. For the category of modality, we developed a novel tag set (MelaTAMP, 2017), which categorizes clauses into factual, possible, and counterfactual. Based on an analysis of the inter-annotator consistency, we argue that our tag set for the modal domain is efficient for our subject languages and might be useful for other languages and purposes.",
}
@inproceedings{mambrini-passarotti-2019-harmonizing,
    title = "Harmonizing Different Lemmatization Strategies for Building a Knowledge Base of Linguistic Resources for {L}atin",
    author = "Mambrini, Francesco  and
      Passarotti, Marco",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4009",
    doi = "10.18653/v1/W19-4009",
    pages = "71--80",
    abstract = "The interoperability between lemmatized corpora of Latin and other resources that use the lemma as indexing key is hampered by the multiple lemmatization strategies that different projects adopt. In this paper we discuss how we tackle the challenges raised by harmonizing different lemmatization criteria in the context of a project that aims to connect linguistic resources for Latin using the Linked Data paradigm. The paper introduces the architecture supporting an open-ended, lemma-based Knowledge Base, built to make textual and lexical resources for Latin interoperable. Particularly, the paper describes the inclusion into the Knowledge Base of its lexical basis, of a word formation lexicon and of a lemmatized and syntactically annotated corpus.",
}
@inproceedings{monsalve-etal-2019-assessing,
    title = "Assessing Back-Translation as a Corpus Generation Strategy for non-{E}nglish Tasks: A Study in Reading Comprehension and Word Sense Disambiguation",
    author = "Monsalve, Fabricio  and
      Rivas Rojas, Kervy  and
      Sobrevilla Cabezudo, Marco Antonio  and
      Oncevay, Arturo",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4010",
    doi = "10.18653/v1/W19-4010",
    pages = "81--89",
    abstract = "Corpora curated by experts have sustained Natural Language Processing mainly in English, but the expensiveness of corpora creation is a barrier for the development in further languages. Thus, we propose a corpus generation strategy that only requires a machine translation system between English and the target language in both directions, where we filter the best translations by computing automatic translation metrics and the task performance score. By studying Reading Comprehension in Spanish and Word Sense Disambiguation in Portuguese, we identified that a more quality-oriented metric has high potential in the corpora selection without degrading the task performance. We conclude that it is possible to systematise the building of quality corpora using machine translation and automatic metrics, besides some prior effort to clean and process the data.",
}
@inproceedings{casey-etal-2019-framework,
    title = "A Framework for Annotating {`}Related Works{'} to Support Feedback to Novice Writers",
    author = "Casey, Arlene  and
      Webber, Bonnie  and
      Glowacka, Dorota",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4011",
    doi = "10.18653/v1/W19-4011",
    pages = "90--99",
    abstract = "Understanding what is expected of academic writing can be difficult for novice writers to assimilate, and recent years have seen several automated tools become available to support academic writing. Our work presents a framework for annotating features of the Related Work section of academic writing, that supports writer feedback.",
}
@inproceedings{lawrence-etal-2019-online,
    title = "An Online Annotation Assistant for Argument Schemes",
    author = "Lawrence, John  and
      Visser, Jacky  and
      Reed, Chris",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4012",
    doi = "10.18653/v1/W19-4012",
    pages = "100--107",
    abstract = "Understanding the inferential principles underpinning an argument is essential to the proper interpretation and evaluation of persuasive discourse. Argument schemes capture the conventional patterns of reasoning appealed to in persuasion. The empirical study of these patterns relies on the availability of data about the actual use of argumentation in communicative practice. Annotated corpora of argument schemes, however, are scarce, small, and unrepresentative. Aiming to address this issue, we present one step in the development of improved datasets by integrating the Argument Scheme Key {--} a novel annotation method based on one of the most popular typologies of argument schemes {--} into the widely used OVA software for argument analysis.",
}
@inproceedings{dobrovoljc-2019-annotating,
    title = "Annotating formulaic sequences in spoken {S}lovenian: structure, function and relevance",
    author = "Dobrovoljc, Kaja",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4013",
    doi = "10.18653/v1/W19-4013",
    pages = "108--112",
    abstract = "This paper presents the identification of formulaic sequences in the reference corpus of spoken Slovenian and their annotation in terms of syntactic structure, pragmatic function and lexicographic relevance. The annotation campaign, specific in terms of setting, subjectivity and the multifunctionality of items under investigation, resulted in a preliminary lexicon of formulaic sequences in spoken Slovenian with immediate potential for future explorations in formulaic language research. This is especially relevant for the notable number of identified multi-word expressions with discourse-structuring and stance-marking functions, which have often been overlooked by traditional phraseology research.",
}
@inproceedings{de-kuthy-etal-2019-annotating,
    title = "Annotating Information Structure in {I}talian: Characteristics and Cross-Linguistic Applicability of a {QUD}-Based Approach",
    author = "De Kuthy, Kordula  and
      Brunetti, Lisa  and
      Berardi, Marta",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4014",
    doi = "10.18653/v1/W19-4014",
    pages = "113--123",
    abstract = "We present a discourse annotation study, in which an annotation method based on Questions under Discussion (QuD) is applied to Italian data. The results of our inter-annotator agreement analysis show that the QUD-based approach, originally spelled out for English and German, can successfully be transferred cross-linguistically, supporting good agree- ment for the annotation of central information structure notions such as focus and non-at-issueness. Our annotation and inter- annotator agreement study on Italian authentic data confirms the cross-linguistic applicability of the QuD-based approach.",
}
@inproceedings{spala-etal-2019-deft,
    title = "{DEFT}: A corpus for definition extraction in free- and semi-structured text",
    author = "Spala, Sasha  and
      Miller, Nicholas A.  and
      Yang, Yiming  and
      Dernoncourt, Franck  and
      Dockhorn, Carl",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4015",
    doi = "10.18653/v1/W19-4015",
    pages = "124--131",
    abstract = "Definition extraction has been a popular topic in NLP research for well more than a decade, but has been historically limited to well-defined, structured, and narrow conditions. In reality, natural language is messy, and messy data requires both complex solutions and data that reflects that reality. In this paper, we present a robust English corpus and annotation schema that allows us to explore the less straightforward examples of term-definition structures in free and semi-structured text.",
}
@inproceedings{kalouli-etal-2019-explaining,
    title = "Explaining Simple Natural Language Inference",
    author = "Kalouli, Aikaterini-Lida  and
      Buis, Annebeth  and
      Real, Livy  and
      Palmer, Martha  and
      dePaiva, Valeria",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4016",
    doi = "10.18653/v1/W19-4016",
    pages = "132--143",
    abstract = "The vast amount of research introducing new corpora and techniques for semi-automatically annotating corpora shows the important role that datasets play in today{'}s research, especially in the machine learning community. This rapid development raises concerns about the quality of the datasets created and consequently of the models trained, as recently discussed with respect to the Natural Language Inference (NLI) task. In this work we conduct an annotation experiment based on a small subset of the SICK corpus. The experiment reveals several problems in the annotation guidelines, and various challenges of the NLI task itself. Our quantitative evaluation of the experiment allows us to assign our empirical observations to specific linguistic phenomena and leads us to recommendations for future annotation tasks, for NLI and possibly for other tasks.",
}
@inproceedings{rehbein-2019-role,
    title = "On the role of discourse relations in persuasive texts",
    author = "Rehbein, Ines",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4017",
    doi = "10.18653/v1/W19-4017",
    pages = "144--154",
    abstract = "This paper investigates the use of explicitly signalled discourse relations in persuasive texts. We present a corpus study where we control for speaker and topic and show that the distribution of different discourse connectives varies considerably across different discourse settings. While this variation can be explained by genre differences, we also observe variation regarding the distribution of discourse relations across different settings. This variation, however, cannot be easily explained by genre differences. We argue that the differences regarding the use of discourse relations reflects different strategies of persuasion and that these might be due to audience design.",
}
@inproceedings{indig-etal-2019-one,
    title = "One format to rule them all {--} The emtsv pipeline for {H}ungarian",
    author = "Indig, Bal{\'a}zs  and
      Sass, B{\'a}lint  and
      Simon, Eszter  and
      Mittelholcz, Iv{\'a}n  and
      Vad{\'a}sz, No{\'e}mi  and
      Makrai, M{\'a}rton",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4018",
    doi = "10.18653/v1/W19-4018",
    pages = "155--165",
    abstract = "We present a more efficient version of the e-magyar NLP pipeline for Hungarian called emtsv. It integrates Hungarian NLP tools in a framework whose individual modules can be developed or replaced independently and allows new ones to be added. The design also allows convenient investigation and manual correction of the data flow from one module to another. The improvements we publish include effective communication between the modules and support of the use of individual modules both in the chain and standing alone. Our goals are accomplished using extended tsv (tab separated values) files, a simple, uniform, generic and self-documenting input/output format. Our vision is maintaining the system for a long time and making it easier for external developers to fit their own modules into the system, thus sharing existing competencies in the field of processing Hungarian, a mid-resourced language. The source code is available under LGPL 3.0 license at https://github.com/dlt-rilmta/emtsv .",
}
@inproceedings{turk-etal-2019-turkish,
    title = "{T}urkish Treebanking: Unifying and Constructing Efforts",
    author = {T{\"u}rk, Utku  and
      Atmaca, Furkan  and
      {\"O}zate{\c{s}}, {\c{S}}aziye Bet{\"u}l  and
      K{\"o}ksal, Abdullatif  and
      Ozturk Basaran, Balkiz  and
      Gungor, Tunga  and
      {\"O}zg{\"u}r, Arzucan},
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4019",
    doi = "10.18653/v1/W19-4019",
    pages = "166--177",
    abstract = {In this paper, we present the current version of two different treebanks, the re-annotation of the Turkish PUD Treebank and the first annotation of the Turkish National Corpus Universal Dependency (henceforth TNC-UD). The annotation of both treebanks, the Turkish PUD Treebank and TNC-UD, was carried out based on the decisions concerning linguistic adequacy of re-annotation of the Turkish IMST-UD Treebank (T{\"u}rk et. al., forthcoming). Both of the treebanks were annotated with the same annotation process and morphological and syntactic analyses. The TNC-UD is planned to have 10,000 sentences. In this paper, we will present the first 500 sentences along with the annotation PUD Treebank. Moreover, this paper also offers the parsing results of a graph-based neural parser on the previous and re-annotated PUD, as well as the TNC-UD. In light of the comparisons, even though we observe a slight decrease in the attachment scores of the Turkish PUD treebank, we demonstrate that the annotation of the TNC-UD improves the parsing accuracy of Turkish. In addition to the treebanks, we have also constructed a custom annotation software with advanced filtering and morphological editing options. Both the treebanks, including a full edit-history and the annotation guidelines, and the custom software are publicly available under an open license online.},
}
@inproceedings{pal-sharma-2019-dataset,
    title = "A Dataset for Semantic Role Labelling of {H}indi-{E}nglish Code-Mixed Tweets",
    author = "Pal, Riya  and
      Sharma, Dipti",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4020",
    doi = "10.18653/v1/W19-4020",
    pages = "178--188",
    abstract = "We present a data set of 1460 Hindi-English code-mixed tweets consisting of 20,949 tokens labelled with Proposition Bank labels marking their semantic roles. We created verb frames for complex predicates present in the corpus and formulated mappings from Paninian dependency labels to Proposition Bank labels. With the help of these mappings and the dependency tree, we propose a baseline rule based system for Semantic Role Labelling of Hindi-English code-mixed data. We obtain an accuracy of 96.74{\%} for Argument Identification and are able to further classify 73.93{\%} of the labels correctly. While there is relevant ongoing research on Semantic Role Labelling and on building tools for code-mixed social media data, this is the first attempt at labelling semantic roles in code-mixed data, to the best of our knowledge.",
}
@inproceedings{eckart-de-castilho-etal-2019-multi,
    title = "A Multi-Platform Annotation Ecosystem for Domain Adaptation",
    author = "Eckart de Castilho, Richard  and
      Ide, Nancy  and
      Kim, Jin-Dong  and
      Klie, Jan-Christoph  and
      Suderman, Keith",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4021",
    doi = "10.18653/v1/W19-4021",
    pages = "189--194",
    abstract = "This paper describes an ecosystem consisting of three independent text annotation platforms. To demonstrate their ability to work in concert, we illustrate how to use them to address an interactive domain adaptation task in biomedical entity recognition. The platforms and the approach are in general domain-independent and can be readily applied to other areas of science.",
}
@inproceedings{park-tyers-2019-new,
    title = "A New Annotation Scheme for the {S}ejong Part-of-speech Tagged Corpus",
    author = "Park, Jungyeul  and
      Tyers, Francis",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4022",
    doi = "10.18653/v1/W19-4022",
    pages = "195--202",
    abstract = "In this paper we present a new annotation scheme for the Sejong part-of-speech tagged corpus based on Universal Dependencies style annotation. By using a new annotation scheme, we can produce Sejong-style morphological analysis and part-of-speech tagging results which have been the \textit{de facto} standard for Korean language processing. We also explore the possibility of doing named-entity recognition and semantic-role labelling for Korean using the new annotation scheme.",
}
@inproceedings{sezerer-etal-2019-turkish,
    title = "A {T}urkish Dataset for Gender Identification of Twitter Users",
    author = "Sezerer, Erhan  and
      Polatbilek, Ozan  and
      Tekir, Selma",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4023",
    doi = "10.18653/v1/W19-4023",
    pages = "203--207",
    abstract = "Author profiling is the identification of an author{'}s gender, age, and language from his/her texts. With the increasing trend of using Twitter as a means to express thought, profiling the gender of an author from his/her tweets has become a challenge. Although several datasets in different languages have been released on this problem, there is still a need for multilingualism. In this work, we propose a dataset of tweets of Turkish Twitter users which are labeled with their gender information. The dataset has 3368 users in training set and 1924 users in test set where each user has 100 tweets. The dataset is publicly available.",
}
@inproceedings{gooding-etal-2019-comparative,
    title = "Comparative judgments are more consistent than binary classification for labelling word complexity",
    author = "Gooding, Sian  and
      Kochmar, Ekaterina  and
      Sarkar, Advait  and
      Blackwell, Alan",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4024",
    doi = "10.18653/v1/W19-4024",
    pages = "208--214",
    abstract = "Lexical simplification systems replace complex words with simple ones based on a model of which words are complex in context. We explore how users can help train complex word identification models through labelling more efficiently and reliably. We show that using an interface where annotators make comparative rather than binary judgments leads to more reliable and consistent labels, and explore whether comparative judgments may provide a faster way for collecting labels.",
}
@inproceedings{lohr-etal-2019-continuous,
    title = "Continuous Quality Control and Advanced Text Segment Annotation with {WAT}-{SL} 2.0",
    author = "Lohr, Christina  and
      Kiesel, Johannes  and
      Luther, Stephanie  and
      Hellrich, Johannes  and
      Kolditz, Tobias  and
      Stein, Benno  and
      Hahn, Udo",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4025",
    doi = "10.18653/v1/W19-4025",
    pages = "215--219",
    abstract = "Today{'}s widely used annotation tools were designed for annotating typically short textual mentions of entities or relations, making their interface cumbersome to use for long(er) stretches of text, e.g, sentences running over several lines in a document. They also lack systematic support for hierarchically structured labels, i.e., one label being conceptually more general than another (e.g., anamnesis in relation to family anamnesis). Moreover, as a more fundamental shortcoming of today{'}s tools, they provide no continuous quality con trol mechanisms for the annotation process, an essential feature to intrinsically support iterative cycles in the development of annotation guidelines. We alleviated these problems by developing WAT-SL 2.0, an open-source web-based annotation tool for long-segment labeling, hierarchically structured label sets and built-ins for quality control.",
}
@inproceedings{novak-etal-2019-creation,
    title = "Creation of a corpus with semantic role labels for {H}ungarian",
    author = {Nov{\'a}k, Attila  and
      Laki, L{\'a}szl{\'o}  and
      Nov{\'a}k, Borb{\'a}la  and
      D{\"o}m{\"o}t{\"o}r, Andrea  and
      Ligeti-Nagy, No{\'e}mi  and
      Kalivoda, {\'A}gnes},
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4026",
    doi = "10.18653/v1/W19-4026",
    pages = "220--229",
    abstract = "In this article, an ongoing research is presented, the immediate goal of which is to create a corpus annotated with semantic role labels for Hungarian that can be used to train a parser-based system capable of formulating relevant questions about the text it processes. We briefly describe the objectives of our research, our efforts at eliminating errors in the Hungarian Universal Dependencies corpus, which we use as the base of our annotation effort, at creating a Hungarian verbal argument database annotated with thematic roles, at classifying adjuncts, and at matching verbal argument frames to specific occurrences of verbs and participles in the corpus.",
}
@inproceedings{cruz-blandon-etal-2019-toward,
    title = "Toward Dialogue Modeling: A Semantic Annotation Scheme for Questions and Answers",
    author = "Cruz Bland{\'o}n, Mar{\'\i}a Andrea  and
      Minnema, Gosse  and
      Nourbakhsh, Aria  and
      Boritchev, Maria  and
      Amblard, Maxime",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4027",
    doi = "10.18653/v1/W19-4027",
    pages = "230--235",
    abstract = "The present study proposes an annotation scheme for classifying the content and discourse contribution of question-answer pairs. We propose detailed guidelines for using the scheme and apply them to dialogues in English, Spanish, and Dutch. Finally, we report on initial machine learning experiments for automatic annotation.",
}
@inproceedings{sobrevilla-cabezudo-pardo-2019-towards,
    title = "Towards a General Abstract Meaning Representation Corpus for {B}razilian {P}ortuguese",
    author = "Sobrevilla Cabezudo, Marco Antonio  and
      Pardo, Thiago",
    booktitle = "Proceedings of the 13th Linguistic Annotation Workshop",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4028",
    doi = "10.18653/v1/W19-4028",
    pages = "236--244",
    abstract = "Abstract Meaning Representation (AMR) is a recent and prominent semantic representation with good acceptance and several applications in the Natural Language Processing area. For English, there is a large annotated corpus (with approximately 39K sentences) that supports the research with the representation. However, to the best of our knowledge, there is only one restricted corpus for Portuguese, which contains 1,527 sentences. In this context, this paper presents an effort to build a general purpose AMR-annotated corpus for Brazilian Portuguese by translating and adapting AMR English guidelines. Our results show that such approach is feasible, but there are some challenging phenomena to solve. More than this, efforts are necessary to increase the coverage of the corresponding lexical resource that supports the annotation.",
}
