@proceedings{ws-2019-innovative,
    title = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    author = "Yannakoudakis, Helen  and
      Kochmar, Ekaterina  and
      Leacock, Claudia  and
      Madnani, Nitin  and
      Pil{\'a}n, Ildik{\'o}  and
      Zesch, Torsten",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4400",
}
@inproceedings{loukina-etal-2019-many,
    title = "The many dimensions of algorithmic fairness in educational applications",
    author = "Loukina, Anastassia  and
      Madnani, Nitin  and
      Zechner, Klaus",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4401",
    doi = "10.18653/v1/W19-4401",
    pages = "1--10",
    abstract = "The issues of algorithmic fairness and bias have recently featured prominently in many publications highlighting the fact that training the algorithms for maximum performance may often result in predictions that are biased against various groups. Educational applications based on NLP and speech processing technologies often combine multiple complex machine learning algorithms and are thus vulnerable to the same sources of bias as other machine learning systems. Yet such systems can have high impact on people{'}s lives especially when deployed as part of high-stakes tests. In this paper we discuss different definitions of fairness and possible ways to apply them to educational applications. We then use simulated and real data to consider how test-takers{'} native language backgrounds can affect their automated scores on an English language proficiency assessment. We illustrate that total fairness may not be achievable and that different definitions of fairness may require different solutions.",
}
@inproceedings{ha-etal-2019-predicting,
    title = "Predicting the Difficulty of Multiple Choice Questions in a High-stakes Medical Exam",
    author = "Ha, Le An  and
      Yaneva, Victoria  and
      Baldwin, Peter  and
      Mee, Janet",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4402",
    doi = "10.18653/v1/W19-4402",
    pages = "11--20",
    abstract = "Predicting the construct-relevant difficulty of Multiple-Choice Questions (MCQs) has the potential to reduce cost while maintaining the quality of high-stakes exams. In this paper, we propose a method for estimating the difficulty of MCQs from a high-stakes medical exam, where all questions were deliberately written to a common reading level. To accomplish this, we extract a large number of linguistic features and embedding types, as well as features quantifying the difficulty of the items for an automatic question-answering system. The results show that the proposed approach outperforms various baselines with a statistically significant difference. Best results were achieved when using the full feature set, where embeddings had the highest predictive power, followed by linguistic features. An ablation study of the various types of linguistic features suggested that information from all levels of linguistic processing contributes to predicting item difficulty, with features related to semantic ambiguity and the psycholinguistic properties of words having a slightly higher importance. Owing to its generic nature, the presented approach has the potential to generalize over other exams containing MCQs.",
}
@inproceedings{zhou-etal-2019-intelligent,
    title = "An Intelligent Testing Strategy for Vocabulary Assessment of {C}hinese Second Language Learners",
    author = "Zhou, Wei  and
      Hu, Renfen  and
      Sun, Feipeng  and
      Huang, Ronghuai",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4403",
    doi = "10.18653/v1/W19-4403",
    pages = "21--29",
    abstract = "Vocabulary is one of the most important parts of language competence. Testing of vocabulary knowledge is central to research on reading and language. However, it usually costs a large amount of time and human labor to build an item bank and to test large number of students. In this paper, we propose a novel testing strategy by combining automatic item generation (AIG) and computerized adaptive testing (CAT) in vocabulary assessment for Chinese L2 learners. Firstly, we generate three types of vocabulary questions by modeling both the vocabulary knowledge and learners{'} writing error data. After evaluation and calibration, we construct a balanced item pool with automatically generated items, and implement a three-parameter computerized adaptive test. We conduct manual item evaluation and online student tests in the experiments. The results show that the combination of AIG and CAT can construct test items efficiently and reduce test cost significantly. Also, the test result of CAT can provide valuable feedback to AIG algorithms.",
}
@inproceedings{weiss-etal-2019-computationally,
    title = "Computationally Modeling the Impact of Task-Appropriate Language Complexity and Accuracy on Human Grading of {G}erman Essays",
    author = {Weiss, Zarah  and
      Riemenschneider, Anja  and
      Schr{\"o}ter, Pauline  and
      Meurers, Detmar},
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4404",
    doi = "10.18653/v1/W19-4404",
    pages = "30--45",
    abstract = "Computational linguistic research on the language complexity of student writing typically involves human ratings as a gold standard. However, educational science shows that teachers find it difficult to identify and cleanly separate accuracy, different aspects of complexity, contents, and structure. In this paper, we therefore explore the use of computational linguistic methods to investigate how task-appropriate complexity and accuracy relate to the grading of overall performance, content performance, and language performance as assigned by teachers. Based on texts written by students for the official school-leaving state examination (Abitur), we show that teachers successfully assign higher language performance grades to essays with higher task-appropriate language complexity and properly separate this from content scores. Yet, accuracy impacts teacher assessment for all grading rubrics, also the content score, overemphasizing the role of accuracy. Our analysis is based on broad computational linguistic modeling of German language complexity and an innovative theory- and data-driven feature aggregation method inferring task-appropriate language complexity.",
}
@inproceedings{snajder-etal-2019-analysing,
    title = "Analysing Rhetorical Structure as a Key Feature of Summary Coherence",
    author = "{\v{S}}najder, Jan  and
      Sladoljev-Agejev, Tamara  and
      Koli{\'c} Vehovec, Svjetlana",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4405",
    doi = "10.18653/v1/W19-4405",
    pages = "46--51",
    abstract = "We present a model for automatic scoring of coherence based on comparing the rhetorical structure (RS) of college student summaries in L2 (English) against expert summaries. Coherence is conceptualised as a construct consisting of the rhetorical relation and its arguments. Comparison with expert-assigned scores shows that RS scores correlate with both cohesion and coherence. Furthermore, RS scores improve the accuracy of a regression model for cohesion score prediction.",
}
@inproceedings{bryant-etal-2019-bea,
    title = "The {BEA}-2019 Shared Task on Grammatical Error Correction",
    author = "Bryant, Christopher  and
      Felice, Mariano  and
      Andersen, {\O}istein E.  and
      Briscoe, Ted",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4406",
    doi = "10.18653/v1/W19-4406",
    pages = "52--75",
    abstract = "This paper reports on the BEA-2019 Shared Task on Grammatical Error Correction (GEC). As with the CoNLL-2014 shared task, participants are required to correct all types of errors in test data. One of the main contributions of the BEA-2019 shared task is the introduction of a new dataset, the Write{\&}Improve+LOCNESS corpus, which represents a wider range of native and learner English levels and abilities. Another contribution is the introduction of tracks, which control the amount of annotated data available to participants. Systems are evaluated in terms of ERRANT F{\_}0.5, which allows us to report a much wider range of performance statistics. The competition was hosted on Codalab and remains open for further submissions on the blind test set.",
}
@inproceedings{flor-etal-2019-benchmark,
    title = "A Benchmark Corpus of {E}nglish Misspellings and a Minimally-supervised Model for Spelling Correction",
    author = "Flor, Michael  and
      Fried, Michael  and
      Rozovskaya, Alla",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4407",
    doi = "10.18653/v1/W19-4407",
    pages = "76--86",
    abstract = "Spelling correction has attracted a lot of attention in the NLP community. However, models have been usually evaluated on artificiallycreated or proprietary corpora. A publiclyavailable corpus of authentic misspellings, annotated in context, is still lacking. To address this, we present and release an annotated data set of 6,121 spelling errors in context, based on a corpus of essays written by English language learners. We also develop a minimallysupervised context-aware approach to spelling correction. It achieves strong results on our data: 88.12{\%} accuracy. This approach can also train with a minimal amount of annotated data (performance reduced by less than 1{\%}). Furthermore, this approach allows easy portability to new domains. We evaluate our model on data from a medical domain and demonstrate that it rivals the performance of a model trained and tuned on in-domain data.",
}
@inproceedings{qiu-park-2019-artificial,
    title = "Artificial Error Generation with Fluency Filtering",
    author = "Qiu, Mengyang  and
      Park, Jungyeul",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4408",
    doi = "10.18653/v1/W19-4408",
    pages = "87--91",
    abstract = "The quantity and quality of training data plays a crucial role in grammatical error correction (GEC). However, due to the fact that obtaining human-annotated GEC data is both time-consuming and expensive, several studies have focused on generating artificial error sentences to boost training data for grammatical error correction, and shown significantly better performance. The present study explores how fluency filtering can affect the quality of artificial errors. By comparing artificial data filtered by different levels of fluency, we find that artificial error sentences with low fluency can greatly facilitate error correction, while high fluency errors introduce more noise.",
}
@inproceedings{johan-berggren-etal-2019-regression,
    title = "Regression or classification? Automated Essay Scoring for {N}orwegian",
    author = "Johan Berggren, Stig  and
      Rama, Taraka  and
      {\O}vrelid, Lilja",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4409",
    doi = "10.18653/v1/W19-4409",
    pages = "92--102",
    abstract = "In this paper we present first results for the task of Automated Essay Scoring for Norwegian learner language. We analyze a number of properties of this task experimentally and assess (i) the formulation of the task as either regression or classification, (ii) the use of various non-neural and neural machine learning architectures with various types of input representations, and (iii) applying multi-task learning for joint prediction of essay scoring and native language identification. We find that a GRU-based attention model trained in a single-task setting performs best at the AES task.",
}
@inproceedings{bell-etal-2019-context,
    title = "Context is Key: Grammatical Error Detection with Contextual Word Representations",
    author = "Bell, Samuel  and
      Yannakoudakis, Helen  and
      Rei, Marek",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4410",
    doi = "10.18653/v1/W19-4410",
    pages = "103--115",
    abstract = "Grammatical error detection (GED) in non- native writing requires systems to identify a wide range of errors in text written by lan- guage learners. Error detection as a purely supervised task can be challenging, as GED datasets are limited in size and the label dis- tributions are highly imbalanced. Contextual- ized word representations offer a possible so- lution, as they can efficiently capture composi- tional information in language and can be opti- mized on large amounts of unsupervised data. In this paper, we perform a systematic com- parison of ELMo, BERT and Flair embeddings (Peters et al., 2017; Devlin et al., 2018; Akbik et al., 2018) on a range of public GED datasets, and propose an approach to effectively inte- grate such representations in current methods, achieving a new state of the art on GED. We further analyze the strengths and weaknesses of different contextual embeddings for the task at hand, and present detailed analyses of their impact on different types of errors.",
}
@inproceedings{riordan-etal-2019-account,
    title = "How to account for mispellings: Quantifying the benefit of character representations in neural content scoring models",
    author = "Riordan, Brian  and
      Flor, Michael  and
      Pugh, Robert",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4411",
    doi = "10.18653/v1/W19-4411",
    pages = "116--126",
    abstract = "Character-based representations in neural models have been claimed to be a tool to overcome spelling variation in in word token-based input. We examine this claim in neural models for content scoring. We formulate precise hypotheses about the possible effects of adding character representations to word-based models and test these hypotheses on large-scale real world content scoring datasets. We find that, while character representations may provide small performance gains in general, their effectiveness in accounting for spelling variation may be limited. We show that spelling correction can provide larger gains than character representations, and that spelling correction improves the performance of models with character representations. With these insights, we report a new state of the art on the ASAP-SAS content scoring dataset.",
}
@inproceedings{alikaniotis-etal-2019-unreasonable,
    title = "The Unreasonable Effectiveness of Transformer Language Models in Grammatical Error Correction",
    author = "Alikaniotis, Dimitris  and
      Raheja, Vipul  and
      Tetreault, Joel",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4412",
    doi = "10.18653/v1/W19-4412",
    pages = "127--133",
    abstract = "Recent work on Grammatical Error Correction (GEC) has highlighted the importance of language modeling in that it is certainly possible to achieve good performance by comparing the probabilities of the proposed edits. At the same time, advancements in language modeling have managed to generate linguistic output, which is almost indistinguishable from that of human-generated text. In this paper, we up the ante by exploring the potential of more sophisticated language models in GEC and offer some key insights on their strengths and weaknesses. We show that, in line with recent results in other NLP tasks, Transformer architectures achieve consistently high performance and provide a competitive baseline for future machine learning models.",
}
@inproceedings{katsumata-komachi-2019-almost,
    title = "(Almost) Unsupervised Grammatical Error Correction using Synthetic Comparable Corpus",
    author = "Katsumata, Satoru  and
      Komachi, Mamoru",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4413",
    doi = "10.18653/v1/W19-4413",
    pages = "134--138",
    abstract = "We introduce unsupervised techniques based on phrase-based statistical machine translation for grammatical error correction (GEC) trained on a pseudo learner corpus created by Google Translation. We verified our GEC system through experiments on a low resource track of the shared task at BEA2019. As a result, we achieved an F0.5 score of 28.31 points with the test data.",
}
@inproceedings{kantor-etal-2019-learning,
    title = "Learning to combine Grammatical Error Corrections",
    author = "Kantor, Yoav  and
      Katz, Yoav  and
      Choshen, Leshem  and
      Cohen-Karlik, Edo  and
      Liberman, Naftali  and
      Toledo, Assaf  and
      Menczel, Amir  and
      Slonim, Noam",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4414",
    doi = "10.18653/v1/W19-4414",
    pages = "139--148",
    abstract = "The field of Grammatical Error Correction (GEC) has produced various systems to deal with focused phenomena or general text editing. We propose an automatic way to combine black-box systems. Our method automatically detects the strength of a system or the combination of several systems per error type, improving precision and recall while optimizing F-score directly. We show consistent improvement over the best standalone system in all the configurations tested. This approach also outperforms average ensembling of different RNN models with random initializations. In addition, we analyze the use of BERT for GEC - reporting promising results on this end. We also present a spellchecker created for this task which outperforms standard spellcheckers tested on the task of spellchecking. This paper describes a system submission to Building Educational Applications 2019 Shared Task: Grammatical Error Correction. Combining the output of top BEA 2019 shared task systems using our approach, currently holds the highest reported score in the open phase of the BEA 2019 shared task, improving F-0.5 score by 3.7 points over the best result reported.",
}
@inproceedings{xu-etal-2019-erroneous,
    title = "Erroneous data generation for Grammatical Error Correction",
    author = "Xu, Shuyao  and
      Zhang, Jiehao  and
      Chen, Jin  and
      Qin, Long",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4415",
    doi = "10.18653/v1/W19-4415",
    pages = "149--158",
    abstract = "It has been demonstrated that the utilization of a monolingual corpus in neural Grammatical Error Correction (GEC) systems can significantly improve the system performance. The previous state-of-the-art neural GEC system is an ensemble of four Transformer models pretrained on a large amount of Wikipedia Edits. The Singsound GEC system follows a similar approach but is equipped with a sophisticated erroneous data generating component. Our system achieved an F0:5 of 66.61 in the BEA 2019 Shared Task: Grammatical Error Correction. With our novel erroneous data generating component, the Singsound neural GEC system yielded an M2 of 63.2 on the CoNLL-2014 benchmark (8.4{\%} relative improvement over the previous state-of-the-art system).",
}
@inproceedings{li-etal-2019-laix,
    title = "The {LAIX} Systems in the {BEA}-2019 {GEC} Shared Task",
    author = "Li, Ruobing  and
      Wang, Chuan  and
      Zha, Yefei  and
      Yu, Yonghong  and
      Guo, Shiman  and
      Wang, Qiang  and
      Liu, Yang  and
      Lin, Hui",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4416",
    doi = "10.18653/v1/W19-4416",
    pages = "159--167",
    abstract = "In this paper, we describe two systems we developed for the three tracks we have participated in the BEA-2019 GEC Shared Task. We investigate competitive classification models with bi-directional recurrent neural networks (Bi-RNN) and neural machine translation (NMT) models. For different tracks, we use ensemble systems to selectively combine the NMT models, the classification models, and some rules, and demonstrate that an ensemble solution can effectively improve GEC performance over single systems. Our GEC systems ranked the first in the Unrestricted Track, and the third in both the Restricted Track and the Low Resource Track.",
}
@inproceedings{stahlberg-byrne-2019-cueds,
    title = "The {CUED}{'}s Grammatical Error Correction Systems for {BEA}-2019",
    author = "Stahlberg, Felix  and
      Byrne, Bill",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4417",
    doi = "10.18653/v1/W19-4417",
    pages = "168--175",
    abstract = "We describe two entries from the Cambridge University Engineering Department to the BEA 2019 Shared Task on grammatical error correction. Our submission to the low-resource track is based on prior work on using finite state transducers together with strong neural language models. Our system for the restricted track is a purely neural system consisting of neural language models and neural machine translation models trained with back-translation and a combination of checkpoint averaging and fine-tuning {--} without the help of any additional tools like spell checkers. The latter system has been used inside a separate system combination entry in cooperation with the Cambridge University Computer Lab.",
}
@inproceedings{asano-etal-2019-aip,
    title = "The {AIP}-Tohoku System at the {BEA}-2019 Shared Task",
    author = "Asano, Hiroki  and
      Mita, Masato  and
      Mizumoto, Tomoya  and
      Suzuki, Jun",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4418",
    doi = "10.18653/v1/W19-4418",
    pages = "176--182",
    abstract = "We introduce the AIP-Tohoku grammatical error correction (GEC) system for the BEA-2019 shared task in Track 1 (Restricted Track) and Track 2 (Unrestricted Track) using the same system architecture. Our system comprises two key components: error generation and sentence-level error detection. In particular, GEC with sentence-level grammatical error detection is a novel and versatile approach, and we experimentally demonstrate that it significantly improves the precision of the base model. Our system is ranked 9th in Track 1 and 2nd in Track 2.",
}
@inproceedings{naplava-straka-2019-cuni,
    title = "{CUNI} System for the Building Educational Applications 2019 Shared Task: Grammatical Error Correction",
    author = "N{\'a}plava, Jakub  and
      Straka, Milan",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4419",
    doi = "10.18653/v1/W19-4419",
    pages = "183--190",
    abstract = "Our submitted models are NMT systems based on the Transformer model, which we improve by incorporating several enhancements: applying dropout to whole source and target words, weighting target subwords, averaging model checkpoints, and using the trained model iteratively for correcting the intermediate translations. The system in the Restricted Track is trained on the provided corpora with oversampled {``}cleaner{''} sentences and reaches 59.39 F0.5 score on the test set. The system in the Low-Resource Track is trained from Wikipedia revision histories and reaches 44.13 F0.5 score. Finally, we finetune the system from the Low-Resource Track on restricted data and achieve 64.55 F0.5 score.",
}
@inproceedings{lacroix-etal-2019-noisy,
    title = "Noisy Channel for Low Resource Grammatical Error Correction",
    author = "Lacroix, Oph{\'e}lie  and
      Flachs, Simon  and
      S{\o}gaard, Anders",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4420",
    doi = "10.18653/v1/W19-4420",
    pages = "191--196",
    abstract = "This paper describes our contribution to the low-resource track of the BEA 2019 shared task on Grammatical Error Correction (GEC). Our approach to GEC builds on the theory of the noisy channel by combining a channel model and language model. We generate confusion sets from the Wikipedia edit history and use the frequencies of edits to estimate the channel model. Additionally, we use two pre-trained language models: 1) Google{'}s BERT model, which we fine-tune for specific error types and 2) OpenAI{'}s GPT-2 model, utilizing that it can operate with previous sentences as context. Furthermore, we search for the optimal combinations of corrections using beam search.",
}
@inproceedings{yang-wang-2019-blcu,
    title = "The {BLCU} System in the {BEA} 2019 Shared Task",
    author = "Yang, Liner  and
      Wang, Chencheng",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4421",
    doi = "10.18653/v1/W19-4421",
    pages = "197--206",
    abstract = "This paper describes the BLCU Group submissions to the Building Educational Applications (BEA) 2019 Shared Task on Grammatical Error Correction (GEC). The task is to detect and correct grammatical errors that occurred in essays. We participate in 2 tracks including the Restricted Track and the Unrestricted Track. Our system is based on a Transformer model architecture. We integrate many effective methods proposed in recent years. Such as, Byte Pair Encoding, model ensemble, checkpoints average and spell checker. We also corrupt the public monolingual data to further improve the performance of the model. On the test data of the BEA 2019 Shared Task, our system yields F0.5 = 58.62 and 59.50, ranking twelfth and fourth respectively.",
}
@inproceedings{kaneko-etal-2019-tmu,
    title = "{TMU} Transformer System Using {BERT} for Re-ranking at {BEA} 2019 Grammatical Error Correction on Restricted Track",
    author = "Kaneko, Masahiro  and
      Hotate, Kengo  and
      Katsumata, Satoru  and
      Komachi, Mamoru",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4422",
    doi = "10.18653/v1/W19-4422",
    pages = "207--212",
    abstract = "We introduce our system that is submitted to the restricted track of the BEA 2019 shared task on grammatical error correction1 (GEC). It is essential to select an appropriate hypothesis sentence from the candidates list generated by the GEC model. A re-ranker can evaluate the naturalness of a corrected sentence us- ing language models trained on large corpora. On the other hand, these language models and language representations do not explicitly take into account the grammatical errors written by learners. Thus, it is not straightforward to utilize language representations trained from a large corpus, such as Bidirectional Encoder Representations from Transformers (BERT), in a form suitable for the learner{'}s grammatical errors. Therefore, we propose to fine- tune BERT on learner corpora with grammatical errors for re-ranking. The experimental results of the W{\&}I+LOCNESS development dataset demonstrate that re-ranking using BERT can effectively improve the correction performance.",
}
@inproceedings{choe-etal-2019-neural,
    title = "A Neural Grammatical Error Correction System Built On Better Pre-training and Sequential Transfer Learning",
    author = "Choe, Yo Joong  and
      Ham, Jiyeon  and
      Park, Kyubyong  and
      Yoon, Yeoil",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4423",
    doi = "10.18653/v1/W19-4423",
    pages = "213--227",
    abstract = "Grammatical error correction can be viewed as a low-resource sequence-to-sequence task, because publicly available parallel corpora are limited.To tackle this challenge, we first generate erroneous versions of large unannotated corpora using a realistic noising function. The resulting parallel corpora are sub-sequently used to pre-train Transformer models. Then, by sequentially applying transfer learning, we adapt these models to the domain and style of the test set. Combined with a context-aware neural spellchecker, our system achieves competitive results in both restricted and low resource tracks in ACL 2019 BEAShared Task. We release all of our code and materials for reproducibility.",
}
@inproceedings{yuan-etal-2019-neural,
    title = "Neural and {FST}-based approaches to grammatical error correction",
    author = "Yuan, Zheng  and
      Stahlberg, Felix  and
      Rei, Marek  and
      Byrne, Bill  and
      Yannakoudakis, Helen",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4424",
    doi = "10.18653/v1/W19-4424",
    pages = "228--239",
    abstract = "In this paper, we describe our submission to the BEA 2019 shared task on grammat- ical error correction. We present a system pipeline that utilises both error detection and correction models. The input text is first corrected by two complementary neural ma- chine translation systems: one using convo- lutional networks and multi-task learning, and another using a neural Transformer-based sys- tem. Training is performed on publicly avail- able data, along with artificial examples gener- ated through back-translation. The n-best lists of these two machine translation systems are then combined and scored using a finite state transducer (FST). Finally, an unsupervised re- ranking system is applied to the n-best output of the FST. The re-ranker uses a number of error detection features to re-rank the FST n- best list and identify the final 1-best correction hypothesis. Our system achieves 66.75{\%} F 0.5 on error correction (ranking 4th), and 82.52{\%} F 0.5 on token-level error detection (ranking 2nd) in the restricted track of the shared task.",
}
@inproceedings{qiu-etal-2019-improving,
    title = "Improving Precision of Grammatical Error Correction with a Cheat Sheet",
    author = "Qiu, Mengyang  and
      Chen, Xuejiao  and
      Liu, Maggie  and
      Parvathala, Krishna  and
      Patil, Apurva  and
      Park, Jungyeul",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4425",
    doi = "10.18653/v1/W19-4425",
    pages = "240--245",
    abstract = "In this paper, we explore two approaches of generating error-focused phrases and examine whether these phrases can lead to better performance in grammatical error correction for the restricted track of BEA 2019 Shared Task on GEC. Our results show that phrases directly extracted from GEC corpora outperform phrases from statistical machine translation phrase table by a large margin. Appending error+context phrases to the original GEC corpora yields comparably high precision. We also explore the generation of artificial syntactic error sentences using error+context phrases for the unrestricted track. The additional training data greatly facilitates syntactic error correction (e.g., verb form) and contributes to better overall performance.",
}
@inproceedings{didenko-shaptala-2019-multi,
    title = "Multi-headed Architecture Based on {BERT} for Grammatical Errors Correction",
    author = "Didenko, Bohdan  and
      Shaptala, Julia",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4426",
    doi = "10.18653/v1/W19-4426",
    pages = "246--251",
    abstract = "In this paper, we describe our approach to GEC using the BERT model for creation of encoded representation and some of our enhancements, namely, {``}Heads{''} are fully-connected networks which are used for finding the errors and later receive recommendation from the networks on dealing with a highlighted part of the sentence only. Among the main advantages of our solution is increasing the system productivity and lowering the time of processing while keeping the high accuracy of GEC results.",
}
@inproceedings{grundkiewicz-etal-2019-neural,
    title = "Neural Grammatical Error Correction Systems with Unsupervised Pre-training on Synthetic Data",
    author = "Grundkiewicz, Roman  and
      Junczys-Dowmunt, Marcin  and
      Heafield, Kenneth",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4427",
    doi = "10.18653/v1/W19-4427",
    pages = "252--263",
    abstract = "Considerable effort has been made to address the data sparsity problem in neural grammatical error correction. In this work, we propose a simple and surprisingly effective unsupervised synthetic error generation method based on confusion sets extracted from a spellchecker to increase the amount of training data. Synthetic data is used to pre-train a Transformer sequence-to-sequence model, which not only improves over a strong baseline trained on authentic error-annotated data, but also enables the development of a practical GEC system in a scenario where little genuine error-annotated data is available. The developed systems placed first in the BEA19 shared task, achieving 69.47 and 64.24 F$_{0.5}$ in the restricted and low-resource tracks respectively, both on the W{\&}I+LOCNESS test set. On the popular CoNLL 2014 test set, we report state-of-the-art results of 64.16 M$^2$ for the submitted system, and 61.30 M$^2$ for the constrained system trained on the NUCLE and Lang-8 data.",
}
@inproceedings{bhalla-klimcikova-2019-evaluation,
    title = "Evaluation of automatic collocation extraction methods for language learning",
    author = "Bhalla, Vishal  and
      Klimcikova, Klara",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4428",
    doi = "10.18653/v1/W19-4428",
    pages = "264--274",
    abstract = "A number of methods have been proposed to automatically extract collocations, i.e., conventionalized lexical combinations, from text corpora. However, the attempts to evaluate and compare them with a specific application in mind lag behind. This paper compares three end-to-end resources for collocation learning, all of which used the same corpus but different methods. Adopting a gold-standard evaluation method, the results show that the method of dependency parsing outperforms regex-over-pos in collocation identification. The lexical association measures (AMs) used for collocation ranking perform about the same overall but differently for individual collocation types. Further analysis has also revealed that there are considerable differences between other commonly used AMs.",
}
@inproceedings{markov-etal-2019-anglicized,
    title = "Anglicized Words and Misspelled Cognates in Native Language Identification",
    author = "Markov, Ilia  and
      Nastase, Vivi  and
      Strapparava, Carlo",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4429",
    doi = "10.18653/v1/W19-4429",
    pages = "275--284",
    abstract = "In this paper, we present experiments that estimate the impact of specific lexical choices of people writing in a second language (L2). In particular, we look at misspelled words that indicate lexical uncertainty on the part of the author, and separate them into three categories: misspelled cognates, {``}L2-ed{''} (in our case, anglicized) words, and all other spelling errors. We test the assumption that such errors contain clues about the native language of an essay{'}s author through the task of native language identification. The results of the experiments show that the information brought by each of these categories is complementary. We also note that while the distribution of such features changes with the proficiency level of the writer, their contribution towards native language identification remains significant at all levels.",
}
@inproceedings{miaschi-etal-2019-linguistically,
    title = "Linguistically-Driven Strategy for Concept Prerequisites Learning on {I}talian",
    author = "Miaschi, Alessio  and
      Alzetta, Chiara  and
      Cardillo, Franco Alberto  and
      Dell{'}Orletta, Felice",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4430",
    doi = "10.18653/v1/W19-4430",
    pages = "285--295",
    abstract = "We present a new concept prerequisite learning method for Learning Object (LO) ordering that exploits only linguistic features extracted from textual educational resources. The method was tested in a cross- and in- domain scenario both for Italian and English. Additionally, we performed experiments based on a incremental training strategy to study the impact of the training set size on the classifier performances. The paper also introduces ITA-PREREQ, to the best of our knowledge the first Italian dataset annotated with prerequisite relations between pairs of educational concepts, and describe the automatic strategy devised to build it.",
}
@inproceedings{arai-etal-2019-grammatical,
    title = "Grammatical-Error-Aware Incorrect Example Retrieval System for Learners of {J}apanese as a Second Language",
    author = "Arai, Mio  and
      Kaneko, Masahiro  and
      Komachi, Mamoru",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4431",
    doi = "10.18653/v1/W19-4431",
    pages = "296--305",
    abstract = "Existing example retrieval systems do not include grammatically incorrect examples or present only a few examples, if any. Even if a retrieval system has a wide coverage of incorrect examples along with the correct counterpart, learners need to know whether their query includes errors or not. Considering the usability of retrieving incorrect examples, our proposed method uses a large-scale corpus and presents correct expressions along with incorrect expressions using a grammatical error detection system so that the learner do not need to be aware of how to search for the examples. Intrinsic and extrinsic evaluations indicate that our method improves accuracy of example sentence retrieval and quality of learner{'}s writing.",
}
@inproceedings{yoon-etal-2019-toward,
    title = "Toward Automated Content Feedback Generation for Non-native Spontaneous Speech",
    author = "Yoon, Su-Youn  and
      Hsieh, Ching-Ni  and
      Zechner, Klaus  and
      Mulholland, Matthew  and
      Wang, Yuan  and
      Madnani, Nitin",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4432",
    doi = "10.18653/v1/W19-4432",
    pages = "306--315",
    abstract = "In this study, we developed an automated algorithm to provide feedback about the specific content of non-native English speakers{'} spoken responses. The responses were spontaneous speech, elicited using integrated tasks where the language learners listened to and/or read passages and integrated the core content in their spoken responses. Our models detected the absence of key points considered to be important in a spoken response to a particular test question, based on two different models: (a) a model using word-embedding based content features and (b) a state-of-the art short response scoring engine using traditional n-gram based features. Both models achieved a substantially improved performance over the majority baseline, and the combination of the two models achieved a significant further improvement. In particular, the models were robust to automated speech recognition (ASR) errors, and performance based on the ASR word hypotheses was comparable to that based on manual transcriptions. The accuracy and F-score of the best model for the questions included in the train set were 0.80 and 0.68, respectively. Finally, we discussed possible approaches to generating targeted feedback about the content of a language learner{'}s response, based on automatically detected missing key points.",
}
@inproceedings{mizumoto-etal-2019-analytic,
    title = "Analytic Score Prediction and Justification Identification in Automated Short Answer Scoring",
    author = "Mizumoto, Tomoya  and
      Ouchi, Hiroki  and
      Isobe, Yoriko  and
      Reisert, Paul  and
      Nagata, Ryo  and
      Sekine, Satoshi  and
      Inui, Kentaro",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4433",
    doi = "10.18653/v1/W19-4433",
    pages = "316--325",
    abstract = "This paper provides an analytical assessment of student short answer responses with a view to potential benefits in pedagogical contexts. We first propose and formalize two novel analytical assessment tasks: analytic score prediction and justification identification, and then provide the first dataset created for analytic short answer scoring research. Subsequently, we present a neural baseline model and report our extensive empirical results to demonstrate how our dataset can be used to explore new and intriguing technical challenges in short answer scoring. The dataset is publicly available for research purposes.",
}
@inproceedings{shah-etal-2019-content,
    title = "Content Customization for Micro Learning using Human Augmented {AI} Techniques",
    author = "Shah, Ayush  and
      Abuelsaad, Tamer  and
      Ahn, Jae-Wook  and
      Dey, Prasenjit  and
      Kokku, Ravi  and
      Sharma Mittal, Ruhi  and
      Vempaty, Aditya  and
      Sharma, Mourvi",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4434",
    doi = "10.18653/v1/W19-4434",
    pages = "326--335",
    abstract = "Visual content has been proven to be effective for micro-learning compared to other media. In this paper, we discuss leveraging this observation in our efforts to build audio-visual content for young learners{'} vocabulary learning. We attempt to tackle two major issues in the process of traditional visual curation tasks. Generic learning videos do not necessarily satisfy the unique context of a learner and/or an educator, and hence may not result in maximal learning outcomes. Also, manual video curation by educators is a highly labor-intensive process. To this end, we present a customizable micro-learning audio-visual content curation tool that is designed to reduce the human (educator) effort in creating just-in-time learning videos from a textual description (learning script). This provides educators with control of the content while preparing the learning scripts, and in turn can also be customized to capture the desired learning objectives and outcomes. As a use case, we automatically generate learning videos with British National Corpus{'} (BNC) frequently spoken vocabulary words and evaluate them with experts. They positively recommended the generated learning videos with an average rating of 4.25 on a Likert scale of 5 points. The inter-annotator agreement between the experts for the video quality was substantial (Fleiss Kappa=0.62) with an overall agreement of 81{\%}.",
}
@inproceedings{raamadhurai-etal-2019-curio,
    title = "Curio {S}mart{C}hat : A system for Natural Language Question Answering for Self-Paced K-12 Learning",
    author = "Raamadhurai, Srikrishna  and
      Baker, Ryan  and
      Poduval, Vikraman",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4435",
    doi = "10.18653/v1/W19-4435",
    pages = "336--342",
    abstract = "During learning, students often have questions which they would benefit from responses to in real time. In class, a student can ask a question to a teacher. During homework, or even in class if the student is shy, it can be more difficult to receive a rapid response. In this work, we introduce Curio SmartChat, an automated question answering system for middle school Science topics. Our system has now been used by around 20,000 students who have so far asked over 100,000 questions. We present data on the challenge created by students{'} grammatical errors and spelling mistakes, and discuss our system{'}s approach and degree of effectiveness at disambiguating questions that the system is initially unsure about. We also discuss the prevalence of student {``}small talk{''} not related to science topics, the pluses and minuses of this behavior, and how a system should respond to these conversational acts. We conclude with discussions and point to directions for potential future work.",
}
@inproceedings{gecchele-etal-2019-supporting,
    title = "Supporting content evaluation of student summaries by Idea Unit embedding",
    author = "Gecchele, Marcello  and
      Yamada, Hiroaki  and
      Tokunaga, Takenobu  and
      Sawaki, Yasuyo",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4436",
    doi = "10.18653/v1/W19-4436",
    pages = "343--348",
    abstract = "This paper discusses the computer-assisted content evaluation of summaries. We propose a method to make a correspondence between the segments of the source text and its summary. As a unit of the segment, we adopt {``}Idea Unit (IU){''} which is proposed in Applied Linguistics. Introducing IUs enables us to make a correspondence even for the sentences that contain multiple ideas. The IU correspondence is made based on the similarity between vector representations of IU. An evaluation experiment with two source texts and 20 summaries showed that the proposed method is more robust against rephrased expressions than the conventional ROUGE-based baselines. Also, the proposed method outperformed the baselines in recall. We im-plemented the proposed method in a GUI tool{``}Segment Matcher{''} that aids teachers to estab-lish a link between corresponding IUs acrossthe summary and source text.",
}
@inproceedings{vajjala-lucic-2019-understanding,
    title = "On Understanding the Relation between Expert Annotations of Text Readability and Target Reader Comprehension",
    author = "Vajjala, Sowmya  and
      Lucic, Ivana",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4437",
    doi = "10.18653/v1/W19-4437",
    pages = "349--359",
    abstract = "Automatic readability assessment aims to ensure that readers read texts that they can comprehend. However, computational models are typically trained on texts created from the perspective of the text writer, not the target reader. There is little experimental research on the relationship between expert annotations of readability, reader{'}s language proficiency, and different levels of reading comprehension. To address this gap, we conducted a user study in which over a 100 participants read texts of different reading levels and answered questions created to test three forms of comprehension. Our results indicate that more than readability annotation or reader proficiency, it is the type of comprehension question asked that shows differences between reader responses - inferential questions were difficult for users of all levels of proficiency across reading levels. The data collected from this study will be released with this paper, which will, for the first time, provide a collection of 45 reader bench marked texts to evaluate readability assessment systems developed for adult learners of English. It can also potentially be useful for the development of question generation approaches in intelligent tutoring systems research.",
}
@inproceedings{forti-etal-2019-measuring,
    title = "Measuring Text Complexity for {I}talian as a Second Language Learning Purposes",
    author = "Forti, Luciana  and
      Milani, Alfredo  and
      Piersanti, Luisa  and
      Santarelli, Filippo  and
      Santucci, Valentino  and
      Spina, Stefania",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4438",
    doi = "10.18653/v1/W19-4438",
    pages = "360--368",
    abstract = "The selection of texts for second language learning purposes typically relies on teachers{'} and test developers{'} individual judgment of the observable qualitative properties of a text. Little or no consideration is generally given to the quantitative dimension within an evidence-based framework of reproducibility. This study aims to fill the gap by evaluating the effectiveness of an automatic tool trained to assess text complexity in the context of Italian as a second language learning. A dataset of texts labeled by expert test developers was used to evaluate the performance of three classifier models (decision tree, random forest, and support vector machine), which were trained using linguistic features measured quantitatively and extracted from the texts. The experimental analysis provided satisfactory results, also in relation to which kind of linguistic trait contributed the most to the final outcome.",
}
@inproceedings{renduchintala-etal-2019-simple,
    title = "Simple Construction of Mixed-Language Texts for Vocabulary Learning",
    author = "Renduchintala, Adithya  and
      Koehn, Philipp  and
      Eisner, Jason",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4439",
    doi = "10.18653/v1/W19-4439",
    pages = "369--379",
    abstract = "We present a machine foreign-language teacher that takes documents written in a student{'}s native language and detects situations where it can replace words with their foreign glosses such that new foreign vocabulary can be learned simply through reading the resulting mixed-language text. We show that it is possible to design such a machine teacher without any supervised data from (human) students. We accomplish this by modifying a cloze language model to incrementally learn new vocabulary items, and use this language model as a proxy for the word guessing and learning ability of real students. Our machine foreign-language teacher decides which subset of words to replace by consulting this language model. We evaluate three variants of our student proxy language models through a study on Amazon Mechanical Turk (MTurk). We find that MTurk {``}students{''} were able to guess the meanings of foreign words introduced by the machine teacher with high accuracy for both function words as well as content words in two out of the three models. In addition, we show that students are able to retain their knowledge about the foreign words after they finish reading the document.",
}
@inproceedings{weiss-meurers-2019-analyzing,
    title = "Analyzing Linguistic Complexity and Accuracy in Academic Language Development of {G}erman across Elementary and Secondary School",
    author = "Weiss, Zarah  and
      Meurers, Detmar",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4440",
    doi = "10.18653/v1/W19-4440",
    pages = "380--393",
    abstract = "We track the development of writing complexity and accuracy in German students{'} early academic language development from first to eighth grade. Combining an empirically broad approach to linguistic complexity with the high-quality error annotation included in the Karlsruhe Children{'}s Text corpus (Lavalley et al. 2015) used, we construct models of German academic language development that successfully identify the student{'}s grade level. We show that classifiers for the early years rely more on accuracy development, whereas development in secondary school is better characterized by increasingly complex language in all domains: linguistic system, language use, and human sentence processing characteristics. We demonstrate the generalizability and robustness of models using such a broad complexity feature set across writing topics.",
}
@inproceedings{yoon-lee-2019-content,
    title = "Content Modeling for Automated Oral Proficiency Scoring System",
    author = "Yoon, Su-Youn  and
      Lee, Chong Min",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4441",
    doi = "10.18653/v1/W19-4441",
    pages = "394--401",
    abstract = "We developed an automated oral proficiency scoring system for non-native English speakers{'} spontaneous speech. Automated systems that score holistic proficiency are expected to assess a wide range of performance categories, and the content is one of the core performance categories. In order to assess the quality of the content, we trained a Siamese convolutional neural network (CNN) to model the semantic relationship between key points generated by experts and a test response. The correlation between human scores and Siamese CNN scores was comparable to human-human agreement (r=0.63), and it was higher than the baseline content features. The inclusion of Siamese CNN-based feature to the existing state-of-the-art automated scoring model achieved a small but statistically significant improvement. However, the new model suffered from score inflation for long atypical responses with serious content issues. We investigated the reasons of this score inflation by analyzing the associations with linguistic features and identifying areas strongly associated with the score errors.",
}
@inproceedings{mondal-etal-2019-learning,
    title = "Learning Outcomes and Their Relatedness in a Medical Curriculum",
    author = "Mondal, Sneha  and
      Dhamecha, Tejas  and
      Godbole, Shantanu  and
      Pathak, Smriti  and
      Mendoza, Red  and
      Wijayarathna, K Gayathri  and
      Zary, Nabil  and
      Saha, Swarnadeep  and
      Chetlur, Malolan",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4442",
    doi = "10.18653/v1/W19-4442",
    pages = "402--411",
    abstract = "A typical medical curriculum is organized in a hierarchy of instructional objectives called Learning Outcomes (LOs); a few thousand LOs span five years of study. Gaining a thorough understanding of the curriculum requires learners to recognize and apply related LOs across years, and across different parts of the curriculum. However, given the large scope of the curriculum, manually labeling related LOs is tedious, and almost impossible to scale. In this paper, we build a system that learns relationships between LOs, and we achieve up to human-level performance in the LO relationship extraction task. We then present an application where the proposed system is employed to build a map of related LOs and Learning Resources (LRs) pertaining to a virtual patient case. We believe that our system can help medical students grasp the curriculum better, within classroom as well as in Intelligent Tutoring Systems (ITS) settings.",
}
@inproceedings{benzahra-yvon-2019-measuring,
    title = "Measuring text readability with machine comprehension: a pilot study",
    author = "Benzahra, Marc  and
      Yvon, Fran{\c{c}}ois",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4443",
    doi = "10.18653/v1/W19-4443",
    pages = "412--422",
    abstract = "This article studies the relationship between text readability indice and automatic machine understanding systems. Our hypothesis is that the simpler a text is, the better it should be understood by a machine. We thus expect to a strong correlation between readability levels on the one hand, and performance of automatic reading systems on the other hand. We test this hypothesis with several understanding systems based on language models of varying strengths, measuring this correlation on two corpora of journalistic texts. Our results suggest that this correlation is rather small that existing comprehension systems are far to reproduce the gradual improvement of their performance on texts of decreasing complexity.",
}
@inproceedings{clausen-nastase-2019-metaphors,
    title = "Metaphors in Text Simplification: To change or not to change, that is the question",
    author = "Clausen, Yulia  and
      Nastase, Vivi",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4444",
    doi = "10.18653/v1/W19-4444",
    pages = "423--434",
    abstract = "We present an analysis of metaphors in news text simplification. Using features that capture general and metaphor specific characteristics, we test whether we can automatically identify which metaphors will be changed or preserved, and whether there are features that have different predictive power for metaphors or literal words. The experiments show that the Age of Acquisition is the most distinctive feature for both metaphors and literal words. Features that capture Imageability and Concreteness are useful when used alone, but within the full set of features they lose their impact. Frequency of use seems to be the best feature to differentiate metaphors that should be changed and those to be preserved.",
}
@inproceedings{wang-etal-2019-application,
    title = "Application of an Automatic Plagiarism Detection System in a Large-scale Assessment of {E}nglish Speaking Proficiency",
    author = "Wang, Xinhao  and
      Evanini, Keelan  and
      Mulholland, Matthew  and
      Qian, Yao  and
      Bruno, James V.",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4445",
    doi = "10.18653/v1/W19-4445",
    pages = "435--443",
    abstract = "This study aims to build an automatic system for the detection of plagiarized spoken responses in the context of an assessment of English speaking proficiency for non-native speakers. Classification models were trained to distinguish between plagiarized and non-plagiarized responses with two different types of features: text-to-text content similarity measures, which are commonly used in the task of plagiarism detection for written documents, and speaking proficiency measures, which were specifically designed for spontaneous speech and extracted using an automated speech scoring system. The experiments were first conducted on a large data set drawn from an operational English proficiency assessment across multiple years, and the best classifier on this heavily imbalanced data set resulted in an F1-score of 0.761 on the plagiarized class. This system was then validated on operational responses collected from a single administration of the assessment and achieved a recall of 0.897. The results indicate that the proposed system can potentially be used to improve the validity of both human and automated assessment of non-native spoken English.",
}
@inproceedings{mayfield-etal-2019-equity,
    title = "Equity Beyond Bias in Language Technologies for Education",
    author = "Mayfield, Elijah  and
      Madaio, Michael  and
      Prabhumoye, Shrimai  and
      Gerritsen, David  and
      McLaughlin, Brittany  and
      Dixon-Rom{\'a}n, Ezekiel  and
      Black, Alan W",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4446",
    doi = "10.18653/v1/W19-4446",
    pages = "444--460",
    abstract = "There is a long record of research on equity in schools. As machine learning researchers begin to study fairness and bias in earnest, language technologies in education have an unusually strong theoretical and applied foundation to build on. Here, we introduce concepts from culturally relevant pedagogy and other frameworks for teaching and learning, identifying future work on equity in NLP. We present case studies in a range of topics like intelligent tutoring systems, computer-assisted language learning, automated essay scoring, and sentiment analysis in classrooms, and provide an actionable agenda for research.",
}
@inproceedings{huang-etal-2019-receptive,
    title = "From Receptive to Productive: Learning to Use Confusing Words through Automatically Selected Example Sentences",
    author = "Huang, Chieh-Yang  and
      Huang, Yi-Ting  and
      Chen, MeiHua  and
      Ku, Lun-Wei",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4447",
    doi = "10.18653/v1/W19-4447",
    pages = "461--471",
    abstract = "Knowing how to use words appropriately has been a key to improving language proficiency. Previous studies typically discuss how students learn receptively to select the correct candidate from a set of confusing words in the fill-in-the-blank task where specific context is given. In this paper, we go one step further, assisting students to learn to use confusing words appropriately in a productive task: sentence translation. We leverage the GiveMe-Example system, which suggests example sentences for each confusing word, to achieve this goal. In this study, students learn to differentiate the confusing words by reading the example sentences, and then choose the appropriate word(s) to complete the sentence translation task. Results show students made substantial progress in terms of sentence structure. In addition, highly proficient students better managed to learn confusing words. In view of the influence of the first language on learners, we further propose an effective approach to improve the quality of the suggested sentences.",
}
@inproceedings{sakakini-etal-2019-equipping,
    title = "Equipping Educational Applications with Domain Knowledge",
    author = "Sakakini, Tarek  and
      Gong, Hongyu  and
      Lee, Jong Yoon  and
      Schloss, Robert  and
      Xiong, JinJun  and
      Bhat, Suma",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4448",
    doi = "10.18653/v1/W19-4448",
    pages = "472--477",
    abstract = "One of the challenges of building natural language processing (NLP) applications for education is finding a large domain-specific corpus for the subject of interest (e.g., history or science). To address this challenge, we propose a tool, Dexter, that extracts a subject-specific corpus from a heterogeneous corpus, such as Wikipedia, by relying on a small seed corpus and distributed document representations. We empirically show the impact of the generated corpus on language modeling, estimating word embeddings, and consequently, distractor generation, resulting in better performances than while using a general domain corpus, a heuristically constructed domain-specific corpus, and a corpus generated by a popular system: BootCaT.",
}
@inproceedings{htut-tetreault-2019-unbearable,
    title = "The Unbearable Weight of Generating Artificial Errors for Grammatical Error Correction",
    author = "Htut, Phu Mon  and
      Tetreault, Joel",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4449",
    doi = "10.18653/v1/W19-4449",
    pages = "478--483",
    abstract = "In this paper, we investigate the impact of using 4 recent neural models for generating artificial errors to help train the neural grammatical error correction models. We conduct a battery of experiments on the effect of data size, models, and comparison with a rule-based approach.",
}
@inproceedings{nadeem-etal-2019-automated,
    title = "Automated Essay Scoring with Discourse-Aware Neural Models",
    author = "Nadeem, Farah  and
      Nguyen, Huy  and
      Liu, Yang  and
      Ostendorf, Mari",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4450",
    doi = "10.18653/v1/W19-4450",
    pages = "484--493",
    abstract = "Automated essay scoring systems typically rely on hand-crafted features to predict essay quality, but such systems are limited by the cost of feature engineering. Neural networks offer an alternative to feature engineering, but they typically require more annotated data. This paper explores network structures, contextualized embeddings and pre-training strategies aimed at capturing discourse characteristics of essays. Experiments on three essay scoring tasks show benefits from all three strategies in different combinations, with simpler architectures being more effective when less training data is available.",
}
@inproceedings{hou-etal-2019-modeling,
    title = "Modeling language learning using specialized Elo rating",
    author = "Hou, Jue  and
      Maximilian, Koppatz  and
      Hoya Quecedo, Jos{\'e} Mar{\'\i}a  and
      Stoyanova, Nataliya  and
      Yangarber, Roman",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4451",
    doi = "10.18653/v1/W19-4451",
    pages = "494--506",
    abstract = "Automatic assessment of the proficiency levels of the learner is a critical part of Intelligent Tutoring Systems. We present methods for assessment in the context of language learning. We use a specialized Elo formula used in conjunction with educational data mining. We simultaneously obtain ratings for the proficiency of the learners and for the difficulty of the linguistic concepts that the learners are trying to master. From the same data we also learn a graph structure representing a domain model capturing the relations among the concepts. This application of Elo provides ratings for learners and concepts which correlate well with subjective proficiency levels of the learners and difficulty levels of the concepts.",
}
@inproceedings{gao-etal-2019-rubric,
    title = "Rubric Reliability and Annotation of Content and Argument in Source-Based Argument Essays",
    author = "Gao, Yanjun  and
      Driban, Alex  and
      Xavier McManus, Brennan  and
      Musi, Elena  and
      Davies, Patricia  and
      Muresan, Smaranda  and
      Passonneau, Rebecca J.",
    booktitle = "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4452",
    doi = "10.18653/v1/W19-4452",
    pages = "507--518",
    abstract = "We present a unique dataset of student source-based argument essays to facilitate research on the relations between content, argumentation skills, and assessment. Two classroom writing assignments were given to college students in a STEM major, accompanied by a carefully designed rubric. The paper presents a reliability study of the rubric, showing it to be highly reliable, and initial annotation on content and argumentation annotation of the essays.",
}
