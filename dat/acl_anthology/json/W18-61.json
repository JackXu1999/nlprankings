[{"id":"W18-6101","title":"Inducing a lexicon of sociolinguistic variables from code-mixed text","authors":["Shoemark, Philippa","Kirby, James","Goldwater, Sharon"],"emails":["p.j.shoemark@ed.ac.uk","j.kirby@ed.ac.uk","sgwater@inf.ed.ac.uk"],"author_id":["philippa-shoemark","james-kirby","sharon-goldwater"],"abstract":"Sociolinguistics is often concerned with how variants of a linguistic item (e.g., nothing vs. nothin{'}) are used by different groups or in different situations. We introduce the task of inducing lexical variables from code-mixed text: that is, identifying equivalence pairs such as (football, fitba) along with their linguistic code (football\u2192British, fitba\u2192Scottish). We adapt a framework for identifying gender-biased word pairs to this new task, and present results on three different pairs of English dialects, using tweets as the code-mixed text. Our system achieves precision of over 70{\\%} for two of these three datasets, and produces useful results even without extensive parameter tuning. Our success in adapting this framework from gender to language variety suggests that it could be used to discover other types of analogous pairs as well.","pages":"1--6","doi":"10.18653\/v1\/W18-6101","url":"https:\/\/www.aclweb.org\/anthology\/W18-6101","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6102","title":"Twitter Geolocation using Knowledge-Based Methods","authors":["Miyazaki, Taro","Rahimi, Afshin","Cohn, Trevor","Baldwin, Timothy"],"emails":["miyazaki.t-jw@nhk.or.jp","rahimia@unimelb.edu.au","trevor.cohn@unimelb.edu.au","tbaldwin@unimelb.edu.au"],"author_id":["taro-miyazaki","afshin-rahimi","trevor-cohn","timothy-baldwin"],"abstract":"Geolocation of user posts on Twitter is useful for many applications, including disaster monitoring and news material gathering. However, the vast majority of tweets have no explicit geotag, motivating the need for automatic geolocation prediction methods. We propose the use of named entity linking in geolocation prediction, modelled using graph convolutional networks over a knowledge base of entity relations, which is combined with text-based models in an end-to-end deep learning framework. We show that our method improves on text-based models, and learns effective representations for named entities that do not appear in the training data.","pages":"7--16","doi":"10.18653\/v1\/W18-6102","url":"https:\/\/www.aclweb.org\/anthology\/W18-6102","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6103","title":"Geocoding Without Geotags: A Text-based Approach for reddit","authors":["Harrigian, Keith"],"emails":["keith.harrigian@appliedanalytics.net"],"author_id":["keith-harrigian"],"abstract":"In this paper, we introduce the first geolocation inference approach for reddit, a social media platform where user pseudonymity has thus far made supervised demographic inference difficult to implement and validate. In particular, we design a text-based heuristic schema to generate ground truth location labels for reddit users in the absence of explicitly geotagged data. After evaluating the accuracy of our labeling procedure, we train and test several geolocation inference models across our reddit data set and three benchmark Twitter geolocation data sets. Ultimately, we show that geolocation models trained and applied on the same domain substantially outperform models attempting to transfer training data across domains, even more so on reddit where platform-specific interest-group metadata can be used to improve inferences.","pages":"17--27","doi":"10.18653\/v1\/W18-6103","url":"https:\/\/www.aclweb.org\/anthology\/W18-6103","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6104","title":"Assigning people to tasks identified in email: The {EPA} dataset for addressee tagging for detected task intent","authors":["Rameshkumar, Revanth","Bailey, Peter","Jha, Abhishek","Quirk, Chris"],"emails":["","","",""],"author_id":["revanth-rameshkumar","peter-bailey","abhishek-jha","chris-quirk"],"abstract":"We describe the Enron People Assignment (EPA) dataset, in which tasks that are described in emails are associated with the person(s) responsible for carrying out these tasks. We identify tasks and the responsible people in the Enron email dataset. We define evaluation methods for this challenge and report scores for our model and na{\\\"\\i}ve baselines. The resulting model enables a user experience operating within a commercial email service: given a person and a task, it determines if the person should be notified of the task.","pages":"28--32","doi":"10.18653\/v1\/W18-6104","url":"https:\/\/www.aclweb.org\/anthology\/W18-6104","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6105","title":"How do you correct run-on sentences it{'}s not as easy as it seems","authors":["Zheng, Junchao","Napoles, Courtney","Tetreault, Joel","Omelianchuk, Kostiantyn"],"emails":["junchao.zheng@grammarly.com","courtney.napoles@grammarly.com","joel.tetreault@grammarly.com","kostiantyn.omelianchuk@grammarly.com"],"author_id":["junchao-zheng","courtney-napoles","joel-tetreault","kostiantyn-omelianchuk"],"abstract":"Run-on sentences are common grammatical mistakes but little research has tackled this problem to date. This work introduces two machine learning models to correct run-on sentences that outperform leading methods for related tasks, punctuation restoration and whole-sentence grammatical error correction. Due to the limited annotated data for this error, we experiment with artificially generating training data from clean newswire text. Our findings suggest artificial training data is viable for this task. We discuss implications for correcting run-ons and other types of mistakes that have low coverage in error-annotated corpora.","pages":"33--38","doi":"10.18653\/v1\/W18-6105","url":"https:\/\/www.aclweb.org\/anthology\/W18-6105","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6106","title":"A {POS} Tagging Model Adapted to Learner {E}nglish","authors":["Nagata, Ryo","Mizumoto, Tomoya","Kikuchi, Yuta","Kawasaki, Yoshifumi","Funakoshi, Kotaro"],"emails":["","","","",""],"author_id":["ryo-nagata","tomoya-mizumoto","yuta-kikuchi","yoshifumi-kawasaki","kotaro-funakoshi"],"abstract":"There has been very limited work on the adaptation of Part-Of-Speech (POS) tagging to learner English despite the fact that POS tagging is widely used in related tasks. In this paper, we explore how we can adapt POS tagging to learner English efficiently and effectively. Based on the discussion of possible causes of POS tagging errors in learner English, we show that deep neural models are particularly suitable for this. Considering the previous findings and the discussion, we introduce the design of our model based on bidirectional Long Short-Term Memory. In addition, we describe how to adapt it to a wide variety of native languages (potentially, hundreds of them). In the evaluation section, we empirically show that it is effective for POS tagging in learner English, achieving an accuracy of 0.964, which significantly outperforms the state-of-the-art POS-tagger. We further investigate the tagging results in detail, revealing which part of the model design does or does not improve the performance.","pages":"39--48","doi":"10.18653\/v1\/W18-6106","url":"https:\/\/www.aclweb.org\/anthology\/W18-6106","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6107","title":"Normalization of Transliterated Words in Code-Mixed Data Using {S}eq2{S}eq Model {\\&} {L}evenshtein Distance","authors":["Mandal, Soumil","Nanmaran, Karthick"],"emails":["soumil.mandal@gmail.com","karthicknanmaran@gmail.com"],"author_id":["soumil-mandal","karthick-nanmaran"],"abstract":"Building tools for code-mixed data is rapidly gaining popularity in the NLP research community as such data is exponentially rising on social media. Working with code-mixed data contains several challenges, especially due to grammatical inconsistencies and spelling variations in addition to all the previous known challenges for social media scenarios. In this article, we present a novel architecture focusing on normalizing phonetic typing variations, which is commonly seen in code-mixed data. One of the main features of our architecture is that in addition to normalizing, it can also be utilized for back-transliteration and word identification in some cases. Our model achieved an accuracy of 90.27{\\%} on the test data.","pages":"49--53","doi":"10.18653\/v1\/W18-6107","url":"https:\/\/www.aclweb.org\/anthology\/W18-6107","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6108","title":"Robust Word Vectors: Context-Informed Embeddings for Noisy Texts","authors":["Malykh, Valentin","Logacheva, Varvara","Khakhulin, Taras"],"emails":["valentin.malykh@phystech.edu","",""],"author_id":["valentin-malykh","varvara-logacheva","taras-khakhulin"],"abstract":"We suggest a new language-independent architecture of robust word vectors (RoVe). It is designed to alleviate the issue of typos, which are common in almost any user-generated content, and hinder automatic text processing. Our model is morphologically motivated, which allows it to deal with unseen word forms in morphologically rich languages.","pages":"54--63","doi":"10.18653\/v1\/W18-6108","url":"https:\/\/www.aclweb.org\/anthology\/W18-6108","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6109","title":"Paraphrase Detection on Noisy Subtitles in Six Languages","authors":["Sj{\\\"o}blom, Eetu","Creutz, Mathias","Aulamo, Mikko"],"emails":["eetu.sjoblom@helsinki.fi","mathias.creutz@helsinki.fi","mikko.aulamo@helsinki.fi"],"author_id":["eetu-sjoblom","mathias-creutz","mikko-aulamo"],"abstract":"We perform automatic paraphrase detection on subtitle data from the Opusparcus corpus comprising six European languages: German, English, Finnish, French, Russian, and Swedish. We train two types of supervised sentence embedding models: a word-averaging (WA) model and a gated recurrent averaging network (GRAN) model. We find out that GRAN outperforms WA and is more robust to noisy training data. Better results are obtained with more and noisier data than less and cleaner data. Additionally, we experiment on other datasets, without reaching the same level of performance, because of domain mismatch between training and test data.","pages":"64--73","doi":"10.18653\/v1\/W18-6109","url":"https:\/\/www.aclweb.org\/anthology\/W18-6109","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6110","title":"Distantly Supervised Attribute Detection from Reviews","authors":["Fu, Lisheng","Barrio, Pablo"],"emails":["lisheng@cs.nyu.edu","pjbarrio@google.com"],"author_id":["lisheng-fu","pablo-barrio"],"abstract":"This paper aims to detect specific attributes of a place (e.g., if it has a romantic atmosphere, or if it offers outdoor seating) from its user reviews via distant supervision: without direct annotation of review text, we use the crowdsourced attribute labels of a place as labels of the review text.","pages":"74--78","doi":"10.18653\/v1\/W18-6110","url":"https:\/\/www.aclweb.org\/anthology\/W18-6110","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6111","title":"Using {W}ikipedia Edits in Low Resource Grammatical Error Correction","authors":["Boyd, Adriane"],"emails":["adriane@sfs.uni-tuebingen.de"],"author_id":["adriane-boyd"],"abstract":"We develop a grammatical error correction (GEC) system for German using a small gold GEC corpus augmented with edits extracted from Wikipedia revision history. We extend the automatic error annotation tool ERRANT (Bryant et al., 2017) for German and use it to analyze both gold GEC corrections and Wikipedia edits (Grundkiewicz and Junczys-Dowmunt, 2014) in order to select as additional training data Wikipedia edits containing grammatical corrections similar to those in the gold corpus. Using a multilayer convolutional encoder-decoder neural network GEC approach (Chollampatt and Ng, 2018), we evaluate the contribution of Wikipedia edits and find that carefully selected Wikipedia edits increase performance by over 5{\\%}.","pages":"79--84","doi":"10.18653\/v1\/W18-6111","url":"https:\/\/www.aclweb.org\/anthology\/W18-6111","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6112","title":"Empirical Evaluation of Character-Based Model on Neural Named-Entity Recognition in {I}ndonesian Conversational Texts","authors":["Kurniawan, Kemal","Louvan, Samuel"],"emails":["kemal@kata.ai","slouvan@fbk.eu"],"author_id":["kemal-kurniawan","samuel-louvan"],"abstract":"Despite the long history of named-entity recognition (NER) task in the natural language processing community, previous work rarely studied the task on conversational texts. Such texts are challenging because they contain a lot of word variations which increase the number of out-of-vocabulary (OOV) words. The high number of OOV words poses a difficulty for word-based neural models. Meanwhile, there is plenty of evidence to the effectiveness of character-based neural models in mitigating this OOV problem. We report an empirical evaluation of neural sequence labeling models with character embedding to tackle NER task in Indonesian conversational texts. Our experiments show that (1) character models outperform word embedding-only models by up to 4 F1 points, (2) character models perform better in OOV cases with an improvement of as high as 15 F1 points, and (3) character models are robust against a very high OOV rate.","pages":"85--92","doi":"10.18653\/v1\/W18-6112","url":"https:\/\/www.aclweb.org\/anthology\/W18-6112","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6113","title":"Orthogonal Matching Pursuit for Text Classification","authors":["Skianis, Konstantinos","Tziortziotis, Nikolaos","Vazirgiannis, Michalis"],"emails":["kskianis@lix.polytechnique.fr","ntziorzi@gmail.com","mvazirg@lix.polytechnique.fr"],"author_id":["konstantinos-skianis","nikolaos-tziortziotis","michalis-vazirgiannis"],"abstract":"In text classification, the problem of overfitting arises due to the high dimensionality, making regularization essential.","pages":"93--103","doi":"10.18653\/v1\/W18-6113","url":"https:\/\/www.aclweb.org\/anthology\/W18-6113","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6114","title":"Training and Prediction Data Discrepancies: Challenges of Text Classification with Noisy, Historical Data","authors":["Kreek, R. Andrew","Apostolova, Emilia"],"emails":["rkree@allstate.com","emilia@language.ai"],"author_id":["r-andrew-kreek","emilia-apostolova"],"abstract":"Industry datasets used for text classification are rarely created for that purpose. In most cases, the data and target predictions are a by-product of accumulated historical data, typically fraught with noise, present in both the text-based document, as well as in the targeted labels. In this work, we address the question of how well performance metrics computed on noisy, historical data reflect the performance on the intended future machine learning model input. The results demonstrate the utility of dirty training datasets used to build prediction models for cleaner (and different) prediction inputs.","pages":"104--109","doi":"10.18653\/v1\/W18-6114","url":"https:\/\/www.aclweb.org\/anthology\/W18-6114","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6115","title":"Detecting Code-Switching between {T}urkish-{E}nglish Language Pair","authors":["Yirmibe{\\c{s}}o{\\u{g}}lu, Zeynep","Eryi{\\u{g}}it, G{\\\"u}l{\\c{s}}en"],"emails":["yirmibesogluz@itu.edu.tr","gulsen.cebiroglu@itu.edu.tr"],"author_id":["zeynep-yirmibesoglu","gulsen-eryigit"],"abstract":"Code-switching (usage of different languages within a single conversation context in an alternative manner) is a highly increasing phenomenon in social media and colloquial usage which poses different challenges for natural language processing. This paper introduces the first study for the detection of Turkish-English code-switching and also a small test data collected from social media in order to smooth the way for further studies.","pages":"110--115","doi":"10.18653\/v1\/W18-6115","url":"https:\/\/www.aclweb.org\/anthology\/W18-6115","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6116","title":"Language Identification in Code-Mixed Data using Multichannel Neural Networks and Context Capture","authors":["Mandal, Soumil","Singh, Anil Kumar"],"emails":["soumil.mandal@gmail.com","aksingh.cse@iitbhu.ac.in"],"author_id":["soumil-mandal","anil-kumar-singh"],"abstract":"An accurate language identification tool is an absolute necessity for building complex NLP systems to be used on code-mixed data. Lot of work has been recently done on the same, but there{'}s still room for improvement. Inspired from the recent advancements in neural network architectures for computer vision tasks, we have implemented multichannel neural networks combining CNN and LSTM for word level language identification of code-mixed data. Combining this with a Bi-LSTM-CRF context capture module, accuracies of 93.28{\\%} and 93.32{\\%} is achieved on out two testing sets.","pages":"116--120","doi":"10.18653\/v1\/W18-6116","url":"https:\/\/www.aclweb.org\/anthology\/W18-6116","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6117","title":"Modeling Student Response Times: Towards Efficient One-on-one Tutoring Dialogues","authors":["Benotti, Luciana","Bhaskaran, Jayadev","Kjartansson, Sigtryggur","Lang, David"],"emails":["benotti@famaf.unc.edu.ar","jayadev@stanford.edu","sigkj@stanford.edu","dnlang86@stanford.edu"],"author_id":["luciana-benotti","jayadev-bhaskaran","sigtryggur-kjartansson","david-lang"],"abstract":"In this paper we investigate the task of modeling how long it would take a student to respond to a tutor question during a tutoring dialogue.","pages":"121--131","doi":"10.18653\/v1\/W18-6117","url":"https:\/\/www.aclweb.org\/anthology\/W18-6117","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6118","title":"Content Extraction and Lexical Analysis from Customer-Agent Interactions","authors":["Nisioi, Sergiu","Bucur, Anca","Dinu, Liviu P."],"emails":["sergiu.nisioi@gmail.com","anca.m.bucur@gmail.com","ldinu@fmi.unibuc.ro"],"author_id":["sergiu-nisioi","anca-bucur","liviu-p-dinu"],"abstract":"In this paper, we provide a lexical comparative analysis of the vocabulary used by customers and agents in an","pages":"132--136","doi":"10.18653\/v1\/W18-6118","url":"https:\/\/www.aclweb.org\/anthology\/W18-6118","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6119","title":"Preferred Answer Selection in Stack Overflow: Better Text Representations ... and Metadata, Metadata, Metadata","authors":["Xu, Steven","Bennett, Andrew","Hoogeveen, Doris","Lau, Jey Han","Baldwin, Timothy"],"emails":["stevenxxiu@gmail.com","awbennett0@gmail.com","doris.hoogeveen@gmail.com","jeyhan.lau@gmail.com","tb@ldwin.net"],"author_id":["steven-xu","andrew-bennett","doris-hoogeveen","jey-han-lau","timothy-baldwin"],"abstract":"Community question answering (cQA) forums provide a rich source of","pages":"137--147","doi":"10.18653\/v1\/W18-6119","url":"https:\/\/www.aclweb.org\/anthology\/W18-6119","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6120","title":"Word-like character n-gram embedding","authors":["Kim, Geewook","Fukui, Kazuki","Shimodaira, Hidetoshi"],"emails":["geewook@sys.i.kyoto-u.ac.jp","k.fukui@sys.i.kyoto-u.ac.jp","shimo@i.kyoto-u.ac.jp"],"author_id":["geewook-kim","kazuki-fukui","hidetoshi-shimodaira"],"abstract":"We propose a new word embedding method called {``}word-like character n-gram embedding{''}, which learns distributed representations of words by embedding word-like character n-grams.","pages":"148--152","doi":"10.18653\/v1\/W18-6120","url":"https:\/\/www.aclweb.org\/anthology\/W18-6120","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6121","title":"Classification of Tweets about Reported Events using Neural Networks","authors":["Makino, Kiminobu","Takei, Yuka","Miyazaki, Taro","Goto, Jun"],"emails":["makino.k-gg@nhk.or.jp","takei.y-ek@nhk.or.jp","miyazaki.t-jw@nhk.or.jp","goto.j-fw@nhk.or.jp"],"author_id":["kiminobu-makino","yuka-takei","taro-miyazaki","jun-goto"],"abstract":"We developed a system that automatically extracts {``}Event-describing Tweets{''} which include incidents or accidents information for creating news reports. Event-describing Tweets can be classified into {``}Reported-event Tweets{''} and {``}New-information Tweets.{''} Reported-event Tweets cite news agencies or user generated content sites, and New-information Tweets are other Event-describing Tweets. A system is needed to classify them so that creators of factual TV programs can use them in their productions. Proposing this Tweet classification task is one of the contributions of this paper, because no prior papers have used the same task even though program creators and other events information collectors have to do it to extract required information from social networking sites. To classify Tweets in this task, this paper proposes a method to input and concatenate character and word sequences in Japanese Tweets by using convolutional neural networks. This proposed method is another contribution of this paper. For comparison, character or word input methods and other neural networks are also used. Results show that a system using the proposed method and architectures can classify Tweets with an F1 score of 88 {\\%}.","pages":"153--163","doi":"10.18653\/v1\/W18-6121","url":"https:\/\/www.aclweb.org\/anthology\/W18-6121","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6122","title":"Learning to Define Terms in the Software Domain","authors":["Balachandran, Vidhisha","Rajagopal, Dheeraj","Kanjirathinkal, Rose Catherine","Cohen, William"],"emails":["vbalacha@cs.cmu.edu","dheeraj@cs.cmu.edu","rosecatherinek@cs.cmu.edu","wcohen@cs.cmu.edu"],"author_id":["vidhisha-balachandran","dheeraj-rajagopal","rose-catherine-kanjirathinkal","william-cohen"],"abstract":"One way to test a person{'}s knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a language model and incorporate additional domain-specific information like word-word co-occurrence, and ontological category information. Our approach improves previous baselines by 2 BLEU points for the definition generation task. Our experiments also show the additional challenges associated with the task and the short-comings of language-model based architectures for definition generation.","pages":"164--172","doi":"10.18653\/v1\/W18-6122","url":"https:\/\/www.aclweb.org\/anthology\/W18-6122","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6123","title":"{F}rame{I}t: Ontology Discovery for Noisy User-Generated Text","authors":["Iter, Dan","Halevy, Alon","Tan, Wang-Chiew"],"emails":["daniter@stanford.edu","alon@megagon.ai","wangchiew@megagon.ai"],"author_id":["dan-iter","alon-halevy","wang-chiew-tan"],"abstract":"A common need of NLP applications is to extract structured data from text corpora in order to perform analytics or trigger an appropriate action. The ontology defining the structure is typically application dependent and in many cases it is not known a priori. We describe the FrameIt System that provides a workflow for (1) quickly discovering an ontology to model a text corpus and (2) learning an SRL model that extracts the instances of the ontology from sentences in the corpus. FrameIt exploits data that is obtained in the ontology discovery phase as weak supervision data to bootstrap the SRL model and then enables the user to refine the model with active learning. We present empirical results and qualitative analysis of the performance of FrameIt on three corpora of noisy user-generated text.","pages":"173--183","doi":"10.18653\/v1\/W18-6123","url":"https:\/\/www.aclweb.org\/anthology\/W18-6123","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6124","title":"Using Author Embeddings to Improve Tweet Stance Classification","authors":["Benton, Adrian","Dredze, Mark"],"emails":["adrian@cs.jhu.edu","mdredze@cs.jhu.edu"],"author_id":["adrian-benton","mark-dredze"],"abstract":"Many social media classification tasks analyze the content of a message, but do not consider","pages":"184--194","doi":"10.18653\/v1\/W18-6124","url":"https:\/\/www.aclweb.org\/anthology\/W18-6124","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6125","title":"Low-resource named entity recognition via multi-source projection: Not quite there yet?","authors":["Enghoff, Jan Vium","Harrison, S{\\o}ren","Agi{\\'c}, {\\v{Z}}eljko"],"emails":["","","zeag@itu.dk"],"author_id":["jan-vium-enghoff","soren-harrison","zeljko-agic"],"abstract":"Projecting linguistic annotations through word alignments is one of the most prevalent approaches to cross-lingual transfer learning. Conventional wisdom suggests that annotation projection {``}just works{''} regardless of the task at hand. We carefully consider multi-source projection for named entity recognition. Our experiment with 17 languages shows that to detect named entities in true low-resource languages, annotation projection may not be the right way to move forward. On a more positive note, we also uncover the conditions that do favor named entity projection from multiple sources. We argue these are infeasible under noisy low-resource constraints.","pages":"195--201","doi":"10.18653\/v1\/W18-6125","url":"https:\/\/www.aclweb.org\/anthology\/W18-6125","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6126","title":"A Case Study on Learning a Unified Encoder of Relations","authors":["Fu, Lisheng","Min, Bonan","Nguyen, Thien Huu","Grishman, Ralph"],"emails":["lisheng@cs.nyu.edu","bonan.min@raytheon.com","thien@cs.uoregon.edu","grishman@cs.nyu.edu"],"author_id":["lisheng-fu","bonan-min","thien-huu-nguyen","ralph-grishman"],"abstract":"Typical relation extraction models are trained on a single corpus annotated with a pre-defined relation schema.","pages":"202--207","doi":"10.18653\/v1\/W18-6126","url":"https:\/\/www.aclweb.org\/anthology\/W18-6126","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6127","title":"Convolutions Are All You Need (For Classifying Character Sequences)","authors":["Wood-Doughty, Zach","Andrews, Nicholas","Dredze, Mark"],"emails":["zach@cs.jhu.edu","noa@cs.jhu.edu","mdredze@cs.jhu.edu"],"author_id":["zach-wood-doughty","nicholas-andrews","mark-dredze"],"abstract":"While recurrent neural networks (RNNs)","pages":"208--213","doi":"10.18653\/v1\/W18-6127","url":"https:\/\/www.aclweb.org\/anthology\/W18-6127","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6128","title":"Step or Not: Discriminator for The Real Instructions in User-generated Recipes","authors":["Inuzuka, Shintaro","Ito, Takahiko","Harashima, Jun"],"emails":["shintaro-inuzuka@cookpad.com","takahi-i@cookpad.com","jun-harashima@cookpad.com"],"author_id":["shintaro-inuzuka","takahiko-ito","jun-harashima"],"abstract":"In a recipe sharing service, users publish recipe instructions in the form of a series of steps. However, some of the {``}steps{''} are not actually part of the cooking process. Specifically, advertisements of recipes themselves (eg {``}introduced on TV{''}) and comments (eg {``}Thanks for many messages{''}) may often be included in the step section of the recipe, like the recipe author{'}s communication tool. However, such fake steps can cause problems when using recipe search indexing or when being spoken by devices such as smart speakers. As presented in this talk, we have constructed a discriminator that distinguishes between such a fake step and the step actually used for cooking. This project includes, but is not limited to, the creation of annotation data by classifying and analyzing recipe steps and the construction of identification models. Our models use only text information to identify the step. In our test, machine learning models achieved higher accuracy than rule-based methods that use manually chosen words.","pages":"214","doi":"10.18653\/v1\/W18-6128","url":"https:\/\/www.aclweb.org\/anthology\/W18-6128","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"},{"id":"W18-6129","title":"Combining Human and Machine Transcriptions on the Zooniverse Platform","authors":["Hanson, Daniel","Simenstad, Andrea"],"emails":["",""],"author_id":["daniel-hanson","andrea-simenstad"],"abstract":"This is a 1-page abstract on a work-in-progress for the Workshop on Noisy User-generated Text.","pages":"215--216","doi":"10.18653\/v1\/W18-6129","url":"https:\/\/www.aclweb.org\/anthology\/W18-6129","publisher":"Association for Computational Linguistics","address":"Brussels, Belgium","year":"2018","month":"November","booktitle":"Proceedings of the 2018 {EMNLP} Workshop W-{NUT}: The 4th Workshop on Noisy User-generated Text"}]