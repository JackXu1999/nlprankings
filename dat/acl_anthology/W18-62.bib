@proceedings{ws-2018-approaches-subjectivity,
    title = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    author = "Balahur, Alexandra  and
      Mohammad, Saif M.  and
      Hoste, Veronique  and
      Klinger, Roman",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6200",
}
@inproceedings{riloff-2018-identifying,
    title = "Identifying Affective Events and the Reasons for their Polarity",
    author = "Riloff, Ellen",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6201",
    doi = "10.18653/v1/W18-6201",
    pages = "1",
    abstract = "Many events have a positive or negative impact on our lives (e.g., {``}I",
}
@inproceedings{ilic-etal-2018-deep,
    title = "Deep contextualized word representations for detecting sarcasm and irony",
    author = "Ili{\'c}, Suzana  and
      Marrese-Taylor, Edison  and
      Balazs, Jorge  and
      Matsuo, Yutaka",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6202",
    doi = "10.18653/v1/W18-6202",
    pages = "2--7",
    abstract = "Predicting context-dependent and non-literal utterances like sarcastic and ironic expressions still remains a challenging task in NLP, as it goes beyond linguistic patterns, encompassing common sense and shared knowledge as crucial components. To capture complex morpho-syntactic features that can usually serve as indicators for irony or sarcasm across dynamic contexts, we propose a model that uses character-level vector representations of words, based on ELMo. We test our model on 7 different datasets derived from 3 different data sources, providing state-of-the-art performance in 6 of them, and otherwise offering competitive results.",
}
@inproceedings{sun-etal-2018-implicit,
    title = "Implicit Subjective and Sentimental Usages in Multi-sense Word Embeddings",
    author = "Sun, Yuqi  and
      Shi, Haoyue  and
      Hu, Junfeng",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6203",
    doi = "10.18653/v1/W18-6203",
    pages = "8--13",
    abstract = "In multi-sense word embeddings, contextual variations in corpus may cause a univocal word to be embedded into different sense vectors.",
}
@inproceedings{saroufim-etal-2018-language,
    title = "Language Independent Sentiment Analysis with Sentiment-Specific Word Embeddings",
    author = "Saroufim, Carl  and
      Almatarky, Akram  and
      Abdel Hady, Mohammad",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6204",
    doi = "10.18653/v1/W18-6204",
    pages = "14--23",
    abstract = "Data annotation is a critical step to train a text model but it is tedious, expensive and time-consuming. We present a language independent method to train a sentiment polarity model with limited amount of manually-labeled data. Word embeddings such as Word2Vec are efficient at incorporating semantic and syntactic properties of words, yielding good results for document classification. However, these embeddings might map words with opposite polarities, to vectors close to each other. We train Sentiment Specific Word Embeddings (SSWE) on top of an unsupervised Word2Vec model, using either Recurrent Neural Networks (RNN) or Convolutional Neural Networks (CNN) on data auto-labeled as {``}Positive{''} or {``}Negative{''}. For this task, we rely on the universality of emojis to auto-label a large number of French tweets using a small set of positive and negative emojis. Finally, we apply a transfer learning approach to refine the network weights with a small-size manually-labeled training data set. Experiments are conducted to evaluate the performance of this approach on French sentiment classification using benchmark data sets from SemEval 2016 competition. We were able to achieve a performance improvement by using SSWE over Word2Vec. We also used a graph-based approach for label propagation to auto-generate a sentiment lexicon.",
}
@inproceedings{ohman-etal-2018-creating,
    title = "Creating a Dataset for Multilingual Fine-grained Emotion-detection Using Gamification-based Annotation",
    author = {{\"O}hman, Emily  and
      Kajava, Kaisla  and
      Tiedemann, J{\"o}rg  and
      Honkela, Timo},
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6205",
    doi = "10.18653/v1/W18-6205",
    pages = "24--30",
    abstract = "This paper introduces a gamified framework for fine-grained sentiment analysis and emotion detection. We present a flexible tool that can be used for efficient annotation based on crowd sourcing and a self-perpetuating gold standard. We also present a novel dataset with multi-dimensional annotations of emotions and sentiments in movie subtitles that enables research on sentiment preservation across languages and the creation of robust multilingual emotion detection tools. The tools and datasets are public and open-source and can easily be extended and applied for various purposes.",
}
@inproceedings{klinger-etal-2018-iest,
    title = "{IEST}: {WASSA}-2018 Implicit Emotions Shared Task",
    author = "Klinger, Roman  and
      De Clercq, Orph{\'e}e  and
      Mohammad, Saif  and
      Balahur, Alexandra",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6206",
    doi = "10.18653/v1/W18-6206",
    pages = "31--42",
    abstract = "Past shared tasks on emotions use data with both overt expressions of emotions (I am so happy to see you!) as well as subtle expressions where the emotions have to be inferred, for instance from event descriptions. Further, most datasets do not focus on the cause or the stimulus of the emotion. Here, for the first time, we propose a shared task where systems have to predict the emotions in a large automatically labeled dataset of tweets without access to words denoting emotions. Based on this intention, we call this the Implicit Emotion Shared Task (IEST) because the systems have to infer the emotion mostly from the context. Every tweet has an occurrence of an explicit emotion word that is masked. The tweets are collected in a manner such that they are likely to include a description of the cause of the emotion {--} the stimulus. Altogether, 30 teams submitted results which range from macro F1 scores of 21 {\%} to 71 {\%}. The baseline (Max-Ent bag of words and bigrams) obtains an F1 score of 60 {\%} which was available to the participants during the development phase. A study with human annotators suggests that automatic methods outperform human predictions, possibly by honing into subtle textual clues not used by humans. Corpora, resources, and results are available at the shared task website at \url{http://implicitemotions.wassa2018.com}.",
}
@inproceedings{rozental-etal-2018-amobee,
    title = "{A}mobee at {IEST} 2018: Transfer Learning from Language Models",
    author = "Rozental, Alon  and
      Fleischer, Daniel  and
      Kelrich, Zohar",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6207",
    doi = "10.18653/v1/W18-6207",
    pages = "43--49",
    abstract = "This paper describes the system developed at Amobee for the WASSA 2018 implicit emotions shared task (IEST). The goal of this task was to predict the emotion expressed by missing words in tweets without an explicit mention of those words. We developed an ensemble system consisting of language models together with LSTM-based networks containing a CNN attention mechanism. Our approach represents a novel use of language models{---}specifically trained on a large Twitter dataset{---}to predict and classify emotions. Our system reached 1st place with a macro F1 score of 0.7145.",
}
@inproceedings{balazs-etal-2018-iiidyt,
    title = "{IIIDYT} at {IEST} 2018: Implicit Emotion Classification With Deep Contextualized Word Representations",
    author = "Balazs, Jorge  and
      Marrese-Taylor, Edison  and
      Matsuo, Yutaka",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6208",
    doi = "10.18653/v1/W18-6208",
    pages = "50--56",
    abstract = "In this paper we describe our system designed for the WASSA 2018 Implicit Emotion Shared Task (IEST), which obtained second place out of 30 teams with a test macro F1 score of 0.710. The system is composed of a single pre-trained ELMo layer for encoding words, a Bidirectional Long-Short Memory Network BiLSTM for enriching word representations with context, a max-pooling operation for creating sentence representations from them, and a Dense Layer for projecting the sentence representations into label space. Our",
}
@inproceedings{chronopoulou-etal-2018-ntua,
    title = "{NTUA}-{SLP} at {IEST} 2018: Ensemble of Neural Transfer Methods for Implicit Emotion Classification",
    author = "Chronopoulou, Alexandra  and
      Margatina, Aikaterini  and
      Baziotis, Christos  and
      Potamianos, Alexandros",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6209",
    doi = "10.18653/v1/W18-6209",
    pages = "57--64",
    abstract = "In this paper we present our approach to tackle",
}
@inproceedings{lukes-sogaard-2018-sentiment,
    title = "Sentiment analysis under temporal shift",
    author = "Lukes, Jan  and
      S{\o}gaard, Anders",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6210",
    doi = "10.18653/v1/W18-6210",
    pages = "65--71",
    abstract = "Sentiment analysis models often rely on training data that is several years old. In this paper, we show that lexical features change polarity over time, leading to degrading performance. This effect is particularly strong in sparse models relying only on highly predictive features. Using predictive feature selection, we are able to significantly improve the accuracy of such models over time.",
}
@inproceedings{sekulic-etal-2018-just,
    title = "Not Just Depressed: Bipolar Disorder Prediction on {R}eddit",
    author = "Sekulic, Ivan  and
      Gjurkovi{\'c}, Matej  and
      {\v{S}}najder, Jan",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6211",
    doi = "10.18653/v1/W18-6211",
    pages = "72--78",
    abstract = "Bipolar disorder, an illness characterized by manic and depressive episodes, affects more than 60 million people worldwide. We present a preliminary study on bipolar disorder prediction from user-generated text on Reddit, which relies on users{'} self-reported labels. Our benchmark classifiers for bipolar disorder prediction outperform the baselines and reach accuracy and F1-scores of above 86{\%}. Feature analysis shows interesting differences in language use between users with bipolar disorders and the control group, including differences in the use of emotion-expressive words.",
}
@inproceedings{bhatia-p-2018-topic,
    title = "Topic-Specific Sentiment Analysis Can Help Identify Political Ideology",
    author = "Bhatia, Sumit  and
      P, Deepak",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6212",
    doi = "10.18653/v1/W18-6212",
    pages = "79--84",
    abstract = "Ideological leanings of an individual can often",
}
@inproceedings{alkorta-etal-2018-saying,
    title = "Saying no but meaning yes: negation and sentiment analysis in Basque",
    author = "Alkorta, Jon  and
      Gojenola, Koldo  and
      Iruskieta, Mikel",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6213",
    doi = "10.18653/v1/W18-6213",
    pages = "85--90",
    abstract = "Negation is one of the shifters or operators that can change the semantic orientation of a word or a sentence and, consequently, it has to be taken into consideration in sentiment analysis. In this work, we have analyzed the effects of negation on the semantic orientation in Basque. The analysis shows that negation markers can strengthen, weaken or have no effect on sentiment orientation of a word or a group of words. Using the Constraint Grammar formalism, we have designed and evaluated a set of linguistic rules to formalize these three phenomena. The results show that two phenomena, strengthening and no change, have been identified accurately and the third one, weakening, with acceptable results.",
}
@inproceedings{xiang-etal-2018-leveraging,
    title = "Leveraging Writing Systems Change for Deep Learning Based {C}hinese Emotion Analysis",
    author = "Xiang, Rong  and
      Long, Yunfei  and
      Lu, Qin  and
      Xiong, Dan  and
      Chen, I-Hsuan",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6214",
    doi = "10.18653/v1/W18-6214",
    pages = "91--96",
    abstract = "Social media text written in Chinese communities contains mixed scripts including major text written with Chinese characters, an ideograph-based writing system, and some minor text using Latin letters, an alphabet-based writing system. This phenomenon is called writing systems change (WSCs). Past studies have shown that WSCs can be used to express emotions, particularly where the social and political environment is more conservative. However, because WSCs can break the syntax of the major text, it poses more challenges in NLP tasks like emotion classification. In this work, we present a novel deep learning based method to include WSCs as an effective feature for emotion analysis. The method first identifies all WSCs points. Representation of the major text is learned through an LSTM model whereas the presentation of the minority text is learned by a separate CNN.Emotions expressed in the minority text are further highlighted through an attention mechanism before emotion classification. It has proven to be significant that incorporating WSCs features in deep learning models can improve the performance which is valid by both F1-scores and p-value. It indicates that WSCs serve as an effective feature in emotion analysis of the social network.",
}
@inproceedings{byrkjeland-etal-2018-ternary,
    title = "Ternary Twitter Sentiment Classification with Distant Supervision and Sentiment-Specific Word Embeddings",
    author = {Byrkjeland, Mats  and
      G{\o}rvell de Lichtenberg, Frederik  and
      Gamb{\"a}ck, Bj{\"o}rn},
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6215",
    doi = "10.18653/v1/W18-6215",
    pages = "97--106",
    abstract = "The paper proposes the Ternary Sentiment Embedding Model, a new model for creating sentiment embeddings based on the Hybrid Ranking Model of Tang et al. (2016), but trained on ternary-labeled data instead of binary-labeled, utilizing sentiment embeddings from datasets made with different distant supervision methods.",
}
@inproceedings{daudert-buitelaar-2018-linking,
    title = "Linking News Sentiment to Microblogs: A Distributional Semantics Approach to Enhance Microblog Sentiment Classification",
    author = "Daudert, Tobias  and
      Buitelaar, Paul",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6216",
    doi = "10.18653/v1/W18-6216",
    pages = "107--115",
    abstract = "Social media{'}s popularity in society and research is gaining momentum and simultaneously increasing the importance of short textual content such as microblogs. Microblogs are affected by many factors including the news media, therefore, we exploit sentiments conveyed from news to detect and classify sentiment in microblogs. Given that texts can deal with the same entity but might not be vastly related when it comes to sentiment, it becomes necessary to introduce further measures ensuring the relatedness of texts while leveraging the contained sentiments. This paper describes ongoing research introducing distributional semantics to improve the exploitation of news-contained sentiment to enhance microblog sentiment classification.",
}
@inproceedings{brun-nikoulina-2018-aspect,
    title = "Aspect Based Sentiment Analysis into the Wild",
    author = "Brun, Caroline  and
      Nikoulina, Vassilina",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6217",
    doi = "10.18653/v1/W18-6217",
    pages = "116--122",
    abstract = "In this paper, we test state-of-the-art Aspect Based Sentiment Analysis (ABSA) systems trained on a widely used dataset on actual data. We created a new manually annotated dataset of user generated data from the same domain as the training dataset, but from other sources and analyse the differences between the new and the standard ABSA dataset. We then analyse the results in performance of different versions of the same system on both datasets. We also propose light adaptation methods to increase system robustness.",
}
@inproceedings{markov-etal-2018-role,
    title = "The Role of Emotions in Native Language Identification",
    author = "Markov, Ilia  and
      Nastase, Vivi  and
      Strapparava, Carlo  and
      Sidorov, Grigori",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6218",
    doi = "10.18653/v1/W18-6218",
    pages = "123--129",
    abstract = "We explore the hypothesis that emotion is one of the dimensions of language that surfaces from the native language into a second language. To check the role of emotions in native language identification (NLI), we model emotion information through polarity and emotion load features, and use document representations using these features to classify the native language of the author. The results indicate that emotion is relevant for NLI, even for high proficiency levels and across topics.",
}
@inproceedings{ambartsoumian-popowich-2018-self,
    title = "Self-Attention: A Better Building Block for Sentiment Analysis Neural Network Classifiers",
    author = "Ambartsoumian, Artaches  and
      Popowich, Fred",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6219",
    doi = "10.18653/v1/W18-6219",
    pages = "130--139",
    abstract = "Sentiment Analysis has seen much progress in the past two decades. For the past few years, neural network approaches, primarily RNNs and CNNs, have been the most successful for this task. Recently, a new category of neural networks, self-attention networks (SANs), have been created which utilizes the attention mechanism as the basic building block. Self-attention networks have been shown to be effective for sequence modeling tasks, while having no recurrence or convolutions. In this work we explore the effectiveness of the SANs for sentiment analysis. We demonstrate that SANs are superior in performance to their RNN and CNN counterparts by comparing their classification accuracy on six datasets as well as their model characteristics such as training speed and memory consumption. Finally, we explore the effects of various SAN modifications such as multi-head attention as well as two methods of incorporating sequence position information into SANs.",
}
@inproceedings{long-etal-2018-dual,
    title = "Dual Memory Network Model for Biased Product Review Classification",
    author = "Long, Yunfei  and
      Ma, Mingyu  and
      Lu, Qin  and
      Xiang, Rong  and
      Huang, Chu-Ren",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6220",
    doi = "10.18653/v1/W18-6220",
    pages = "140--148",
    abstract = "In sentiment analysis (SA) of product reviews,",
}
@inproceedings{cuba-gyllensten-sahlgren-2018-measuring,
    title = "Measuring Issue Ownership using Word Embeddings",
    author = "Cuba Gyllensten, Amaru  and
      Sahlgren, Magnus",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6221",
    doi = "10.18653/v1/W18-6221",
    pages = "149--155",
    abstract = "Sentiment and topic analysis are common methods used for social media monitoring. Essentially, these methods answers questions such as, {``}What is being talked about, regarding X{''}, and {``}What do people feel, regarding X{''}. In this paper, we investigate another venue for social media monitoring, namely issue ownership. In political science, issue ownership has been used to explain voter choice and electoral outcomes. The theory states that voters value certain issues, and cast votes according to the party which they feel best address these issues. We argue that issue alignment can be seen as a kind of semantic source similarity of the kind {``}How similar is source A to issue owner P, when talking about issue X{''}, and as such can be measured using Word/Document embedding techniques. We present work in progress towards measuring that kind of conditioned similarity, and introduce a new notion of similarity for predictive embeddings.",
}
@inproceedings{kaljahi-foster-2018-sentiment,
    title = "Sentiment Expression Boundaries in Sentiment Polarity Classification",
    author = "Kaljahi, Rasoul  and
      Foster, Jennifer",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6222",
    doi = "10.18653/v1/W18-6222",
    pages = "156--166",
    abstract = "We investigate the effect of using sentiment expression boundaries in predicting sentiment polarity in aspect-level sentiment analysis. We manually annotate a freely available English sentiment polarity dataset with these boundaries and carry out a series of experiments which demonstrate that high quality sentiment expressions can boost the performance of polarity classification. Our experiments with various neural architectures also show that CNN networks outperform LSTMs on this task.",
}
@inproceedings{sawhney-etal-2018-exploring,
    title = "Exploring and Learning Suicidal Ideation Connotations on Social Media with Deep Learning",
    author = "Sawhney, Ramit  and
      Manchanda, Prachi  and
      Mathur, Puneet  and
      Shah, Rajiv  and
      Singh, Raj",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6223",
    doi = "10.18653/v1/W18-6223",
    pages = "167--175",
    abstract = "The increasing suicide rates amongst youth and its high correlation with suicidal ideation expression on social media warrants a deeper investigation into models for the detection of suicidal intent in text such as tweets to enable prevention. However, the complexity of the natural language constructs makes this task very challenging. Deep Learning architectures such as LSTMs, CNNs, and RNNs show promise in sentence level classification problems. This work investigates the ability of deep learning architectures to build an accurate and robust model for suicidal ideation detection and compares their performance with standard baselines in text classification problems. The experimental results reveal the merit in C-LSTM based models compared to other deep learning and machine learning based classification models for suicidal ideation detection.",
}
@inproceedings{paetzold-2018-utfpr,
    title = "{UTFPR} at {IEST} 2018: Exploring Character-to-Word Composition for Emotion Analysis",
    author = "Paetzold, Gustavo",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6224",
    doi = "10.18653/v1/W18-6224",
    pages = "176--181",
    abstract = "We introduce the UTFPR system for the Implicit Emotions Shared Task of 2018: A compositional character-to-word recurrent neural network that does not exploit heavy and/or hard-to-obtain resources. We find that our approach can outperform multiple baselines, and offers an elegant and effective solution to the problem of orthographic variance in tweets.",
}
@inproceedings{naderalvojoud-etal-2018-humir,
    title = "{HUMIR} at {IEST}-2018: Lexicon-Sensitive and Left-Right Context-Sensitive {B}i{LSTM} for Implicit Emotion Recognition",
    author = "Naderalvojoud, Behzad  and
      Ucan, Alaettin  and
      Akcapinar Sezer, Ebru",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6225",
    doi = "10.18653/v1/W18-6225",
    pages = "182--188",
    abstract = "This paper describes the approaches used in HUMIR system for the WASSA-2018 shared task on the implicit emotion recognition. The objective of this task is to predict the emotion expressed by the target word that has been excluded from the given tweet. We suppose this task as a word sense disambiguation in which the target word is considered as a synthetic word that can express 6 emotions depending on the context. To predict the correct emotion, we propose a deep neural network model that uses two BiLSTM networks to represent the contexts in the left and right sides of the target word. The BiLSTM outputs achieved from the left and right contexts are considered as context-sensitive features. These features are used in a feed-forward neural network to predict the target word emotion. Besides this approach, we also combine the BiLSTM model with lexicon-based and emotion-based features. Finally, we employ all models in the final system using Bagging ensemble method. We achieved macro F-measure value of 68.8 on the official test set and ranked sixth out of 30 participants.",
}
@inproceedings{zhou-wu-2018-nlp,
    title = "{NLP} at {IEST} 2018: {B}i{LSTM}-Attention and {LSTM}-Attention via Soft Voting in Emotion Classification",
    author = "Zhou, Qimin  and
      Wu, Hao",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6226",
    doi = "10.18653/v1/W18-6226",
    pages = "189--194",
    abstract = "This paper describes our method that competed at WASSA2018 Implicit Emotion Shared Task. The goal of this task is to classify the emotions of excluded words in tweets into six different classes: sad, joy, disgust, surprise, anger and fear. For this, we examine a BiLSTM architecture with attention mechanism (BiLSTM-Attention) and a LSTM architecture with attention mechanism (LSTM-Attention), and try different dropout rates based on these two models. We then exploit an ensemble of these methods to give the final prediction which improves the model performance significantly compared with the baseline model. The proposed method achieves 7th position out of 30 teams and outperforms the baseline method by 12.5{\%} in terms of macro F1.",
}
@inproceedings{plaza-del-arco-etal-2018-sinai-iest,
    title = "{SINAI} at {IEST} 2018: Neural Encoding of Emotional External Knowledge for Emotion Classification",
    author = "Plaza-del-Arco, Flor Miriam  and
      Mart{\'\i}nez-C{\'a}mara, Eugenio  and
      Martin, Maite  and
      Ure{\~n}a- L{\'o}pez, L. Alfonso",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6227",
    doi = "10.18653/v1/W18-6227",
    pages = "195--200",
    abstract = "In this paper, we describe our participation in WASSA 2018 Implicit Emotion Shared Task (IEST 2018). We claim that the use of emotional external knowledge may enhance the performance and the capacity of generalization of an emotion classification system based on neural networks. Accordingly, we submitted four deep learning systems grounded in a sequence encoding layer. They mainly differ in the feature vector space and the recurrent neural network used in the sequence encoding layer. The official results show that the systems that used emotional external knowledge have a higher capacity of generalization, hence our claim holds.",
}
@inproceedings{liu-2018-emonlp-iest,
    title = "{E}mo{NLP} at {IEST} 2018: An Ensemble of Deep Learning Models and Gradient Boosting Regression Tree for Implicit Emotion Prediction in Tweets",
    author = "Liu, Man",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6228",
    doi = "10.18653/v1/W18-6228",
    pages = "201--204",
    abstract = "This paper describes our system submitted to IEST 2018, a shared task to predict the emotion types. Six emotion types are involved: anger, joy, fear, surprise, disgust and sad. We perform three different approaches: feed forward neural network (FFNN), convolutional BLSTM (ConBLSTM) and Gradient Boosting Regression Tree Method (GBM). Word embeddings used in convolutional BLSTM are pre-trained on 470 million tweets which are filtered using the emotional words and emojis. In addition, broad sets of features (i.e. syntactic features, lexicon features, cluster features) are adopted to train GBM and FFNN. The three approaches are finally ensembled by the weighted average of predicted probabilities of each emotion type.",
}
@inproceedings{wang-2018-hgsgnlp,
    title = "{HGSGNLP} at {IEST} 2018: An Ensemble of Machine Learning and Deep Neural Architectures for Implicit Emotion Classification in Tweets",
    author = "Wang, Wenting",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6229",
    doi = "10.18653/v1/W18-6229",
    pages = "205--210",
    abstract = "This paper describes our system designed for the WASSA-2018 Implicit Emotion Shared Task (IEST). The task is to predict the emotion category expressed in a tweet by removing the terms angry, afraid, happy, sad, surprised, disgusted and their synonyms. Our final submission is an ensemble of one supervised learning model and three deep neural network based models, where each model approaches the problem from essentially different directions. Our system achieves the macro F1 score of 65.8{\%}, which is a 5.9{\%} performance improvement over the baseline and is ranked 12 out of 30 participating teams.",
}
@inproceedings{senarath-thayasivam-2018-datasearch,
    title = "{D}ata{SEARCH} at {IEST} 2018: Multiple Word Embedding based Models for Implicit Emotion Classification of Tweets with Deep Learning",
    author = "Senarath, Yasas  and
      Thayasivam, Uthayasanker",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6230",
    doi = "10.18653/v1/W18-6230",
    pages = "211--216",
    abstract = "This paper describes an approach to solve implicit emotion classification with the use of pre-trained word embedding models to train multiple neural networks. The system described in this paper is composed of a sequential combination of Long Short-Term Memory and Convolutional Neural Network for feature extraction and Feedforward Neural Network for classification. In this paper, we successfully show that features extracted using multiple pre-trained embeddings can be used to improve the overall performance of the system with Emoji being one of the significant features. The evaluations show that our approach outperforms the baseline system by more than 8{\%} without using any external corpus or lexicon. This approach is ranked 8th in Implicit Emotion Shared Task (IEST) at WASSA-2018.",
}
@inproceedings{pecar-etal-2018-nl,
    title = "{NL}-{FIIT} at {IEST}-2018: Emotion Recognition utilizing Neural Networks and Multi-level Preprocessing",
    author = "Pecar, Samuel  and
      Farkas, Michal  and
      Simko, Marian  and
      Lacko, Peter  and
      Bielikova, Maria",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6231",
    doi = "10.18653/v1/W18-6231",
    pages = "217--223",
    abstract = "In this paper, we present neural models submitted to Shared Task on Implicit Emotion Recognition, organized as part of WASSA 2018. We propose a Bi-LSTM architecture with regularization through dropout and Gaussian noise. Our models use three different embedding layers: GloVe word embeddings trained on Twitter dataset, ELMo embeddings and also sentence embeddings. We see preprocessing as one of the most important parts of the task. We focused on handling emojis, emoticons, hashtags, and also various shortened word forms. In some cases, we proposed to remove some parts of the text, as they do not affect emotion of the original sentence. We also experimented with other modifications like category weights for learning and stacking multiple layers. Our model achieved a macro average F1 score of 65.55{\%}, significantly outperforming the baseline model produced by a simple logistic regression.",
}
@inproceedings{priban-martinek-2018-uwb,
    title = "{UWB} at {IEST} 2018: Emotion Prediction in Tweets with Bidirectional Long Short-Term Memory Neural Network",
    author = "P{\v{r}}ib{\'a}{\v{n}}, Pavel  and
      Mart{\'\i}nek, Ji{\v{r}}{\'\i}",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6232",
    doi = "10.18653/v1/W18-6232",
    pages = "224--230",
    abstract = "This paper describes our system created for the WASSA 2018 Implicit Emotion Shared Task. The goal of this task is to predict the emotion of a given tweet, from which a certain emotion word is removed. The removed word can be sad, happy, disgusted, angry, afraid or a synonym of one of them. Our proposed system is based on deep-learning methods. We use Bidirectional Long Short-Term Memory (BiLSTM) with word embeddings as an input. Pre-trained DeepMoji model and pre-trained emoji2vec emoji embeddings are also used as additional inputs.",
}
@inproceedings{rissola-etal-2018-usi,
    title = "{USI}-{IR} at {IEST} 2018: Sequence Modeling and Pseudo-Relevance Feedback for Implicit Emotion Detection",
    author = "R{\'\i}ssola, Esteban  and
      Giachanou, Anastasia  and
      Crestani, Fabio",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6233",
    doi = "10.18653/v1/W18-6233",
    pages = "231--234",
    abstract = "This paper describes the participation of USI-IR in WASSA 2018 Implicit Emotion Shared Task. We propose a relevance feedback approach employing a sequential model (biLSTM) and word embeddings derived from a large collection of tweets. To this end, we assume that the top-k predictions produce at a first classification step are correct (based on the model accuracy) and use them as new examples to re-train the network.",
}
@inproceedings{proisl-etal-2018-emotiklue,
    title = "{E}moti{KLUE} at {IEST} 2018: Topic-Informed Classification of Implicit Emotions",
    author = "Proisl, Thomas  and
      Heinrich, Philipp  and
      Kabashi, Besim  and
      Evert, Stefan",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6234",
    doi = "10.18653/v1/W18-6234",
    pages = "235--242",
    abstract = "EmotiKLUE is a submission to the Implicit Emotion Shared Task. It is a deep learning system that combines independent representations of the left and right contexts of the emotion word with the topic distribution of an LDA topic model. EmotiKLUE achieves a macro average F1 score of 67.13{\%}, significantly outperforming the baseline produced by a simple ML classifier. Further enhancements after the evaluation period lead to an improved F1 score of 68.10{\%}.",
}
@inproceedings{gratian-haid-2018-braint,
    title = "{B}rain{T} at {IEST} 2018: Fine-tuning Multiclass Perceptron For Implicit Emotion Classification",
    author = "Gratian, Vachagan  and
      Haid, Marina",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6235",
    doi = "10.18653/v1/W18-6235",
    pages = "243--247",
    abstract = "We present BrainT, a multiclass, averaged perceptron tested on implicit emotion prediction of tweets. We show that the dataset is linearly separable and explore ways in fine-tuning the baseline classifier. Our results indicate that the bag-of-words features benefit the model moderately and prediction can be improved significantly with bigrams, trigrams, skip-one-tetragrams and POS-tags. Furthermore, we find preprocessing of the n-grams, including stemming, lowercasing, stopword filtering, emoji and emoticon conversion, generally not useful. The model is trained on an annotated corpus of 153,383 tweets and predictions on the test data were submitted to the WASSA-2018 Implicit Emotion Shared Task. BrainT attained a Macro F-score of 0.63.",
}
@inproceedings{witon-etal-2018-disney,
    title = "Disney at {IEST} 2018: Predicting Emotions using an Ensemble",
    author = "Witon, Wojciech  and
      Colombo, Pierre  and
      Modi, Ashutosh  and
      Kapadia, Mubbasir",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6236",
    doi = "10.18653/v1/W18-6236",
    pages = "248--253",
    abstract = "This paper describes our participating system in the WASSA 2018 shared task on emotion prediction. The task focusses on implicit emotion prediction in a tweet. In this task, keywords corresponding to the six emotion label names (anger, fear, disgust, joy, sad, and surprise) have been removed from the tweet text, making emotion prediction implicit and the task challenging. We propose a model based on ensemble of classifiers for prediction. Each classifier in the ensemble uses sequence of Convolutional Neural Network (CNN) architecture blocks and uses ELMo (Embeddings from Language Model) (Peters et al., 2018) as input. Our system achieves 66.2{\%} F1 score on the test set. The best performing system in the shared task has reported 71.4{\%} F1 score.",
}
@inproceedings{rathnayaka-etal-2018-sentylic,
    title = "Sentylic at {IEST} 2018: Gated Recurrent Neural Network and Capsule Network Based Approach for Implicit Emotion Detection",
    author = "Rathnayaka, Prabod  and
      Abeysinghe, Supun  and
      Samarajeewa, Chamod  and
      Manchanayake, Isura  and
      Walpola, Malaka",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6237",
    doi = "10.18653/v1/W18-6237",
    pages = "254--259",
    abstract = "In this paper, we present the system we have used for the Implicit WASSA 2018 Implicit Emotion Shared Task. The task is to predict the emotion of a tweet of which the explicit mentions of emotion terms have been removed. The idea is to come up with a model which has the ability to implicitly identify the emotion expressed given the context words. We have used a Gated Recurrent Neural Network (GRU) and a Capsule Network based model for the task. Pre-trained word embeddings have been utilized to incorporate contextual knowledge about words into the model. GRU layer learns latent representations using the input word embeddings. Subsequent Capsule Network layer learns high-level features from that hidden representation. The proposed model managed to achieve a macro-F1 score of 0.692.",
}
@inproceedings{salaka-etal-2018-fast,
    title = "Fast Approach to Build an Automatic Sentiment Annotator for Legal Domain using Transfer Learning",
    author = "Salaka, Viraj  and
      Warushavithana, Menuka  and
      de Silva, Nisansa  and
      Perera, Amal Shehan  and
      Ratnayaka, Gathika  and
      Rupasinghe, Thejan",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6238",
    doi = "10.18653/v1/W18-6238",
    pages = "260--265",
    abstract = "This study proposes a novel way of identifying the sentiment of the phrases used in the legal domain. The added complexity of the language used in law, and the inability of the existing systems to accurately predict the sentiments of words in law are the main motivations behind this study. This is a transfer learning approach, which can be used for other domain adaptation tasks as well. The proposed methodology achieves an improvement of over 6{\%} compared to the source model{'}s accuracy in the legal domain.",
}
@inproceedings{gopalakrishna-pillai-etal-2018-makes,
    title = "What Makes You Stressed? Finding Reasons From Tweets",
    author = "Gopalakrishna Pillai, Reshmi  and
      Thelwall, Mike  and
      Orasan, Constantin",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6239",
    doi = "10.18653/v1/W18-6239",
    pages = "266--272",
    abstract = "Detecting stress from social media gives a non-intrusive and inexpensive alternative to traditional tools such as questionnaires or physiological sensors for monitoring mental state of individuals. This paper introduces a novel framework for finding reasons for stress from tweets, analyzing multiple categories for the first time. Three word-vector based methods are evaluated on collections of tweets about politics or airlines and are found to be more accurate than standard machine learning algorithms.",
}
@inproceedings{mazoure-etal-2018-emojigan,
    title = "{E}moji{GAN}: learning emojis distributions with a generative model",
    author = "Mazoure, Bogdan  and
      Doan, Thang  and
      Ray, Saibal",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6240",
    doi = "10.18653/v1/W18-6240",
    pages = "273--279",
    abstract = "Generative models have recently experienced a surge in popularity due to the development of more efficient training algorithms and increasing computational power. Models such as adversarial generative networks (GANs) have been successfully used in various areas such as computer vision, medical imaging, style transfer and natural language generation. Adversarial nets were recently shown to yield results in the image-to-text task, where given a set of images, one has to provide their corresponding text description. In this paper, we take a similar approach and propose a image-to-emoji architecture, which is trained on data from social networks and can be used to score a given picture using ideograms. We show empirical results of our algorithm on data obtained from the most influential Instagram accounts.",
}
@inproceedings{abercrombie-batista-navarro-2018-identifying,
    title = "Identifying Opinion-Topics and Polarity of Parliamentary Debate Motions",
    author = "Abercrombie, Gavin  and
      Batista-Navarro, Riza Theresa",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6241",
    doi = "10.18653/v1/W18-6241",
    pages = "280--285",
    abstract = "Analysis of the topics mentioned and opinions expressed in parliamentary debate motions{--}or proposals{--}is difficult for human readers, but necessary for understanding and automatic processing of the content of the subsequent speeches. We present a dataset of debate motions with pre-existing {`}policy{'} labels, and investigate the utility of these labels for simultaneous topic and opinion polarity analysis. For topic detection, we apply one-versus-the-rest supervised topic classification, finding that good performance is achieved in predicting the policy topics, and that textual features derived from the debate titles associated with the motions are particularly indicative of motion topic. We then examine whether the output could also be used to determine the positions taken by proposers towards the different policies by investigating how well humans agree in interpreting the opinion polarities of the motions. Finding very high levels of agreement, we conclude that the policies used can be reliable labels for use in these tasks, and that successful topic detection can therefore provide opinion analysis of the motions {`}for free{'}.",
}
@inproceedings{van-den-beukel-aroyo-2018-homonym,
    title = "Homonym Detection For Humor Recognition In Short Text",
    author = "van den Beukel, Sven  and
      Aroyo, Lora",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6242",
    doi = "10.18653/v1/W18-6242",
    pages = "286--291",
    abstract = "In this paper, automatic homophone- and homograph detection are suggested as new useful features for humor recognition systems. The system combines style-features from previous studies on humor recognition in short text with ambiguity-based features. The performance of two potentially useful homograph detection methods is evaluated using crowdsourced annotations as ground truth. Adding homophones and homographs as features to the classifier results in a small but significant improvement over the style-features alone. For the task of humor recognition, recall appears to be a more important quality measure than precision. Although the system was designed for humor recognition in oneliners, it also performs well at the classification of longer humorous texts.",
}
@inproceedings{xu-etal-2018-emo2vec,
    title = "{E}mo2{V}ec: Learning Generalized Emotion Representation by Multi-task Training",
    author = "Xu, Peng  and
      Madotto, Andrea  and
      Wu, Chien-Sheng  and
      Park, Ji Ho  and
      Fung, Pascale",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6243",
    doi = "10.18653/v1/W18-6243",
    pages = "292--298",
    abstract = "In this paper, we propose Emo2Vec which encodes emotional semantics into vectors. We train Emo2Vec by multi-task learning six different emotion-related tasks, including emotion/sentiment analysis, sarcasm classification, stress detection, abusive language classification, insult detection, and personality recognition. Our evaluation on Emo2Vec shows that it outperforms existing affect-related representations, such as Sentiment-Specific Word Embedding and DeepMoji embeddings with much smaller training corpora. When concatenated with GloVe, Emo2Vec achieves competitive performances to state-of-the-art results on several tasks using simple logistic regression classifier. Finally, we visualize the learned vectors, showing that Emo2Vec can cluster words with similar emotion together.",
}
@inproceedings{meisheri-khadilkar-2018-learning,
    title = "Learning representations for sentiment classification using Multi-task framework",
    author = "Meisheri, Hardik  and
      Khadilkar, Harshad",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6244",
    doi = "10.18653/v1/W18-6244",
    pages = "299--308",
    abstract = "Most of the existing state of the art sentiment classification techniques involve the use of pre-trained embeddings. This paper postulates a generalized representation that collates training on multiple datasets using a Multi-task learning framework. We incorporate publicly available, pre-trained embeddings with Bidirectional LSTM{'}s to develop the multi-task model. We validate the representations on an independent test Irony dataset that can contain several sentiments within each sample, with an arbitrary distribution. Our experiments show a significant improvement in results as compared to the available baselines for individual datasets on which independent models are trained. Results also suggest superior performance of the representations generated over Irony dataset.",
}
@inproceedings{sun-etal-2018-super,
    title = "Super Characters: A Conversion from Sentiment Classification to Image Classification",
    author = "Sun, Baohua  and
      Yang, Lin  and
      Dong, Patrick  and
      Zhang, Wenhan  and
      Dong, Jason  and
      Young, Charles",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6245",
    doi = "10.18653/v1/W18-6245",
    pages = "309--315",
    abstract = "We propose a method named Super Characters for sentiment classification. This method converts the sentiment classification problem into image classification problem by projecting texts into images and then applying CNN models for classification. Text features are extracted automatically from the generated Super Characters images, hence there is no need of any explicit step of embedding the words or characters into numerical vector representations. Experimental results on large social media corpus show that the Super Characters method consistently outperforms other methods for sentiment classification and topic classification tasks on ten large social media datasets of millions of contents in four different languages, including Chinese, Japanese,Korean and English.",
}
@inproceedings{rethmeier-etal-2018-learning,
    title = "Learning Comment Controversy Prediction in Web Discussions Using Incidentally Supervised Multi-Task {CNN}s",
    author = {Rethmeier, Nils  and
      H{\"u}bner, Marc  and
      Hennig, Leonhard},
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6246",
    doi = "10.18653/v1/W18-6246",
    pages = "316--321",
    abstract = "Comments on web news contain controversies that manifest as inter-group agreement-conflicts. Tracking such rapidly evolving controversy may be used to ease conflict resolution and author-user interaction.",
}
@inproceedings{muralidhar-etal-2018-words,
    title = "Words Worth: Verbal Content and Hirability Impressions in {Y}ou{T}ube Video Resumes",
    author = "Muralidhar, Skanda  and
      Nguyen, Laurent  and
      Gatica-Perez, Daniel",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6247",
    doi = "10.18653/v1/W18-6247",
    pages = "322--327",
    abstract = "Automatic hirability prediction from video resumes is gaining increasing attention in both psychology and computing. Most existing works have investigated hirability from the perspective of nonverbal behavior, with verbal content receiving little interest. In this study, we leverage the advances in deep-learning based text representation techniques (like word embedding) in natural language processing to investigate the relationship between verbal content and perceived hirability ratings. To this end, we use 292 conversational video resumes from YouTube, develop a computational framework to automatically extract various representations of verbal content, and evaluate them in a regression task. We obtain a best performance of R{\mbox{$^2$}} = 0.23 using GloVe, and R{\mbox{$^2$}} = 0.22 using Word2Vec representations for manual and automatically transcribed texts respectively. Our inference results indicate the feasibility of using deep learning based verbal content representation in inferring hirability scores from online conversational video resumes.",
}
@inproceedings{hilte-etal-2018-predicting,
    title = "Predicting Adolescents{'} Educational Track from Chat Messages on {D}utch Social Media",
    author = "Hilte, Lisa  and
      Daelemans, Walter  and
      Vandekerckhove, Reinhild",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6248",
    doi = "10.18653/v1/W18-6248",
    pages = "328--334",
    abstract = "We aim to predict Flemish adolescents{'} educational track based on their Dutch social media writing. We distinguish between the three main types of Belgian secondary education: General (theory-oriented), Vocational (practice-oriented), and Technical Secondary Education (hybrid). The best results are obtained with a Naive Bayes model, i.e. an F-score of 0.68 (std. dev. 0.05) in 10-fold cross-validation experiments on the train data and an F-score of 0.60 on unseen data. Many of the most informative features are character n-grams containing specific occurrences of chatspeak phenomena such as emoticons. While the detection of the most theory- and practice-oriented educational tracks seems to be a relatively easy task, the hybrid Technical level appears to be much harder to capture based on online writing style, as expected.",
}
@inproceedings{guellil-etal-2018-arabizi,
    title = "{A}rabizi sentiment analysis based on transliteration and automatic corpus annotation",
    author = "Guellil, Imane  and
      Adeel, Ahsan  and
      Azouaou, Faical  and
      Benali, Fodil  and
      Hachani, Ala-eddine  and
      Hussain, Amir",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6249",
    doi = "10.18653/v1/W18-6249",
    pages = "335--341",
    abstract = "Arabizi is a form of writing Arabic text which relies on Latin letters, numerals and punctuation rather than Arabic letters. In the literature, the difficulties associated with Arabizi sentiment analysis have been underestimated, principally due to the complexity of Arabizi. In this paper, we present an approach to automatically classify sentiments of Arabizi messages into positives or negatives. In the proposed approach, Arabizi messages are first transliterated into Arabic. Afterwards, we automatically classify the sentiment of the transliterated corpus using an automatically annotated corpus. For corpus validation, shallow machine learning algorithms such as Support Vectors Machine (SVM) and Naive Bays (NB) are used. Simulations results demonstrate the outperformance of NB algorithm over all others. The highest achieved F1-score is up to 78{\%} and 76{\%} for manually and automatically transliterated dataset respectively. Ongoing work is aimed at improving the transliterator module and annotated sentiment dataset.",
}
@inproceedings{alhuzali-etal-2018-ubc,
    title = "{UBC}-{NLP} at {IEST} 2018: Learning Implicit Emotion With an Ensemble of Language Models",
    author = "Alhuzali, Hassan  and
      Elaraby, Mohamed  and
      Abdul-Mageed, Muhammad",
    booktitle = "Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6250",
    doi = "10.18653/v1/W18-6250",
    pages = "342--347",
    abstract = "We describe UBC-NLP contribution to IEST-2018, focused at learning implicit emotion in Twitter data. Among the 30 participating teams, our system ranked the 4th (with 69.3{\%} F-score). Post competition, we were able to score slightly higher than the 3rd ranking system (reaching 70.7{\%}). Our system is trained on top of a pre-trained language model (LM),fine-tuned on the data provided by the task organizers. Our best results are acquired by an average of an ensemble of language models.We also offer an analysis of system performance and the impact of training data size on the task. For example, we show that training our best model for only one epoch with {\textless} 40{\%} of the data enables better performance than the baseline reported by Klinger et al. (2018) for the task.",
}
