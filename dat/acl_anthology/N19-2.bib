@proceedings{naacl-2019-2019-north,
    title = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    author = "Loukina, Anastassia  and
      Morales, Michelle  and
      Kumar, Rohit",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2000",
}
@inproceedings{yao-etal-2019-enabling,
    title = "Enabling Real-time Neural {IME} with Incremental Vocabulary Selection",
    author = "Yao, Jiali  and
      Shu, Raphael  and
      Li, Xinjian  and
      Ohtsuki, Katsutoshi  and
      Nakayama, Hideki",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2001",
    doi = "10.18653/v1/N19-2001",
    pages = "1--8",
    abstract = "Input method editor (IME) converts sequential alphabet key inputs to words in a target language. It is an indispensable service for billions of Asian users. Although the neural-based language model is extensively studied and shows promising results in sequence-to-sequence tasks, applying a neural-based language model to IME was not considered feasible due to high latency when converting words on user devices. In this work, we articulate the bottleneck of neural IME decoding to be the heavy softmax computation over a large vocabulary. We propose an approach that incrementally builds a subset vocabulary from the word lattice. Our approach always computes the probability with a selected subset vocabulary. When the selected vocabulary is updated, the stale probabilities in previous steps are fixed by recomputing the missing logits. The experiments on Japanese IME benchmark shows an over 50x speedup for the softmax computations comparing to the baseline, reaching real-time speed even on commodity CPU without losing conversion accuracy. The approach is potentially applicable to other incremental sequence-to-sequence decoding tasks such as real-time continuous speech recognition.",
}
@inproceedings{lee-etal-2019-locale,
    title = "Locale-agnostic Universal Domain Classification Model in Spoken Language Understanding",
    author = "Lee, Jihwan  and
      Sarikaya, Ruhi  and
      Kim, Young-Bum",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2002",
    doi = "10.18653/v1/N19-2002",
    pages = "9--15",
    abstract = "In this paper, we introduce an approach for leveraging available data across multiple locales sharing the same language to 1) improve domain classification model accuracy in Spoken Language Understanding and user experience even if new locales do not have sufficient data and 2) reduce the cost of scaling the domain classifier to a large number of locales. We propose a locale-agnostic universal domain classification model based on selective multi-task learning that learns a joint representation of an utterance over locales with different sets of domains and allows locales to share knowledge selectively depending on the domains. The experimental results demonstrate the effectiveness of our approach on domain classification task in the scenario of multiple locales with imbalanced data and disparate domain sets. The proposed approach outperforms other baselines models especially when classifying locale-specific domains and also low-resourced domains.",
}
@inproceedings{damonte-etal-2019-practical,
    title = "Practical Semantic Parsing for Spoken Language Understanding",
    author = "Damonte, Marco  and
      Goel, Rahul  and
      Chung, Tagyoung",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2003",
    doi = "10.18653/v1/N19-2003",
    pages = "16--23",
    abstract = "Executable semantic parsing is the task of converting natural language utterances into logical forms that can be directly used as queries to get a response. We build a transfer learning framework for executable semantic parsing. We show that the framework is effective for Question Answering (Q{\&}A) as well as for Spoken Language Understanding (SLU). We further investigate the case where a parser on a new domain can be learned by exploiting data on other domains, either via multi-task learning between the target domain and an auxiliary domain or via pre-training on the auxiliary domain and fine-tuning on the target domain. With either flavor of transfer learning, we are able to improve performance on most domains; we experiment with public data sets such as Overnight and NLmaps as well as with commercial SLU data. The experiments carried out on data sets that are different in nature show how executable semantic parsing can unify different areas of NLP such as Q{\&}A and SLU.",
}
@inproceedings{liu-etal-2019-fast,
    title = "Fast Prototyping a Dialogue Comprehension System for Nurse-Patient Conversations on Symptom Monitoring",
    author = "Liu, Zhengyuan  and
      Lim, Hazel  and
      Suhaimi, Nur Farah Ain  and
      Tong, Shao Chuen  and
      Ong, Sharon  and
      Ng, Angela  and
      Lee, Sheldon  and
      Macdonald, Michael R.  and
      Ramasamy, Savitha  and
      Krishnaswamy, Pavitra  and
      Chow, Wai Leng  and
      Chen, Nancy F.",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2004",
    doi = "10.18653/v1/N19-2004",
    pages = "24--31",
    abstract = "Data for human-human spoken dialogues for research and development are currently very limited in quantity, variety, and sources; such data are even scarcer in healthcare. In this work, we investigate fast prototyping of a dialogue comprehension system by leveraging on minimal nurse-to-patient conversations. We propose a framework inspired by nurse-initiated clinical symptom monitoring conversations to construct a simulated human-human dialogue dataset, embodying linguistic characteristics of spoken interactions like thinking aloud, self-contradiction, and topic drift. We then adopt an established bidirectional attention pointer network on this simulated dataset, achieving more than 80{\%} F1 score on a held-out test set from real-world nurse-to-patient conversations. The ability to automatically comprehend conversations in the healthcare domain by exploiting only limited data has implications for improving clinical workflows through red flag symptom detection and triaging capabilities. We demonstrate the feasibility for efficient and effective extraction, retrieval and comprehension of symptom checking information discussed in multi-turn human-human spoken conversations.",
}
@inproceedings{liu-etal-2019-graph,
    title = "Graph Convolution for Multimodal Information Extraction from Visually Rich Documents",
    author = "Liu, Xiaojing  and
      Gao, Feiyu  and
      Zhang, Qiong  and
      Zhao, Huasha",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2005",
    doi = "10.18653/v1/N19-2005",
    pages = "32--39",
    abstract = "Visually rich documents (VRDs) are ubiquitous in daily business and life. Examples are purchase receipts, insurance policy documents, custom declaration forms and so on. In VRDs, visual and layout information is critical for document understanding, and texts in such documents cannot be serialized into the one-dimensional sequence without losing information. Classic information extraction models such as BiLSTM-CRF typically operate on text sequences and do not incorporate visual features. In this paper, we introduce a graph convolution based model to combine textual and visual information presented in VRDs. Graph embeddings are trained to summarize the context of a text segment in the document, and further combined with text embeddings for entity extraction. Extensive experiments have been conducted to show that our method outperforms BiLSTM-CRF baselines by significant margins, on two real-world datasets. Additionally, ablation studies are also performed to evaluate the effectiveness of each component of our model.",
}
@inproceedings{deb-etal-2019-diversifying,
    title = "Diversifying Reply Suggestions Using a Matching-Conditional Variational Autoencoder",
    author = "Deb, Budhaditya  and
      Bailey, Peter  and
      Shokouhi, Milad",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2006",
    doi = "10.18653/v1/N19-2006",
    pages = "40--47",
    abstract = "We consider the problem of diversifying automated reply suggestions for a commercial instant-messaging (IM) system (Skype). Our conversation model is a standard matching based information retrieval architecture, which consists of two parallel encoders to project messages and replies into a common feature representation. During inference, we select replies from a fixed response set using nearest neighbors in the feature space. To diversify responses, we formulate the model as a generative latent variable model with Conditional Variational Auto-Encoder (M-CVAE). We propose a constrained-sampling approach to make the variational inference in M-CVAE efficient for our production system. In offline experiments, M-CVAE consistently increased diversity by ∼30−40{\%} without significant impact on relevance. This translated to a ∼5{\%} gain in click-rate in our online production system.",
}
@inproceedings{lu-etal-2019-goal,
    title = "Goal-Oriented End-to-End Conversational Models with Profile Features in a Real-World Setting",
    author = "Lu, Yichao  and
      Srivastava, Manisha  and
      Kramer, Jared  and
      Elfardy, Heba  and
      Kahn, Andrea  and
      Wang, Song  and
      Bhardwaj, Vikas",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2007",
    doi = "10.18653/v1/N19-2007",
    pages = "48--55",
    abstract = "End-to-end neural models for goal-oriented conversational systems have become an increasingly active area of research, though results in real-world settings are few. We present real-world results for two issue types in the customer service domain. We train models on historical chat transcripts and test on live contacts using a human-in-the-loop research platform. Additionally, we incorporate customer profile features to assess their impact on model performance. We experiment with two approaches for response generation: (1) sequence-to-sequence generation and (2) template ranking. To test our models, a customer service agent handles live contacts and at each turn we present the top four model responses and allow the agent to select (and optionally edit) one of the suggestions or to type their own. We present results for turn acceptance rate, response coverage, and edit rate based on approximately 600 contacts, as well as qualitative analysis on patterns of turn rejection and edit behavior. Top-4 turn acceptance rate across all models ranges from 63{\%}-80{\%}. Our results suggest that these models are promising for an agent-support application.",
}
@inproceedings{yang-etal-2019-detecting,
    title = "Detecting Customer Complaint Escalation with Recurrent Neural Networks and Manually-Engineered Features",
    author = "Yang, Wei  and
      Tan, Luchen  and
      Lu, Chunwei  and
      Cui, Anqi  and
      Li, Han  and
      Chen, Xi  and
      Xiong, Kun  and
      Wang, Muzi  and
      Li, Ming  and
      Pei, Jian  and
      Lin, Jimmy",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2008",
    doi = "10.18653/v1/N19-2008",
    pages = "56--63",
    abstract = "Consumers dissatisfied with the normal dispute resolution process provided by an e-commerce company{'}s customer service agents have the option of escalating their complaints by filing grievances with a government authority. This paper tackles the challenge of monitoring ongoing text chat dialogues to identify cases where the customer expresses such an intent, providing triage and prioritization for a separate pool of specialized agents specially trained to handle more complex situations. We describe a hybrid model that tackles this challenge by integrating recurrent neural networks with manually-engineered features. Experiments show that both components are complementary and contribute to overall recall, outperforming competitive baselines. A trial online deployment of our model demonstrates its business value in improving customer service.",
}
@inproceedings{zhang-etal-2019-multi-modal,
    title = "Multi-Modal Generative Adversarial Network for Short Product Title Generation in Mobile E-Commerce",
    author = "Zhang, Jianguo  and
      Zou, Pengcheng  and
      Li, Zhao  and
      Wan, Yao  and
      Pan, Xiuming  and
      Gong, Yu  and
      Yu, Philip S.",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2009",
    doi = "10.18653/v1/N19-2009",
    pages = "64--72",
    abstract = "Nowadays, more and more customers browse and purchase products in favor of using mobile E-Commerce Apps such as Taobao and Amazon. Since merchants are usually inclined to describe redundant and over-informative product titles to attract attentions from customers, it is important to concisely display short product titles on limited screen of mobile phones. To address this discrepancy, previous studies mainly consider textual information of long product titles and lacks of human-like view during training and evaluation process. In this paper, we propose a Multi-Modal Generative Adversarial Network (MM-GAN) for short product title generation in E-Commerce, which innovatively incorporates image information and attribute tags from product, as well as textual information from original long titles. MM-GAN poses short title generation as a reinforcement learning process, where the generated titles are evaluated by the discriminator in a human-like view. Extensive experiments on a large-scale E-Commerce dataset demonstrate that our algorithm outperforms other state-of-the-art methods. Moreover, we deploy our model into a real-world online E-Commerce environment and effectively boost the performance of click through rate and click conversion rate by 1.66{\%} and 1.87{\%}, respectively.",
}
@inproceedings{murao-etal-2019-case,
    title = "A Case Study on Neural Headline Generation for Editing Support",
    author = "Murao, Kazuma  and
      Kobayashi, Ken  and
      Kobayashi, Hayato  and
      Yatsuka, Taichi  and
      Masuyama, Takeshi  and
      Higurashi, Tatsuru  and
      Tabuchi, Yoshimune",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2010",
    doi = "10.18653/v1/N19-2010",
    pages = "73--82",
    abstract = "There have been many studies on neural headline generation models trained with a lot of (article, headline) pairs. However, there are few situations for putting such models into practical use in the real world since news articles typically already have corresponding headlines. In this paper, we describe a practical use case of neural headline generation in a news aggregator, where dozens of professional editors constantly select important news articles and manually create their headlines, which are much shorter than the original headlines. Specifically, we show how to deploy our model to an editing support tool and report the results of comparing the behavior of the editors before and after the release.",
}
@inproceedings{williams-2019-neural,
    title = "Neural Lexicons for Slot Tagging in Spoken Language Understanding",
    author = "Williams, Kyle",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2011",
    doi = "10.18653/v1/N19-2011",
    pages = "83--89",
    abstract = "We explore the use of lexicons or gazettes in neural models for slot tagging in spoken language understanding. We develop models that encode lexicon information as neural features for use in a Long-short term memory neural network. Experiments are performed on data from 4 domains from an intelligent assistant under conditions that often occur in an industry setting, where there may be: 1) large amounts of training data, 2) limited amounts of training data for new domains, and 3) cross domain training. Results show that the use of neural lexicon information leads to a significant improvement in slot tagging, with improvements in the F-score of up to 12{\%}. Our findings have implications for how lexicons can be used to improve the performance of neural slot tagging models.",
}
@inproceedings{peshterliev-etal-2019-active,
    title = "Active Learning for New Domains in Natural Language Understanding",
    author = "Peshterliev, Stanislav  and
      Kearney, John  and
      Jagannatha, Abhyuday  and
      Kiss, Imre  and
      Matsoukas, Spyros",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2012",
    doi = "10.18653/v1/N19-2012",
    pages = "90--96",
    abstract = "We explore active learning (AL) for improving the accuracy of new domains in a natural language understanding (NLU) system. We propose an algorithm called Majority-CRF that uses an ensemble of classification models to guide the selection of relevant utterances, as well as a sequence labeling model to help prioritize informative examples. Experiments with three domains show that Majority-CRF achieves 6.6{\%}-9{\%} relative error rate reduction compared to random sampling with the same annotation budget, and statistically significant improvements compared to other AL approaches. Additionally, case studies with human-in-the-loop AL on six new domains show 4.6{\%}-9{\%} improvement on an existing NLU system.",
}
@inproceedings{rastogi-etal-2019-scaling,
    title = "Scaling Multi-Domain Dialogue State Tracking via Query Reformulation",
    author = "Rastogi, Pushpendre  and
      Gupta, Arpit  and
      Chen, Tongfei  and
      Lambert, Mathias",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2013",
    doi = "10.18653/v1/N19-2013",
    pages = "97--105",
    abstract = "We present a novel approach to dialogue state tracking and referring expression resolution tasks. Successful contextual understanding of multi-turn spoken dialogues requires resolving referring expressions across turns and tracking the entities relevant to the conversation across turns. Tracking conversational state is particularly challenging in a multi-domain scenario when there exist multiple spoken language understanding (SLU) sub-systems, and each SLU sub-system operates on its domain-specific meaning representation. While previous approaches have addressed the disparate schema issue by learning candidate transformations of the meaning representation, in this paper, we instead model the reference resolution as a dialogue context-aware user query reformulation task {--} the dialog state is serialized to a sequence of natural language tokens representing the conversation. We develop our model for query reformulation using a pointer-generator network and a novel multi-task learning setup. In our experiments, we show a significant improvement in absolute F1 on an internal as well as a, soon to be released, public benchmark respectively.",
}
@inproceedings{meteer-etal-2019-tools,
    title = "Are the Tools up to the Task? an Evaluation of Commercial Dialog Tools in Developing Conversational Enterprise-grade Dialog Systems",
    author = "Meteer, Marie  and
      Hickey, Meghan  and
      Rothberg, Carmi  and
      Nahamoo, David  and
      Eide Kislal, Ellen",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2014",
    doi = "10.18653/v1/N19-2014",
    pages = "106--113",
    abstract = "There has been a significant investment in dialog systems (tools and runtime) for building conversational systems by major companies including Google, IBM, Microsoft, and Amazon. The question remains whether these tools are up to the task of building conversational, task-oriented dialog applications at the enterprise level. In our company, we are exploring and comparing several toolsets in an effort to determine their strengths and weaknesses in meeting our goals for dialog system development: accuracy, time to market, ease of replicating and extending applications, and efficiency and ease of use by developers. In this paper, we provide both quantitative and qualitative results in three main areas: natural language understanding, dialog, and text generation. While existing toolsets were all incomplete, we hope this paper will provide a roadmap of where they need to go to meet the goal of building effective dialog systems.",
}
@inproceedings{afzal-etal-2019-development,
    title = "Development and Deployment of a Large-Scale Dialog-based Intelligent Tutoring System",
    author = "Afzal, Shazia  and
      Dhamecha, Tejas  and
      Mukhi, Nirmal  and
      Sindhgatta, Renuka  and
      Marvaniya, Smit  and
      Ventura, Matthew  and
      Yarbro, Jessica",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2015",
    doi = "10.18653/v1/N19-2015",
    pages = "114--121",
    abstract = "There are significant challenges involved in the design and implementation of a dialog-based tutoring system (DBT) ranging from domain engineering to natural language classification and eventually instantiating an adaptive, personalized dialog strategy. These issues are magnified when implementing such a system at scale and across domains. In this paper, we describe and reflect on the design, methods, decisions and assessments that led to the successful deployment of our AI driven DBT currently being used by several hundreds of college level students for practice and self-regulated study in diverse subjects like Sociology, Communications, and American Government.",
}
@inproceedings{godin-etal-2019-learning,
    title = "Learning When Not to Answer: a Ternary Reward Structure for Reinforcement Learning Based Question Answering",
    author = "Godin, Fr{\'e}deric  and
      Kumar, Anjishnu  and
      Mittal, Arpit",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2016",
    doi = "10.18653/v1/N19-2016",
    pages = "122--129",
    abstract = "In this paper, we investigate the challenges of using reinforcement learning agents for question-answering over knowledge graphs for real-world applications. We examine the performance metrics used by state-of-the-art systems and determine that they are inadequate for such settings. More specifically, they do not evaluate the systems correctly for situations when there is no answer available and thus agents optimized for these metrics are poor at modeling confidence. We introduce a simple new performance metric for evaluating question-answering agents that is more representative of practical usage conditions, and optimize for this metric by extending the binary reward structure used in prior work to a ternary reward structure which also rewards an agent for not answering a question rather than giving an incorrect answer. We show that this can drastically improve the precision of answered questions while only not answering a limited number of previously correctly answered questions. Employing a supervised learning strategy using depth-first-search paths to bootstrap the reinforcement learning algorithm further improves performance.",
}
@inproceedings{palshikar-etal-2019-extraction-message,
    title = "Extraction of Message Sequence Charts from Software Use-Case Descriptions",
    author = "Palshikar, Girish  and
      Ramrakhiyani, Nitin  and
      Patil, Sangameshwar  and
      Pawar, Sachin  and
      Hingmire, Swapnil  and
      Varma, Vasudeva  and
      Bhattacharyya, Pushpak",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2017",
    doi = "10.18653/v1/N19-2017",
    pages = "130--137",
    abstract = "Software Requirement Specification documents provide natural language descriptions of the core functional requirements as a set of use-cases. Essentially, each use-case contains a set of actors and sequences of steps describing the interactions among them. Goals of use-case reviews and analyses include their correctness, completeness, detection of ambiguities, prototyping, verification, test case generation and traceability. Message Sequence Chart (MSC) have been proposed as a expressive, rigorous yet intuitive visual representation of use-cases. In this paper, we describe a linguistic knowledge-based approach to extract MSCs from use-cases. Compared to existing techniques, we extract richer constructs of the MSC notation such as timers, conditions and alt-boxes. We apply this tool to extract MSCs from several real-life software use-case descriptions and show that it performs better than the existing techniques. We also discuss the benefits and limitations of the extracted MSCs to meet the above goals.",
}
@inproceedings{peng-etal-2019-improving,
    title = "Improving Knowledge Base Construction from Robust Infobox Extraction",
    author = "Peng, Boya  and
      Huh, Yejin  and
      Ling, Xiao  and
      Banko, Michele",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2018",
    doi = "10.18653/v1/N19-2018",
    pages = "138--148",
    abstract = "A capable, automatic Question Answering (QA) system can provide more complete and accurate answers using a comprehensive knowledge base (KB). One important approach to constructing a comprehensive knowledge base is to extract information from Wikipedia infobox tables to populate an existing KB. Despite previous successes in the Infobox Extraction (IBE) problem (e.g., DBpedia), three major challenges remain: 1) Deterministic extraction patterns used in DBpedia are vulnerable to template changes; 2) Over-trusting Wikipedia anchor links can lead to entity disambiguation errors; 3) Heuristic-based extraction of unlinkable entities yields low precision, hurting both accuracy and completeness of the final KB. This paper presents a robust approach that tackles all three challenges. We build probabilistic models to predict relations between entity mentions directly from the infobox tables in HTML. The entity mentions are linked to identifiers in an existing KB if possible. The unlinkable ones are also parsed and preserved in the final output. Training data for both the relation extraction and the entity linking models are automatically generated using distant supervision. We demonstrate the empirical effectiveness of the proposed method in both precision and recall compared to a strong IBE baseline, DBpedia, with an absolute improvement of 41.3{\%} in average F1. We also show that our extraction makes the final KB significantly more complete, improving the completeness score of list-value relation types by 61.4{\%}.",
}
@inproceedings{chen-chen-2019-k,
    title = "A k-Nearest Neighbor Approach towards Multi-level Sequence Labeling",
    author = "Chen, Yue  and
      Chen, John",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2019",
    doi = "10.18653/v1/N19-2019",
    pages = "149--156",
    abstract = "In this paper we present a new method for intent recognition for complex dialog management in low resource situations. Complex dialog management is required because our target domain is real world mixed initiative food ordering between agents and their customers, where individual customer utterances may contain multiple intents and refer to food items with complex structure. For example, a customer might say {``}Can I get a deluxe burger with large fries and oh put extra mayo on the burger would you?{''} We approach this task as a multi-level sequence labeling problem, with the constraint of limited real training data. Both traditional methods like HMM, MEMM, or CRF and newer methods like DNN or BiLSTM use only homogeneous feature sets. Newer methods perform better but also require considerably more data. Previous research has done pseudo-data synthesis to obtain the required amounts of training data. We propose to use a k-NN learner with heterogeneous feature set. We used windowed word n-grams, POS tag n-grams and pre-trained word embeddings as features. For the experiments we perform a comparison between using pseudo-data and real world data. We also perform semi-supervised self-training to obtain additional labeled data, in order to better model real world scenarios. Instead of using massive pseudo-data, we show that with only less than 1{\%} of the data size, we can achieve better result than any of the methods above by annotating real world data. We achieve labeled bracketed F-scores of 75.46, 52.84 and 49.66 for the three levels of sequence labeling where each level has a longer word span than its previous level. Overall we achieve 60.71F. In comparison, two previous systems, MEMM and DNN-ELMO, achieved 52.32 and 45.25 respectively.",
}
@inproceedings{poddar-etal-2019-train,
    title = "Train One Get One Free: Partially Supervised Neural Network for Bug Report Duplicate Detection and Clustering",
    author = "Poddar, Lahari  and
      Neves, Leonardo  and
      Brendel, William  and
      Marujo, Luis  and
      Tulyakov, Sergey  and
      Karuturi, Pradeep",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2020",
    doi = "10.18653/v1/N19-2020",
    pages = "157--165",
    abstract = "Tracking user reported bugs requires considerable engineering effort in going through many repetitive reports and assigning them to the correct teams. This paper proposes a neural architecture that can jointly (1) detect if two bug reports are duplicates, and (2) aggregate them into latent topics. Leveraging the assumption that learning the topic of a bug is a sub-task for detecting duplicates, we design a loss function that can jointly perform both tasks but needs supervision for only duplicate classification, achieving topic clustering in an unsupervised fashion. We use a two-step attention module that uses self-attention for topic clustering and conditional attention for duplicate detection. We study the characteristics of two types of real world datasets that have been marked for duplicate bugs by engineers and by non-technical annotators. The results demonstrate that our model not only can outperform state-of-the-art methods for duplicate classification on both cases, but can also learn meaningful latent clusters without additional supervision.",
}
@inproceedings{marzinotto-etal-2019-robust,
    title = "Robust Semantic Parsing with Adversarial Learning for Domain Generalization",
    author = "Marzinotto, Gabriel  and
      Damnati, G{\'e}raldine  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Favre, Beno{\^\i}t",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2021",
    doi = "10.18653/v1/N19-2021",
    pages = "166--173",
    abstract = "This paper addresses the issue of generalization for Semantic Parsing in an adversarial framework. Building models that are more robust to inter-document variability is crucial for the integration of Semantic Parsing technologies in real applications. The underlying question throughout this study is whether adversarial learning can be used to train models on a higher level of abstraction in order to increase their robustness to lexical and stylistic variations. We propose to perform Semantic Parsing with a domain classification adversarial task, covering various use-cases with or without explicit knowledge of the domain. The strategy is first evaluated on a French corpus of encyclopedic documents, annotated with FrameNet, in an information retrieval perspective. This corpus constitutes a new public benchmark, gathering documents from various thematic domains and various sources. We show that adversarial learning yields improved results when using explicit domain classification as the adversarial task. We also propose an unsupervised domain discovery approach that yields equivalent improvements. The latter is also evaluated on a PropBank Semantic Role Labeling task on the CoNLL-2005 benchmark and is shown to increase the model{'}s generalization capabilities on out-of-domain data.",
}
@inproceedings{sun-etal-2019-toi,
    title = "{TOI}-{CNN}: a Solution of Information Extraction on {C}hinese Insurance Policy",
    author = "Sun, Lin  and
      Zhang, Kai  and
      Ji, Fule  and
      Yang, Zhenhua",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2022",
    doi = "10.18653/v1/N19-2022",
    pages = "174--181",
    abstract = "Contract analysis can significantly ease the work for humans using AI techniques. This paper shows a problem of Element Tagging on Insurance Policy (ETIP). A novel Text-Of-Interest Convolutional Neural Network (TOI-CNN) is proposed for the ETIP solution. We introduce a TOI pooling layer to replace traditional pooling layer for processing the nested phrasal or clausal elements in insurance policies. The advantage of TOI pooling layer is that the nested elements from one sentence could share computation and context in the forward and backward passes. The computation of backpropagation through TOI pooling is also demonstrated in the paper. We have collected a large Chinese insurance contract dataset and labeled the critical elements of seven categories to test the performance of the proposed method. The results show the promising performance of our method in the ETIP problem.",
}
@inproceedings{johnson-etal-2019-cross,
    title = "Cross-lingual Transfer Learning for {J}apanese Named Entity Recognition",
    author = "Johnson, Andrew  and
      Karanasou, Penny  and
      Gaspers, Judith  and
      Klakow, Dietrich",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2023",
    doi = "10.18653/v1/N19-2023",
    pages = "182--189",
    abstract = "This work explores cross-lingual transfer learning (TL) for named entity recognition, focusing on bootstrapping Japanese from English. A deep neural network model is adopted and the best combination of weights to transfer is extensively investigated. Moreover, a novel approach is presented that overcomes linguistic differences between this language pair by romanizing a portion of the Japanese input. Experiments are conducted on external datasets, as well as internal large-scale real-world ones. Gains with TL are achieved for all evaluated cases. Finally, the influence on TL of the target dataset size and of the target tagset distribution is further investigated.",
}
@inproceedings{mansfield-etal-2019-neural,
    title = "Neural Text Normalization with Subword Units",
    author = {Mansfield, Courtney  and
      Sun, Ming  and
      Liu, Yuzong  and
      Gandhe, Ankur  and
      Hoffmeister, Bj{\"o}rn},
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2024",
    doi = "10.18653/v1/N19-2024",
    pages = "190--196",
    abstract = "Text normalization (TN) is an important step in conversational systems. It converts written text to its spoken form to facilitate speech recognition, natural language understanding and text-to-speech synthesis. Finite state transducers (FSTs) are commonly used to build grammars that handle text normalization. However, translating linguistic knowledge into grammars requires extensive effort. In this paper, we frame TN as a machine translation task and tackle it with sequence-to-sequence (seq2seq) models. Previous research focuses on normalizing a word (or phrase) with the help of limited word-level context, while our approach directly normalizes full sentences. We find subword models with additional linguistic features yield the best performance (with a word error rate of 0.17{\%}).",
}
@inproceedings{cohn-etal-2019-audio,
    title = "Audio De-identification - a New Entity Recognition Task",
    author = "Cohn, Ido  and
      Laish, Itay  and
      Beryozkin, Genady  and
      Li, Gang  and
      Shafran, Izhak  and
      Szpektor, Idan  and
      Hartman, Tzvika  and
      Hassidim, Avinatan  and
      Matias, Yossi",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2025",
    doi = "10.18653/v1/N19-2025",
    pages = "197--204",
    abstract = "Named Entity Recognition (NER) has been mostly studied in the context of written text. Specifically, NER is an important step in de-identification (de-ID) of medical records, many of which are recorded conversations between a patient and a doctor. In such recordings, audio spans with personal information should be redacted, similar to the redaction of sensitive character spans in de-ID for written text. The application of NER in the context of audio de-identification has yet to be fully investigated. To this end, we define the task of audio de-ID, in which audio spans with entity mentions should be detected. We then present our pipeline for this task, which involves Automatic Speech Recognition (ASR), NER on the transcript text, and text-to-audio alignment. Finally, we introduce a novel metric for audio de-ID and a new evaluation benchmark consisting of a large labeled segment of the Switchboard and Fisher audio datasets and detail our pipeline{'}s results on it.",
}
@inproceedings{prateek-etal-2019-news,
    title = "In Other News: a Bi-style Text-to-speech Model for Synthesizing Newscaster Voice with Limited Data",
    author = "Prateek, Nishant  and
      {\L}ajszczak, Mateusz  and
      Barra-Chicote, Roberto  and
      Drugman, Thomas  and
      Lorenzo-Trueba, Jaime  and
      Merritt, Thomas  and
      Ronanki, Srikanth  and
      Wood, Trevor",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2026",
    doi = "10.18653/v1/N19-2026",
    pages = "205--213",
    abstract = "Neural text-to-speech synthesis (NTTS) models have shown significant progress in generating high-quality speech, however they require a large quantity of training data. This makes creating models for multiple styles expensive and time-consuming. In this paper different styles of speech are analysed based on prosodic variations, from this a model is proposed to synthesise speech in the style of a newscaster, with just a few hours of supplementary data. We pose the problem of synthesising in a target style using limited data as that of creating a bi-style model that can synthesise both neutral-style and newscaster-style speech via a one-hot vector which factorises the two styles. We also propose conditioning the model on contextual word embeddings, and extensively evaluate it against neutral NTTS, and neutral concatenative-based synthesis. This model closes the gap in perceived style-appropriateness between natural recordings for newscaster-style of speech, and neutral speech synthesis by approximately two-thirds.",
}
@inproceedings{challa-etal-2019-generate,
    title = "Generate, Filter, and Rank: Grammaticality Classification for Production-Ready {NLG} Systems",
    author = "Challa, Ashwini  and
      Upasani, Kartikeya  and
      Balakrishnan, Anusha  and
      Subba, Rajen",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2027",
    doi = "10.18653/v1/N19-2027",
    pages = "214--225",
    abstract = "Neural approaches to Natural Language Generation (NLG) have been promising for goal-oriented dialogue. One of the challenges of productionizing these approaches, however, is the ability to control response quality, and ensure that generated responses are acceptable. We propose the use of a generate, filter, and rank framework, in which candidate responses are first filtered to eliminate unacceptable responses, and then ranked to select the best response. While acceptability includes grammatical correctness and semantic correctness, we focus only on grammaticality classification in this paper, and show that existing datasets for grammatical error correction don{'}t correctly capture the distribution of errors that data-driven generators are likely to make. We release a grammatical classification and semantic correctness classification dataset for the weather domain that consists of responses generated by 3 data-driven NLG systems. We then explore two supervised learning approaches (CNNs and GBDTs) for classifying grammaticality. Our experiments show that grammaticality classification is very sensitive to the distribution of errors in the data, and that these distributions vary significantly with both the source of the response as well as the domain. We show that it{'}s possible to achieve high precision with reasonable recall on our dataset.",
}
@inproceedings{davoudi-etal-2019-content,
    title = "Content-based Dwell Time Engagement Prediction Model for News Articles",
    author = "Davoudi, Heidar  and
      An, Aijun  and
      Edall, Gordon",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis - Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-2028",
    doi = "10.18653/v1/N19-2028",
    pages = "226--233",
    abstract = "The article dwell time (i.e., expected time that users spend on an article) is among the most important factors showing the article engagement. It is of great interest to predict the dwell time of an article before its release. This allows digital newspapers to make informed decisions and publish more engaging articles. In this paper, we propose a novel content-based approach based on a deep neural network architecture for predicting article dwell times. The proposed model extracts emotion, event and entity features from an article, learns interactions among them, and combines the interactions with the word-based features of the article to learn a model for predicting the dwell time. The experimental results on a real dataset from a major newspaper show that the proposed model outperforms other state-of-the-art baselines.",
}
