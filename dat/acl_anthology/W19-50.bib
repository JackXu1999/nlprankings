@proceedings{ws-2019-bionlp,
    title = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    author = "Demner-Fushman, Dina  and
      Cohen, Kevin Bretonnel  and
      Ananiadou, Sophia  and
      Tsujii, Junichi",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5000",
}
@inproceedings{newman-griffis-etal-2019-classifying,
    title = "Classifying the reported ability in clinical mobility descriptions",
    author = "Newman-Griffis, Denis  and
      Zirikly, Ayah  and
      Divita, Guy  and
      Desmet, Bart",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5001",
    doi = "10.18653/v1/W19-5001",
    pages = "1--10",
    abstract = "Assessing how individuals perform different activities is key information for modeling health states of individuals and populations. Descriptions of activity performance in clinical free text are complex, including syntactic negation and similarities to textual entailment tasks. We explore a variety of methods for the novel task of classifying four types of assertions about activity performance: Able, Unable, Unclear, and None (no information). We find that ensembling an SVM trained with lexical features and a CNN achieves 77.9{\%} macro F1 score on our task, and yields nearly 80{\%} recall on the rare Unclear and Unable samples. Finally, we highlight several challenges in classifying performance assertions, including capturing information about sources of assistance, incorporating syntactic structure and negation scope, and handling new modalities at test time. Our findings establish a strong baseline for this novel task, and identify intriguing areas for further research.",
}
@inproceedings{yuwono-etal-2019-learning,
    title = "Learning from the Experience of Doctors: Automated Diagnosis of Appendicitis Based on Clinical Notes",
    author = "Yuwono, Steven Kester  and
      Ng, Hwee Tou  and
      Ngiam, Kee Yuan",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5002",
    doi = "10.18653/v1/W19-5002",
    pages = "11--19",
    abstract = "The objective of this work is to develop an automated diagnosis system that is able to predict the probability of appendicitis given a free-text emergency department (ED) note and additional structured information (e.g., lab test results). Our clinical corpus consists of about 180,000 ED notes based on ten years of patient visits to the Accident and Emergency (A{\&}E) Department of the National University Hospital (NUH), Singapore. We propose a novel neural network approach that learns to diagnose acute appendicitis based on doctors{'} free-text ED notes without any feature engineering. On a test set of 2,000 ED notes with equal number of appendicitis (positive) and non-appendicitis (negative) diagnosis and in which all the negative ED notes only consist of abdominal-related diagnosis, our model is able to achieve a promising F{\_}0.5-score of 0.895 while ED doctors achieve F{\_}0.5-score of 0.900. Visualization shows that our model is able to learn important features, signs, and symptoms of patients from unstructured free-text ED notes, which will help doctors to make better diagnosis.",
}
@inproceedings{soni-roberts-2019-paraphrase,
    title = "A Paraphrase Generation System for {EHR} Question Answering",
    author = "Soni, Sarvesh  and
      Roberts, Kirk",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5003",
    doi = "10.18653/v1/W19-5003",
    pages = "20--29",
    abstract = "This paper proposes a dataset and method for automatically generating paraphrases for clinical questions relating to patient-specific information in electronic health records (EHRs). Crowdsourcing is used to collect 10,578 unique questions across 946 semantically distinct paraphrase clusters. This corpus is then used with a deep learning-based question paraphrasing method utilizing variational autoencoder and LSTM encoder/decoder. The ultimate use of such a method is to improve the performance of automatic question answering methods for EHRs.",
}
@inproceedings{chauhan-etal-2019-reflex,
    title = "{RE}flex: Flexible Framework for Relation Extraction in Multiple Domains",
    author = "Chauhan, Geeticka  and
      McDermott, Matthew B.A.  and
      Szolovits, Peter",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5004",
    doi = "10.18653/v1/W19-5004",
    pages = "30--47",
    abstract = "Systematic comparison of methods for relation extraction (RE) is difficult because many experiments in the field are not described precisely enough to be completely reproducible and many papers fail to report ablation studies that would highlight the relative contributions of their various combined techniques. In this work, we build a unifying framework for RE, applying this on three highly used datasets (from the general, biomedical and clinical domains) with the ability to be extendable to new datasets. By performing a systematic exploration of modeling, pre-processing and training methodologies, we find that choices of preprocessing are a large contributor performance and that omission of such information can further hinder fair comparison. Other insights from our exploration allow us to provide recommendations for future research in this area.",
}
@inproceedings{ormerod-etal-2019-analysing,
    title = "Analysing Representations of Memory Impairment in a Clinical Notes Classification Model",
    author = "Ormerod, Mark  and
      Mart{\'\i}nez-del-Rinc{\'o}n, Jes{\'u}s  and
      Robertson, Neil  and
      McGuinness, Bernadette  and
      Devereux, Barry",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5005",
    doi = "10.18653/v1/W19-5005",
    pages = "48--57",
    abstract = "Despite recent advances in the application of deep neural networks to various kinds of medical data, extracting information from unstructured textual sources remains a challenging task. The challenges of training and interpreting document classification models are amplified when dealing with small and highly technical datasets, as are common in the clinical domain. Using a dataset of de-identified clinical letters gathered at a memory clinic, we construct several recurrent neural network models for letter classification, and evaluate them on their ability to build meaningful representations of the documents and predict patients{'} diagnoses. Additionally, we probe sentence embedding models in order to build a human-interpretable representation of the neural network{'}s features, using a simple and intuitive technique based on perturbative approaches to sentence importance. In addition to showing which sentences in a document are most informative about the patient{'}s condition, this method reveals the types of sentences that lead the model to make incorrect diagnoses. Furthermore, we identify clusters of sentences in the embedding space that correlate strongly with importance scores for each clinical diagnosis class.",
}
@inproceedings{peng-etal-2019-transfer,
    title = "Transfer Learning in Biomedical Natural Language Processing: An Evaluation of {BERT} and {ELM}o on Ten Benchmarking Datasets",
    author = "Peng, Yifan  and
      Yan, Shankai  and
      Lu, Zhiyong",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5006",
    doi = "10.18653/v1/W19-5006",
    pages = "58--65",
    abstract = "Inspired by the success of the General Language Understanding Evaluation benchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE) benchmark to facilitate research in the development of pre-training language representations in the biomedicine domain. The benchmark consists of five tasks with ten datasets that cover both biomedical and clinical texts with different dataset sizes and difficulties. We also evaluate several baselines based on BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results. We make the datasets, pre-trained models, and codes publicly available at https://github.com/ ncbi-nlp/BLUE{\_}Benchmark.",
}
@inproceedings{apostolova-etal-2019-combining,
    title = "Combining Structured and Free-text Electronic Medical Record Data for Real-time Clinical Decision Support",
    author = "Apostolova, Emilia  and
      Wang, Tony  and
      Tschampel, Tim  and
      Koutroulis, Ioannis  and
      Velez, Tom",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5007",
    doi = "10.18653/v1/W19-5007",
    pages = "66--70",
    abstract = "The goal of this work is to utilize Electronic Medical Record (EMR) data for real-time Clinical Decision Support (CDS). We present a deep learning approach to combining in real time available diagnosis codes (ICD codes) and free-text notes: Patient Context Vectors. Patient Context Vectors are created by averaging ICD code embeddings, and by predicting the same from free-text notes via a Convolutional Neural Network. The Patient Context Vectors were then simply appended to available structured data (vital signs and lab results) to build prediction models for a specific condition. Experiments on predicting ARDS, a rare and complex condition, demonstrate the utility of Patient Context Vectors as a means of summarizing the patient history and overall condition, and improve significantly the prediction model results.",
}
@inproceedings{mitrofan-etal-2019-monero,
    title = "{M}o{NER}o: a Biomedical Gold Standard Corpus for the {R}omanian Language",
    author = "Mitrofan, Maria  and
      Barbu Mititelu, Verginica  and
      Mitrofan, Grigorina",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5008",
    doi = "10.18653/v1/W19-5008",
    pages = "71--79",
    abstract = "In an era when large amounts of data are generated daily in various fields, the biomedical field among others, linguistic resources can be exploited for various tasks of Natural Language Processing. Moreover, increasing number of biomedical documents are available in languages other than English. To be able to extract information from natural language free text resources, methods and tools are needed for a variety of languages. This paper presents the creation of the MoNERo corpus, a gold standard biomedical corpus for Romanian, annotated with both part of speech tags and named entities. MoNERo comprises 154,825 morphologically annotated tokens and 23,188 entity annotations belonging to four entity semantic groups corresponding to UMLS Semantic Groups.",
}
@inproceedings{rajagopal-etal-2019-domain,
    title = "Domain Adaptation of {SRL} Systems for Biological Processes",
    author = "Rajagopal, Dheeraj  and
      Vyas, Nidhi  and
      Siddhant, Aditya  and
      Rayasam, Anirudha  and
      Tandon, Niket  and
      Hovy, Eduard",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5009",
    doi = "10.18653/v1/W19-5009",
    pages = "80--87",
    abstract = "Domain adaptation remains one of the most challenging aspects in the wide-spread use of Semantic Role Labeling (SRL) systems. Current state-of-the-art methods are typically trained on large-scale datasets, but their performances do not directly transfer to low-resource domain-specific settings. In this paper, we propose two approaches for domain adaptation in the biological domain that involves pre-training LSTM-CRF based on existing large-scale datasets and adapting it for a low-resource corpus of biological processes. Our first approach defines a mapping between the source labels and the target labels, and the other approach modifies the final CRF layer in sequence-labeling neural network architecture. We perform our experiments on ProcessBank dataset which contains less than 200 paragraphs on biological processes. We improve over the previous state-of-the-art system on this dataset by 21 F1 points. We also show that, by incorporating event-event relationship in ProcessBank, we are able to achieve an additional 2.6 F1 gain, giving us possible insights into how to improve SRL systems for biological process using richer annotations.",
}
@inproceedings{jin-etal-2019-deep,
    title = "Deep Contextualized Biomedical Abbreviation Expansion",
    author = "Jin, Qiao  and
      Liu, Jinling  and
      Lu, Xinghua",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5010",
    doi = "10.18653/v1/W19-5010",
    pages = "88--96",
    abstract = "Automatic identification and expansion of ambiguous abbreviations are essential for biomedical natural language processing applications, such as information retrieval and question answering systems. In this paper, we present DEep Contextualized Biomedical Abbreviation Expansion (DECBAE) model. DECBAE automatically collects substantial and relatively clean annotated contexts for 950 ambiguous abbreviations from PubMed abstracts using a simple heuristic. Then it utilizes BioELMo to extract the contextualized features of words, and feed those features to abbreviation-specific bidirectional LSTMs, where the hidden states of the ambiguous abbreviations are used to assign the exact definitions. Our DECBAE model outperforms other baselines by large margins, achieving average accuracy of 0.961 and macro-F1 of 0.917 on the dataset. It also surpasses human performance for expanding a sample abbreviation, and remains robust in imbalanced, low-resources and clinical settings.",
}
@inproceedings{pylieva-etal-2019-rnn,
    title = "{RNN} Embeddings for Identifying Difficult to Understand Medical Words",
    author = "Pylieva, Hanna  and
      Chernodub, Artem  and
      Grabar, Natalia  and
      Hamon, Thierry",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5011",
    doi = "10.18653/v1/W19-5011",
    pages = "97--104",
    abstract = "Patients and their families often require a better understanding of medical information provided by doctors. We currently address this issue by improving the identification of difficult to understand medical words. We introduce novel embeddings received from RNN - FrnnMUTE (French RNN Medical Understandability Text Embeddings) which allow to reach up to 87.0 F1 score in identification of difficult words. We also note that adding pre-trained FastText word embeddings to the feature set substantially improves the performance of the model which classifies words ac- cording to their difficulty. We study the generalizability of different models through three cross-validation scenarios which allow testing classifiers in real-world conditions: understanding of medical words by new users, and classification of new unseen words by the automatic models. The RNN - FrnnMUTE embeddings and the categorization code are being made available for the research.",
}
@inproceedings{norman-etal-2019-distantly,
    title = "A distantly supervised dataset for automated data extraction from diagnostic studies",
    author = "Norman, Christopher  and
      Leeflang, Mariska  and
      Spijker, Ren{\'e}  and
      Kanoulas, Evangelos  and
      N{\'e}v{\'e}ol, Aur{\'e}lie",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5012",
    doi = "10.18653/v1/W19-5012",
    pages = "105--114",
    abstract = "Systematic reviews are important in evidence based medicine, but are expensive to produce. Automating or semi-automating the data extraction of index test, target condition, and reference standard from articles has the potential to decrease the cost of conducting systematic reviews of diagnostic test accuracy, but relevant training data is not available. We create a distantly supervised dataset of approximately 90,000 sentences, and let two experts manually annotate a small subset of around 1,000 sentences for evaluation. We evaluate the performance of BioBERT and logistic regression for ranking the sentences, and compare the performance for distant and direct supervision. Our results suggest that distant supervision can work as well as, or better than direct supervision on this problem, and that distantly trained models can perform as well as, or better than human annotators.",
}
@inproceedings{bordea-etal-2019-query,
    title = "Query selection methods for automated corpora construction with a use case in food-drug interactions",
    author = "Bordea, Georgeta  and
      Randriatsitohaina, Tsanta  and
      Mougin, Fleur  and
      Grabar, Natalia  and
      Hamon, Thierry",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5013",
    doi = "10.18653/v1/W19-5013",
    pages = "115--124",
    abstract = "In this paper, we address the problem of automatically constructing a relevant corpus of scientific articles about food-drug interactions. There is a growing number of scientific publications that describe food-drug interactions but currently building a high-coverage corpus that can be used for information extraction purposes is not trivial. We investigate several methods for automating the query selection process using an expert-curated corpus of food-drug interactions. Our experiments show that index term features along with a decision tree classifier are the best approach for this task and that feature selection approaches and in particular gain ratio outperform frequency-based methods for query selection.",
}
@inproceedings{chiu-etal-2019-enhancing,
    title = "Enhancing biomedical word embeddings by retrofitting to verb clusters",
    author = "Chiu, Billy  and
      Baker, Simon  and
      Palmer, Martha  and
      Korhonen, Anna",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5014",
    doi = "10.18653/v1/W19-5014",
    pages = "125--134",
    abstract = "Verbs play a fundamental role in many biomed-ical tasks and applications such as relation and event extraction. We hypothesize that performance on many downstream tasks can be improved by aligning the input pretrained embeddings according to semantic verb classes.In this work, we show that by using semantic clusters for verbs, a large lexicon of verbclasses derived from biomedical literature, weare able to improve the performance of common pretrained embeddings in downstream tasks by retrofitting them to verb classes. We present a simple and computationally efficient approach using a widely-available {``}off-the-shelf{''} retrofitting algorithm to align pretrained embeddings according to semantic verb clusters. We achieve state-of-the-art results on text classification and relation extraction tasks.",
}
@inproceedings{joshi-etal-2019-comparison,
    title = "A Comparison of Word-based and Context-based Representations for Classification Problems in Health Informatics",
    author = "Joshi, Aditya  and
      Karimi, Sarvnaz  and
      Sparks, Ross  and
      Paris, Cecile  and
      MacIntyre, C Raina",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5015",
    doi = "10.18653/v1/W19-5015",
    pages = "135--141",
    abstract = "Distributed representations of text can be used as features when training a statistical classifier. These representations may be created as a composition of word vectors or as context-based sentence vectors. We compare the two kinds of representations (word versus context) for three classification problems: influenza infection classification, drug usage classification and personal health mention classification. For statistical classifiers trained for each of these problems, context-based representations based on ELMo, Universal Sentence Encoder, Neural-Net Language Model and FLAIR are better than Word2Vec, GloVe and the two adapted using the MESH ontology. There is an improvement of 2-4{\%} in the accuracy when these context-based representations are used instead of word-based representations.",
}
@inproceedings{fauqueur-etal-2019-constructing,
    title = "Constructing large scale biomedical knowledge bases from scratch with rapid annotation of interpretable patterns",
    author = "Fauqueur, Julien  and
      Thillaisundaram, Ashok  and
      Togia, Theodosia",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5016",
    doi = "10.18653/v1/W19-5016",
    pages = "142--151",
    abstract = "Knowledge base construction is crucial for summarising, understanding and inferring relationships between biomedical entities. However, for many practical applications such as drug discovery, the scarcity of relevant facts (e.g. gene X is therapeutic target for disease Y) severely limits a domain expert{'}s ability to create a usable knowledge base, either directly or by training a relation extraction model. In this paper, we present a simple and effective method of extracting new facts with a pre-specified binary relationship type from the biomedical literature, without requiring any training data or hand-crafted rules. Our system discovers, ranks and presents the most salient patterns to domain experts in an interpretable form. By marking patterns as compatible with the desired relationship type, experts indirectly batch-annotate candidate pairs whose relationship is expressed with such patterns in the literature. Even with a complete absence of seed data, experts are able to discover thousands of high-quality pairs with the desired relationship within minutes. When a small number of relevant pairs do exist - even when their relationship is more general (e.g. gene X is biologically associated with disease Y) than the relationship of interest - our system leverages them in order to i) learn a better ranking of the patterns to be annotated or ii) generate weakly labelled pairs in a fully automated manner. We evaluate our method both intrinsically and via a downstream knowledge base completion task, and show that it is an effective way of constructing knowledge bases when few or no relevant facts are already available.",
}
@inproceedings{campillos-llanos-2019-first,
    title = "First Steps towards Building a Medical Lexicon for {S}panish with Linguistic and Semantic Information",
    author = "Campillos-Llanos, Leonardo",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5017",
    doi = "10.18653/v1/W19-5017",
    pages = "152--164",
    abstract = "We report the work-in-progress of collecting MedLexSp, an unified medical lexicon for the Spanish language, featuring terms and inflected word forms mapped to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs), semantic types and groups. First, we leveraged a list of term lemmas and forms from a previous project, and mapped them to UMLS terms and CUIs. To enrich the lexicon, we used both domain-corpora (e.g. Summaries of Product Characteristics and MedlinePlus) and natural language processing techniques such as string distance methods or generation of syntactic variants of multi-word terms. We also added term variants by mapping their CUIs to missing items available in the Spanish versions of standard thesauri (e.g. Medical Subject Headings and World Health Organization Adverse Drug Re- actions terminology). We enhanced the vocabulary coverage by gathering missing terms from resources such as the Anatomical Therapeutical Classification, the National Cancer Institute (NCI) Dictionary of Cancer Terms, OrphaData, or the Nomencl{\'a}tor de Prescripci{\'o}n for drug names. Part-of-Speech information is being included in the lexicon, and the current version amounts up to 76 454 lemmas and 203 043 inflected forms (including conjugated verbs, number and gender variants), corresponding to 30 647 UMLS CUIs. MedLexSp is distributed freely for research purposes.",
}
@inproceedings{wang-mercer-2019-incorporating,
    title = "Incorporating Figure Captions and Descriptive Text in {M}e{SH} Term Indexing",
    author = "Wang, Xindi  and
      Mercer, Robert E.",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5018",
    doi = "10.18653/v1/W19-5018",
    pages = "165--175",
    abstract = "The goal of text classification is to automatically assign categories to documents. Deep learning automatically learns effective features from data instead of adopting human-designed features. In this paper, we focus specifically on biomedical document classification using a deep learning approach. We present a novel multichannel TextCNN model for MeSH term indexing. Beyond the normal use of the text from the abstract and title for model training, we also consider figure and table captions, as well as paragraphs associated with the figures and tables. We demonstrate that these latter text sources are important feature sources for our method. A new dataset consisting of these text segments curated from 257,590 full text articles together with the articles{'} MEDLINE/PubMed MeSH terms is publicly available.",
}
@inproceedings{khachatrian-etal-2019-biorelex,
    title = "{B}io{R}el{E}x 1.0: Biological Relation Extraction Benchmark",
    author = "Khachatrian, Hrant  and
      Nersisyan, Lilit  and
      Hambardzumyan, Karen  and
      Galstyan, Tigran  and
      Hakobyan, Anna  and
      Arakelyan, Arsen  and
      Rzhetsky, Andrey  and
      Galstyan, Aram",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5019",
    doi = "10.18653/v1/W19-5019",
    pages = "176--190",
    abstract = "Automatic extraction of relations and interactions between biological entities from scientific literature remains an extremely challenging problem in biomedical information extraction and natural language processing in general. One of the reasons for slow progress is the relative scarcity of standardized and publicly available benchmarks. In this paper we introduce BioRelEx, a new dataset of fully annotated sentences from biomedical literature that capture \textit{binding} interactions between proteins and/or biomolecules. To foster reproducible research on the interaction extraction task, we define a precise and transparent evaluation process, tools for error analysis and significance tests. Finally, we conduct extensive experiments to evaluate several baselines, including SciIE, a recently introduced neural multi-task architecture that has demonstrated state-of-the-art performance on several tasks.",
}
@inproceedings{goodrum-etal-2019-extraction,
    title = "Extraction of Lactation Frames from Drug Labels and {L}act{M}ed",
    author = "Goodrum, Heath  and
      Gudala, Meghana  and
      Misra, Ankita  and
      Roberts, Kirk",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5020",
    doi = "10.18653/v1/W19-5020",
    pages = "191--200",
    abstract = "This paper describes a natural language processing (NLP) approach to extracting lactation-specific drug information from two sources: FDA-mandated drug labels and the NLM Drugs and Lactation Database (LactMed). A frame semantic approach is utilized, and the paper describes the selected frames, their annotation on a set of 900 sections from drug labels and LactMed articles, and the NLP system to extract such frame instances automatically. The ultimate goal of the project is to use such a system to identify discrepancies in lactation-related drug information between these resources.",
}
@inproceedings{viani-etal-2019-annotating,
    title = "Annotating Temporal Information in Clinical Notes for Timeline Reconstruction: Towards the Definition of Calendar Expressions",
    author = "Viani, Natalia  and
      Tissot, Hegler  and
      Bernardino, Ariane  and
      Velupillai, Sumithra",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5021",
    doi = "10.18653/v1/W19-5021",
    pages = "201--210",
    abstract = "To automatically analyse complex trajectory information enclosed in clinical text (e.g. timing of symptoms, duration of treatment), it is important to understand the related temporal aspects, anchoring each event on an absolute point in time. In the clinical domain, few temporally annotated corpora are currently available. Moreover, underlying annotation schemas - which mainly rely on the TimeML standard - are not necessarily easily applicable for applications such as patient timeline reconstruction. In this work, we investigated how temporal information is documented in clinical text by annotating a corpus of medical reports with time expressions (TIMEXes), based on TimeML. The developed corpus is available to the NLP community. Starting from our annotations, we analysed the suitability of the TimeML TIMEX schema for capturing timeline information, identifying challenges and possible solutions. As a result, we propose a novel annotation schema that could be useful for timeline reconstruction: CALendar EXpression (CALEX).",
}
@inproceedings{gron-etal-2019-leveraging,
    title = "Leveraging Sublanguage Features for the Semantic Categorization of Clinical Terms",
    author = {Gr{\"o}n, Leonie  and
      Bertels, Ann  and
      Heylen, Kris},
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5022",
    doi = "10.18653/v1/W19-5022",
    pages = "211--216",
    abstract = "The automatic processing of clinical documents, such as Electronic Health Records (EHRs), could benefit substantially from the enrichment of medical terminologies with terms encountered in clinical practice. To integrate such terms into existing knowledge sources, they must be linked to corresponding concepts. We present a method for the semantic categorization of clinical terms based on their surface form. We find that features based on sublanguage properties can provide valuable cues for the classification of term variants.",
}
@inproceedings{mezaoui-etal-2019-enhancing,
    title = "Enhancing {PIO} Element Detection in Medical Text Using Contextualized Embedding",
    author = "Mezaoui, Hichem  and
      Gunasekara, Isuru  and
      Gontcharov, Aleksandr",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5023",
    doi = "10.18653/v1/W19-5023",
    pages = "217--222",
    abstract = "In this paper, we presented an improved methodology to extract PIO elements, from abstracts of medical papers, that reduces ambiguity. The proposed technique was used to build a dataset of PIO elements that we call PICONET. We further proposed a model of PIO elements classification using state of the art BERT embedding. In addition, we investigated a contextualized embedding, BioBERT, trained on medical corpora. It has been found that using the BioBERT embedding improved the classification accuracy, outperforming the BERT-based model. This result reinforces the idea of the importance of embedding contextualization in subsequent classification tasks in this specific context.Furthermore, to enhance the accuracy of the model, we have investigated an ensemble method based on the LGBM algorithm. We trained the LGBM model, with the above models as base learners, to learn a linear combination of the predicted probabilities for the 3 classes with the TF-IDF score and the QIEF that optimizes the classification. The results indicate that these text features were good features to consider in order to boost the deeply contextualized classification model. We compared the performance of the classifier when using the features with one of the base learners and the case where we combine the base learners along with the features. We obtained the highest score in terms of AUC when we combine the base learners.The present work resulted in the creation of a PIO element dataset, PICONET, and a classification tool. These constitute and important component of our system of automatic mining of medical abstracts. We intend to extend the dataset to full medical articles. The model will be modified to take into account the higher complexity of full text data and more efficient features for model boosting will be investigated.",
}
@inproceedings{lopes-etal-2019-contributions,
    title = "Contributions to Clinical Named Entity Recognition in {P}ortuguese",
    author = "Lopes, F{\'a}bio  and
      Teixeira, C{\'e}sar  and
      Gon{\c{c}}alo Oliveira, Hugo",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5024",
    doi = "10.18653/v1/W19-5024",
    pages = "223--233",
    abstract = "Having in mind that different languages might present different challenges, this paper presents the following contributions to the area of Information Extraction from clinical text, targeting the Portuguese language: a collection of 281 clinical texts in this language, with manually-annotated named entities; word embeddings trained in a larger collection of similar texts; results of using BiLSTM-CRF neural networks for named entity recognition on the annotated collection, including a comparison of using in-domain or out-of-domain word embeddings in this task. Although learned with much less data, performance is higher when using in-domain embeddings. When tested in 20 independent clinical texts, this model achieved better results than a model using larger out-of-domain embeddings.",
}
@inproceedings{yan-etal-2019-character,
    title = "Can Character Embeddings Improve Cause-of-Death Classification for Verbal Autopsy Narratives?",
    author = "Yan, Zhaodong  and
      Jeblee, Serena  and
      Hirst, Graeme",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5025",
    doi = "10.18653/v1/W19-5025",
    pages = "234--239",
    abstract = "We present two models for combining word and character embeddings for cause-of-death classification of verbal autopsy reports using the text of the narratives. We find that for smaller datasets (500 to 1000 records), adding character information to the model improves classification, making character-based CNNs a promising method for automated verbal autopsy coding.",
}
@inproceedings{wang-etal-2019-artificial,
    title = "Is artificial data useful for biomedical Natural Language Processing algorithms?",
    author = "Wang, Zixu  and
      Ive, Julia  and
      Velupillai, Sumithra  and
      Specia, Lucia",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5026",
    doi = "10.18653/v1/W19-5026",
    pages = "240--249",
    abstract = "A major obstacle to the development of Natural Language Processing (NLP) methods in the biomedical domain is data accessibility. This problem can be addressed by generating medical data artificially. Most previous studies have focused on the generation of short clinical text, and evaluation of the data utility has been limited. We propose a generic methodology to guide the generation of clinical text with key phrases. We use the artificial data as additional training data in two key biomedical NLP tasks: text classification and temporal relation extraction. We show that artificially generated training data used in conjunction with real training data can lead to performance boosts for data-greedy neural network algorithms. We also demonstrate the usefulness of the generated data for NLP setups where it fully replaces real training data.",
}
@inproceedings{tian-etal-2019-chimed,
    title = "{C}hi{M}ed: A {C}hinese Medical Corpus for Question Answering",
    author = "Tian, Yuanhe  and
      Ma, Weicheng  and
      Xia, Fei  and
      Song, Yan",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5027",
    doi = "10.18653/v1/W19-5027",
    pages = "250--260",
    abstract = "Question answering (QA) is a challenging task in natural language processing (NLP), especially when it is applied to specific domains. While models trained in the general domain can be adapted to a new target domain, their performance often degrades significantly due to domain mismatch. Alternatively, one can require a large amount of domain-specific QA data, but such data are rare, especially for the medical domain. In this study, we first collect a large-scale Chinese medical QA corpus called ChiMed; second we annotate a small fraction of the corpus to check the quality of the answers; third, we extract two datasets from the corpus and use them for the relevancy prediction task and the adoption prediction task. Several benchmark models are applied to the datasets, producing good results for both tasks.",
}
@inproceedings{wiegreffe-etal-2019-clinical,
    title = "Clinical Concept Extraction for Document-Level Coding",
    author = "Wiegreffe, Sarah  and
      Choi, Edward  and
      Yan, Sherry  and
      Sun, Jimeng  and
      Eisenstein, Jacob",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5028",
    doi = "10.18653/v1/W19-5028",
    pages = "261--272",
    abstract = "The text of clinical notes can be a valuable source of patient information and clinical assessments. Historically, the primary approach for exploiting clinical notes has been information extraction: linking spans of text to concepts in a detailed domain ontology. However, recent work has demonstrated the potential of supervised machine learning to extract document-level codes directly from the raw text of clinical notes. We propose to bridge the gap between the two approaches with two novel syntheses: (1) treating extracted concepts as features, which are used to supplement or replace the text of the note; (2) treating extracted concepts as labels, which are used to learn a better representation of the text. Unfortunately, the resulting concepts do not yield performance gains on the document-level clinical coding task. We explore possible explanations and future research directions.",
}
@inproceedings{grouin-etal-2019-clinical,
    title = "Clinical Case Reports for {NLP}",
    author = "Grouin, Cyril  and
      Grabar, Natalia  and
      Claveau, Vincent  and
      Hamon, Thierry",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5029",
    doi = "10.18653/v1/W19-5029",
    pages = "273--282",
    abstract = "Textual data are useful for accessing expert information. Yet, since the texts are representative of distinct language uses, it is necessary to build specific corpora in order to be able to design suitable NLP tools. In some domains, such as medical domain, it may be complicated to access the representative textual data and their semantic annotations, while there exists a real need for providing efficient tools and methods. Our paper presents a corpus of clinical cases written in French, and their semantic annotations. Thus, we manually annotated a set of 717 files into four general categories (age, gender, outcome, and origin) for a total number of 2,835 annotations. The values of age, gender, and outcome are normalized. A subset with 70 files has been additionally manually annotated into 27 categories for a total number of 5,198 annotations.",
}
@inproceedings{liu-etal-2019-two,
    title = "Two-stage Federated Phenotyping and Patient Representation Learning",
    author = "Liu, Dianbo  and
      Dligach, Dmitriy  and
      Miller, Timothy",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5030",
    doi = "10.18653/v1/W19-5030",
    pages = "283--291",
    abstract = "A large percentage of medical information is in unstructured text format in electronic medical record systems. Manual extraction of information from clinical notes is extremely time consuming. Natural language processing has been widely used in recent years for automatic information extraction from medical texts. However, algorithms trained on data from a single healthcare provider are not generalizable and error-prone due to the heterogeneity and uniqueness of medical documents. We develop a two-stage federated natural language processing method that enables utilization of clinical notes from different hospitals or clinics without moving the data, and demonstrate its performance using obesity and comorbities phenotyping as medical task. This approach not only improves the quality of a specific clinical task but also facilitates knowledge progression in the whole healthcare system, which is an essential part of learning health system. To the best of our knowledge, this is the first application of federated machine learning in clinical NLP.",
}
@inproceedings{kyriakakis-etal-2019-transfer,
    title = "Transfer Learning for Causal Sentence Detection",
    author = "Kyriakakis, Manolis  and
      Androutsopoulos, Ion  and
      Saudabayev, Artur  and
      Gin{\'e}s i Ametll{\'e}, Joan",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5031",
    doi = "10.18653/v1/W19-5031",
    pages = "292--297",
    abstract = "We consider the task of detecting sentences that express causality, as a step towards mining causal relations from texts. To bypass the scarcity of causal instances in relation extraction datasets, we exploit transfer learning, namely ELMO and BERT, using a bidirectional GRU with self-attention ( BIGRUATT ) as a baseline. We experiment with both generic public relation extraction datasets and a new biomedical causal sentence detection dataset, a subset of which we make publicly available. We find that transfer learning helps only in very small datasets. With larger datasets, BIGRUATT reaches a performance plateau, then larger datasets and transfer learning do not help.",
}
@inproceedings{kotitsas-etal-2019-embedding,
    title = "Embedding Biomedical Ontologies by Jointly Encoding Network Structure and Textual Node Descriptors",
    author = "Kotitsas, Sotiris  and
      Pappas, Dimitris  and
      Androutsopoulos, Ion  and
      McDonald, Ryan  and
      Apidianaki, Marianna",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5032",
    doi = "10.18653/v1/W19-5032",
    pages = "298--308",
    abstract = "Network Embedding (NE) methods, which map network nodes to low-dimensional feature vectors, have wide applications in network analysis and bioinformatics. Many existing NE methods rely only on network structure, overlooking other information associated with the nodes, e.g., text describing the nodes. Recent attempts to combine the two sources of information only consider local network structure. We extend NODE2VEC, a well-known NE method that considers broader network structure, to also consider textual node descriptors using recurrent neural encoders. Our method is evaluated on link prediction in two networks derived from UMLS. Experimental results demonstrate the effectiveness of the proposed approach compared to previous work.",
}
@inproceedings{koptient-etal-2019-simplification,
    title = "Simplification-induced transformations: typology and some characteristics",
    author = {Koptient, Ana{\"\i}s  and
      Cardon, R{\'e}mi  and
      Grabar, Natalia},
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5033",
    doi = "10.18653/v1/W19-5033",
    pages = "309--318",
    abstract = "The purpose of automatic text simplification is to transform technical or difficult to understand texts into a more friendly version. The semantics must be preserved during this transformation. Automatic text simplification can be done at different levels (lexical, syntactic, semantic, stylistic...) and relies on the corresponding knowledge and resources (lexicon, rules...). Our objective is to propose methods and material for the creation of transformation rules from a small set of parallel sentences differentiated by their technicity. We also propose a typology of transformations and quantify them. We work with French-language data related to the medical domain, although we assume that the method can be exploited on texts in any language and from any domain.",
}
@inproceedings{neumann-etal-2019-scispacy,
    title = "{S}cispa{C}y: Fast and Robust Models for Biomedical Natural Language Processing",
    author = "Neumann, Mark  and
      King, Daniel  and
      Beltagy, Iz  and
      Ammar, Waleed",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5034",
    doi = "10.18653/v1/W19-5034",
    pages = "319--327",
    abstract = "Despite recent advances in natural language processing, many statistical models for processing text perform extremely poorly under domain shift. Processing biomedical and clinical text is a critically important application area of natural language processing, for which there are few robust, practical, publicly available models. This paper describes scispaCy, a new Python library and models for practical biomedical/scientific text processing, which heavily leverages the spaCy library. We detail the performance of two packages of models released in scispaCy and demonstrate their robustness on several tasks and datasets. Models and code are available at https://allenai.github.io/scispacy/.",
}
@inproceedings{zhai-etal-2019-improving,
    title = "Improving Chemical Named Entity Recognition in Patents with Contextualized Word Embeddings",
    author = "Zhai, Zenan  and
      Nguyen, Dat Quoc  and
      Akhondi, Saber  and
      Thorne, Camilo  and
      Druckenbrodt, Christian  and
      Cohn, Trevor  and
      Gregory, Michelle  and
      Verspoor, Karin",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5035",
    doi = "10.18653/v1/W19-5035",
    pages = "328--338",
    abstract = "Chemical patents are an important resource for chemical information. However, few chemical Named Entity Recognition (NER) systems have been evaluated on patent documents, due in part to their structural and linguistic complexity. In this paper, we explore the NER performance of a BiLSTM-CRF model utilising pre-trained word embeddings, character-level word representations and contextualized ELMo word representations for chemical patents. We compare word embeddings pre-trained on biomedical and chemical patent corpora. The effect of tokenizers optimized for the chemical domain on NER performance in chemical patents is also explored. The results on two patent corpora show that contextualized word representations generated from ELMo substantially improve chemical NER performance w.r.t. the current state-of-the-art. We also show that domain-specific resources such as word embeddings trained on chemical patents and chemical-specific tokenizers, have a positive impact on NER performance.",
}
@inproceedings{alhuzali-ananiadou-2019-improving,
    title = "Improving classification of Adverse Drug Reactions through Using Sentiment Analysis and Transfer Learning",
    author = "Alhuzali, Hassan  and
      Ananiadou, Sophia",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5036",
    doi = "10.18653/v1/W19-5036",
    pages = "339--347",
    abstract = "The availability of large-scale and real-time data on social media has motivated research into adverse drug reactions (ADRs). ADR classification helps to identify negative effects of drugs, which can guide health professionals and pharmaceutical companies in making medications safer and advocating patients{'} safety. Based on the observation that in social media, negative sentiment is frequently expressed towards ADRs, this study presents a neural model that combines sentiment analysis with transfer learning techniques to improve ADR detection in social media postings. Our system is firstly trained to classify sentiment in tweets concerning current affairs, using the SemEval17-task4A corpus. We then apply transfer learning to adapt the model to the task of detecting ADRs in social media postings. We show that, in combination with rich representations of words and their contexts, transfer learning is beneficial, especially given the large degree of vocabulary overlap between the current affairs posts in the SemEval17-task4A corpus and posts about ADRs. We compare our results with previous approaches, and show that our model can outperform them by up to 3{\%} F-score.",
}
@inproceedings{vashisth-etal-2019-exploring,
    title = "Exploring Diachronic Changes of Biomedical Knowledge using Distributed Concept Representations",
    author = "Vashisth, Gaurav  and
      Voigt-Antons, Jan-Niklas  and
      Mikhailov, Michael  and
      Roller, Roland",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5037",
    doi = "10.18653/v1/W19-5037",
    pages = "348--358",
    abstract = "In research best practices can change over time as new discoveries are made and novel methods are implemented. Scientific publications reporting about the latest facts and current state-of-the-art can be possibly outdated after some years or even proved to be false. A publication usually sheds light only on the knowledge of the period it has been published. Thus, the aspect of time can play an essential role in the reliability of the presented information. In Natural Language Processing many methods focus on information extraction from text, such as detecting entities and their relationship to each other. Those methods mostly focus on the facts presented in the text itself and not on the aspects of knowledge which changes over time. This work instead examines the evolution in biomedical knowledge over time using scientific literature in terms of diachronic change. Mainly the usage of temporal and distributional concept representations are explored and evaluated by a proof-of-concept.",
}
@inproceedings{koroleva-paroubek-2019-extracting,
    title = "Extracting relations between outcomes and significance levels in Randomized Controlled Trials ({RCT}s) publications",
    author = "Koroleva, Anna  and
      Paroubek, Patrick",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5038",
    doi = "10.18653/v1/W19-5038",
    pages = "359--369",
    abstract = "Randomized controlled trials assess the effects of an experimental intervention by comparing it to a control intervention with regard to some variables - trial outcomes. Statistical hypothesis testing is used to test if the experimental intervention is superior to the control. Statistical significance is typically reported for the measured outcomes and is an important characteristic of the results. We propose a machine learning approach to automatically extract reported outcomes, significance levels and the relation between them. We annotated a corpus of 663 sentences with 2,552 outcome - significance level relations (1,372 positive and 1,180 negative relations). We compared several classifiers, using a manually crafted feature set, and a number of deep learning models. The best performance (F-measure of 94{\%}) was shown by the BioBERT fine-tuned model.",
}
@inproceedings{ben-abacha-etal-2019-overview,
    title = "Overview of the {MEDIQA} 2019 Shared Task on Textual Inference, Question Entailment and Question Answering",
    author = "Ben Abacha, Asma  and
      Shivade, Chaitanya  and
      Demner-Fushman, Dina",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5039",
    doi = "10.18653/v1/W19-5039",
    pages = "370--379",
    abstract = "This paper presents the MEDIQA 2019 shared task organized at the ACL-BioNLP work- shop. The shared task is motivated by a need to develop relevant methods, techniques and gold standards for inference and entail- ment in the medical domain, and their ap- plication to improve domain specific infor- mation retrieval and question answering sys- tems. MEDIQA 2019 includes three tasks: Natural Language Inference (NLI), Recogniz- ing Question Entailment (RQE), and Question Answering (QA) in the medical domain. 72 teams participated in the challenge, achieving an accuracy of 98{\%} in the NLI task, 74.9{\%} in the RQE task, and 78.3{\%} in the QA task. In this paper, we describe the tasks, the datasets, and the participants{'} approaches and results. We hope that this shared task will attract fur- ther research efforts in textual inference, ques- tion entailment, and question answering in the medical domain.",
}
@inproceedings{zhu-etal-2019-panlp,
    title = "{PANLP} at {MEDIQA} 2019: Pre-trained Language Models, Transfer Learning and Knowledge Distillation",
    author = "Zhu, Wei  and
      Zhou, Xiaofeng  and
      Wang, Keqiang  and
      Luo, Xun  and
      Li, Xiepeng  and
      Ni, Yuan  and
      Xie, Guotong",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5040",
    doi = "10.18653/v1/W19-5040",
    pages = "380--388",
    abstract = "This paper describes the models designated for the MEDIQA 2019 shared tasks by the team PANLP. We take advantages of the recent advances in pre-trained bidirectional transformer language models such as BERT (Devlin et al., 2018) and MT-DNN (Liu et al., 2019b). We find that pre-trained language models can significantly outperform traditional deep learning models. Transfer learning from the NLI task to the RQE task is also experimented, which proves to be useful in improving the results of fine-tuning MT-DNN large. A knowledge distillation process is implemented, to distill the knowledge contained in a set of models and transfer it into an single model, whose performance turns out to be comparable with that obtained by the ensemble of that set of models. Finally, for test submissions, model ensemble and a re-ranking process are implemented to boost the performances. Our models participated in all three tasks and ranked the 1st place for the RQE task, and the 2nd place for the NLI task, and also the 2nd place for the QA task.",
}
@inproceedings{pugaliya-etal-2019-pentagon,
    title = "Pentagon at {MEDIQA} 2019: Multi-task Learning for Filtering and Re-ranking Answers using Language Inference and Question Entailment",
    author = "Pugaliya, Hemant  and
      Saxena, Karan  and
      Garg, Shefali  and
      Shalini, Sheetal  and
      Gupta, Prashant  and
      Nyberg, Eric  and
      Mitamura, Teruko",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5041",
    doi = "10.18653/v1/W19-5041",
    pages = "389--398",
    abstract = "Parallel deep learning architectures like fine-tuned BERT and MT-DNN, have quickly become the state of the art, bypassing previous deep and shallow learning methods by a large margin. More recently, pre-trained models from large related datasets have been able to perform well on many downstream tasks by just fine-tuning on domain-specific datasets (similar to transfer learning). However, using powerful models on non-trivial tasks, such as ranking and large document classification, still remains a challenge due to input size limitations of parallel architecture and extremely small datasets (insufficient for fine-tuning). In this work, we introduce an end-to-end system, trained in a multi-task setting, to filter and re-rank answers in the medical domain. We use task-specific pre-trained models as deep feature extractors. Our model achieves the highest Spearman{'}s Rho and Mean Reciprocal Rank of 0.338 and 0.9622 respectively, on the ACL-BioNLP workshop MediQA Question Answering shared-task.",
}
@inproceedings{xu-etal-2019-doubletransfer,
    title = "{D}ouble{T}ransfer at {MEDIQA} 2019: Multi-Source Transfer Learning for Natural Language Understanding in the Medical Domain",
    author = "Xu, Yichong  and
      Liu, Xiaodong  and
      Li, Chunyuan  and
      Poon, Hoifung  and
      Gao, Jianfeng",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5042",
    doi = "10.18653/v1/W19-5042",
    pages = "399--405",
    abstract = "This paper describes our competing system to enter the MEDIQA-2019 competition. We use a multi-source transfer learning approach to transfer the knowledge from MT-DNN and SciBERT to natural language understanding tasks in the medical domain. For transfer learning fine-tuning, we use multi-task learning on NLI, RQE and QA tasks on general and medical domains to improve performance. The proposed methods are proved effective for natural language understanding in the medical domain, and we rank the first place on the QA task.",
}
@inproceedings{nam-etal-2019-surf,
    title = "Surf at {MEDIQA} 2019: Improving Performance of Natural Language Inference in the Clinical Domain by Adopting Pre-trained Language Model",
    author = "Nam, Jiin  and
      Yoon, Seunghyun  and
      Jung, Kyomin",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5043",
    doi = "10.18653/v1/W19-5043",
    pages = "406--414",
    abstract = "While deep learning techniques have shown promising results in many natural language processing (NLP) tasks, it has not been widely applied to the clinical domain. The lack of large datasets and the pervasive use of domain-specific language (i.e. abbreviations and acronyms) in the clinical domain causes slower progress in NLP tasks than that of the general NLP tasks. To fill this gap, we employ word/subword-level based models that adopt large-scale data-driven methods such as pre-trained language models and transfer learning in analyzing text for the clinical domain. Empirical results demonstrate the superiority of the proposed methods by achieving 90.6{\%} accuracy in medical domain natural language inference task. Furthermore, we inspect the independent strengths of the proposed approaches in quantitative and qualitative manners. This analysis will help researchers to select necessary components in building models for the medical domain.",
}
@inproceedings{wu-etal-2019-wtmed,
    title = "{WTMED} at {MEDIQA} 2019: A Hybrid Approach to Biomedical Natural Language Inference",
    author = "Wu, Zhaofeng  and
      Song, Yan  and
      Huang, Sicong  and
      Tian, Yuanhe  and
      Xia, Fei",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5044",
    doi = "10.18653/v1/W19-5044",
    pages = "415--426",
    abstract = "Natural language inference (NLI) is challenging, especially when it is applied to technical domains such as biomedical settings. In this paper, we propose a hybrid approach to biomedical NLI where different types of information are exploited for this task. Our base model includes a pre-trained text encoder as the core component, and a syntax encoder and a feature encoder to capture syntactic and domain-specific information. Then we combine the output of different base models to form more powerful ensemble models. Finally, we design two conflict resolution strategies when the test data contain multiple (premise, hypothesis) pairs with the same premise. We train our models on the MedNLI dataset, yielding the best performance on the test set of the MEDIQA 2019 Task 1.",
}
@inproceedings{cengiz-etal-2019-ku,
    title = "{KU}{\_}ai at {MEDIQA} 2019: Domain-specific Pre-training and Transfer Learning for Medical {NLI}",
    author = "Cengiz, Cemil  and
      Sert, Ula{\c{s}}  and
      Yuret, Deniz",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5045",
    doi = "10.18653/v1/W19-5045",
    pages = "427--436",
    abstract = "In this paper, we describe our system and results submitted for the Natural Language Inference (NLI) track of the MEDIQA 2019 Shared Task. As KU{\_}ai team, we used BERT as our baseline model and pre-processed the MedNLI dataset to mitigate the negative impact of de-identification artifacts. Moreover, we investigated different pre-training and transfer learning approaches to improve the performance. We show that pre-training the language model on rich biomedical corpora has a significant effect in teaching the model domain-specific language. In addition, training the model on large NLI datasets such as MultiNLI and SNLI helps in learning task-specific reasoning. Finally, we ensembled our highest-performing models, and achieved 84.7{\%} accuracy on the unseen test dataset and ranked 10th out of 17 teams in the official results.",
}
@inproceedings{zhou-etal-2019-dut,
    title = "{DUT}-{NLP} at {MEDIQA} 2019: An Adversarial Multi-Task Network to Jointly Model Recognizing Question Entailment and Question Answering",
    author = "Zhou, Huiwei  and
      Li, Xuefei  and
      Yao, Weihong  and
      Lang, Chengkun  and
      Ning, Shixian",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5046",
    doi = "10.18653/v1/W19-5046",
    pages = "437--445",
    abstract = "In this paper, we propose a novel model called Adversarial Multi-Task Network (AMTN) for jointly modeling Recognizing Question Entailment (RQE) and medical Question Answering (QA) tasks. AMTN utilizes a pre-trained BioBERT model and an Interactive Transformer to learn the shared semantic representations across different task through parameter sharing mechanism. Meanwhile, an adversarial training strategy is introduced to separate the private features of each task from the shared representations. Experiments on BioNLP 2019 RQE and QA Shared Task datasets show that our model benefits from the shared representations of both tasks provided by multi-task learning and adversarial training, and obtains significant improvements upon the single-task models.",
}
@inproceedings{zhou-etal-2019-dut-bim,
    title = "{DUT}-{BIM} at {MEDIQA} 2019: Utilizing Transformer Network and Medical Domain-Specific Contextualized Representations for Question Answering",
    author = "Zhou, Huiwei  and
      Lei, Bizun  and
      Liu, Zhe  and
      Liu, Zhuang",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5047",
    doi = "10.18653/v1/W19-5047",
    pages = "446--452",
    abstract = "In medical domain, given a medical question, it is difficult to manually select the most relevant information from a large number of search results. BioNLP 2019 proposes Question Answering (QA) task, which encourages the use of text mining technology to automatically judge whether a search result is an answer to the medical question. The main challenge of QA task is how to mine the semantic relation between question and answer. We propose BioBERT Transformer model to tackle this challenge, which applies Transformers to extract semantic relation between different words in questions and answers. Furthermore, BioBERT is utilized to encode medical domain-specific contextualized word representations. Our method has reached the accuracy of 76.24{\%} and spearman of 17.12{\%} on the BioNLP 2019 QA task.",
}
@inproceedings{bannihatti-kumar-etal-2019-dr,
    title = "{D}r.{Q}uad at {MEDIQA} 2019: Towards Textual Inference and Question Entailment using contextualized representations",
    author = "Bannihatti Kumar, Vinayshekhar  and
      Srinivasan, Ashwin  and
      Chaudhary, Aditi  and
      Route, James  and
      Mitamura, Teruko  and
      Nyberg, Eric",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5048",
    doi = "10.18653/v1/W19-5048",
    pages = "453--461",
    abstract = "This paper presents the submissions by TeamDr.Quad to the ACL-BioNLP 2019 shared task on Textual Inference and Question Entailment in the Medical Domain. Our system is based on the prior work Liu et al. (2019) which uses a multi-task objective function for textual entailment. In this work, we explore different strategies for generalizing state-of-the-art language understanding models to the specialized medical domain. Our results on the shared task demonstrate that incorporating domain knowledge through data augmentation is a powerful strategy for addressing challenges posed specialized domains such as medicine.",
}
@inproceedings{bhaskar-etal-2019-sieg,
    title = "Sieg at {MEDIQA} 2019: Multi-task Neural Ensemble for Biomedical Inference and Entailment",
    author = "Bhaskar, Sai Abishek  and
      Rungta, Rashi  and
      Route, James  and
      Nyberg, Eric  and
      Mitamura, Teruko",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5049",
    doi = "10.18653/v1/W19-5049",
    pages = "462--470",
    abstract = "This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain. Recognizing textual inference relations and question similarity can address the issue of answering new consumer health questions by mapping them to Frequently Asked Questions on reputed websites like the NIH. We show that leveraging information from parallel tasks across domains along with medical knowledge integration allows our model to learn better biomedical feature representations. Our final models for the NLI and RQE tasks achieve the 4th and 2nd rank on the shared-task leaderboard respectively.",
}
@inproceedings{sharma-roychowdhury-2019-iit,
    title = "{IIT}-{KGP} at {MEDIQA} 2019: Recognizing Question Entailment using Sci-{BERT} stacked with a Gradient Boosting Classifier",
    author = "Sharma, Prakhar  and
      Roychowdhury, Sumegh",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5050",
    doi = "10.18653/v1/W19-5050",
    pages = "471--477",
    abstract = "Official System Description paper of Team IIT-KGP ranked 1st in the Development phase and 3rd in Testing Phase in MEDIQA 2019 - Recognizing Question Entailment (RQE) Shared Task of BioNLP workshop - ACL 2019. The number of people turning to the Internet to search for a diverse range of health-related subjects continues to grow and with this multitude of information available, duplicate questions are becoming more frequent and finding the most appropriate answers becomes problematic. This issue is important for question answering platforms as it complicates the retrieval of all information relevant to the same topic, particularly when questions similar in essence are expressed differently, and answering a given medical question by retrieving similar questions that are already answered by human experts seems to be a promising solution. In this paper, we present our novel approach to detect question entailment by determining the type of question asked rather than focusing on the type of the ailment given. This unique methodology makes the approach robust towards examples which have different ailment names but are synonyms of each other. Also, it enables us to check entailment at a much more fine-grained level. QSpider is a staged system consisting of state-of-the-art model Sci-BERT used as a multi-class classifier aimed at capturing both question types and semantic relations stacked with a Gradient Boosting Classifier which checks for entailment. QSpider achieves an accuracy score of 68.4{\%} on the Test set which outperforms the baseline model (54.1{\%}) by an accuracy score of 14.3{\%}.",
}
@inproceedings{nguyen-etal-2019-anu,
    title = "{ANU}-{CSIRO} at {MEDIQA} 2019: Question Answering Using Deep Contextual Knowledge",
    author = "Nguyen, Vincent  and
      Karimi, Sarvnaz  and
      Xing, Zhenchang",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5051",
    doi = "10.18653/v1/W19-5051",
    pages = "478--487",
    abstract = "We report on our system for textual inference and question entailment in the medical domain for the ACL BioNLP 2019 Shared Task, MEDIQA. Textual inference is the task of finding the semantic relationships between pairs of text. Question entailment involves identifying pairs of questions which have similar semantic content. To improve upon medical natural language inference and question entailment approaches to further medical question answering, we propose a system that incorporates open-domain and biomedical domain approaches to improve semantic understanding and ambiguity resolution. Our models achieve 80{\%} accuracy on medical natural language inference (6.5{\%} absolute improvement over the original baseline), 48.9{\%} accuracy on recognising medical question entailment, 0.248 Spearman{'}s rho for question answering ranking and 68.6{\%} accuracy for question answering classification.",
}
@inproceedings{chopra-etal-2019-msit,
    title = "{MSIT}{\_}{SRIB} at {MEDIQA} 2019: Knowledge Directed Multi-task Framework for Natural Language Inference in Clinical Domain.",
    author = "Chopra, Sahil  and
      Gupta, Ankita  and
      Kaushik, Anupama",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5052",
    doi = "10.18653/v1/W19-5052",
    pages = "488--492",
    abstract = "In this paper, we present Biomedical Multi-Task Deep Neural Network (Bio-MTDNN) on the NLI task of MediQA 2019 challenge. Bio-MTDNN utilizes {``}transfer learning{''} based paradigm where not only the source and target domains are different but also the source and target tasks are varied, although related. Further, Bio-MTDNN integrates knowledge from external sources such as clinical databases (UMLS) enhancing its performance on the clinical domain. Our proposed method outperformed the official baseline and other prior models (such as ESIM and Infersent on dev set) by a considerable margin as evident from our experimental results.",
}
@inproceedings{tawfik-spruit-2019-uu,
    title = "{UU}{\_}{TAILS} at {MEDIQA} 2019: Learning Textual Entailment in the Medical Domain",
    author = "Tawfik, Noha  and
      Spruit, Marco",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5053",
    doi = "10.18653/v1/W19-5053",
    pages = "493--499",
    abstract = "This article describes the participation of the UU{\_}TAILS team in the 2019 MEDIQA challenge intended to improve domain-specific models in medical and clinical NLP. The challenge consists of 3 tasks: medical language inference (NLI), recognizing textual entailment (RQE) and question answering (QA). Our team participated in tasks 1 and 2 and our best runs achieved a performance accuracy of 0.852 and 0.584 respectively for the test sets. The models proposed for task 1 relied on BERT embeddings and different ensemble techniques. For the RQE task, we trained a traditional multilayer perceptron network based on embeddings generated by the universal sentence encoder.",
}
@inproceedings{kearns-etal-2019-uw,
    title = "{UW}-{BHI} at {MEDIQA} 2019: An Analysis of Representation Methods for Medical Natural Language Inference",
    author = "Kearns, William  and
      Lau, Wilson  and
      Thomas, Jason",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5054",
    doi = "10.18653/v1/W19-5054",
    pages = "500--509",
    abstract = "Recent advances in distributed language modeling have led to large performance increases on a variety of natural language processing (NLP) tasks. However, it is not well understood how these methods may be augmented by knowledge-based approaches. This paper compares the performance and internal representation of an Enhanced Sequential Inference Model (ESIM) between three experimental conditions based on the representation method: Bidirectional Encoder Representations from Transformers (BERT), Embeddings of Semantic Predications (ESP), or Cui2Vec. The methods were evaluated on the Medical Natural Language Inference (MedNLI) subtask of the MEDIQA 2019 shared task. This task relied heavily on semantic understanding and thus served as a suitable evaluation set for the comparison of these representation methods.",
}
@inproceedings{kanakarajan-etal-2019-saama,
    title = "Saama Research at {MEDIQA} 2019: Pre-trained {B}io{BERT} with Attention Visualisation for Medical Natural Language Inference",
    author = "Kanakarajan, Kamal raj  and
      Ramamoorthy, Suriyadeepan  and
      Archana, Vaidheeswaran  and
      Chatterjee, Soham  and
      Sankarasubbu, Malaikannan",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5055",
    doi = "10.18653/v1/W19-5055",
    pages = "510--516",
    abstract = "Natural Language inference is the task of identifying relation between two sentences as entailment, contradiction or neutrality. MedNLI is a biomedical flavour of NLI for clinical domain. This paper explores the use of Bidirectional Encoder Representation from Transformer (BERT) for solving MedNLI. The proposed model, BERT pre-trained on PMC, PubMed and fine-tuned on MIMICIII v1.4, achieves state of the art results on MedNLI (83.45{\%}) and an accuracy of 78.5{\%} in MEDIQA challenge. The authors present an analysis of the attention patterns that emerged as a result of training BERT on MedNLI using a visualization tool, bertviz.",
}
@inproceedings{bandyopadhyay-etal-2019-iitp,
    title = "{IITP} at {MEDIQA} 2019: Systems Report for Natural Language Inference, Question Entailment and Question Answering",
    author = "Bandyopadhyay, Dibyanayan  and
      Gain, Baban  and
      Saikh, Tanik  and
      Ekbal, Asif",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5056",
    doi = "10.18653/v1/W19-5056",
    pages = "517--522",
    abstract = "This paper presents the experiments accomplished as a part of our participation in the MEDIQA challenge, an (Abacha et al., 2019) shared task. We participated in all the three tasks defined in this particular shared task. The tasks are viz. i. Natural Language Inference (NLI) ii. Recognizing Question Entailment(RQE) and their application in medical Question Answering (QA). We submitted runs using multiple deep learning based systems (runs) for each of these three tasks. We submitted five system results in each of the NLI and RQE tasks, and four system results for the QA task. The systems yield encouraging results in all the three tasks. The highest performance obtained in NLI, RQE and QA tasks are 81.8{\%}, 53.2{\%}, and 71.7{\%}, respectively.",
}
@inproceedings{lamurias-couto-2019-lasigebiotm,
    title = "{L}asige{B}io{TM} at {MEDIQA} 2019: Biomedical Question Answering using Bidirectional Transformers and Named Entity Recognition",
    author = "Lamurias, Andre  and
      Couto, Francisco M",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5057",
    doi = "10.18653/v1/W19-5057",
    pages = "523--527",
    abstract = "Biomedical Question Answering (QA) aims at providing automated answers to user questions, regarding a variety of biomedical topics. For example, these questions may ask for related to diseases, drugs, symptoms, or medical procedures. Automated biomedical QA systems could improve the retrieval of information necessary to answer these questions. The MEDIQA challenge consisted of three tasks concerning various aspects of biomedical QA. This challenge aimed at advancing approaches to Natural Language Inference (NLI) and Recognizing Question Entailment (RQE), which would then result in enhanced approaches to biomedical QA. Our approach explored a common Transformer-based architecture that could be applied to each task. This approach shared the same pre-trained weights, but which were then fine-tuned for each task using the provided training data. Furthermore, we augmented the training data with external datasets and enriched the question and answer texts using MER, a named entity recognition tool. Our approach obtained high levels of accuracy, in particular on the NLI task, which classified pairs of text according to their relation. For the QA task, we obtained higher Spearman{'}s rank correlation values using the entities recognized by MER.",
}
@inproceedings{lee-etal-2019-ncuee,
    title = "{NCUEE} at {MEDIQA} 2019: Medical Text Inference Using Ensemble {BERT}-{B}i{LSTM}-Attention Model",
    author = "Lee, Lung-Hao  and
      Lu, Yi  and
      Chen, Po-Han  and
      Lee, Po-Lei  and
      Shyu, Kuo-Kai",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5058",
    doi = "10.18653/v1/W19-5058",
    pages = "528--532",
    abstract = "This study describes the model design of the NCUEE system for the MEDIQA challenge at the ACL-BioNLP 2019 workshop. We use the BERT (Bidirectional Encoder Representations from Transformers) as the word embedding method to integrate the BiLSTM (Bidirectional Long Short-Term Memory) network with an attention mechanism for medical text inferences. A total of 42 teams participated in natural language inference task at MEDIQA 2019. Our best accuracy score of 0.84 ranked the top-third among all submissions in the leaderboard.",
}
@inproceedings{agrawal-etal-2019-ars,
    title = "{ARS}{\_}{NITK} at {MEDIQA} 2019:Analysing Various Methods for Natural Language Inference, Recognising Question Entailment and Medical Question Answering System",
    author = "Agrawal, Anumeha  and
      Anil George, Rosa  and
      Ravi, Selvan Suntiha  and
      Kamath, Sowmya  and
      Kumar, Anand",
    booktitle = "Proceedings of the 18th BioNLP Workshop and Shared Task",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5059",
    doi = "10.18653/v1/W19-5059",
    pages = "533--540",
    abstract = "In this paper, we present three approaches for Natural Language Inference, Question Entailment Recognition and Question-Answering to improve domain-specific Information Retrieval. For addressing the NLI task, the UMLS Metathesaurus was used to find the synonyms of medical terms in given sentences, on which the InferSent model was trained to predict if the given sentence is an entailment, contradictory or neutral. We also introduce a new Extreme gradient boosting model built on PubMed embeddings to perform RQE. Further, a closed-domain Question Answering technique that uses Bi-directional LSTMs trained on the SquAD dataset to determine relevant ranks of answers for a given question is also discussed.",
}
