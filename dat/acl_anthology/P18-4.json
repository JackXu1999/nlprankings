[{"id":"P18-4001","title":"Platforms for Non-speakers Annotating Names in Any Language","authors":["Lin, Ying","Costello, Cash","Zhang, Boliang","Lu, Di","Ji, Heng","Mayfield, James","McNamee, Paul"],"emails":["liny9@rpi.edu","ccostel2@jhu.edu","zhangb8@rpi.edu","lud2@rpi.edu","jih@rpi.edu","mayfield@jhu.edu","mcnamee@jhu.edu"],"author_id":["ying-lin","cash-costello","boliang-zhang","di-lu","heng-ji","james-mayfield","paul-mcnamee"],"abstract":"We demonstrate two annotation platforms that allow an English speaker to annotate names for any language without knowing the language. These platforms provided high-quality {'}{`}silver standard{''} annotations for low-resource language name taggers (Zhang et al., 2017) that achieved state-of-the-art performance on two surprise languages (Oromo and Tigrinya) at LoreHLT20171 and ten languages at TAC-KBP EDL2017 (Ji et al., 2017). We discuss strengths and limitations and compare other methods of creating silver- and gold-standard annotations using native speakers. We will make our tools publicly available for research use.","pages":"1--6","doi":"10.18653\/v1\/P18-4001","url":"https:\/\/www.aclweb.org\/anthology\/P18-4001","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4002","title":"{N}ovel{P}erspective: Identifying Point of View Characters","authors":["White, Lyndon","Togneri, Roberto","Liu, Wei","Bennamoun, Mohammed"],"emails":["lyndon.white@research.uwa.edu.au","roberto.togneri@uwa.edu.au","wei.liu@uwa.edu.au","mohammed.bennamoun@uwa.edu.au"],"author_id":["lyndon-white","roberto-togneri","wei-liu","mohammed-bennamoun"],"abstract":"We present NovelPerspective: a tool to allow consumers to subset their digital literature, based on point of view (POV) character. Many novels have multiple main characters each with their own storyline running in parallel. A well-known example is George R. R. Martin{'}s novel: {``}A Game of Thrones{''}, and others from that series. Our tool detects the main character that each section is from the POV of, and allows the user to generate a new ebook with only those sections. This gives consumers new options in how they consume their media; allowing them to pursue the storylines sequentially, or skip chapters about characters they find boring. We present two heuristic-based baselines, and two machine learning based methods for the detection of the main character.","pages":"7--12","doi":"10.18653\/v1\/P18-4002","url":"https:\/\/www.aclweb.org\/anthology\/P18-4002","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4003","title":"Out-of-the-box Universal {R}omanization Tool uroman","authors":["Hermjakob, Ulf","May, Jonathan","Knight, Kevin"],"emails":["ulf@isi.edu","jonmay@isi.edu","knight@isi.edu"],"author_id":["ulf-hermjakob","jonathan-may","kevin-knight"],"abstract":"We present uroman, a tool for converting text in myriads of languages and scripts such as Chinese, Arabic and Cyrillic into a common Latin-script representation. The tool relies on Unicode data and other tables, and handles nearly all character sets, including some that are quite obscure such as Tibetan and Tifinagh. uroman converts digital numbers in various scripts to Western Arabic numerals. Romanization enables the application of string-similarity metrics to texts from different scripts without the need and complexity of an intermediate phonetic representation. The tool is freely and publicly available as a Perl script suitable for inclusion in data processing pipelines and as an interactive demo web page.","pages":"13--18","doi":"10.18653\/v1\/P18-4003","url":"https:\/\/www.aclweb.org\/anthology\/P18-4003","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4004","title":"{H}arri{GT}: A Tool for Linking News to Science","authors":["Ravenscroft, James","Clare, Amanda","Liakata, Maria"],"emails":["","",""],"author_id":["james-ravenscroft","amanda-clare","maria-liakata"],"abstract":"Being able to reliably link scientific works to the newspaper articles that discuss them could provide a breakthrough in the way we rationalise and measure the impact of science on our society. Linking these articles is challenging because the language used in the two domains is very different, and the gathering of online resources to align the two is a substantial information retrieval endeavour. We present HarriGT, a semi-automated tool for building corpora of news articles linked to the scientific papers that they discuss. Our aim is to facilitate future development of information-retrieval tools for newspaper\/scientific work citation linking. HarriGT retrieves newspaper articles from an archive containing 17 years of UK web content. It also integrates with 3 large external citation networks, leveraging named entity extraction, and document classification to surface relevant examples of scientific literature to the user. We also provide a tuned candidate ranking algorithm to highlight potential links between scientific papers and newspaper articles to the user, in order of likelihood. HarriGT is provided as an open source tool (\\url{http:\/\/harrigt.xyz}).","pages":"19--24","doi":"10.18653\/v1\/P18-4004","url":"https:\/\/www.aclweb.org\/anthology\/P18-4004","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4005","title":"Jack the Reader {--} A Machine Reading Framework","authors":["Weissenborn, Dirk","Minervini, Pasquale","Augenstein, Isabelle","Welbl, Johannes","Rockt{\\\"a}schel, Tim","Bo{\\v{s}}njak, Matko","Mitchell, Jeff","Demeester, Thomas","Dettmers, Tim","Stenetorp, Pontus","Riedel, Sebastian"],"emails":["","","","","","","","","","",""],"author_id":["dirk-weissenborn","pasquale-minervini","isabelle-augenstein","johannes-welbl","tim-rocktaschel","matko-bosnjak","jeff-mitchell","thomas-demeester","tim-dettmers","pontus-stenetorp","sebastian-riedel"],"abstract":"Many Machine Reading and Natural Language Understanding tasks require reading supporting text in order to answer questions. For example, in Question Answering, the supporting text can be newswire or Wikipedia articles; in Natural Language Inference, premises can be seen as the supporting text and hypotheses as questions. Providing a set of useful primitives operating in a single framework of related tasks would allow for expressive modelling, and easier model comparison and replication. To that end, we present Jack the Reader (JACK), a framework for Machine Reading that allows for quick model prototyping by component reuse, evaluation of new models on existing datasets as well as integrating new datasets and applying them on a growing set of implemented baseline models. JACK is currently supporting (but not limited to) three tasks: Question Answering, Natural Language Inference, and Link Prediction. It is developed with the aim of increasing research efficiency and code reuse.","pages":"25--30","doi":"10.18653\/v1\/P18-4005","url":"https:\/\/www.aclweb.org\/anthology\/P18-4005","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4006","title":"{YEDDA}: A Lightweight Collaborative Text Span Annotation Tool","authors":["Yang, Jie","Zhang, Yue","Li, Linwei","Li, Xingxuan"],"emails":["","zhang@sutd.edu.sg","li@mymail.sutd.edu.sg",""],"author_id":["jie-yang","yue-zhang","linwei-li","xingxuan-li"],"abstract":"In this paper, we introduce Yedda, a lightweight but efficient and comprehensive open-source tool for text span annotation. Yedda provides a systematic solution for text span annotation, ranging from collaborative user annotation to administrator evaluation and analysis. It overcomes the low efficiency of traditional text annotation tools by annotating entities through both command line and shortcut keys, which are configurable with custom labels. Yedda also gives intelligent recommendations by learning the up-to-date annotated text. An administrator client is developed to evaluate annotation quality of multiple annotators and generate detailed comparison report for each annotator pair. Experiments show that the proposed system can reduce the annotation time by half compared with existing annotation tools. And the annotation time can be further compressed by 16.47{\\%} through intelligent recommendation.","pages":"31--36","doi":"10.18653\/v1\/P18-4006","url":"https:\/\/www.aclweb.org\/anthology\/P18-4006","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4007","title":"{N}ext{G}en {AML}: Distributed Deep Learning based Language Technologies to Augment Anti Money Laundering Investigation","authors":["Han, Jingguang","Barman, Utsab","Hayes, Jeremiah","Du, Jinhua","Burgin, Edward","Wan, Dadong"],"emails":["jingguang.han@accenture.com","utsab.barman@ucd.ie","jeremiah.hayes@accenture.com","jinhua.du@adaptcentre.ie","edward.burgin@accenture.com","dadong.wan@accenture.com"],"author_id":["jingguang-han","utsab-barman","jer-hayes","jinhua-du","edward-burgin","dadong-wan"],"abstract":"Most of the current anti money laundering (AML) systems, using handcrafted rules, are heavily reliant on existing structured databases, which are not capable of effectively and efficiently identifying hidden and complex ML activities, especially those with dynamic and time-varying characteristics, resulting in a high percentage of false positives. Therefore, analysts are engaged for further investigation which significantly increases human capital cost and processing time. To alleviate these issues, this paper presents a novel framework for the next generation AML by applying and visualizing deep learning-driven natural language processing (NLP) technologies in a distributed and scalable manner to augment AML monitoring and investigation. The proposed distributed framework performs news and tweet sentiment analysis, entity recognition, relation extraction, entity linking and link analysis on different data sources (e.g. news articles and tweets) to provide additional evidence to human investigators for final decision-making. Each NLP module is evaluated on a task-specific data set, and the overall experiments are performed on synthetic and real-world datasets. Feedback from AML practitioners suggests that our system can reduce approximately 30{\\%} time and cost compared to their previous manual approaches of AML investigation.","pages":"37--42","doi":"10.18653\/v1\/P18-4007","url":"https:\/\/www.aclweb.org\/anthology\/P18-4007","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4008","title":"{NLP} Web Services for Resource-Scarce Languages","authors":["Puttkammer, Martin","Eiselen, Roald","Hocking, Justin","Koen, Frederik"],"emails":["","iselen@nwu.ac.za","",""],"author_id":["martin-puttkammer","roald-eiselen","justin-hocking","frederik-koen"],"abstract":"In this paper, we present a project where existing text-based core technologies were ported to Java-based web services from various architectures. These technologies were developed over a period of eight years through various government funded projects for 10 resource-scarce languages spoken in South Africa. We describe the API and a simple web front-end capable of completing various predefined tasks.","pages":"43--49","doi":"10.18653\/v1\/P18-4008","url":"https:\/\/www.aclweb.org\/anthology\/P18-4008","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4009","title":"{DCFEE}: A Document-level {C}hinese Financial Event Extraction System based on Automatically Labeled Training Data","authors":["Yang, Hang","Chen, Yubo","Liu, Kang","Xiao, Yang","Zhao, Jun"],"emails":["","","","",""],"author_id":["hang-yang","yubo-chen","kang-liu","yang-xiao","jun-zhao"],"abstract":"We present an event extraction framework to detect event mentions and extract events from the document-level financial news. Up to now, methods based on supervised learning paradigm gain the highest performance in public datasets (such as ACE2005, KBP2015). These methods heavily depend on the manually labeled training data. However, in particular areas, such as financial, medical and judicial domains, there is no enough labeled data due to the high cost of data labeling process. Moreover, most of the current methods focus on extracting events from one sentence, but an event is usually expressed by multiple sentences in one document. To solve these problems, we propose a Document-level Chinese Financial Event Extraction (DCFEE) system which can automatically generate a large scaled labeled data and extract events from the whole document. Experimental results demonstrate the effectiveness of it","pages":"50--55","doi":"10.18653\/v1\/P18-4009","url":"https:\/\/www.aclweb.org\/anthology\/P18-4009","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4010","title":"Sentence Suggestion of {J}apanese Functional Expressions for {C}hinese-speaking Learners","authors":["Liu, Jun","Shindo, Hiroyuki","Matsumoto, Yuji"],"emails":["liu.jun.lc3@is.naist.jp","shindo@is.naist.jp","matsu@is.naist.jp"],"author_id":["jun-liu","hiroyuki-shindo","yuji-matsumoto"],"abstract":"We present a computer-assisted learning system, Jastudy, which is particularly designed for Chinese-speaking learners of Japanese as a second language (JSL) to learn Japanese functional expressions with suggestion of appropriate example sentences. The system automatically recognizes Japanese functional expressions using a free Japanese morphological analyzer MeCab, which is retrained on a new Conditional Random Fields (CRF) model. In order to select appropriate example sentences, we apply a pairwise-based machine learning tool, Support Vector Machine for Ranking (SVMrank) to estimate the complexity of the example sentences using Japanese{--}Chinese homographs as an important feature. In addition, we cluster the example sentences that contain Japanese functional expressions with two or more meanings and usages, based on part-of-speech, conjugation forms of verbs and semantic attributes, using the K-means clustering algorithm in Scikit-Learn. Experimental results demonstrate the effectiveness of our approach.","pages":"56--61","doi":"10.18653\/v1\/P18-4010","url":"https:\/\/www.aclweb.org\/anthology\/P18-4010","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4011","title":"Translating a Language You Don{'}t Know In the {C}hinese Room","authors":["Hermjakob, Ulf","May, Jonathan","Pust, Michael","Knight, Kevin"],"emails":["ulf@isi.edu","jonmay@isi.edu","pust@isi.edu","knight@isi.edu"],"author_id":["ulf-hermjakob","jonathan-may","michael-pust","kevin-knight"],"abstract":"In a corruption of John Searle{'}s famous AI thought experiment, the Chinese Room (Searle, 1980), we twist its original intent by enabling humans to translate text, e.g. from Uyghur to English, even if they don{'}t have any prior knowledge of the source language. Our enabling tool, which we call the Chinese Room, is equipped with the same resources made available to a machine translation engine. We find that our superior language model and world knowledge allows us to create perfectly fluent and nearly adequate translations, with human expertise required only for the target language. The Chinese Room tool can be used to rapidly create small corpora of parallel data when bilingual translators are not readily available, in particular for low-resource languages.","pages":"62--67","doi":"10.18653\/v1\/P18-4011","url":"https:\/\/www.aclweb.org\/anthology\/P18-4011","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4012","title":"{SANTO}: A Web-based Annotation Tool for Ontology-driven Slot Filling","authors":["Hartung, Matthias","ter Horst, Hendrik","Grimm, Frank","Diekmann, Tim","Klinger, Roman","Cimiano, Philipp"],"emails":["mhartung@techfak.uni-bielefeld.de","hterhors@techfak.uni-bielefeld.de","fgrimm@techfak.uni-bielefeld.de","tdiekmann@techfak.uni-bielefeld.de","roman.klinger@ims.uni-stuttgart.de","cimiano@techfak.uni-bielefeld.de"],"author_id":["matthias-hartung","hendrik-ter-horst","frank-grimm","tim-diekmann","roman-klinger","philipp-cimiano"],"abstract":"Supervised machine learning algorithms require training data whose generation for complex relation extraction tasks tends to be difficult. Being optimized for relation extraction at sentence level, many annotation tools lack in facilitating the annotation of relational structures that are widely spread across the text. This leads to non-intuitive and cumbersome visualizations, making the annotation process unnecessarily time-consuming. We propose SANTO, an easy-to-use, domain-adaptive annotation tool specialized for complex slot filling tasks which may involve problems of cardinality and referential grounding. The web-based architecture enables fast and clearly structured annotation for multiple users in parallel. Relational structures are formulated as templates following the conceptualization of an underlying ontology. Further, import and export procedures of standard formats enable interoperability with external sources and tools.","pages":"68--73","doi":"10.18653\/v1\/P18-4012","url":"https:\/\/www.aclweb.org\/anthology\/P18-4012","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4013","title":"{NCRF}++: An Open-source Neural Sequence Labeling Toolkit","authors":["Yang, Jie","Zhang, Yue"],"emails":["yang@mymail.sutd.edu.sg","zhang@sutd.edu.sg"],"author_id":["jie-yang","yue-zhang"],"abstract":"This paper describes NCRF++, a toolkit for neural sequence labeling. NCRF++ is designed for quick implementation of different neural sequence labeling models with a CRF inference layer. It provides users with an inference for building the custom model structure through configuration file with flexible neural feature design and utilization. Built on PyTorch \\url{http:\/\/pytorch.org\/}, the core operations are calculated in batch, making the toolkit efficient with the acceleration of GPU. It also includes the implementations of most state-of-the-art neural sequence labeling models such as LSTM-CRF, facilitating reproducing and refinement on those methods.","pages":"74--79","doi":"10.18653\/v1\/P18-4013","url":"https:\/\/www.aclweb.org\/anthology\/P18-4013","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4014","title":"{TALEN}: Tool for Annotation of Low-resource {EN}tities","authors":["Mayhew, Stephen","Roth, Dan"],"emails":["mayhew@seas.upenn.edu","danroth@seas.upenn.edu"],"author_id":["stephen-mayhew","dan-roth"],"abstract":"We present a new web-based interface, TALEN, designed for named entity annotation in low-resource settings where the annotators do not speak the language. To address this non-traditional scenario, TALEN includes such features as in-place lexicon integration, TF-IDF token statistics, Internet search, and entity propagation, all implemented so as to make this difficult task efficient and frictionless. We conduct a small user study to compare against a popular annotation tool, showing that TALEN achieves higher precision and recall against ground-truth annotations, and that users strongly prefer it over the alternative. TALEN is available at: \\url{github.com\/CogComp\/talen}.","pages":"80--86","doi":"10.18653\/v1\/P18-4014","url":"https:\/\/www.aclweb.org\/anthology\/P18-4014","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4015","title":"A Web-scale system for scientific knowledge exploration","authors":["Shen, Zhihong","Ma, Hao","Wang, Kuansan"],"emails":["zhihosh@microsoft.com","haoma@microsoft.com","kuansanw@microsoft.com"],"author_id":["zhihong-shen","hao-ma","kuansan-wang"],"abstract":"To enable efficient exploration of Web-scale scientific knowledge, it is necessary to organize scientific publications into a hierarchical concept structure. In this work, we present a large-scale system to (1) identify hundreds of thousands of scientific concepts, (2) tag these identified concepts to hundreds of millions of scientific publications by leveraging both text and graph structure, and (3) build a six-level concept hierarchy with a subsumption-based model. The system builds the most comprehensive cross-domain scientific concept ontology published to date, with more than 200 thousand concepts and over one million relationships.","pages":"87--92","doi":"10.18653\/v1\/P18-4015","url":"https:\/\/www.aclweb.org\/anthology\/P18-4015","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4016","title":"{S}cout{B}ot: A Dialogue System for Collaborative Navigation","authors":["Lukin, Stephanie M.","Gervits, Felix","Hayes, Cory J.","Moolchandani, Pooja","Leuski, Anton","Rogers III, John G.","Sanchez Amaro, Carlos","Marge, Matthew","Voss, Clare R.","Traum, David"],"emails":["stephanie.m.lukin.civ@mail.mil","felix.gervits@tufts.edu","","","","","","","","traum@ict.usc.edu"],"author_id":["stephanie-lukin","felix-gervits","cory-hayes","pooja-moolchandani","anton-leuski","john-g-rogers-iii","carlos-sanchez-amaro","matthew-marge","clare-voss","david-traum"],"abstract":"ScoutBot is a dialogue interface to physical and simulated robots that supports collaborative exploration of environments. The demonstration will allow users to issue unconstrained spoken language commands to ScoutBot. ScoutBot will prompt for clarification if the user{'}s instruction needs additional input. It is trained on human-robot dialogue collected from Wizard-of-Oz experiments, where robot responses were initiated by a human wizard in previous interactions. The demonstration will show a simulated ground robot (Clearpath Jackal) in a simulated environment supported by ROS (Robot Operating System).","pages":"93--98","doi":"10.18653\/v1\/P18-4016","url":"https:\/\/www.aclweb.org\/anthology\/P18-4016","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4017","title":"The {SUMMA} Platform: A Scalable Infrastructure for Multi-lingual Multi-media Monitoring","authors":["Germann, Ulrich","Liepins, Ren{\\=a}rs","Barzdins, Guntis","Gosko, Didzis","Miranda, Sebasti{\\~a}o","Nogueira, David"],"emails":["ugermann@ed.ac.uk","renars.liepins@leta.lv","guntis.barzdins@lu.lv","didzis.gosko@leta.lv","iranda@priberam.pt","ogueira@priberam.pt"],"author_id":["ulrich-germann","renars-liepins","guntis-barzdins","didzis-gosko","sebastiao-miranda","david-nogueira"],"abstract":"The open-source SUMMA Platform is a highly scalable distributed architecture for monitoring a large number of media broadcasts in parallel, with a lag behind actual broadcast time of at most a few minutes. The Platform offers a fully automated media ingestion pipeline capable of recording live broadcasts, detection and transcription of spoken content, translation of all text (original or transcribed) into English, recognition and linking of Named Entities, topic detection, clustering and cross-lingual multi-document summarization of related media items, and last but not least, extraction and storage of factual claims in these news items. Browser-based graphical user interfaces provide humans with aggregated information as well as structured access to individual news items stored in the Platform{'}s database. This paper describes the intended use cases and provides an overview over the system{'}s implementation.","pages":"99--104","doi":"10.18653\/v1\/P18-4017","url":"https:\/\/www.aclweb.org\/anthology\/P18-4017","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4018","title":"{CRUISE}: Cold-Start New Skill Development via Iterative Utterance Generation","authors":["Shen, Yilin","Ray, Avik","Patel, Abhishek","Jin, Hongxia"],"emails":["yilin.shen@samsung.com","avik.r@samsung.com","abhisehek.p@samsung.com","hongxia.jin@samsung.com"],"author_id":["yilin-shen","avik-ray","abhishek-patel","hongxia-jin"],"abstract":"We present a system, CRUISE, that guides ordinary software developers to build a high quality natural language understanding (NLU) engine from scratch. This is the fundamental step of building a new skill in personal assistants. Unlike existing solutions that require either developers or crowdsourcing to manually generate and annotate a large number of utterances, we design a hybrid rule-based and data-driven approach with the capability to iteratively generate more and more utterances. Our system only requires light human workload to iteratively prune incorrect utterances. CRUISE outputs a well trained NLU engine and a large scale annotated utterance corpus that third parties can use to develop their custom skills. Using both benchmark dataset and custom datasets we collected in real-world settings, we validate the high quality of CRUISE generated utterances via both competitive NLU performance and human evaluation. We also show the largely reduced human workload in terms of both cognitive load and human pruning time consumption.","pages":"105--110","doi":"10.18653\/v1\/P18-4018","url":"https:\/\/www.aclweb.org\/anthology\/P18-4018","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4019","title":"{P}raaline: An Open-Source System for Managing, Annotating, Visualising and Analysing Speech Corpora","authors":["Christodoulides, George"],"emails":["george@mycontent.gr"],"author_id":["george-christodoulides"],"abstract":"In this system demonstration we present the latest developments of Praaline, an open-source software system for constituting and managing, manually and automatically annotating, visualising and analysing spoken language and multimodal corpora. We review the system{'}s functionality and design architecture, present current use cases and directions for future development.","pages":"111--115","doi":"10.18653\/v1\/P18-4019","url":"https:\/\/www.aclweb.org\/anthology\/P18-4019","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4020","title":"{M}arian: Fast Neural Machine Translation in {C}++","authors":["Junczys-Dowmunt, Marcin","Grundkiewicz, Roman","Dwojak, Tomasz","Hoang, Hieu","Heafield, Kenneth","Neckermann, Tom","Seide, Frank","Germann, Ulrich","Aji, Alham Fikri","Bogoychev, Nikolay","Martins, Andr{\\'e} F. T.","Birch, Alexandra"],"emails":["","","","","","","","","","","",""],"author_id":["marcin-junczys-dowmunt","roman-grundkiewicz","tomasz-dwojak","hieu-hoang","kenneth-heafield","tom-neckermann","frank-seide","ulrich-germann","alham-fikri-aji","nikolay-bogoychev","andre-f-t-martins","alexandra-birch"],"abstract":"We present Marian, an efficient and self-contained Neural Machine Translation framework with an integrated automatic differentiation engine based on dynamic computation graphs. Marian is written entirely in C++. We describe the design of the encoder-decoder framework and demonstrate that a research-friendly toolkit can achieve high training and translation speed.","pages":"116--121","doi":"10.18653\/v1\/P18-4020","url":"https:\/\/www.aclweb.org\/anthology\/P18-4020","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4021","title":"{D}eep{P}avlov: Open-Source Library for Dialogue Systems","authors":["Burtsev, Mikhail","Seliverstov, Alexander","Airapetyan, Rafael","Arkhipov, Mikhail","Baymurzina, Dilyara","Bushkov, Nickolay","Gureenkova, Olga","Khakhulin, Taras","Kuratov, Yuri","Kuznetsov, Denis","Litinsky, Alexey","Logacheva, Varvara","Lymar, Alexey","Malykh, Valentin","Petrov, Maxim","Polulyakh, Vadim","Pugachev, Leonid","Sorokin, Alexey","Vikhreva, Maria","Zaynutdinov, Marat"],"emails":["burtcev.ms@mipt.ru","","","","","","","","","","","","","","","","","","",""],"author_id":["mikhail-burtsev","alexander-seliverstov","rafael-airapetyan","mikhail-arkhipov","dilyara-baymurzina","nickolay-bushkov","olga-gureenkova","taras-khakhulin","yurii-kuratov","denis-kuznetsov","alexey-litinsky","varvara-logacheva","alexey-lymar","valentin-malykh","maxim-petrov","vadim-polulyakh","leonid-pugachev","alexey-sorokin","maria-vikhreva","marat-zaynutdinov"],"abstract":"Adoption of messaging communication and voice assistants has grown rapidly in the last years. This creates a demand for tools that speed up prototyping of feature-rich dialogue systems. An open-source library DeepPavlov is tailored for development of conversational agents. The library prioritises efficiency, modularity, and extensibility with the goal to make it easier to develop dialogue systems from scratch and with limited data available. It supports modular as well as end-to-end approaches to implementation of conversational agents. Conversational agent consists of skills and every skill can be decomposed into components. Components are usually models which solve typical NLP tasks such as intent classification, named entity recognition or pre-trained word vectors. Sequence-to-sequence chit-chat skill, question answering skill or task-oriented skill can be assembled from components provided in the library.","pages":"122--127","doi":"10.18653\/v1\/P18-4021","url":"https:\/\/www.aclweb.org\/anthology\/P18-4021","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4022","title":"{RETURNN} as a Generic Flexible Neural Toolkit with Application to Translation and Speech Recognition","authors":["Zeyer, Albert","Alkhouli, Tamer","Ney, Hermann"],"emails":["","surname@cs.rwth-aachen.de",""],"author_id":["albert-zeyer","tamer-alkhouli","hermann-ney"],"abstract":"We compare the fast training and decoding speed of RETURNN of attention models for translation, due to fast CUDA LSTM kernels, and a fast pure TensorFlow beam search decoder. We show that a layer-wise pretraining scheme for recurrent attention models gives over 1{\\%} BLEU improvement absolute and it allows to train deeper recurrent encoder networks. Promising preliminary results on max. expected BLEU training are presented. We are able to train state-of-the-art models for translation and end-to-end models for speech recognition and show results on WMT 2017 and Switchboard. The flexibility of RETURNN allows a fast research feedback loop to experiment with alternative architectures, and its generality allows to use it on a wide range of applications.","pages":"128--133","doi":"10.18653\/v1\/P18-4022","url":"https:\/\/www.aclweb.org\/anthology\/P18-4022","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4023","title":"A Flexible, Efficient and Accurate Framework for Community Question Answering Pipelines","authors":["Romeo, Salvatore","Da San Martino, Giovanni","Barr{\\'o}n-Cede{\\~n}o, Alberto","Moschitti, Alessandro"],"emails":["sromeo@hbku.edu.qa","gmartino@hbku.edu.qa","albarron@hbku.edu.qa","amosch@amazon.com"],"author_id":["salvatore-romeo","giovanni-da-san-martino","alberto-barron-cedeno","alessandro-moschitti"],"abstract":"Although deep neural networks have been proving to be excellent tools to deliver state-of-the-art results, when data is scarce and the tackled tasks involve complex semantic inference, deep linguistic processing and traditional structure-based approaches, such as tree kernel methods, are an alternative solution. Community Question Answering is a research area that benefits from deep linguistic analysis to improve the experience of the community of forum users. In this paper, we present a UIMA framework to distribute the computation of cQA tasks over computer clusters such that traditional systems can scale to large datasets and deliver fast processing.","pages":"134--139","doi":"10.18653\/v1\/P18-4023","url":"https:\/\/www.aclweb.org\/anthology\/P18-4023","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"},{"id":"P18-4024","title":"Moon {IME}: Neural-based {C}hinese Pinyin Aided Input Method with Customizable Association","authors":["Huang, Yafang","Li, Zuchao","Zhang, Zhuosheng","Zhao, Hai"],"emails":["huangyafang@sjtu.edu.cn","charlee@sjtu.edu.cn","zhangzs@sjtu.edu.cn","zhaohai@cs.sjtu.edu.cn"],"author_id":["yafang-huang","zuchao-li","zhuosheng-zhang","hai-zhao"],"abstract":"Chinese pinyin input method engine (IME) lets user conveniently input Chinese into a computer by typing pinyin through the common keyboard. In addition to offering high conversion quality, modern pinyin IME is supposed to aid user input with extended association function. However, existing solutions for such functions are roughly based on oversimplified matching algorithms at word-level, whose resulting products provide limited extension associated with user inputs. This work presents the Moon IME, a pinyin IME that integrates the attention-based neural machine translation (NMT) model and Information Retrieval (IR) to offer amusive and customizable association ability. The released IME is implemented on Windows via text services framework.","pages":"140--145","doi":"10.18653\/v1\/P18-4024","url":"https:\/\/www.aclweb.org\/anthology\/P18-4024","publisher":"Association for Computational Linguistics","address":"Melbourne, Australia","year":"2018","month":"July","booktitle":"Proceedings of {ACL} 2018, System Demonstrations"}]