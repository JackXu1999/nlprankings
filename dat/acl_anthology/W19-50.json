[{"id":"W19-5001","title":"Classifying the reported ability in clinical mobility descriptions","authors":["Newman-Griffis, Denis","Zirikly, Ayah","Divita, Guy","Desmet, Bart"],"emails":["denis.griffis@nih.gov","ayah.zirikly@nih.gov","guy.divita@nih.gov","bart.desmet@nih.gov"],"author_id":["denis-newman-griffis","ayah-zirikly","guy-divita","bart-desmet"],"abstract":"Assessing how individuals perform different activities is key information for modeling health states of individuals and populations. Descriptions of activity performance in clinical free text are complex, including syntactic negation and similarities to textual entailment tasks. We explore a variety of methods for the novel task of classifying four types of assertions about activity performance: Able, Unable, Unclear, and None (no information). We find that ensembling an SVM trained with lexical features and a CNN achieves 77.9{\\%} macro F1 score on our task, and yields nearly 80{\\%} recall on the rare Unclear and Unable samples. Finally, we highlight several challenges in classifying performance assertions, including capturing information about sources of assistance, incorporating syntactic structure and negation scope, and handling new modalities at test time. Our findings establish a strong baseline for this novel task, and identify intriguing areas for further research.","pages":"1--10","doi":"10.18653\/v1\/W19-5001","url":"https:\/\/www.aclweb.org\/anthology\/W19-5001","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5002","title":"Learning from the Experience of Doctors: Automated Diagnosis of Appendicitis Based on Clinical Notes","authors":["Yuwono, Steven Kester","Ng, Hwee Tou","Ngiam, Kee Yuan"],"emails":["sky@u.nus.edu","nght@comp.nus.edu.sg","ngiam@nuhs.edu.sg"],"author_id":["steven-kester-yuwono","hwee-tou-ng","kee-yuan-ngiam"],"abstract":"The objective of this work is to develop an automated diagnosis system that is able to predict the probability of appendicitis given a free-text emergency department (ED) note and additional structured information (e.g., lab test results). Our clinical corpus consists of about 180,000 ED notes based on ten years of patient visits to the Accident and Emergency (A{\\&}E) Department of the National University Hospital (NUH), Singapore. We propose a novel neural network approach that learns to diagnose acute appendicitis based on doctors{'} free-text ED notes without any feature engineering. On a test set of 2,000 ED notes with equal number of appendicitis (positive) and non-appendicitis (negative) diagnosis and in which all the negative ED notes only consist of abdominal-related diagnosis, our model is able to achieve a promising F{\\_}0.5-score of 0.895 while ED doctors achieve F{\\_}0.5-score of 0.900. Visualization shows that our model is able to learn important features, signs, and symptoms of patients from unstructured free-text ED notes, which will help doctors to make better diagnosis.","pages":"11--19","doi":"10.18653\/v1\/W19-5002","url":"https:\/\/www.aclweb.org\/anthology\/W19-5002","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5003","title":"A Paraphrase Generation System for {EHR} Question Answering","authors":["Soni, Sarvesh","Roberts, Kirk"],"emails":["sarvesh.soni@uth.tmc.edu","kirk.roberts@uth.tmc.edu"],"author_id":["sarvesh-soni","kirk-roberts"],"abstract":"This paper proposes a dataset and method for automatically generating paraphrases for clinical questions relating to patient-specific information in electronic health records (EHRs). Crowdsourcing is used to collect 10,578 unique questions across 946 semantically distinct paraphrase clusters. This corpus is then used with a deep learning-based question paraphrasing method utilizing variational autoencoder and LSTM encoder\/decoder. The ultimate use of such a method is to improve the performance of automatic question answering methods for EHRs.","pages":"20--29","doi":"10.18653\/v1\/W19-5003","url":"https:\/\/www.aclweb.org\/anthology\/W19-5003","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5004","title":"{RE}flex: Flexible Framework for Relation Extraction in Multiple Domains","authors":["Chauhan, Geeticka","McDermott, Matthew B.A.","Szolovits, Peter"],"emails":["geeticka@mit.edu","mmd@mit.edu","psz@mit.edu"],"author_id":["geeticka-chauhan","matthew-b-a-mcdermott","peter-szolovits"],"abstract":"Systematic comparison of methods for relation extraction (RE) is difficult because many experiments in the field are not described precisely enough to be completely reproducible and many papers fail to report ablation studies that would highlight the relative contributions of their various combined techniques. In this work, we build a unifying framework for RE, applying this on three highly used datasets (from the general, biomedical and clinical domains) with the ability to be extendable to new datasets. By performing a systematic exploration of modeling, pre-processing and training methodologies, we find that choices of preprocessing are a large contributor performance and that omission of such information can further hinder fair comparison. Other insights from our exploration allow us to provide recommendations for future research in this area.","pages":"30--47","doi":"10.18653\/v1\/W19-5004","url":"https:\/\/www.aclweb.org\/anthology\/W19-5004","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5005","title":"Analysing Representations of Memory Impairment in a Clinical Notes Classification Model","authors":["Ormerod, Mark","Mart{\\'\\i}nez-del-Rinc{\\'o}n, Jes{\\'u}s","Robertson, Neil","McGuinness, Bernadette","Devereux, Barry"],"emails":["mormerod01@qub.ac.uk","j.martinez-del-rincon@qub.ac.uk","n.robertson@qub.ac.uk","b.mcguinness@qub.ac.uk","b.devereux@qub.ac.uk"],"author_id":["mark-ormerod","jesus-martinez-del-rincon","neil-robertson","bernadette-mcguinness","barry-devereux"],"abstract":"Despite recent advances in the application of deep neural networks to various kinds of medical data, extracting information from unstructured textual sources remains a challenging task. The challenges of training and interpreting document classification models are amplified when dealing with small and highly technical datasets, as are common in the clinical domain. Using a dataset of de-identified clinical letters gathered at a memory clinic, we construct several recurrent neural network models for letter classification, and evaluate them on their ability to build meaningful representations of the documents and predict patients{'} diagnoses. Additionally, we probe sentence embedding models in order to build a human-interpretable representation of the neural network{'}s features, using a simple and intuitive technique based on perturbative approaches to sentence importance. In addition to showing which sentences in a document are most informative about the patient{'}s condition, this method reveals the types of sentences that lead the model to make incorrect diagnoses. Furthermore, we identify clusters of sentences in the embedding space that correlate strongly with importance scores for each clinical diagnosis class.","pages":"48--57","doi":"10.18653\/v1\/W19-5005","url":"https:\/\/www.aclweb.org\/anthology\/W19-5005","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5006","title":"Transfer Learning in Biomedical Natural Language Processing: An Evaluation of {BERT} and {ELM}o on Ten Benchmarking Datasets","authors":["Peng, Yifan","Yan, Shankai","Lu, Zhiyong"],"emails":["yifan.peng@nih.gov","shankai.yan@nih.gov","zhiyong.lu@nih.gov"],"author_id":["yifan-peng","shankai-yan","zhiyong-lu"],"abstract":"Inspired by the success of the General Language Understanding Evaluation benchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE) benchmark to facilitate research in the development of pre-training language representations in the biomedicine domain. The benchmark consists of five tasks with ten datasets that cover both biomedical and clinical texts with different dataset sizes and difficulties. We also evaluate several baselines based on BERT and ELMo and find that the BERT model pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results. We make the datasets, pre-trained models, and codes publicly available at https:\/\/github.com\/ ncbi-nlp\/BLUE{\\_}Benchmark.","pages":"58--65","doi":"10.18653\/v1\/W19-5006","url":"https:\/\/www.aclweb.org\/anthology\/W19-5006","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5007","title":"Combining Structured and Free-text Electronic Medical Record Data for Real-time Clinical Decision Support","authors":["Apostolova, Emilia","Wang, Tony","Tschampel, Tim","Koutroulis, Ioannis","Velez, Tom"],"emails":["emilia@language.ai","xwang@imedacs.com","tim.tschampel@cta.com","ikoutrouli@childrensnational.org","tom.velez@cta.com"],"author_id":["emilia-apostolova","tony-wang","tim-tschampel","ioannis-koutroulis","tom-velez"],"abstract":"The goal of this work is to utilize Electronic Medical Record (EMR) data for real-time Clinical Decision Support (CDS). We present a deep learning approach to combining in real time available diagnosis codes (ICD codes) and free-text notes: Patient Context Vectors. Patient Context Vectors are created by averaging ICD code embeddings, and by predicting the same from free-text notes via a Convolutional Neural Network. The Patient Context Vectors were then simply appended to available structured data (vital signs and lab results) to build prediction models for a specific condition. Experiments on predicting ARDS, a rare and complex condition, demonstrate the utility of Patient Context Vectors as a means of summarizing the patient history and overall condition, and improve significantly the prediction model results.","pages":"66--70","doi":"10.18653\/v1\/W19-5007","url":"https:\/\/www.aclweb.org\/anthology\/W19-5007","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5008","title":"{M}o{NER}o: a Biomedical Gold Standard Corpus for the {R}omanian Language","authors":["Mitrofan, Maria","Barbu Mititelu, Verginica","Mitrofan, Grigorina"],"emails":["maria@racai.ro","vergi@racai.ro","grigorinam@gmail.com"],"author_id":["maria-mitrofan","verginica-barbu-mititelu","grigorina-mitrofan"],"abstract":"In an era when large amounts of data are generated daily in various fields, the biomedical field among others, linguistic resources can be exploited for various tasks of Natural Language Processing. Moreover, increasing number of biomedical documents are available in languages other than English. To be able to extract information from natural language free text resources, methods and tools are needed for a variety of languages. This paper presents the creation of the MoNERo corpus, a gold standard biomedical corpus for Romanian, annotated with both part of speech tags and named entities. MoNERo comprises 154,825 morphologically annotated tokens and 23,188 entity annotations belonging to four entity semantic groups corresponding to UMLS Semantic Groups.","pages":"71--79","doi":"10.18653\/v1\/W19-5008","url":"https:\/\/www.aclweb.org\/anthology\/W19-5008","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5009","title":"Domain Adaptation of {SRL} Systems for Biological Processes","authors":["Rajagopal, Dheeraj","Vyas, Nidhi","Siddhant, Aditya","Rayasam, Anirudha","Tandon, Niket","Hovy, Eduard"],"emails":["dheeraj@andrew.cmu.edu","nkvyas@andrew.cmu.edu","asiddhan@andrew.cmu.edu","arayasam@andrew.cmu.edu","nikett@allenai.org","hovy@cmu.edu"],"author_id":["dheeraj-rajagopal","nidhi-vyas","aditya-siddhant","anirudha-rayasam","niket-tandon","eduard-hovy"],"abstract":"Domain adaptation remains one of the most challenging aspects in the wide-spread use of Semantic Role Labeling (SRL) systems. Current state-of-the-art methods are typically trained on large-scale datasets, but their performances do not directly transfer to low-resource domain-specific settings. In this paper, we propose two approaches for domain adaptation in the biological domain that involves pre-training LSTM-CRF based on existing large-scale datasets and adapting it for a low-resource corpus of biological processes. Our first approach defines a mapping between the source labels and the target labels, and the other approach modifies the final CRF layer in sequence-labeling neural network architecture. We perform our experiments on ProcessBank dataset which contains less than 200 paragraphs on biological processes. We improve over the previous state-of-the-art system on this dataset by 21 F1 points. We also show that, by incorporating event-event relationship in ProcessBank, we are able to achieve an additional 2.6 F1 gain, giving us possible insights into how to improve SRL systems for biological process using richer annotations.","pages":"80--87","doi":"10.18653\/v1\/W19-5009","url":"https:\/\/www.aclweb.org\/anthology\/W19-5009","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5010","title":"Deep Contextualized Biomedical Abbreviation Expansion","authors":["Jin, Qiao","Liu, Jinling","Lu, Xinghua"],"emails":["qiao.jin@pitt.edu","jil172@pitt.edu","xinghua@pitt.edu"],"author_id":["qiao-jin","jinling-liu","xinghua-lu"],"abstract":"Automatic identification and expansion of ambiguous abbreviations are essential for biomedical natural language processing applications, such as information retrieval and question answering systems. In this paper, we present DEep Contextualized Biomedical Abbreviation Expansion (DECBAE) model. DECBAE automatically collects substantial and relatively clean annotated contexts for 950 ambiguous abbreviations from PubMed abstracts using a simple heuristic. Then it utilizes BioELMo to extract the contextualized features of words, and feed those features to abbreviation-specific bidirectional LSTMs, where the hidden states of the ambiguous abbreviations are used to assign the exact definitions. Our DECBAE model outperforms other baselines by large margins, achieving average accuracy of 0.961 and macro-F1 of 0.917 on the dataset. It also surpasses human performance for expanding a sample abbreviation, and remains robust in imbalanced, low-resources and clinical settings.","pages":"88--96","doi":"10.18653\/v1\/W19-5010","url":"https:\/\/www.aclweb.org\/anthology\/W19-5010","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5011","title":"{RNN} Embeddings for Identifying Difficult to Understand Medical Words","authors":["Pylieva, Hanna","Chernodub, Artem","Grabar, Natalia","Hamon, Thierry"],"emails":["pylieva@ucu.edu.ua","chernodub@ucu.edu.ua","natalia.grabar@univ-lille.fr","hamon@limsi.fr"],"author_id":["hanna-pylieva","artem-chernodub","natalia-grabar","thierry-hamon"],"abstract":"Patients and their families often require a better understanding of medical information provided by doctors. We currently address this issue by improving the identification of difficult to understand medical words. We introduce novel embeddings received from RNN - FrnnMUTE (French RNN Medical Understandability Text Embeddings) which allow to reach up to 87.0 F1 score in identification of difficult words. We also note that adding pre-trained FastText word embeddings to the feature set substantially improves the performance of the model which classifies words ac- cording to their difficulty. We study the generalizability of different models through three cross-validation scenarios which allow testing classifiers in real-world conditions: understanding of medical words by new users, and classification of new unseen words by the automatic models. The RNN - FrnnMUTE embeddings and the categorization code are being made available for the research.","pages":"97--104","doi":"10.18653\/v1\/W19-5011","url":"https:\/\/www.aclweb.org\/anthology\/W19-5011","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5012","title":"A distantly supervised dataset for automated data extraction from diagnostic studies","authors":["Norman, Christopher","Leeflang, Mariska","Spijker, Ren{\\'e}","Kanoulas, Evangelos","N{\\'e}v{\\'e}ol, Aur{\\'e}lie"],"emails":["norman@limsi.fr","m.m.leeflang@amc.uva.nl","pijker-2@umcutrecht.nl","anoulas@uva.nl","neveol@limsi.fr"],"author_id":["christopher-norman","mariska-leeflang","rene-spijker","evangelos-kanoulas","aurelie-neveol"],"abstract":"Systematic reviews are important in evidence based medicine, but are expensive to produce. Automating or semi-automating the data extraction of index test, target condition, and reference standard from articles has the potential to decrease the cost of conducting systematic reviews of diagnostic test accuracy, but relevant training data is not available. We create a distantly supervised dataset of approximately 90,000 sentences, and let two experts manually annotate a small subset of around 1,000 sentences for evaluation. We evaluate the performance of BioBERT and logistic regression for ranking the sentences, and compare the performance for distant and direct supervision. Our results suggest that distant supervision can work as well as, or better than direct supervision on this problem, and that distantly trained models can perform as well as, or better than human annotators.","pages":"105--114","doi":"10.18653\/v1\/W19-5012","url":"https:\/\/www.aclweb.org\/anthology\/W19-5012","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5013","title":"Query selection methods for automated corpora construction with a use case in food-drug interactions","authors":["Bordea, Georgeta","Randriatsitohaina, Tsanta","Mougin, Fleur","Grabar, Natalia","Hamon, Thierry"],"emails":["georgeta.bordea@u-bordeaux.fr","tsanta.randriatsitohaina@u-bordeaux.fr","fleur.mougin@u-bordeaux.fr","natalia.grabar@u-bordeaux.fr","thierry.hamon@u-bordeaux.fr"],"author_id":["georgeta-bordea","tsanta-randriatsitohaina","fleur-mougin","natalia-grabar","thierry-hamon"],"abstract":"In this paper, we address the problem of automatically constructing a relevant corpus of scientific articles about food-drug interactions. There is a growing number of scientific publications that describe food-drug interactions but currently building a high-coverage corpus that can be used for information extraction purposes is not trivial. We investigate several methods for automating the query selection process using an expert-curated corpus of food-drug interactions. Our experiments show that index term features along with a decision tree classifier are the best approach for this task and that feature selection approaches and in particular gain ratio outperform frequency-based methods for query selection.","pages":"115--124","doi":"10.18653\/v1\/W19-5013","url":"https:\/\/www.aclweb.org\/anthology\/W19-5013","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5014","title":"Enhancing biomedical word embeddings by retrofitting to verb clusters","authors":["Chiu, Billy","Baker, Simon","Palmer, Martha","Korhonen, Anna"],"emails":["hwc25@cam.ac.uk","sb895@cam.ac.uk","mpalmer@colorado.edu","alk23@cam.ac.uk"],"author_id":["billy-chiu","simon-baker","martha-palmer","anna-korhonen"],"abstract":"Verbs play a fundamental role in many biomed-ical tasks and applications such as relation and event extraction. We hypothesize that performance on many downstream tasks can be improved by aligning the input pretrained embeddings according to semantic verb classes.In this work, we show that by using semantic clusters for verbs, a large lexicon of verbclasses derived from biomedical literature, weare able to improve the performance of common pretrained embeddings in downstream tasks by retrofitting them to verb classes. We present a simple and computationally efficient approach using a widely-available {``}off-the-shelf{''} retrofitting algorithm to align pretrained embeddings according to semantic verb clusters. We achieve state-of-the-art results on text classification and relation extraction tasks.","pages":"125--134","doi":"10.18653\/v1\/W19-5014","url":"https:\/\/www.aclweb.org\/anthology\/W19-5014","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5015","title":"A Comparison of Word-based and Context-based Representations for Classification Problems in Health Informatics","authors":["Joshi, Aditya","Karimi, Sarvnaz","Sparks, Ross","Paris, Cecile","MacIntyre, C Raina"],"emails":["aditya.joshi@csiro.au","sarvnaz.karimi@csiro.au","ross.sparks@csiro.au","cecile.paris@csiro.au","r.macintyre@unsw.edu.au"],"author_id":["aditya-joshi","sarvnaz-karimi","ross-sparks","cecile-paris","c-raina-macintyre"],"abstract":"Distributed representations of text can be used as features when training a statistical classifier. These representations may be created as a composition of word vectors or as context-based sentence vectors. We compare the two kinds of representations (word versus context) for three classification problems: influenza infection classification, drug usage classification and personal health mention classification. For statistical classifiers trained for each of these problems, context-based representations based on ELMo, Universal Sentence Encoder, Neural-Net Language Model and FLAIR are better than Word2Vec, GloVe and the two adapted using the MESH ontology. There is an improvement of 2-4{\\%} in the accuracy when these context-based representations are used instead of word-based representations.","pages":"135--141","doi":"10.18653\/v1\/W19-5015","url":"https:\/\/www.aclweb.org\/anthology\/W19-5015","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5016","title":"Constructing large scale biomedical knowledge bases from scratch with rapid annotation of interpretable patterns","authors":["Fauqueur, Julien","Thillaisundaram, Ashok","Togia, Theodosia"],"emails":["julien@benevolent.ai","ashok@benevolent.ai","sia@benevolent.ai"],"author_id":["julien-fauqueur","ashok-thillaisundaram","theodosia-togia"],"abstract":"Knowledge base construction is crucial for summarising, understanding and inferring relationships between biomedical entities. However, for many practical applications such as drug discovery, the scarcity of relevant facts (e.g. gene X is therapeutic target for disease Y) severely limits a domain expert{'}s ability to create a usable knowledge base, either directly or by training a relation extraction model. In this paper, we present a simple and effective method of extracting new facts with a pre-specified binary relationship type from the biomedical literature, without requiring any training data or hand-crafted rules. Our system discovers, ranks and presents the most salient patterns to domain experts in an interpretable form. By marking patterns as compatible with the desired relationship type, experts indirectly batch-annotate candidate pairs whose relationship is expressed with such patterns in the literature. Even with a complete absence of seed data, experts are able to discover thousands of high-quality pairs with the desired relationship within minutes. When a small number of relevant pairs do exist - even when their relationship is more general (e.g. gene X is biologically associated with disease Y) than the relationship of interest - our system leverages them in order to i) learn a better ranking of the patterns to be annotated or ii) generate weakly labelled pairs in a fully automated manner. We evaluate our method both intrinsically and via a downstream knowledge base completion task, and show that it is an effective way of constructing knowledge bases when few or no relevant facts are already available.","pages":"142--151","doi":"10.18653\/v1\/W19-5016","url":"https:\/\/www.aclweb.org\/anthology\/W19-5016","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5017","title":"First Steps towards Building a Medical Lexicon for {S}panish with Linguistic and Semantic Information","authors":["Campillos-Llanos, Leonardo"],"emails":["leonardo.campillos@uam.es"],"author_id":["leonardo-campillos-llanos1"],"abstract":"We report the work-in-progress of collecting MedLexSp, an unified medical lexicon for the Spanish language, featuring terms and inflected word forms mapped to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs), semantic types and groups. First, we leveraged a list of term lemmas and forms from a previous project, and mapped them to UMLS terms and CUIs. To enrich the lexicon, we used both domain-corpora (e.g. Summaries of Product Characteristics and MedlinePlus) and natural language processing techniques such as string distance methods or generation of syntactic variants of multi-word terms. We also added term variants by mapping their CUIs to missing items available in the Spanish versions of standard thesauri (e.g. Medical Subject Headings and World Health Organization Adverse Drug Re- actions terminology). We enhanced the vocabulary coverage by gathering missing terms from resources such as the Anatomical Therapeutical Classification, the National Cancer Institute (NCI) Dictionary of Cancer Terms, OrphaData, or the Nomencl{\\'a}tor de Prescripci{\\'o}n for drug names. Part-of-Speech information is being included in the lexicon, and the current version amounts up to 76 454 lemmas and 203 043 inflected forms (including conjugated verbs, number and gender variants), corresponding to 30 647 UMLS CUIs. MedLexSp is distributed freely for research purposes.","pages":"152--164","doi":"10.18653\/v1\/W19-5017","url":"https:\/\/www.aclweb.org\/anthology\/W19-5017","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5018","title":"Incorporating Figure Captions and Descriptive Text in {M}e{SH} Term Indexing","authors":["Wang, Xindi","Mercer, Robert E."],"emails":["xwang842@uwo.ca","mercer@csd.uwo.ca"],"author_id":["xindi-wang","robert-e-mercer"],"abstract":"The goal of text classification is to automatically assign categories to documents. Deep learning automatically learns effective features from data instead of adopting human-designed features. In this paper, we focus specifically on biomedical document classification using a deep learning approach. We present a novel multichannel TextCNN model for MeSH term indexing. Beyond the normal use of the text from the abstract and title for model training, we also consider figure and table captions, as well as paragraphs associated with the figures and tables. We demonstrate that these latter text sources are important feature sources for our method. A new dataset consisting of these text segments curated from 257,590 full text articles together with the articles{'} MEDLINE\/PubMed MeSH terms is publicly available.","pages":"165--175","doi":"10.18653\/v1\/W19-5018","url":"https:\/\/www.aclweb.org\/anthology\/W19-5018","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5019","title":"{B}io{R}el{E}x 1.0: Biological Relation Extraction Benchmark","authors":["Khachatrian, Hrant","Nersisyan, Lilit","Hambardzumyan, Karen","Galstyan, Tigran","Hakobyan, Anna","Arakelyan, Arsen","Rzhetsky, Andrey","Galstyan, Aram"],"emails":["hrant@yerevann.com","","","","","","",""],"author_id":["hrant-khachatrian","lilit-nersisyan","karen-hambardzumyan","tigran-galstyan","anna-hakobyan","arsen-arakelyan","andrey-rzhetsky","aram-galstyan"],"abstract":"Automatic extraction of relations and interactions between biological entities from scientific literature remains an extremely challenging problem in biomedical information extraction and natural language processing in general. One of the reasons for slow progress is the relative scarcity of standardized and publicly available benchmarks. In this paper we introduce BioRelEx, a new dataset of fully annotated sentences from biomedical literature that capture \\textit{binding} interactions between proteins and\/or biomolecules. To foster reproducible research on the interaction extraction task, we define a precise and transparent evaluation process, tools for error analysis and significance tests. Finally, we conduct extensive experiments to evaluate several baselines, including SciIE, a recently introduced neural multi-task architecture that has demonstrated state-of-the-art performance on several tasks.","pages":"176--190","doi":"10.18653\/v1\/W19-5019","url":"https:\/\/www.aclweb.org\/anthology\/W19-5019","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5020","title":"Extraction of Lactation Frames from Drug Labels and {L}act{M}ed","authors":["Goodrum, Heath","Gudala, Meghana","Misra, Ankita","Roberts, Kirk"],"emails":["heath.goodrum@uth.tmc.edu","","","kirk.roberts@uth.tmc.edu"],"author_id":["heath-goodrum","meghana-gudala","ankita-misra","kirk-roberts"],"abstract":"This paper describes a natural language processing (NLP) approach to extracting lactation-specific drug information from two sources: FDA-mandated drug labels and the NLM Drugs and Lactation Database (LactMed). A frame semantic approach is utilized, and the paper describes the selected frames, their annotation on a set of 900 sections from drug labels and LactMed articles, and the NLP system to extract such frame instances automatically. The ultimate goal of the project is to use such a system to identify discrepancies in lactation-related drug information between these resources.","pages":"191--200","doi":"10.18653\/v1\/W19-5020","url":"https:\/\/www.aclweb.org\/anthology\/W19-5020","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5021","title":"Annotating Temporal Information in Clinical Notes for Timeline Reconstruction: Towards the Definition of Calendar Expressions","authors":["Viani, Natalia","Tissot, Hegler","Bernardino, Ariane","Velupillai, Sumithra"],"emails":["","","",""],"author_id":["natalia-viani","hegler-tissot","ariane-bernardino","sumithra-velupillai"],"abstract":"To automatically analyse complex trajectory information enclosed in clinical text (e.g. timing of symptoms, duration of treatment), it is important to understand the related temporal aspects, anchoring each event on an absolute point in time. In the clinical domain, few temporally annotated corpora are currently available. Moreover, underlying annotation schemas - which mainly rely on the TimeML standard - are not necessarily easily applicable for applications such as patient timeline reconstruction. In this work, we investigated how temporal information is documented in clinical text by annotating a corpus of medical reports with time expressions (TIMEXes), based on TimeML. The developed corpus is available to the NLP community. Starting from our annotations, we analysed the suitability of the TimeML TIMEX schema for capturing timeline information, identifying challenges and possible solutions. As a result, we propose a novel annotation schema that could be useful for timeline reconstruction: CALendar EXpression (CALEX).","pages":"201--210","doi":"10.18653\/v1\/W19-5021","url":"https:\/\/www.aclweb.org\/anthology\/W19-5021","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5022","title":"Leveraging Sublanguage Features for the Semantic Categorization of Clinical Terms","authors":["Gr{\\\"o}n, Leonie","Bertels, Ann","Heylen, Kris"],"emails":["","",""],"author_id":["leonie-gron","ann-bertels","kris-heylen"],"abstract":"The automatic processing of clinical documents, such as Electronic Health Records (EHRs), could benefit substantially from the enrichment of medical terminologies with terms encountered in clinical practice. To integrate such terms into existing knowledge sources, they must be linked to corresponding concepts. We present a method for the semantic categorization of clinical terms based on their surface form. We find that features based on sublanguage properties can provide valuable cues for the classification of term variants.","pages":"211--216","doi":"10.18653\/v1\/W19-5022","url":"https:\/\/www.aclweb.org\/anthology\/W19-5022","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5023","title":"Enhancing {PIO} Element Detection in Medical Text Using Contextualized Embedding","authors":["Mezaoui, Hichem","Gunasekara, Isuru","Gontcharov, Aleksandr"],"emails":["hichem@imrsv.ai","isuru@imrsv.ai","aleksandr.gontcharov@imrsv.ai"],"author_id":["hichem-mezaoui","isuru-gunasekara","aleksandr-gontcharov"],"abstract":"In this paper, we presented an improved methodology to extract PIO elements, from abstracts of medical papers, that reduces ambiguity. The proposed technique was used to build a dataset of PIO elements that we call PICONET. We further proposed a model of PIO elements classification using state of the art BERT embedding. In addition, we investigated a contextualized embedding, BioBERT, trained on medical corpora. It has been found that using the BioBERT embedding improved the classification accuracy, outperforming the BERT-based model. This result reinforces the idea of the importance of embedding contextualization in subsequent classification tasks in this specific context.Furthermore, to enhance the accuracy of the model, we have investigated an ensemble method based on the LGBM algorithm. We trained the LGBM model, with the above models as base learners, to learn a linear combination of the predicted probabilities for the 3 classes with the TF-IDF score and the QIEF that optimizes the classification. The results indicate that these text features were good features to consider in order to boost the deeply contextualized classification model. We compared the performance of the classifier when using the features with one of the base learners and the case where we combine the base learners along with the features. We obtained the highest score in terms of AUC when we combine the base learners.The present work resulted in the creation of a PIO element dataset, PICONET, and a classification tool. These constitute and important component of our system of automatic mining of medical abstracts. We intend to extend the dataset to full medical articles. The model will be modified to take into account the higher complexity of full text data and more efficient features for model boosting will be investigated.","pages":"217--222","doi":"10.18653\/v1\/W19-5023","url":"https:\/\/www.aclweb.org\/anthology\/W19-5023","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5024","title":"Contributions to Clinical Named Entity Recognition in {P}ortuguese","authors":["Lopes, F{\\'a}bio","Teixeira, C{\\'e}sar","Gon{\\c{c}}alo Oliveira, Hugo"],"emails":["fadcl@student.dei.uc.pt","cteixei@dei.uc.pt","hroliv@dei.uc.pt"],"author_id":["fabio-lopes","cesar-teixeira","hugo-goncalo-oliveira"],"abstract":"Having in mind that different languages might present different challenges, this paper presents the following contributions to the area of Information Extraction from clinical text, targeting the Portuguese language: a collection of 281 clinical texts in this language, with manually-annotated named entities; word embeddings trained in a larger collection of similar texts; results of using BiLSTM-CRF neural networks for named entity recognition on the annotated collection, including a comparison of using in-domain or out-of-domain word embeddings in this task. Although learned with much less data, performance is higher when using in-domain embeddings. When tested in 20 independent clinical texts, this model achieved better results than a model using larger out-of-domain embeddings.","pages":"223--233","doi":"10.18653\/v1\/W19-5024","url":"https:\/\/www.aclweb.org\/anthology\/W19-5024","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5025","title":"Can Character Embeddings Improve Cause-of-Death Classification for Verbal Autopsy Narratives?","authors":["Yan, Zhaodong","Jeblee, Serena","Hirst, Graeme"],"emails":["zhaodong.yan@mail.utoronto.ca","sjeblee@cs.toronto.edu","gh@cs.toronto.edu"],"author_id":["zhaodong-yan","serena-jeblee","graeme-hirst"],"abstract":"We present two models for combining word and character embeddings for cause-of-death classification of verbal autopsy reports using the text of the narratives. We find that for smaller datasets (500 to 1000 records), adding character information to the model improves classification, making character-based CNNs a promising method for automated verbal autopsy coding.","pages":"234--239","doi":"10.18653\/v1\/W19-5025","url":"https:\/\/www.aclweb.org\/anthology\/W19-5025","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5026","title":"Is artificial data useful for biomedical Natural Language Processing algorithms?","authors":["Wang, Zixu","Ive, Julia","Velupillai, Sumithra","Specia, Lucia"],"emails":["zixu.wang18@imperial.ac.uk","j.ive@sheffield.ac.uk","sumithra.velupillai@kcl.ac.uk","l.specia@imperial.ac.uk"],"author_id":["zixu-wang","julia-ive","sumithra-velupillai","lucia-specia"],"abstract":"A major obstacle to the development of Natural Language Processing (NLP) methods in the biomedical domain is data accessibility. This problem can be addressed by generating medical data artificially. Most previous studies have focused on the generation of short clinical text, and evaluation of the data utility has been limited. We propose a generic methodology to guide the generation of clinical text with key phrases. We use the artificial data as additional training data in two key biomedical NLP tasks: text classification and temporal relation extraction. We show that artificially generated training data used in conjunction with real training data can lead to performance boosts for data-greedy neural network algorithms. We also demonstrate the usefulness of the generated data for NLP setups where it fully replaces real training data.","pages":"240--249","doi":"10.18653\/v1\/W19-5026","url":"https:\/\/www.aclweb.org\/anthology\/W19-5026","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5027","title":"{C}hi{M}ed: A {C}hinese Medical Corpus for Question Answering","authors":["Tian, Yuanhe","Ma, Weicheng","Xia, Fei","Song, Yan"],"emails":["yhtian@uw.edu","wm724@nyu.edu","fxia@uw.edu","clksong@gmail.com"],"author_id":["yuanhe-tian","weicheng-ma","fei-xia","yan-song"],"abstract":"Question answering (QA) is a challenging task in natural language processing (NLP), especially when it is applied to specific domains. While models trained in the general domain can be adapted to a new target domain, their performance often degrades significantly due to domain mismatch. Alternatively, one can require a large amount of domain-specific QA data, but such data are rare, especially for the medical domain. In this study, we first collect a large-scale Chinese medical QA corpus called ChiMed; second we annotate a small fraction of the corpus to check the quality of the answers; third, we extract two datasets from the corpus and use them for the relevancy prediction task and the adoption prediction task. Several benchmark models are applied to the datasets, producing good results for both tasks.","pages":"250--260","doi":"10.18653\/v1\/W19-5027","url":"https:\/\/www.aclweb.org\/anthology\/W19-5027","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5028","title":"Clinical Concept Extraction for Document-Level Coding","authors":["Wiegreffe, Sarah","Choi, Edward","Yan, Sherry","Sun, Jimeng","Eisenstein, Jacob"],"emails":["saw@gatech.edu","edwardchoi@google.com","yansx@sutterhealth.org","jsun@cc.gatech.edu","jacobe@gatech.edu"],"author_id":["sarah-wiegreffe","edward-choi","sherry-yan","jimeng-sun","jacob-eisenstein"],"abstract":"The text of clinical notes can be a valuable source of patient information and clinical assessments. Historically, the primary approach for exploiting clinical notes has been information extraction: linking spans of text to concepts in a detailed domain ontology. However, recent work has demonstrated the potential of supervised machine learning to extract document-level codes directly from the raw text of clinical notes. We propose to bridge the gap between the two approaches with two novel syntheses: (1) treating extracted concepts as features, which are used to supplement or replace the text of the note; (2) treating extracted concepts as labels, which are used to learn a better representation of the text. Unfortunately, the resulting concepts do not yield performance gains on the document-level clinical coding task. We explore possible explanations and future research directions.","pages":"261--272","doi":"10.18653\/v1\/W19-5028","url":"https:\/\/www.aclweb.org\/anthology\/W19-5028","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5029","title":"Clinical Case Reports for {NLP}","authors":["Grouin, Cyril","Grabar, Natalia","Claveau, Vincent","Hamon, Thierry"],"emails":["cyril.grouin@limsi.fr","natalia.grabar@univ-lille.fr","vincent.claveau@irisa.fr","thierry.hamon@limsi.fr"],"author_id":["cyril-grouin","natalia-grabar","vincent-claveau","thierry-hamon"],"abstract":"Textual data are useful for accessing expert information. Yet, since the texts are representative of distinct language uses, it is necessary to build specific corpora in order to be able to design suitable NLP tools. In some domains, such as medical domain, it may be complicated to access the representative textual data and their semantic annotations, while there exists a real need for providing efficient tools and methods. Our paper presents a corpus of clinical cases written in French, and their semantic annotations. Thus, we manually annotated a set of 717 files into four general categories (age, gender, outcome, and origin) for a total number of 2,835 annotations. The values of age, gender, and outcome are normalized. A subset with 70 files has been additionally manually annotated into 27 categories for a total number of 5,198 annotations.","pages":"273--282","doi":"10.18653\/v1\/W19-5029","url":"https:\/\/www.aclweb.org\/anthology\/W19-5029","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5030","title":"Two-stage Federated Phenotyping and Patient Representation Learning","authors":["Liu, Dianbo","Dligach, Dmitriy","Miller, Timothy"],"emails":["ianbo.liu@childrens.harvard.edu","ddligach@luc.edu","iller@childrens.harvard.edu"],"author_id":["dianbo-liu","dmitriy-dligach","timothy-miller"],"abstract":"A large percentage of medical information is in unstructured text format in electronic medical record systems. Manual extraction of information from clinical notes is extremely time consuming. Natural language processing has been widely used in recent years for automatic information extraction from medical texts. However, algorithms trained on data from a single healthcare provider are not generalizable and error-prone due to the heterogeneity and uniqueness of medical documents. We develop a two-stage federated natural language processing method that enables utilization of clinical notes from different hospitals or clinics without moving the data, and demonstrate its performance using obesity and comorbities phenotyping as medical task. This approach not only improves the quality of a specific clinical task but also facilitates knowledge progression in the whole healthcare system, which is an essential part of learning health system. To the best of our knowledge, this is the first application of federated machine learning in clinical NLP.","pages":"283--291","doi":"10.18653\/v1\/W19-5030","url":"https:\/\/www.aclweb.org\/anthology\/W19-5030","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5031","title":"Transfer Learning for Causal Sentence Detection","authors":["Kyriakakis, Manolis","Androutsopoulos, Ion","Saudabayev, Artur","Gin{\\'e}s i Ametll{\\'e}, Joan"],"emails":["m.kyriakakis@causaly.com","ion@aueb.gr","artur@causaly.com","joan.g@causaly.com"],"author_id":["manolis-kyriakakis","ion-androutsopoulos","artur-saudabayev","joan-gines-i-ametlle"],"abstract":"We consider the task of detecting sentences that express causality, as a step towards mining causal relations from texts. To bypass the scarcity of causal instances in relation extraction datasets, we exploit transfer learning, namely ELMO and BERT, using a bidirectional GRU with self-attention ( BIGRUATT ) as a baseline. We experiment with both generic public relation extraction datasets and a new biomedical causal sentence detection dataset, a subset of which we make publicly available. We find that transfer learning helps only in very small datasets. With larger datasets, BIGRUATT reaches a performance plateau, then larger datasets and transfer learning do not help.","pages":"292--297","doi":"10.18653\/v1\/W19-5031","url":"https:\/\/www.aclweb.org\/anthology\/W19-5031","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5032","title":"Embedding Biomedical Ontologies by Jointly Encoding Network Structure and Textual Node Descriptors","authors":["Kotitsas, Sotiris","Pappas, Dimitris","Androutsopoulos, Ion","McDonald, Ryan","Apidianaki, Marianna"],"emails":["p3150077@aueb.gr","pappasd@aueb.gr","ion@aueb.gr","ryanmcd@google.com","marianna@limsi.fr"],"author_id":["sotiris-kotitsas","dimitris-pappas","ion-androutsopoulos","ryan-mcdonald","marianna-apidianaki"],"abstract":"Network Embedding (NE) methods, which map network nodes to low-dimensional feature vectors, have wide applications in network analysis and bioinformatics. Many existing NE methods rely only on network structure, overlooking other information associated with the nodes, e.g., text describing the nodes. Recent attempts to combine the two sources of information only consider local network structure. We extend NODE2VEC, a well-known NE method that considers broader network structure, to also consider textual node descriptors using recurrent neural encoders. Our method is evaluated on link prediction in two networks derived from UMLS. Experimental results demonstrate the effectiveness of the proposed approach compared to previous work.","pages":"298--308","doi":"10.18653\/v1\/W19-5032","url":"https:\/\/www.aclweb.org\/anthology\/W19-5032","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5033","title":"Simplification-induced transformations: typology and some characteristics","authors":["Koptient, Ana{\\\"\\i}s","Cardon, R{\\'e}mi","Grabar, Natalia"],"emails":["ana{\\\"\\i}s.koptient@univ-lille.fr","r{\\'e}mi.cardon@univ-lille.fr","natalia.grabar@univ-lille.fr"],"author_id":["anais-koptient","remi-cardon","natalia-grabar"],"abstract":"The purpose of automatic text simplification is to transform technical or difficult to understand texts into a more friendly version. The semantics must be preserved during this transformation. Automatic text simplification can be done at different levels (lexical, syntactic, semantic, stylistic...) and relies on the corresponding knowledge and resources (lexicon, rules...). Our objective is to propose methods and material for the creation of transformation rules from a small set of parallel sentences differentiated by their technicity. We also propose a typology of transformations and quantify them. We work with French-language data related to the medical domain, although we assume that the method can be exploited on texts in any language and from any domain.","pages":"309--318","doi":"10.18653\/v1\/W19-5033","url":"https:\/\/www.aclweb.org\/anthology\/W19-5033","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5034","title":"{S}cispa{C}y: Fast and Robust Models for Biomedical Natural Language Processing","authors":["Neumann, Mark","King, Daniel","Beltagy, Iz","Ammar, Waleed"],"emails":["markn@allenai.org","daniel@allenai.org","beltagy@allenai.org","waleeda@allenai.org"],"author_id":["mark-neumann","daniel-king","iz-beltagy","waleed-ammar"],"abstract":"Despite recent advances in natural language processing, many statistical models for processing text perform extremely poorly under domain shift. Processing biomedical and clinical text is a critically important application area of natural language processing, for which there are few robust, practical, publicly available models. This paper describes scispaCy, a new Python library and models for practical biomedical\/scientific text processing, which heavily leverages the spaCy library. We detail the performance of two packages of models released in scispaCy and demonstrate their robustness on several tasks and datasets. Models and code are available at https:\/\/allenai.github.io\/scispacy\/.","pages":"319--327","doi":"10.18653\/v1\/W19-5034","url":"https:\/\/www.aclweb.org\/anthology\/W19-5034","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5035","title":"Improving Chemical Named Entity Recognition in Patents with Contextualized Word Embeddings","authors":["Zhai, Zenan","Nguyen, Dat Quoc","Akhondi, Saber","Thorne, Camilo","Druckenbrodt, Christian","Cohn, Trevor","Gregory, Michelle","Verspoor, Karin"],"emails":["zenan.zhai@unimelb.edu.au","dqnguyen@unimelb.edu.au","s.akhondi@elsevier.com","c.thorne.1@elsevier.com","c.druckenbrodt@elsevier.com","trevor.cohn@unimelb.edu.au","m.gregory@elsevier.com","karin.verspoor@unimelb.edu.au"],"author_id":["zenan-zhai","dat-quoc-nguyen","saber-akhondi","camilo-thorne","christian-druckenbrodt","trevor-cohn","michelle-gregory","karin-verspoor"],"abstract":"Chemical patents are an important resource for chemical information. However, few chemical Named Entity Recognition (NER) systems have been evaluated on patent documents, due in part to their structural and linguistic complexity. In this paper, we explore the NER performance of a BiLSTM-CRF model utilising pre-trained word embeddings, character-level word representations and contextualized ELMo word representations for chemical patents. We compare word embeddings pre-trained on biomedical and chemical patent corpora. The effect of tokenizers optimized for the chemical domain on NER performance in chemical patents is also explored. The results on two patent corpora show that contextualized word representations generated from ELMo substantially improve chemical NER performance w.r.t. the current state-of-the-art. We also show that domain-specific resources such as word embeddings trained on chemical patents and chemical-specific tokenizers, have a positive impact on NER performance.","pages":"328--338","doi":"10.18653\/v1\/W19-5035","url":"https:\/\/www.aclweb.org\/anthology\/W19-5035","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5036","title":"Improving classification of Adverse Drug Reactions through Using Sentiment Analysis and Transfer Learning","authors":["Alhuzali, Hassan","Ananiadou, Sophia"],"emails":["hassan.alhuzali@manchester.ac.uk","sophia.ananiadou@manchester.ac.uk"],"author_id":["hassan-alhuzali","sophia-ananiadou"],"abstract":"The availability of large-scale and real-time data on social media has motivated research into adverse drug reactions (ADRs). ADR classification helps to identify negative effects of drugs, which can guide health professionals and pharmaceutical companies in making medications safer and advocating patients{'} safety. Based on the observation that in social media, negative sentiment is frequently expressed towards ADRs, this study presents a neural model that combines sentiment analysis with transfer learning techniques to improve ADR detection in social media postings. Our system is firstly trained to classify sentiment in tweets concerning current affairs, using the SemEval17-task4A corpus. We then apply transfer learning to adapt the model to the task of detecting ADRs in social media postings. We show that, in combination with rich representations of words and their contexts, transfer learning is beneficial, especially given the large degree of vocabulary overlap between the current affairs posts in the SemEval17-task4A corpus and posts about ADRs. We compare our results with previous approaches, and show that our model can outperform them by up to 3{\\%} F-score.","pages":"339--347","doi":"10.18653\/v1\/W19-5036","url":"https:\/\/www.aclweb.org\/anthology\/W19-5036","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5037","title":"Exploring Diachronic Changes of Biomedical Knowledge using Distributed Concept Representations","authors":["Vashisth, Gaurav","Voigt-Antons, Jan-Niklas","Mikhailov, Michael","Roller, Roland"],"emails":["gaurav.vashisth@dfki.de","jan-niklas.voigt-antons@dfki.de","michael.mikhailov@dfki.de","roland.roller@dfki.de"],"author_id":["gaurav-vashisth","jan-niklas-voigt-antons","michael-mikhailov","roland-roller"],"abstract":"In research best practices can change over time as new discoveries are made and novel methods are implemented. Scientific publications reporting about the latest facts and current state-of-the-art can be possibly outdated after some years or even proved to be false. A publication usually sheds light only on the knowledge of the period it has been published. Thus, the aspect of time can play an essential role in the reliability of the presented information. In Natural Language Processing many methods focus on information extraction from text, such as detecting entities and their relationship to each other. Those methods mostly focus on the facts presented in the text itself and not on the aspects of knowledge which changes over time. This work instead examines the evolution in biomedical knowledge over time using scientific literature in terms of diachronic change. Mainly the usage of temporal and distributional concept representations are explored and evaluated by a proof-of-concept.","pages":"348--358","doi":"10.18653\/v1\/W19-5037","url":"https:\/\/www.aclweb.org\/anthology\/W19-5037","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5038","title":"Extracting relations between outcomes and significance levels in Randomized Controlled Trials ({RCT}s) publications","authors":["Koroleva, Anna","Paroubek, Patrick"],"emails":["koroleva@limsi.fr","pap@limsi.fr"],"author_id":["anna-koroleva","patrick-paroubek"],"abstract":"Randomized controlled trials assess the effects of an experimental intervention by comparing it to a control intervention with regard to some variables - trial outcomes. Statistical hypothesis testing is used to test if the experimental intervention is superior to the control. Statistical significance is typically reported for the measured outcomes and is an important characteristic of the results. We propose a machine learning approach to automatically extract reported outcomes, significance levels and the relation between them. We annotated a corpus of 663 sentences with 2,552 outcome - significance level relations (1,372 positive and 1,180 negative relations). We compared several classifiers, using a manually crafted feature set, and a number of deep learning models. The best performance (F-measure of 94{\\%}) was shown by the BioBERT fine-tuned model.","pages":"359--369","doi":"10.18653\/v1\/W19-5038","url":"https:\/\/www.aclweb.org\/anthology\/W19-5038","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5039","title":"Overview of the {MEDIQA} 2019 Shared Task on Textual Inference, Question Entailment and Question Answering","authors":["Ben Abacha, Asma","Shivade, Chaitanya","Demner-Fushman, Dina"],"emails":["asma.benabacha@nih.gov","cshivade@us.ibm.com","ddemner@mail.nih.gov"],"author_id":["asma-ben-abacha1","chaitanya-shivade","dina-demner-fushman"],"abstract":"This paper presents the MEDIQA 2019 shared task organized at the ACL-BioNLP work- shop. The shared task is motivated by a need to develop relevant methods, techniques and gold standards for inference and entail- ment in the medical domain, and their ap- plication to improve domain specific infor- mation retrieval and question answering sys- tems. MEDIQA 2019 includes three tasks: Natural Language Inference (NLI), Recogniz- ing Question Entailment (RQE), and Question Answering (QA) in the medical domain. 72 teams participated in the challenge, achieving an accuracy of 98{\\%} in the NLI task, 74.9{\\%} in the RQE task, and 78.3{\\%} in the QA task. In this paper, we describe the tasks, the datasets, and the participants{'} approaches and results. We hope that this shared task will attract fur- ther research efforts in textual inference, ques- tion entailment, and question answering in the medical domain.","pages":"370--379","doi":"10.18653\/v1\/W19-5039","url":"https:\/\/www.aclweb.org\/anthology\/W19-5039","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5040","title":"{PANLP} at {MEDIQA} 2019: Pre-trained Language Models, Transfer Learning and Knowledge Distillation","authors":["Zhu, Wei","Zhou, Xiaofeng","Wang, Keqiang","Luo, Xun","Li, Xiepeng","Ni, Yuan","Xie, Guotong"],"emails":["zhuwei972@pingan.com.cn","zhouxiaofeng824@pingan.com.cn","wangkeqiang265@pingan.com.cn","luoxun492@pingan.com.cn","lixiepeng538@pingan.com.cn","niyuan442@pingan.com.cn","xieguotong@pingan.com.cn"],"author_id":["wei-zhu","xiaofeng-zhou","keqiang-wang","xun-luo","xiepeng-li","yuan-ni","guotong-xie"],"abstract":"This paper describes the models designated for the MEDIQA 2019 shared tasks by the team PANLP. We take advantages of the recent advances in pre-trained bidirectional transformer language models such as BERT (Devlin et al., 2018) and MT-DNN (Liu et al., 2019b). We find that pre-trained language models can significantly outperform traditional deep learning models. Transfer learning from the NLI task to the RQE task is also experimented, which proves to be useful in improving the results of fine-tuning MT-DNN large. A knowledge distillation process is implemented, to distill the knowledge contained in a set of models and transfer it into an single model, whose performance turns out to be comparable with that obtained by the ensemble of that set of models. Finally, for test submissions, model ensemble and a re-ranking process are implemented to boost the performances. Our models participated in all three tasks and ranked the 1st place for the RQE task, and the 2nd place for the NLI task, and also the 2nd place for the QA task.","pages":"380--388","doi":"10.18653\/v1\/W19-5040","url":"https:\/\/www.aclweb.org\/anthology\/W19-5040","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5041","title":"Pentagon at {MEDIQA} 2019: Multi-task Learning for Filtering and Re-ranking Answers using Language Inference and Question Entailment","authors":["Pugaliya, Hemant","Saxena, Karan","Garg, Shefali","Shalini, Sheetal","Gupta, Prashant","Nyberg, Eric","Mitamura, Teruko"],"emails":["hpugaliy@cs.cmu.edu","karansax@cs.cmu.edu","shefalig@cs.cmu.edu","sshalini@cs.cmu.edu","prashang@cs.cmu.edu","ehn@cs.cmu.edu","teruko@cs.cmu.edu"],"author_id":["hemant-pugaliya","karan-saxena","shefali-garg","sheetal-shalini","prashant-gupta","eric-nyberg","teruko-mitamura"],"abstract":"Parallel deep learning architectures like fine-tuned BERT and MT-DNN, have quickly become the state of the art, bypassing previous deep and shallow learning methods by a large margin. More recently, pre-trained models from large related datasets have been able to perform well on many downstream tasks by just fine-tuning on domain-specific datasets (similar to transfer learning). However, using powerful models on non-trivial tasks, such as ranking and large document classification, still remains a challenge due to input size limitations of parallel architecture and extremely small datasets (insufficient for fine-tuning). In this work, we introduce an end-to-end system, trained in a multi-task setting, to filter and re-rank answers in the medical domain. We use task-specific pre-trained models as deep feature extractors. Our model achieves the highest Spearman{'}s Rho and Mean Reciprocal Rank of 0.338 and 0.9622 respectively, on the ACL-BioNLP workshop MediQA Question Answering shared-task.","pages":"389--398","doi":"10.18653\/v1\/W19-5041","url":"https:\/\/www.aclweb.org\/anthology\/W19-5041","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5042","title":"{D}ouble{T}ransfer at {MEDIQA} 2019: Multi-Source Transfer Learning for Natural Language Understanding in the Medical Domain","authors":["Xu, Yichong","Liu, Xiaodong","Li, Chunyuan","Poon, Hoifung","Gao, Jianfeng"],"emails":["yichongx@cs.cmu.edu","i@microsoft.com","","hoifung@microsoft.com","jfgao@microsoft.com"],"author_id":["yichong-xu","xiaodong-liu","chunyuan-li","hoifung-poon","jianfeng-gao"],"abstract":"This paper describes our competing system to enter the MEDIQA-2019 competition. We use a multi-source transfer learning approach to transfer the knowledge from MT-DNN and SciBERT to natural language understanding tasks in the medical domain. For transfer learning fine-tuning, we use multi-task learning on NLI, RQE and QA tasks on general and medical domains to improve performance. The proposed methods are proved effective for natural language understanding in the medical domain, and we rank the first place on the QA task.","pages":"399--405","doi":"10.18653\/v1\/W19-5042","url":"https:\/\/www.aclweb.org\/anthology\/W19-5042","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5043","title":"Surf at {MEDIQA} 2019: Improving Performance of Natural Language Inference in the Clinical Domain by Adopting Pre-trained Language Model","authors":["Nam, Jiin","Yoon, Seunghyun","Jung, Kyomin"],"emails":["jiin.nam@samsung.com","mysmilesh@snu.ac.kr","kjung@snu.ac.kr"],"author_id":["jiin-nam","seunghyun-yoon","kyomin-jung"],"abstract":"While deep learning techniques have shown promising results in many natural language processing (NLP) tasks, it has not been widely applied to the clinical domain. The lack of large datasets and the pervasive use of domain-specific language (i.e. abbreviations and acronyms) in the clinical domain causes slower progress in NLP tasks than that of the general NLP tasks. To fill this gap, we employ word\/subword-level based models that adopt large-scale data-driven methods such as pre-trained language models and transfer learning in analyzing text for the clinical domain. Empirical results demonstrate the superiority of the proposed methods by achieving 90.6{\\%} accuracy in medical domain natural language inference task. Furthermore, we inspect the independent strengths of the proposed approaches in quantitative and qualitative manners. This analysis will help researchers to select necessary components in building models for the medical domain.","pages":"406--414","doi":"10.18653\/v1\/W19-5043","url":"https:\/\/www.aclweb.org\/anthology\/W19-5043","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5044","title":"{WTMED} at {MEDIQA} 2019: A Hybrid Approach to Biomedical Natural Language Inference","authors":["Wu, Zhaofeng","Song, Yan","Huang, Sicong","Tian, Yuanhe","Xia, Fei"],"emails":["zfw7@cs.washington.edu","clksong@gmail.com","huangs33@uw.edu","yhtian@uw.edu","fxia@uw.edu"],"author_id":["zhaofeng-wu","yan-song","sicong-huang","yuanhe-tian","fei-xia"],"abstract":"Natural language inference (NLI) is challenging, especially when it is applied to technical domains such as biomedical settings. In this paper, we propose a hybrid approach to biomedical NLI where different types of information are exploited for this task. Our base model includes a pre-trained text encoder as the core component, and a syntax encoder and a feature encoder to capture syntactic and domain-specific information. Then we combine the output of different base models to form more powerful ensemble models. Finally, we design two conflict resolution strategies when the test data contain multiple (premise, hypothesis) pairs with the same premise. We train our models on the MedNLI dataset, yielding the best performance on the test set of the MEDIQA 2019 Task 1.","pages":"415--426","doi":"10.18653\/v1\/W19-5044","url":"https:\/\/www.aclweb.org\/anthology\/W19-5044","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5045","title":"{KU}{\\_}ai at {MEDIQA} 2019: Domain-specific Pre-training and Transfer Learning for Medical {NLI}","authors":["Cengiz, Cemil","Sert, Ula{\\c{s}}","Yuret, Deniz"],"emails":["ccengiz17@ku.edu.tr","usert17@ku.edu.tr","dyuret@ku.edu.tr"],"author_id":["cemil-cengiz","ulas-sert","deniz-yuret"],"abstract":"In this paper, we describe our system and results submitted for the Natural Language Inference (NLI) track of the MEDIQA 2019 Shared Task. As KU{\\_}ai team, we used BERT as our baseline model and pre-processed the MedNLI dataset to mitigate the negative impact of de-identification artifacts. Moreover, we investigated different pre-training and transfer learning approaches to improve the performance. We show that pre-training the language model on rich biomedical corpora has a significant effect in teaching the model domain-specific language. In addition, training the model on large NLI datasets such as MultiNLI and SNLI helps in learning task-specific reasoning. Finally, we ensembled our highest-performing models, and achieved 84.7{\\%} accuracy on the unseen test dataset and ranked 10th out of 17 teams in the official results.","pages":"427--436","doi":"10.18653\/v1\/W19-5045","url":"https:\/\/www.aclweb.org\/anthology\/W19-5045","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5046","title":"{DUT}-{NLP} at {MEDIQA} 2019: An Adversarial Multi-Task Network to Jointly Model Recognizing Question Entailment and Question Answering","authors":["Zhou, Huiwei","Li, Xuefei","Yao, Weihong","Lang, Chengkun","Ning, Shixian"],"emails":["","","","",""],"author_id":["huiwei-zhou","xuefei-li","weihong-yao","chengkun-lang","shixian-ning"],"abstract":"In this paper, we propose a novel model called Adversarial Multi-Task Network (AMTN) for jointly modeling Recognizing Question Entailment (RQE) and medical Question Answering (QA) tasks. AMTN utilizes a pre-trained BioBERT model and an Interactive Transformer to learn the shared semantic representations across different task through parameter sharing mechanism. Meanwhile, an adversarial training strategy is introduced to separate the private features of each task from the shared representations. Experiments on BioNLP 2019 RQE and QA Shared Task datasets show that our model benefits from the shared representations of both tasks provided by multi-task learning and adversarial training, and obtains significant improvements upon the single-task models.","pages":"437--445","doi":"10.18653\/v1\/W19-5046","url":"https:\/\/www.aclweb.org\/anthology\/W19-5046","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5047","title":"{DUT}-{BIM} at {MEDIQA} 2019: Utilizing Transformer Network and Medical Domain-Specific Contextualized Representations for Question Answering","authors":["Zhou, Huiwei","Lei, Bizun","Liu, Zhe","Liu, Zhuang"],"emails":["","","",""],"author_id":["huiwei-zhou","bizun-lei","zhe-liu","zhuang-liu"],"abstract":"In medical domain, given a medical question, it is difficult to manually select the most relevant information from a large number of search results. BioNLP 2019 proposes Question Answering (QA) task, which encourages the use of text mining technology to automatically judge whether a search result is an answer to the medical question. The main challenge of QA task is how to mine the semantic relation between question and answer. We propose BioBERT Transformer model to tackle this challenge, which applies Transformers to extract semantic relation between different words in questions and answers. Furthermore, BioBERT is utilized to encode medical domain-specific contextualized word representations. Our method has reached the accuracy of 76.24{\\%} and spearman of 17.12{\\%} on the BioNLP 2019 QA task.","pages":"446--452","doi":"10.18653\/v1\/W19-5047","url":"https:\/\/www.aclweb.org\/anthology\/W19-5047","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5048","title":"{D}r.{Q}uad at {MEDIQA} 2019: Towards Textual Inference and Question Entailment using contextualized representations","authors":["Bannihatti Kumar, Vinayshekhar","Srinivasan, Ashwin","Chaudhary, Aditi","Route, James","Mitamura, Teruko","Nyberg, Eric"],"emails":["vbkumar@cs.cmu.edu","ashwinsr@cs.cmu.edu","aschaudh@cs.cmu.edu","jroute@cs.cmu.edu","teruko@cs.cmu.edu","ehn@cs.cmu.edu"],"author_id":["vinayshekhar-bannihatti-kumar","ashwin-srinivasan","aditi-chaudhary","james-route","teruko-mitamura","eric-nyberg"],"abstract":"This paper presents the submissions by TeamDr.Quad to the ACL-BioNLP 2019 shared task on Textual Inference and Question Entailment in the Medical Domain. Our system is based on the prior work Liu et al. (2019) which uses a multi-task objective function for textual entailment. In this work, we explore different strategies for generalizing state-of-the-art language understanding models to the specialized medical domain. Our results on the shared task demonstrate that incorporating domain knowledge through data augmentation is a powerful strategy for addressing challenges posed specialized domains such as medicine.","pages":"453--461","doi":"10.18653\/v1\/W19-5048","url":"https:\/\/www.aclweb.org\/anthology\/W19-5048","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5049","title":"Sieg at {MEDIQA} 2019: Multi-task Neural Ensemble for Biomedical Inference and Entailment","authors":["Bhaskar, Sai Abishek","Rungta, Rashi","Route, James","Nyberg, Eric","Mitamura, Teruko"],"emails":["sabhaska@cs.cmu.edu","rashir@cs.cmu.edu","jroute@cs.cmu.edu","ehn@cs.cmu.edu","teruko@cs.cmu.edu"],"author_id":["sai-abishek-bhaskar","rashi-rungta","james-route","eric-nyberg","teruko-mitamura"],"abstract":"This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain. Recognizing textual inference relations and question similarity can address the issue of answering new consumer health questions by mapping them to Frequently Asked Questions on reputed websites like the NIH. We show that leveraging information from parallel tasks across domains along with medical knowledge integration allows our model to learn better biomedical feature representations. Our final models for the NLI and RQE tasks achieve the 4th and 2nd rank on the shared-task leaderboard respectively.","pages":"462--470","doi":"10.18653\/v1\/W19-5049","url":"https:\/\/www.aclweb.org\/anthology\/W19-5049","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5050","title":"{IIT}-{KGP} at {MEDIQA} 2019: Recognizing Question Entailment using Sci-{BERT} stacked with a Gradient Boosting Classifier","authors":["Sharma, Prakhar","Roychowdhury, Sumegh"],"emails":["prakharsharma@iitkgp.ac.in","sumegh01@iitkgp.ac.in"],"author_id":["prakhar-sharma","sumegh-roychowdhury"],"abstract":"Official System Description paper of Team IIT-KGP ranked 1st in the Development phase and 3rd in Testing Phase in MEDIQA 2019 - Recognizing Question Entailment (RQE) Shared Task of BioNLP workshop - ACL 2019. The number of people turning to the Internet to search for a diverse range of health-related subjects continues to grow and with this multitude of information available, duplicate questions are becoming more frequent and finding the most appropriate answers becomes problematic. This issue is important for question answering platforms as it complicates the retrieval of all information relevant to the same topic, particularly when questions similar in essence are expressed differently, and answering a given medical question by retrieving similar questions that are already answered by human experts seems to be a promising solution. In this paper, we present our novel approach to detect question entailment by determining the type of question asked rather than focusing on the type of the ailment given. This unique methodology makes the approach robust towards examples which have different ailment names but are synonyms of each other. Also, it enables us to check entailment at a much more fine-grained level. QSpider is a staged system consisting of state-of-the-art model Sci-BERT used as a multi-class classifier aimed at capturing both question types and semantic relations stacked with a Gradient Boosting Classifier which checks for entailment. QSpider achieves an accuracy score of 68.4{\\%} on the Test set which outperforms the baseline model (54.1{\\%}) by an accuracy score of 14.3{\\%}.","pages":"471--477","doi":"10.18653\/v1\/W19-5050","url":"https:\/\/www.aclweb.org\/anthology\/W19-5050","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5051","title":"{ANU}-{CSIRO} at {MEDIQA} 2019: Question Answering Using Deep Contextual Knowledge","authors":["Nguyen, Vincent","Karimi, Sarvnaz","Xing, Zhenchang"],"emails":["vincent.nguyen@anu.edu.au","sarvnaz.karimi@csiro.au","zhenchang.xing@anu.edu.au"],"author_id":["vincent-nguyen","sarvnaz-karimi","zhenchang-xing"],"abstract":"We report on our system for textual inference and question entailment in the medical domain for the ACL BioNLP 2019 Shared Task, MEDIQA. Textual inference is the task of finding the semantic relationships between pairs of text. Question entailment involves identifying pairs of questions which have similar semantic content. To improve upon medical natural language inference and question entailment approaches to further medical question answering, we propose a system that incorporates open-domain and biomedical domain approaches to improve semantic understanding and ambiguity resolution. Our models achieve 80{\\%} accuracy on medical natural language inference (6.5{\\%} absolute improvement over the original baseline), 48.9{\\%} accuracy on recognising medical question entailment, 0.248 Spearman{'}s rho for question answering ranking and 68.6{\\%} accuracy for question answering classification.","pages":"478--487","doi":"10.18653\/v1\/W19-5051","url":"https:\/\/www.aclweb.org\/anthology\/W19-5051","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5052","title":"{MSIT}{\\_}{SRIB} at {MEDIQA} 2019: Knowledge Directed Multi-task Framework for Natural Language Inference in Clinical Domain.","authors":["Chopra, Sahil","Gupta, Ankita","Kaushik, Anupama"],"emails":["sahilchopra@msit.in","gupta.ankita@samsung.com","anupama@msit.in"],"author_id":["sahil-chopra","ankita-gupta","anupama-kaushik"],"abstract":"In this paper, we present Biomedical Multi-Task Deep Neural Network (Bio-MTDNN) on the NLI task of MediQA 2019 challenge. Bio-MTDNN utilizes {``}transfer learning{''} based paradigm where not only the source and target domains are different but also the source and target tasks are varied, although related. Further, Bio-MTDNN integrates knowledge from external sources such as clinical databases (UMLS) enhancing its performance on the clinical domain. Our proposed method outperformed the official baseline and other prior models (such as ESIM and Infersent on dev set) by a considerable margin as evident from our experimental results.","pages":"488--492","doi":"10.18653\/v1\/W19-5052","url":"https:\/\/www.aclweb.org\/anthology\/W19-5052","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5053","title":"{UU}{\\_}{TAILS} at {MEDIQA} 2019: Learning Textual Entailment in the Medical Domain","authors":["Tawfik, Noha","Spruit, Marco"],"emails":["noha.abdelsalam@aast.edu","m.r.spruit@uu.nl"],"author_id":["noha-tawfik","marco-spruit"],"abstract":"This article describes the participation of the UU{\\_}TAILS team in the 2019 MEDIQA challenge intended to improve domain-specific models in medical and clinical NLP. The challenge consists of 3 tasks: medical language inference (NLI), recognizing textual entailment (RQE) and question answering (QA). Our team participated in tasks 1 and 2 and our best runs achieved a performance accuracy of 0.852 and 0.584 respectively for the test sets. The models proposed for task 1 relied on BERT embeddings and different ensemble techniques. For the RQE task, we trained a traditional multilayer perceptron network based on embeddings generated by the universal sentence encoder.","pages":"493--499","doi":"10.18653\/v1\/W19-5053","url":"https:\/\/www.aclweb.org\/anthology\/W19-5053","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5054","title":"{UW}-{BHI} at {MEDIQA} 2019: An Analysis of Representation Methods for Medical Natural Language Inference","authors":["Kearns, William","Lau, Wilson","Thomas, Jason"],"emails":["kearnsw@uw.edu","wlau@uw.edu","thomasjt@uw.edu"],"author_id":["william-kearns","wilson-lau","jason-thomas"],"abstract":"Recent advances in distributed language modeling have led to large performance increases on a variety of natural language processing (NLP) tasks. However, it is not well understood how these methods may be augmented by knowledge-based approaches. This paper compares the performance and internal representation of an Enhanced Sequential Inference Model (ESIM) between three experimental conditions based on the representation method: Bidirectional Encoder Representations from Transformers (BERT), Embeddings of Semantic Predications (ESP), or Cui2Vec. The methods were evaluated on the Medical Natural Language Inference (MedNLI) subtask of the MEDIQA 2019 shared task. This task relied heavily on semantic understanding and thus served as a suitable evaluation set for the comparison of these representation methods.","pages":"500--509","doi":"10.18653\/v1\/W19-5054","url":"https:\/\/www.aclweb.org\/anthology\/W19-5054","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5055","title":"Saama Research at {MEDIQA} 2019: Pre-trained {B}io{BERT} with Attention Visualisation for Medical Natural Language Inference","authors":["Kanakarajan, Kamal raj","Ramamoorthy, Suriyadeepan","Archana, Vaidheeswaran","Chatterjee, Soham","Sankarasubbu, Malaikannan"],"emails":["kamal.raj@saama.com","suriyadeepan.ramamoorthy@saama.com","archana.iyer@saama.com","soham.chatterjee@saama.com","malaikannan.sankarasubbu@saama.com"],"author_id":["kamal-raj-kanakarajan","suriyadeepan-ramamoorthy","vaidheeswaran-archana","soham-chatterjee","malaikannan-sankarasubbu"],"abstract":"Natural Language inference is the task of identifying relation between two sentences as entailment, contradiction or neutrality. MedNLI is a biomedical flavour of NLI for clinical domain. This paper explores the use of Bidirectional Encoder Representation from Transformer (BERT) for solving MedNLI. The proposed model, BERT pre-trained on PMC, PubMed and fine-tuned on MIMICIII v1.4, achieves state of the art results on MedNLI (83.45{\\%}) and an accuracy of 78.5{\\%} in MEDIQA challenge. The authors present an analysis of the attention patterns that emerged as a result of training BERT on MedNLI using a visualization tool, bertviz.","pages":"510--516","doi":"10.18653\/v1\/W19-5055","url":"https:\/\/www.aclweb.org\/anthology\/W19-5055","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5056","title":"{IITP} at {MEDIQA} 2019: Systems Report for Natural Language Inference, Question Entailment and Question Answering","authors":["Bandyopadhyay, Dibyanayan","Gain, Baban","Saikh, Tanik","Ekbal, Asif"],"emails":["dibyanayan@gmail.com","gainbaban@gmail.com","1821cs08@iitp.ac.in","asif@iitp.ac.in"],"author_id":["dibyanayan-bandyopadhyay","baban-gain","tanik-saikh","asif-ekbal"],"abstract":"This paper presents the experiments accomplished as a part of our participation in the MEDIQA challenge, an (Abacha et al., 2019) shared task. We participated in all the three tasks defined in this particular shared task. The tasks are viz. i. Natural Language Inference (NLI) ii. Recognizing Question Entailment(RQE) and their application in medical Question Answering (QA). We submitted runs using multiple deep learning based systems (runs) for each of these three tasks. We submitted five system results in each of the NLI and RQE tasks, and four system results for the QA task. The systems yield encouraging results in all the three tasks. The highest performance obtained in NLI, RQE and QA tasks are 81.8{\\%}, 53.2{\\%}, and 71.7{\\%}, respectively.","pages":"517--522","doi":"10.18653\/v1\/W19-5056","url":"https:\/\/www.aclweb.org\/anthology\/W19-5056","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5057","title":"{L}asige{B}io{TM} at {MEDIQA} 2019: Biomedical Question Answering using Bidirectional Transformers and Named Entity Recognition","authors":["Lamurias, Andre","Couto, Francisco M"],"emails":["",""],"author_id":["andre-lamurias","francisco-m-couto1"],"abstract":"Biomedical Question Answering (QA) aims at providing automated answers to user questions, regarding a variety of biomedical topics. For example, these questions may ask for related to diseases, drugs, symptoms, or medical procedures. Automated biomedical QA systems could improve the retrieval of information necessary to answer these questions. The MEDIQA challenge consisted of three tasks concerning various aspects of biomedical QA. This challenge aimed at advancing approaches to Natural Language Inference (NLI) and Recognizing Question Entailment (RQE), which would then result in enhanced approaches to biomedical QA. Our approach explored a common Transformer-based architecture that could be applied to each task. This approach shared the same pre-trained weights, but which were then fine-tuned for each task using the provided training data. Furthermore, we augmented the training data with external datasets and enriched the question and answer texts using MER, a named entity recognition tool. Our approach obtained high levels of accuracy, in particular on the NLI task, which classified pairs of text according to their relation. For the QA task, we obtained higher Spearman{'}s rank correlation values using the entities recognized by MER.","pages":"523--527","doi":"10.18653\/v1\/W19-5057","url":"https:\/\/www.aclweb.org\/anthology\/W19-5057","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5058","title":"{NCUEE} at {MEDIQA} 2019: Medical Text Inference Using Ensemble {BERT}-{B}i{LSTM}-Attention Model","authors":["Lee, Lung-Hao","Lu, Yi","Chen, Po-Han","Lee, Po-Lei","Shyu, Kuo-Kai"],"emails":["","","","",""],"author_id":["lung-hao-lee","yi-lu","po-han-chen","po-lei-lee","kuo-kai-shyu"],"abstract":"This study describes the model design of the NCUEE system for the MEDIQA challenge at the ACL-BioNLP 2019 workshop. We use the BERT (Bidirectional Encoder Representations from Transformers) as the word embedding method to integrate the BiLSTM (Bidirectional Long Short-Term Memory) network with an attention mechanism for medical text inferences. A total of 42 teams participated in natural language inference task at MEDIQA 2019. Our best accuracy score of 0.84 ranked the top-third among all submissions in the leaderboard.","pages":"528--532","doi":"10.18653\/v1\/W19-5058","url":"https:\/\/www.aclweb.org\/anthology\/W19-5058","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"},{"id":"W19-5059","title":"{ARS}{\\_}{NITK} at {MEDIQA} 2019:Analysing Various Methods for Natural Language Inference, Recognising Question Entailment and Medical Question Answering System","authors":["Agrawal, Anumeha","Anil George, Rosa","Ravi, Selvan Suntiha","Kamath, Sowmya","Kumar, Anand"],"emails":["anumehaagrawal29@gmail.com","rosageorge97@gmail.com","","sunitha98selvan@gmail.com","anandkumar@nitk.edu.in"],"author_id":["anumeha-agrawal","rosa-anil-george","selvan-suntiha-ravi","sowmya-kamath","anand-kumar"],"abstract":"In this paper, we present three approaches for Natural Language Inference, Question Entailment Recognition and Question-Answering to improve domain-specific Information Retrieval. For addressing the NLI task, the UMLS Metathesaurus was used to find the synonyms of medical terms in given sentences, on which the InferSent model was trained to predict if the given sentence is an entailment, contradictory or neutral. We also introduce a new Extreme gradient boosting model built on PubMed embeddings to perform RQE. Further, a closed-domain Question Answering technique that uses Bi-directional LSTMs trained on the SquAD dataset to determine relevant ranks of answers for a given question is also discussed.","pages":"533--540","doi":"10.18653\/v1\/W19-5059","url":"https:\/\/www.aclweb.org\/anthology\/W19-5059","publisher":"Association for Computational Linguistics","address":"Florence, Italy","year":"2019","month":"August","booktitle":"Proceedings of the 18th BioNLP Workshop and Shared Task"}]