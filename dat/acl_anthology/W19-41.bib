@proceedings{ws-2019-nlp-conversational,
    title = "Proceedings of the First Workshop on NLP for Conversational AI",
    author = "Chen, Yun-Nung  and
      Bedrax-Weiss, Tania  and
      Hakkani-Tur, Dilek  and
      Kumar, Anuj  and
      Lewis, Mike  and
      Luong, Thang-Minh  and
      Su, Pei-Hao  and
      Wen, Tsung-Hsien",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4100",
}
@inproceedings{henderson-etal-2019-repository,
    title = "A Repository of Conversational Datasets",
    author = "Henderson, Matthew  and
      Budzianowski, Pawe{\l}  and
      Casanueva, I{\~n}igo  and
      Coope, Sam  and
      Gerz, Daniela  and
      Kumar, Girish  and
      Mrk{\v{s}}i{\'c}, Nikola  and
      Spithourakis, Georgios  and
      Su, Pei-Hao  and
      Vuli{\'c}, Ivan  and
      Wen, Tsung-Hsien",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4101",
    doi = "10.18653/v1/W19-4101",
    pages = "1--10",
    abstract = "Progress in Machine Learning is often driven by the availability of large datasets, and consistent evaluation metrics for comparing modeling approaches. To this end, we present a repository of conversational datasets consisting of hundreds of millions of examples, and a standardised evaluation procedure for conversational response selection models using 1-of-100 accuracy. The repository contains scripts that allow researchers to reproduce the standard datasets, or to adapt the pre-processing and data filtering steps to their needs. We introduce and evaluate several competitive baselines for conversational response selection, whose implementations are shared in the repository, as well as a neural encoder model that is trained on the entire training set.",
}
@inproceedings{ohsugi-etal-2019-simple,
    title = "A Simple but Effective Method to Incorporate Multi-turn Context with {BERT} for Conversational Machine Comprehension",
    author = "Ohsugi, Yasuhito  and
      Saito, Itsumi  and
      Nishida, Kyosuke  and
      Asano, Hisako  and
      Tomita, Junji",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4102",
    doi = "10.18653/v1/W19-4102",
    pages = "11--17",
    abstract = "Conversational machine comprehension (CMC) requires understanding the context of multi-turn dialogue. Using BERT, a pretraining language model, has been successful for single-turn machine comprehension, while modeling multiple turns of question answering with BERT has not been established because BERT has a limit on the number and the length of input sequences. In this paper, we propose a simple but effective method with BERT for CMC. Our method uses BERT to encode a paragraph independently conditioned with each question and each answer in a multi-turn context. Then, the method predicts an answer on the basis of the paragraph representations encoded with BERT. The experiments with representative CMC datasets, QuAC and CoQA, show that our method outperformed recently published methods (+0.8 F1 on QuAC and +2.1 F1 on CoQA). In addition, we conducted a detailed analysis of the effects of the number and types of dialogue history on the accuracy of CMC, and we found that the gold answer history, which may not be given in an actual conversation, contributed to the model performance most on both datasets.",
}
@inproceedings{dziri-etal-2019-augmenting,
    title = "Augmenting Neural Response Generation with Context-Aware Topical Attention",
    author = "Dziri, Nouha  and
      Kamalloo, Ehsan  and
      Mathewson, Kory  and
      Zaiane, Osmar",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4103",
    doi = "10.18653/v1/W19-4103",
    pages = "18--31",
    abstract = "Sequence-to-Sequence (Seq2Seq) models have witnessed a notable success in generating natural conversational exchanges. Notwithstanding the syntactically well-formed responses generated by these neural network models, they are prone to be acontextual, short and generic. In this work, we introduce a Topical Hierarchical Recurrent Encoder Decoder (THRED), a novel, fully data-driven, multi-turn response generation system intended to produce contextual and topic-aware responses. Our model is built upon the basic Seq2Seq model by augmenting it with a hierarchical joint attention mechanism that incorporates topical concepts and previous interactions into the response generation. To train our model, we provide a clean and high-quality conversational dataset mined from Reddit comments. We evaluate THRED on two novel automated metrics, dubbed Semantic Similarity and Response Echo Index, as well as with human evaluation. Our experiments demonstrate that the proposed model is able to generate more diverse and contextually relevant responses compared to the strong baselines.",
}
@inproceedings{swanson-etal-2019-building,
    title = "Building a Production Model for Retrieval-Based Chatbots",
    author = "Swanson, Kyle  and
      Yu, Lili  and
      Fox, Christopher  and
      Wohlwend, Jeremy  and
      Lei, Tao",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4104",
    doi = "10.18653/v1/W19-4104",
    pages = "32--41",
    abstract = "Response suggestion is an important task for building human-computer conversation systems. Recent approaches to conversation modeling have introduced new model architectures with impressive results, but relatively little attention has been paid to whether these models would be practical in a production setting. In this paper, we describe the unique challenges of building a production retrieval-based conversation system, which selects outputs from a whitelist of candidate responses. To address these challenges, we propose a dual encoder architecture which performs rapid inference and scales well with the size of the whitelist. We also introduce and compare two methods for generating whitelists, and we carry out a comprehensive analysis of the model and whitelists. Experimental results on a large, proprietary help desk chat dataset, including both offline metrics and a human evaluation, indicate production-quality performance and illustrate key lessons about conversation modeling in practice.",
}
@inproceedings{hamalainen-honkela-2019-co,
    title = "Co-Operation as an Asymmetric Form of Human-Computer Creativity. Case: Peace Machine",
    author = {H{\"a}m{\"a}l{\"a}inen, Mika  and
      Honkela, Timo},
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4105",
    doi = "10.18653/v1/W19-4105",
    pages = "42--50",
    abstract = "This theoretical paper identifies a need for a definition of asymmetric co-creativity where creativity is expected from the computational agent but not from the human user. Our co-operative creativity framework takes into account that the computational agent has a message to convey in a co-operative fashion, which introduces a trade-off on how creative the computer can be. The requirements of co-operation are identified from an interdisciplinary point of view. We divide co-operative creativity in message creativity, contextual creativity and communicative creativity. Finally these notions are applied in the context of the Peace Machine system concept.",
}
@inproceedings{tanaka-etal-2019-conversational,
    title = "Conversational Response Re-ranking Based on Event Causality and Role Factored Tensor Event Embedding",
    author = "Tanaka, Shohei  and
      Yoshino, Koichiro  and
      Sudoh, Katsuhito  and
      Nakamura, Satoshi",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4106",
    doi = "10.18653/v1/W19-4106",
    pages = "51--59",
    abstract = "We propose a novel method for selecting coherent and diverse responses for a given dialogue context. The proposed method re-ranks response candidates generated from conversational models by using event causality relations between events in a dialogue history and response candidates (e.g., {``}be stressed out{''} precedes {``}relieve stress{''}). We use distributed event representation based on the Role Factored Tensor Model for a robust matching of event causality relations due to limited event causality knowledge of the system. Experimental results showed that the proposed method improved coherency and dialogue continuity of system responses.",
}
@inproceedings{gunasekara-etal-2019-dstc7,
    title = "{DSTC}7 Task 1: Noetic End-to-End Response Selection",
    author = "Gunasekara, Chulaka  and
      Kummerfeld, Jonathan K.  and
      Polymenakos, Lazaros  and
      Lasecki, Walter",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4107",
    doi = "10.18653/v1/W19-4107",
    pages = "60--67",
    abstract = "Goal-oriented dialogue in complex domains is an extremely challenging problem and there are relatively few datasets. This task provided two new resources that presented different challenges: one was focused but small, while the other was large but diverse. We also considered several new variations on the next utterance selection problem: (1) increasing the number of candidates, (2) including paraphrases, and (3) not including a correct option in the candidate set. Twenty teams participated, developing a range of neural network models, including some that successfully incorporated external data to boost performance. Both datasets have been publicly released, enabling future work to build on these results, working towards robust goal-oriented dialogue systems.",
}
@inproceedings{yang-etal-2019-end,
    title = "End-to-End Neural Context Reconstruction in {C}hinese Dialogue",
    author = "Yang, Wei  and
      Qiao, Rui  and
      Qin, Haocheng  and
      Sun, Amy  and
      Tan, Luchen  and
      Xiong, Kun  and
      Li, Ming",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4108",
    doi = "10.18653/v1/W19-4108",
    pages = "68--76",
    abstract = "We tackle the problem of context reconstruction in Chinese dialogue, where the task is to replace pronouns, zero pronouns, and other referring expressions with their referent nouns so that sentences can be processed in isolation without context. Following a standard decomposition of the context reconstruction task into referring expression detection and coreference resolution, we propose a novel end-to-end architecture for separately and jointly accomplishing this task. Key features of this model include POS and position encoding using CNNs and a novel pronoun masking mechanism. One perennial problem in building such models is the paucity of training data, which we address by augmenting previously-proposed methods to generate a large amount of realistic training data. The combination of more data and better models yields accuracy higher than the state-of-the-art method in coreference resolution and end-to-end context reconstruction.",
}
@inproceedings{trinh-etal-2019-energy,
    title = "Energy-Based Modelling for Dialogue State Tracking",
    author = "Trinh, Anh Duong  and
      Ross, Robert  and
      Kelleher, John",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4109",
    doi = "10.18653/v1/W19-4109",
    pages = "77--86",
    abstract = "The uncertainties of language and the complexity of dialogue contexts make accurate dialogue state tracking one of the more challenging aspects of dialogue processing. To improve state tracking quality, we argue that relationships between different aspects of dialogue state must be taken into account as they can often guide a more accurate interpretation process. To this end, we present an energy-based approach to dialogue state tracking as a structured classification task. The novelty of our approach lies in the use of an energy network on top of a deep learning architecture to explore more signal correlations between network variables including input features and output labels. We demonstrate that the energy-based approach improves the performance of a deep learning dialogue state tracker towards state-of-the-art results without the need for many of the other steps required by current state-of-the-art methods.",
}
@inproceedings{kuksenok-martyniv-2019-evaluation,
    title = "Evaluation and Improvement of Chatbot Text Classification Data Quality Using Plausible Negative Examples",
    author = "Kuksenok, Kit  and
      Martyniv, Andriy",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4110",
    doi = "10.18653/v1/W19-4110",
    pages = "87--95",
    abstract = "We describe and validate a metric for estimating multi-class classifier performance based on cross-validation and adapted for improvement of small, unbalanced natural-language datasets used in chatbot design. Our experiences draw upon building recruitment chatbots that mediate communication between job-seekers and recruiters by exposing the ML/NLP dataset to the recruiting team. Evaluation approaches must be understandable to various stakeholders, and useful for improving chatbot performance. The metric, nex-cv, uses negative examples in the evaluation of text classification, and fulfils three requirements. First, it is actionable: it can be used by non-developer staff. Second, it is not overly optimistic compared to human ratings, making it a fast method for comparing classifiers. Third, it allows model-agnostic comparison, making it useful for comparing systems despite implementation differences. We validate the metric based on seven recruitment-domain datasets in English and German over the course of one year.",
}
@inproceedings{chen-etal-2019-improving,
    title = "Improving Long Distance Slot Carryover in Spoken Dialogue Systems",
    author = "Chen, Tongfei  and
      Naik, Chetan  and
      He, Hua  and
      Rastogi, Pushpendre  and
      Mathias, Lambert",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4111",
    doi = "10.18653/v1/W19-4111",
    pages = "96--105",
    abstract = "Tracking the state of the conversation is a central component in task-oriented spoken dialogue systems. One such approach for tracking the dialogue state is slot carryover, where a model makes a binary decision if a slot from the context is relevant to the current turn. Previous work on the slot carryover task used models that made independent decisions for each slot. A close analysis of the results show that this approach results in poor performance over longer context dialogues. In this paper, we propose to jointly model the slots. We propose two neural network architectures, one based on pointer networks that incorporate slot ordering information, and the other based on transformer networks that uses self attention mechanism to model the slot interdependencies. Our experiments on an internal dialogue benchmark dataset and on the public DSTC2 dataset demonstrate that our proposed models are able to resolve longer distance slot references and are able to achieve competitive performance.",
}
@inproceedings{gupta-etal-2019-insights,
    title = "Insights from Building an Open-Ended Conversational Agent",
    author = "Gupta, Khyatti  and
      Joshi, Meghana  and
      Chatterjee, Ankush  and
      Damani, Sonam  and
      Narahari, Kedhar Nath  and
      Agrawal, Puneet",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4112",
    doi = "10.18653/v1/W19-4112",
    pages = "106--112",
    abstract = "Dialogue systems and conversational agents are becoming increasingly popular in modern society. We conceptualized one such conversational agent, Microsoft{'}s {``}Ruuh{''} with the promise to be able to talk to its users on any subject they choose. Building an open-ended conversational agent like Ruuh at onset seems like a daunting task, since the agent needs to think beyond the utilitarian notion of merely generating {``}relevant{''} responses and meet a wider range of user social needs, like expressing happiness when user{'}s favourite sports team wins, sharing a cute comment on showing the pictures of the user{'}s pet and so on. The agent also needs to detect and respond to abusive language, sensitive topics and trolling behaviour of the users. Many of these problems pose significant research challenges as well as product design limitations as one needs to circumnavigate the technical limitations to create an acceptable user experience. However, as the product reaches the real users the true test begins, and one realizes the challenges and opportunities that lie in the vast domain of conversations. With over 2.5 million real-world users till date who have generated over 300 million user conversations with Ruuh, there is a plethora of learning, insights and opportunities that we will talk about in this paper.",
}
@inproceedings{nie-etal-2019-learning,
    title = "Learning to Explain: Answering Why-Questions via Rephrasing",
    author = "Nie, Allen  and
      Bennett, Erin  and
      Goodman, Noah",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4113",
    doi = "10.18653/v1/W19-4113",
    pages = "113--120",
    abstract = "Providing plausible responses to why questions is a challenging but critical goal for language based human-machine interaction. Explanations are challenging in that they require many different forms of abstract knowledge and reasoning. Previous work has either relied on human-curated structured knowledge bases or detailed domain representation to generate satisfactory explanations. They are also often limited to ranking pre-existing explanation choices. In our work, we contribute to the under-explored area of generating natural language explanations for general phenomena. We automatically collect large datasets of explanation-phenomenon pairs which allow us to train sequence-to-sequence models to generate natural language explanations. We compare different training strategies and evaluate their performance using both automatic scores and human ratings. We demonstrate that our strategy is sufficient to generate highly plausible explanations for general open-domain phenomena compared to other models trained on different datasets.",
}
@inproceedings{olabiyi-etal-2019-multi,
    title = "Multi-turn Dialogue Response Generation in an Adversarial Learning Framework",
    author = "Olabiyi, Oluwatobi  and
      Salimov, Alan O  and
      Khazane, Anish  and
      Mueller, Erik",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4114",
    doi = "10.18653/v1/W19-4114",
    pages = "121--132",
    abstract = "We propose an adversarial learning approach for generating multi-turn dialogue responses. Our proposed framework, hredGAN, is based on conditional generative adversarial networks (GANs). The GAN{'}s generator is a modified hierarchical recurrent encoder-decoder network (HRED) and the discriminator is a word-level bidirectional RNN that shares context and word embeddings with the generator. During inference, noise samples conditioned on the dialogue history are used to perturb the generator{'}s latent space to generate several possible responses. The final response is the one ranked best by the discriminator. The hredGAN shows improved performance over existing methods: (1) it generalizes better than networks trained using only the log-likelihood criterion, and (2) it generates longer, more informative and more diverse responses with high utterance and topic relevance even with limited training data. This performance improvement is demonstrated on the Movie triples and Ubuntu dialogue datasets with both the automatic and human evaluations.",
}
@inproceedings{takayama-arase-2019-relevant,
    title = "Relevant and Informative Response Generation using Pointwise Mutual Information",
    author = "Takayama, Junya  and
      Arase, Yuki",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4115",
    doi = "10.18653/v1/W19-4115",
    pages = "133--138",
    abstract = "A sequence-to-sequence model tends to generate generic responses with little information for input utterances. To solve this problem, we propose a neural model that generates relevant and informative responses. Our model has simple architecture to enable easy application to existing neural dialogue models. Specifically, using positive pointwise mutual information, it first identifies keywords that frequently co-occur in responses given an utterance. Then, the model encourages the decoder to use the keywords for response generation. Experiment results demonstrate that our model successfully diversifies responses relative to previous models.",
}
@inproceedings{chikai-etal-2019-responsive,
    title = "Responsive and Self-Expressive Dialogue Generation",
    author = "Chikai, Kozo  and
      Takayama, Junya  and
      Arase, Yuki",
    booktitle = "Proceedings of the First Workshop on NLP for Conversational AI",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-4116",
    doi = "10.18653/v1/W19-4116",
    pages = "139--149",
    abstract = "A neural conversation model is a promising approach to develop dialogue systems with the ability of chit-chat. It allows training a model in an end-to-end manner without complex rule design nor feature engineering. However, as a side effect, the neural model tends to generate safe but uninformative and insensitive responses like {``}OK{''} and {``}I don{'}t know.{''} Such replies are called generic responses and regarded as a critical problem for user-engagement of dialogue systems. For a more engaging chit-chat experience, we propose a neural conversation model that generates responsive and self-expressive replies. Specifically, our model generates domain-aware and sentiment-rich responses. Experiments empirically confirmed that our model outperformed the sequence-to-sequence model; 68.1{\%} of our responses were domain-aware with sentiment polarities, which was only 2.7{\%} for responses generated by the sequence-to-sequence model.",
}
