[{"id":"W17-1901","title":"Compositional Semantics using Feature-Based Models from {W}ord{N}et","authors":["Gamallo, Pablo","Pereira-Fari{\\~n}a, Mart{\\'\\i}n"],"emails":["pablo.gamallo@usc.es","m.z.pereirafarina@dundee.ac.uk"],"author_id":["pablo-gamallo","martin-pereira-farina"],"abstract":"This article describes a method to build semantic representations of composite expressions in a compositional way by using WordNet relations to represent the meaning of words. The meaning of a target word is modelled as a vector in which its semantically related words are assigned weights according to both the type of the relationship and the distance to the target word. Word vectors are compositionally combined by syntactic dependencies. Each syntactic dependency triggers two complementary compositional functions: the named head function and dependent function. The experiments show that the proposed compositional method outperforms the state-of-the-art for both intransitive subject-verb and transitive subject-verb-object constructions.","pages":"1--11","doi":"10.18653\/v1\/W17-1901","url":"https:\/\/www.aclweb.org\/anthology\/W17-1901","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1902","title":"Automated {W}ord{N}et Construction Using Word Embeddings","authors":["Khodak, Mikhail","Risteski, Andrej","Fellbaum, Christiane","Arora, Sanjeev"],"emails":["mkhodak@cs.princeton.edu","risteski@cs.princeton.edu","fellbaum@cs.princeton.edu","arora@cs.princeton.edu"],"author_id":["mikhail-khodak","andrej-risteski","christiane-fellbaum","sanjeev-arora"],"abstract":"We present a fully unsupervised method for automated construction of WordNets based upon recent advances in distributional representations of sentences and word-senses combined with readily available machine translation tools. The approach requires very few linguistic resources and is thus extensible to multiple target languages. To evaluate our method we construct two 600-word testsets for word-to-synset matching in French and Russian using native speakers and evaluate the performance of our method along with several other recent approaches. Our method exceeds the best language-specific and multi-lingual automated WordNets in F-score for both languages. The databases we construct for French and Russian, both languages without large publicly available manually constructed WordNets, will be publicly released along with the testsets.","pages":"12--23","doi":"10.18653\/v1\/W17-1902","url":"https:\/\/www.aclweb.org\/anthology\/W17-1902","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1903","title":"Improving Verb Metaphor Detection by Propagating Abstractness to Words, Phrases and Individual Senses","authors":["K{\\\"o}per, Maximilian","Schulte im Walde, Sabine"],"emails":["maximilian.koeper@ims.uni-stuttgart.de","schulte@ims.uni-stuttgart.de"],"author_id":["maximilian-koper","sabine-schulte-im-walde"],"abstract":"Abstract words refer to things that can not be seen, heard, felt, smelled, or tasted as opposed to concrete words. Among other applications, the degree of abstractness has been shown to be a useful information for metaphor detection. Our contribution to this topic are as follows: i) we compare supervised techniques to learn and extend abstractness ratings for huge vocabularies ii) we learn and investigate norms for larger units by propagating abstractness to verb-noun pairs which lead to better metaphor detection iii) we overcome the limitation of learning a single rating per word and show that multi-sense abstractness ratings are potentially useful for metaphor detection. Finally, with this paper we publish automatically created abstractness norms for 3million English words and multi-words as well as automatically created sense specific abstractness ratings","pages":"24--30","doi":"10.18653\/v1\/W17-1903","url":"https:\/\/www.aclweb.org\/anthology\/W17-1903","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1904","title":"Improving Clinical Diagnosis Inference through Integration of Structured and Unstructured Knowledge","authors":["Ling, Yuan","An, Yuan","Hasan, Sadid"],"emails":["yl638@drexel.edu","ya45@drexel.edu","sadid.hasan@philips.com"],"author_id":["yuan-ling","yuan-an","sadid-a-hasan"],"abstract":"This paper presents a novel approach to the task of automatically inferring the most probable diagnosis from a given clinical narrative. Structured Knowledge Bases (KBs) can be useful for such complex tasks but not sufficient. Hence, we leverage a vast amount of unstructured free text to integrate with structured KBs. The key innovative ideas include building a concept graph from both structured and unstructured knowledge sources and ranking the diagnosis concepts using the enhanced word embedding vectors learned from integrated sources. Experiments on the TREC CDS and HumanDx datasets showed that our methods improved the results of clinical diagnosis inference.","pages":"31--36","doi":"10.18653\/v1\/W17-1904","url":"https:\/\/www.aclweb.org\/anthology\/W17-1904","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1905","title":"Classifying Lexical-semantic Relationships by Exploiting Sense\/Concept Representations","authors":["Kanada, Kentaro","Kobayashi, Tetsunori","Hayashi, Yoshihiko"],"emails":["kanada@pcl.cs.waseda.ac.jp","koba@waseda.jp","yshk.hayashi@aoni.waseda.jp"],"author_id":["kentaro-kanada","tetsunori-kobayashi","yoshihiko-hayashi"],"abstract":"This paper proposes a method for classifying the type of lexical-semantic relation between a given pair of words. Given an inventory of target relationships, this task can be seen as a multi-class classification problem. We train a supervised classifier by assuming: (1) a specific type of lexical-semantic relation between a pair of words would be indicated by a carefully designed set of relation-specific similarities associated with the words; and (2) the similarities could be effectively computed by {``}sense representations{''} (sense\/concept embeddings). The experimental results show that the proposed method clearly outperforms an existing state-of-the-art method that does not utilize sense\/concept embeddings, thereby demonstrating the effectiveness of the sense representations.","pages":"37--46","doi":"10.18653\/v1\/W17-1905","url":"https:\/\/www.aclweb.org\/anthology\/W17-1905","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1906","title":"Supervised and unsupervised approaches to measuring usage similarity","authors":["King, Milton","Cook, Paul"],"emails":["milton.king@unb.ca","paul.cook@unb.ca"],"author_id":["milton-king","paul-cook"],"abstract":"Usage similarity (USim) is an approach to determining word meaning in context that does not rely on a sense inventory. Instead, pairs of usages of a target lemma are rated on a scale. In this paper we propose unsupervised approaches to USim based on embeddings for words, contexts, and sentences, and achieve state-of-the-art results over two USim datasets. We further consider supervised approaches to USim, and find that although they outperform unsupervised approaches, they are unable to generalize to lemmas that are unseen in the training data.","pages":"47--52","doi":"10.18653\/v1\/W17-1906","url":"https:\/\/www.aclweb.org\/anthology\/W17-1906","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1907","title":"Lexical Disambiguation of {I}gbo using Diacritic Restoration","authors":["Ezeani, Ignatius","Hepple, Mark","Onyenwe, Ikechukwu"],"emails":["ignatius.ezeani@sheffield.ac.uk","m.r.hepple@sheffield.ac.uk","i.onyenwe@sheffield.ac.uk"],"author_id":["ignatius-ezeani","mark-hepple","ikechukwu-onyenwe"],"abstract":"Properly written texts in Igbo, a low-resource African language, are rich in both orthographic and tonal diacritics. Diacritics are essential in capturing the distinctions in pronunciation and meaning of words, as well as in lexical disambiguation. Unfortunately, most electronic texts in diacritic languages are written without diacritics. This makes diacritic restoration a necessary step in corpus building and language processing tasks for languages with diacritics. In our previous work, we built some n-gram models with simple smoothing techniques based on a closed-world assumption. However, as a classification task, diacritic restoration is well suited for and will be more generalisable with machine learning. This paper, therefore, presents a more standard approach to dealing with the task which involves the application of machine learning algorithms.","pages":"53--60","doi":"10.18653\/v1\/W17-1907","url":"https:\/\/www.aclweb.org\/anthology\/W17-1907","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1908","title":"Creating and Validating Multilingual Semantic Representations for Six Languages: Expert versus Non-Expert Crowds","authors":["El-Haj, Mahmoud","Rayson, Paul","Piao, Scott","Wattam, Stephen"],"emails":["initial.surname@lancaster.ac.uk","","",""],"author_id":["mahmoud-el-haj","paul-rayson","scott-s-l-piao","stephen-wattam"],"abstract":"Creating high-quality wide-coverage multilingual semantic lexicons to support knowledge-based approaches is a challenging time-consuming manual task. This has traditionally been performed by linguistic experts: a slow and expensive process. We present an experiment in which we adapt and evaluate crowdsourcing methods employing native speakers to generate a list of coarse-grained senses under a common multilingual semantic taxonomy for sets of words in six languages. 451 non-experts (including 427 Mechanical Turk workers) and 15 expert participants semantically annotated 250 words manually for Arabic, Chinese, English, Italian, Portuguese and Urdu lexicons. In order to avoid erroneous (spam) crowdsourced results, we used a novel task-specific two-phase filtering process where users were asked to identify synonyms in the target language, and remove erroneous senses.","pages":"61--71","doi":"10.18653\/v1\/W17-1908","url":"https:\/\/www.aclweb.org\/anthology\/W17-1908","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1909","title":"Using Linked Disambiguated Distributional Networks for Word Sense Disambiguation","authors":["Panchenko, Alexander","Faralli, Stefano","Ponzetto, Simone Paolo","Biemann, Chris"],"emails":["panchenko@informatik.uni-hamburg.de","faralli@informatik.uni-mannheim.de","simone@informatik.uni-mannheim.de","biemann@informatik.uni-hamburg.de"],"author_id":["alexander-panchenko","stefano-faralli","simone-paolo-ponzetto","chris-biemann"],"abstract":"We introduce a new method for unsupervised knowledge-based word sense disambiguation (WSD) based on a resource that links two types of sense-aware lexical networks: one is induced from a corpus using distributional semantics, the other is manually constructed. The combination of two networks reduces the sparsity of sense representations used for WSD. We evaluate these enriched representations within two lexical sample sense disambiguation benchmarks. Our results indicate that (1) features extracted from the corpus-based resource help to significantly outperform a model based solely on the lexical resource; (2) our method achieves results comparable or better to four state-of-the-art unsupervised knowledge-based WSD systems including three hybrid systems that also rely on text corpora. In contrast to these hybrid methods, our approach does not require access to web search engines, texts mapped to a sense inventory, or machine translation systems.","pages":"72--78","doi":"10.18653\/v1\/W17-1909","url":"https:\/\/www.aclweb.org\/anthology\/W17-1909","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1910","title":"One Representation per Word - Does it make Sense for Composition?","authors":["Kober, Thomas","Weeds, Julie","Wilkie, John","Reffin, Jeremy","Weir, David"],"emails":["t.kober@sussex.ac.uk","j.e.weeds@sussex.ac.uk","jw478@sussex.ac.uk","j.p.reffin@sussex.ac.uk","d.j.weir@sussex.ac.uk"],"author_id":["thomas-kober","julie-weeds","john-wilkie","jeremy-reffin","david-weir"],"abstract":"In this paper, we investigate whether an a priori disambiguation of word senses is strictly necessary or whether the meaning of a word in context can be disambiguated through composition alone. We evaluate the performance of off-the-shelf single-vector and multi-sense vector models on a benchmark phrase similarity task and a novel task for word-sense discrimination. We find that single-sense vector models perform as well or better than multi-sense vector models despite arguably less clean elementary representations. Our findings furthermore show that simple composition functions such as pointwise addition are able to recover sense specific information from a single-sense vector model remarkably well.","pages":"79--90","doi":"10.18653\/v1\/W17-1910","url":"https:\/\/www.aclweb.org\/anthology\/W17-1910","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1911","title":"Elucidating Conceptual Properties from Word Embeddings","authors":["Jang, Kyoung-Rok","Myaeng, Sung-Hyon"],"emails":["kyoungrok.jang@kaist.ac.kr","myaeng@kaist.ac.kr"],"author_id":["kyoung-rok-jang","sung-hyon-myaeng"],"abstract":"In this paper, we introduce a method of identifying the components (i.e. dimensions) of word embeddings that strongly signifies properties of a word. By elucidating such properties hidden in word embeddings, we could make word embeddings more interpretable, and also could perform property-based meaning comparison. With the capability, we can answer questions like {``}To what degree a given word has the property cuteness?{''} or {``}In what perspective two words are similar?{''}. We verify our method by examining how the strength of property-signifying components correlates with the degree of prototypicality of a target word.","pages":"91--95","doi":"10.18653\/v1\/W17-1911","url":"https:\/\/www.aclweb.org\/anthology\/W17-1911","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1912","title":"TTCS$^{\\mathcal{E}}$: a Vectorial Resource for Computing Conceptual Similarity","authors":["Mensa, Enrico","Radicioni, Daniele P.","Lieto, Antonio"],"emails":["mensa@di.unito.it","radicion@di.unito.it","lieto@di.unito.it"],"author_id":["enrico-mensa","daniele-p-radicioni","antonio-lieto"],"abstract":"In this paper we introduce the TTCS$^{\\mathcal{E}}$, a linguistic resource that relies on BabelNet, NASARI and ConceptNet, that has now been used to compute the conceptual similarity between concept pairs. The conceptual representation herein provides uniform access to concepts based on BabelNet synset IDs, and consists of a vector-based semantic representation which is compliant with the Conceptual Spaces, a geometric framework for common-sense knowledge representation and reasoning. The TTCS$^{\\mathcal{E}}$ has been evaluated in a preliminary experimentation on a conceptual similarity task.","pages":"96--101","doi":"10.18653\/v1\/W17-1912","url":"https:\/\/www.aclweb.org\/anthology\/W17-1912","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1913","title":"Measuring the {I}talian-{E}nglish lexical gap for action verbs and its impact on translation","authors":["Gregori, Lorenzo","Panunzi, Alessandro"],"emails":["lorenzo.gregori@unifi.it","alessandro.panunzi@unifi.it"],"author_id":["lorenzo-gregori","alessandro-panunzi"],"abstract":"This paper describes a method to measure the lexical gap of action verbs in Italian and English by using the IMAGACT ontology of action. The fine-grained categorization of action concepts of the data source allowed to have wide overview of the relation between concepts in the two languages. The calculated lexical gap for both English and Italian is about 30{\\%} of the action concepts, much higher than previous results. Beyond this general numbers a deeper analysis has been performed in order to evaluate the impact that lexical gaps can have on translation. In particular a distinction has been made between the cases in which the presence of a lexical gap affects translation correctness and completeness at a semantic level. The results highlight a high percentage of concepts that can be considered hard to translate (about 18{\\%} from English to Italian and 20{\\%} from Italian to English) and confirms that action verbs are a critical lexical class for translation tasks.","pages":"102--109","doi":"10.18653\/v1\/W17-1913","url":"https:\/\/www.aclweb.org\/anthology\/W17-1913","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1914","title":"Word Sense Filtering Improves Embedding-Based Lexical Substitution","authors":["Cocos, Anne","Apidianaki, Marianna","Callison-Burch, Chris"],"emails":["acocos@seas.upenn.edu","marapi@seas.upenn.edu","ccb@seas.upenn.edu"],"author_id":["anne-cocos","marianna-apidianaki","chris-callison-burch"],"abstract":"The role of word sense disambiguation in lexical substitution has been questioned due to the high performance of vector space models which propose good substitutes without explicitly accounting for sense. We show that a filtering mechanism based on a sense inventory optimized for substitutability can improve the results of these models. Our sense inventory is constructed using a clustering method which generates paraphrase clusters that are congruent with lexical substitution annotations in a development set. The results show that lexical substitution can still benefit from senses which can improve the output of vector space paraphrase ranking models.","pages":"110--119","doi":"10.18653\/v1\/W17-1914","url":"https:\/\/www.aclweb.org\/anthology\/W17-1914","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"},{"id":"W17-1915","title":"Supervised and Unsupervised Word Sense Disambiguation on Word Embedding Vectors of Unambigous Synonyms","authors":["Wawer, Aleksander","Mykowiecka, Agnieszka"],"emails":["axw@ipipan.waw.pl","agn@ipipan.waw.pl"],"author_id":["aleksander-wawer","agnieszka-mykowiecka"],"abstract":"This paper compares two approaches to word sense disambiguation using word embeddings trained on unambiguous synonyms. The first is unsupervised method based on computing log probability from sequences of word embedding vectors, taking into account ambiguous word senses and guessing correct sense from context. The second method is supervised. We use a multilayer neural network model to learn a context-sensitive transformation that maps an input vector of ambiguous word into an output vector representing its sense. We evaluate both methods on corpora with manual annotations of word senses from the Polish wordnet (plWordnet).","pages":"120--125","doi":"10.18653\/v1\/W17-1915","url":"https:\/\/www.aclweb.org\/anthology\/W17-1915","publisher":"Association for Computational Linguistics","address":"Valencia, Spain","year":"2017","month":"April","booktitle":"Proceedings of the 1st Workshop on Sense, Concept and Entity Representations and their Applications"}]