@proceedings{ws-2017-linguistic,
    title = "Proceedings of the 11th Linguistic Annotation Workshop",
    author = "Schneider, Nathan  and
      Xue, Nianwen",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0800",
    doi = "10.18653/v1/W17-08",
}
@inproceedings{buechel-hahn-2017-readers,
    title = "Readers vs. Writers vs. Texts: Coping with Different Perspectives of Text Understanding in Emotion Annotation",
    author = "Buechel, Sven  and
      Hahn, Udo",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0801",
    doi = "10.18653/v1/W17-0801",
    pages = "1--12",
    abstract = "We here examine how different perspectives of understanding written discourse, like the reader{'}s, the writer{'}s or the text{'}s point of view, affect the quality of emotion annotations. We conducted a series of annotation experiments on two corpora, a popular movie review corpus and a genre- and domain-balanced corpus of standard English. We found statistical evidence that the writer{'}s perspective yields superior annotation quality overall. However, the quality one perspective yields compared to the other(s) seems to depend on the domain the utterance originates from. Our data further suggest that the popular movie review data set suffers from an atypical bimodal distribution which may decrease model performance when used as a training resource.",
}
@inproceedings{napoles-etal-2017-finding,
    title = "Finding Good Conversations Online: The Yahoo News Annotated Comments Corpus",
    author = "Napoles, Courtney  and
      Tetreault, Joel  and
      Pappu, Aasish  and
      Rosato, Enrica  and
      Provenzale, Brian",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0802",
    doi = "10.18653/v1/W17-0802",
    pages = "13--23",
    abstract = "This work presents a dataset and annotation scheme for the new task of identifying {``}good{''} conversations that occur online, which we call ERICs: Engaging, Respectful, and/or Informative Conversations. We develop a taxonomy to reflect features of entire threads and individual comments which we believe contribute to identifying ERICs; code a novel dataset of Yahoo News comment threads (2.4k threads and 10k comments) and 1k threads from the Internet Argument Corpus; and analyze the features characteristic of ERICs. This is one of the largest annotated corpora of online human dialogues, with the most detailed set of annotations. It will be valuable for identifying ERICs and other aspects of argumentation, dialogue, and discourse.",
}
@inproceedings{scholman-demberg-2017-crowdsourcing,
    title = "Crowdsourcing discourse interpretations: On the influence of context and the reliability of a connective insertion task",
    author = "Scholman, Merel  and
      Demberg, Vera",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0803",
    doi = "10.18653/v1/W17-0803",
    pages = "24--33",
    abstract = "Traditional discourse annotation tasks are considered costly and time-consuming, and the reliability and validity of these tasks is in question. In this paper, we investigate whether crowdsourcing can be used to obtain reliable discourse relation annotations. We also examine the influence of context on the reliability of the data. The results of a crowdsourced connective insertion task showed that the method can be used to obtain reliable annotations: The majority of the inserted connectives converged with the original label. Further, the method is sensitive to the fact that multiple senses can often be inferred for a single relation. Regarding the presence of context, the results show no significant difference in distributions of insertions between conditions overall. However, a by-item comparison revealed several characteristics of segments that determine whether the presence of context makes a difference in annotations. The findings discussed in this paper can be taken as evidence that crowdsourcing can be used as a valuable method to obtain insights into the sense(s) of relations.",
}
@inproceedings{cetinoglu-2017-code,
    title = "A Code-Switching Corpus of {T}urkish-{G}erman Conversations",
    author = {{\c{C}}etino{\u{g}}lu, {\"O}zlem},
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0804",
    doi = "10.18653/v1/W17-0804",
    pages = "34--40",
    abstract = "We present a code-switching corpus of Turkish-German that is collected by recording conversations of bilinguals. The recordings are then transcribed in two layers following speech and orthography conventions, and annotated with sentence boundaries and intersentential, intrasentential, and intra-word switch points. The total amount of data is 5 hours of speech which corresponds to 3614 sentences. The corpus aims at serving as a resource for speech or text analysis, as well as a collection for linguistic inquiries.",
}
@inproceedings{martinez-alonso-etal-2017-annotating,
    title = "Annotating omission in statement pairs",
    author = "Mart{\'\i}nez Alonso, H{\'e}ctor  and
      Delamaire, Amaury  and
      Sagot, Beno{\^\i}t",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0805",
    doi = "10.18653/v1/W17-0805",
    pages = "41--45",
    abstract = "We focus on the identification of omission in statement pairs. We compare three annotation schemes, namely two different crowdsourcing schemes and manual expert annotation. We show that the simplest of the two crowdsourcing approaches yields a better annotation quality than the more complex one. We use a dedicated classifier to assess whether the annotators{'} behavior can be explained by straightforward linguistic features. The classifier benefits from a modeling that uses lexical information beyond length and overlap measures. However, for our task, we argue that expert and not crowdsourcing-based annotation is the best compromise between annotation cost and quality.",
}
@inproceedings{bary-etal-2017-annotating,
    title = "Annotating Speech, Attitude and Perception Reports",
    author = "Bary, Corien  and
      Hess, Leopold  and
      Thijs, Kees  and
      Berck, Peter  and
      Hendrickx, Iris",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0806",
    doi = "10.18653/v1/W17-0806",
    pages = "46--56",
    abstract = "We present REPORTS, an annotation scheme for the annotation of speech, attitude and perception reports. Such a scheme makes it possible to annotate the various text elements involved in such reports (e.g. embedding entity, complement, complement head) and their relations in a uniform way, which in turn facilitates the automatic extraction of information on, for example, complementation and vocabulary distribution. We also present the Ancient Greek corpus RAG (Thucydides{'} History of the Peloponnesian War), to which we have applied this scheme using the annotation tool BRAT. We discuss some of the issues, both theoretical and practical, that we encountered, show how the corpus helps in answering specific questions, and conclude that REPORTS fitted in well with our needs.",
}
@inproceedings{fujita-etal-2017-consistent,
    title = "Consistent Classification of Translation Revisions: A Case Study of {E}nglish-{J}apanese Student Translations",
    author = "Fujita, Atsushi  and
      Tanabe, Kikuko  and
      Toyoshima, Chiho  and
      Yamamoto, Mayuka  and
      Kageura, Kyo  and
      Hartley, Anthony",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0807",
    doi = "10.18653/v1/W17-0807",
    pages = "57--66",
    abstract = "Consistency is a crucial requirement in text annotation. It is especially important in educational applications, as lack of consistency directly affects learners{'} motivation and learning performance. This paper presents a quality assessment scheme for English-to-Japanese translations produced by learner translators at university. We constructed a revision typology and a decision tree manually through an application of the OntoNotes method, i.e., an iteration of assessing learners{'} translations and hypothesizing the conditions for consistent decision making, as well as re-organizing the typology. Intrinsic evaluation of the created scheme confirmed its potential contribution to the consistent classification of identified erroneous text spans, achieving visibly higher Cohen{'}s kappa values, up to 0.831, than previous work. This paper also describes an application of our scheme to an English-to-Japanese translation exercise course for undergraduate students at a university in Japan.",
}
@inproceedings{eckart-de-castilho-etal-2017-representation,
    title = "Representation and Interchange of Linguistic Annotation. An In-Depth, Side-by-Side Comparison of Three Designs",
    author = "Eckart de Castilho, Richard  and
      Ide, Nancy  and
      Lapponi, Emanuele  and
      Oepen, Stephan  and
      Suderman, Keith  and
      Velldal, Erik  and
      Verhagen, Marc",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0808",
    doi = "10.18653/v1/W17-0808",
    pages = "67--75",
    abstract = "For decades, most self-respecting linguistic engineering initiatives have designed and implemented custom representations for various layers of, for example, morphological, syntactic, and semantic analysis. Despite occasional efforts at harmonization or even standardization, our field today is blessed with a multitude of ways of encoding and exchanging linguistic annotations of these types, both at the levels of {`}abstract syntax{'}, naming choices, and of course file formats. To a large degree, it is possible to work within and across design plurality by conversion, and often there may be good reasons for divergent design reflecting differences in use. However, it is likely that some abstract commonalities across choices of representation are obscured by more superficial differences, and conversely there is no obvious procedure to tease apart what actually constitute contentful vs. mere technical divergences. In this study, we seek to conceptually align three representations for common types of morpho-syntactic analysis, pinpoint what in our view constitute contentful differences, and reflect on the underlying principles and specific requirements that led to individual choices. We expect that a more in-depth understanding of these choices across designs may led to increased harmonization, or at least to more informed design of future representations.",
}
@inproceedings{zeyrek-kurfali-2017-tdb,
    title = "{TDB} 1.1: Extensions on {T}urkish Discourse Bank",
    author = "Zeyrek, Deniz  and
      Kurfal{\i}, Murathan",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0809",
    doi = "10.18653/v1/W17-0809",
    pages = "76--81",
    abstract = "This paper presents the recent developments on Turkish Discourse Bank (TDB). First, the resource is summarized and an evaluation is presented. Then, TDB 1.1, i.e. enrichments on 10{\%} of the corpus are described (namely, senses for explicit discourse connectives, and new annotations for three discourse relation types - implicit relations, entity relations and alternative lexicalizations). The method of annotation is explained and the data are evaluated.",
}
@inproceedings{di-buono-etal-2017-two,
    title = "Two Layers of Annotation for Representing Event Mentions in News Stories",
    author = "di Buono, Maria Pia  and
      Tutek, Martin  and
      {\v{S}}najder, Jan  and
      Glava{\v{s}}, Goran  and
      Dalbelo Ba{\v{s}}i{\'c}, Bojana  and
      Mili{\'c}-Frayling, Nata{\v{s}}a",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0810",
    doi = "10.18653/v1/W17-0810",
    pages = "82--90",
    abstract = "In this paper, we describe our preliminary study on annotating event mention as a part of our research on high-precision news event extraction models. To this end, we propose a two-layer annotation scheme, designed to separately capture the functional and conceptual aspects of event mentions. We hypothesize that the precision of models can be improved by modeling and extracting separately the different aspects of news events, and then combining the extracted information by leveraging the complementarities of the models. In addition, we carry out a preliminary annotation using the proposed scheme and analyze the annotation quality in terms of inter-annotator agreement.",
}
@inproceedings{akhtar-etal-2017-word,
    title = "Word Similarity Datasets for {I}ndian Languages: Annotation and Baseline Systems",
    author = "Akhtar, Syed Sarfaraz  and
      Gupta, Arihant  and
      Vajpayee, Avijit  and
      Srivastava, Arjit  and
      Shrivastava, Manish",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0811",
    doi = "10.18653/v1/W17-0811",
    pages = "91--94",
    abstract = "With the advent of word representations, word similarity tasks are becoming increasing popular as an evaluation metric for the quality of the representations. In this paper, we present manually annotated monolingual word similarity datasets of six Indian languages - Urdu, Telugu, Marathi, Punjabi, Tamil and Gujarati. These languages are most spoken Indian languages worldwide after Hindi and Bengali. For the construction of these datasets, our approach relies on translation and re-annotation of word similarity datasets of English. We also present baseline scores for word representation models using state-of-the-art techniques for Urdu, Telugu and Marathi by evaluating them on newly created word similarity datasets.",
}
@inproceedings{dunietz-etal-2017-corpus,
    title = "The {BEC}au{SE} Corpus 2.0: Annotating Causality and Overlapping Relations",
    author = "Dunietz, Jesse  and
      Levin, Lori  and
      Carbonell, Jaime",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0812",
    doi = "10.18653/v1/W17-0812",
    pages = "95--104",
    abstract = "Language of cause and effect captures an essential component of the semantics of a text. However, causal language is also intertwined with other semantic relations, such as temporal precedence and correlation. This makes it difficult to determine when causation is the primary intended meaning. This paper presents BECauSE 2.0, a new version of the BECauSE corpus with exhaustively annotated expressions of causal language, but also seven semantic relations that are frequently co-present with causation. The new corpus shows high inter-annotator agreement, and yields insights both about the linguistic expressions of causation and about the process of annotating co-present semantic relations.",
}
@inproceedings{rehbein-ruppenhofer-2017-catching,
    title = "Catching the Common Cause: Extraction and Annotation of Causal Relations and their Participants",
    author = "Rehbein, Ines  and
      Ruppenhofer, Josef",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0813",
    doi = "10.18653/v1/W17-0813",
    pages = "105--114",
    abstract = "In this paper, we present a simple, yet effective method for the automatic identification and extraction of causal relations from text, based on a large English-German parallel corpus. The goal of this effort is to create a lexical resource for German causal relations. The resource will consist of a lexicon that describes constructions that trigger causality as well as the participants of the causal event, and will be augmented by a corpus with annotated instances for each entry, that can be used as training data to develop a system for automatic classification of causal relations. Focusing on verbs, our method harvested a set of 100 different lexical triggers of causality, including support verb constructions. At the moment, our corpus includes over 1,000 annotated instances. The lexicon and the annotated data will be made available to the research community.",
}
@inproceedings{hartmann-etal-2017-assessing,
    title = "Assessing {SRL} Frameworks with Automatic Training Data Expansion",
    author = "Hartmann, Silvana  and
      M{\'u}jdricza-Maydt, {\'E}va  and
      Kuznetsov, Ilia  and
      Gurevych, Iryna  and
      Frank, Anette",
    booktitle = "Proceedings of the 11th Linguistic Annotation Workshop",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W17-0814",
    doi = "10.18653/v1/W17-0814",
    pages = "115--121",
    abstract = "We present the first experiment-based study that explicitly contrasts the three major semantic role labeling frameworks. As a prerequisite, we create a dataset labeled with parallel FrameNet-, PropBank-, and VerbNet-style labels for German. We train a state-of-the-art SRL tool for German for the different annotation styles and provide a comparative analysis across frameworks. We further explore the behavior of the frameworks with automatic training data generation. VerbNet provides larger semantic expressivity than PropBank, and we find that its generalization capacity approaches PropBank in SRL training, but it benefits less from training data expansion than the sparse-data affected FrameNet.",
}
